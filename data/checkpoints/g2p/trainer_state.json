{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.3056,
  "eval_steps": 500,
  "global_step": 95500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 6.4e-05,
      "grad_norm": 19.984381915653476,
      "learning_rate": 9.999999988770584e-05,
      "loss": 11.2743,
      "step": 20
    },
    {
      "epoch": 0.000128,
      "grad_norm": 5.487518887641428,
      "learning_rate": 9.999999955082334e-05,
      "loss": 3.8589,
      "step": 40
    },
    {
      "epoch": 0.000192,
      "grad_norm": 4.286714311160932,
      "learning_rate": 9.999999898935252e-05,
      "loss": 3.356,
      "step": 60
    },
    {
      "epoch": 0.000256,
      "grad_norm": 3.3802473703861526,
      "learning_rate": 9.999999820329337e-05,
      "loss": 3.1579,
      "step": 80
    },
    {
      "epoch": 0.00032,
      "grad_norm": 5.4682032716968445,
      "learning_rate": 9.999999719264588e-05,
      "loss": 2.9438,
      "step": 100
    },
    {
      "epoch": 0.000384,
      "grad_norm": 4.188895453976329,
      "learning_rate": 9.999999595741009e-05,
      "loss": 2.5031,
      "step": 120
    },
    {
      "epoch": 0.000448,
      "grad_norm": 5.127885297805202,
      "learning_rate": 9.9999994497586e-05,
      "loss": 1.9916,
      "step": 140
    },
    {
      "epoch": 0.000512,
      "grad_norm": 8.299321191456816,
      "learning_rate": 9.999999281317358e-05,
      "loss": 1.7096,
      "step": 160
    },
    {
      "epoch": 0.000576,
      "grad_norm": 9.847377491500083,
      "learning_rate": 9.999999090417287e-05,
      "loss": 1.1331,
      "step": 180
    },
    {
      "epoch": 0.00064,
      "grad_norm": 2.9451663138487314,
      "learning_rate": 9.999998877058386e-05,
      "loss": 0.5498,
      "step": 200
    },
    {
      "epoch": 0.000704,
      "grad_norm": 2.6375340984228384,
      "learning_rate": 9.999998641240658e-05,
      "loss": 0.3297,
      "step": 220
    },
    {
      "epoch": 0.000768,
      "grad_norm": 2.1657603462311803,
      "learning_rate": 9.999998382964102e-05,
      "loss": 0.2479,
      "step": 240
    },
    {
      "epoch": 0.000832,
      "grad_norm": 1.6084174334554693,
      "learning_rate": 9.999998102228721e-05,
      "loss": 0.1949,
      "step": 260
    },
    {
      "epoch": 0.000896,
      "grad_norm": 1.3618933389068795,
      "learning_rate": 9.999997799034515e-05,
      "loss": 0.1743,
      "step": 280
    },
    {
      "epoch": 0.00096,
      "grad_norm": 1.4689364448955022,
      "learning_rate": 9.999997473381486e-05,
      "loss": 0.1629,
      "step": 300
    },
    {
      "epoch": 0.001024,
      "grad_norm": 1.0551072709393718,
      "learning_rate": 9.999997125269635e-05,
      "loss": 0.1512,
      "step": 320
    },
    {
      "epoch": 0.001088,
      "grad_norm": 1.303626280533112,
      "learning_rate": 9.999996754698965e-05,
      "loss": 0.1312,
      "step": 340
    },
    {
      "epoch": 0.001152,
      "grad_norm": 0.9015109235230854,
      "learning_rate": 9.999996361669474e-05,
      "loss": 0.1236,
      "step": 360
    },
    {
      "epoch": 0.001216,
      "grad_norm": 0.795632156046167,
      "learning_rate": 9.999995946181169e-05,
      "loss": 0.1114,
      "step": 380
    },
    {
      "epoch": 0.00128,
      "grad_norm": 0.8853577606070548,
      "learning_rate": 9.999995508234047e-05,
      "loss": 0.1105,
      "step": 400
    },
    {
      "epoch": 0.001344,
      "grad_norm": 0.7217127786071534,
      "learning_rate": 9.999995047828114e-05,
      "loss": 0.0972,
      "step": 420
    },
    {
      "epoch": 0.001408,
      "grad_norm": 0.7517999410008976,
      "learning_rate": 9.999994564963369e-05,
      "loss": 0.0997,
      "step": 440
    },
    {
      "epoch": 0.001472,
      "grad_norm": 0.8263726057198254,
      "learning_rate": 9.999994059639815e-05,
      "loss": 0.0942,
      "step": 460
    },
    {
      "epoch": 0.001536,
      "grad_norm": 0.8537447532924352,
      "learning_rate": 9.999993531857455e-05,
      "loss": 0.0849,
      "step": 480
    },
    {
      "epoch": 0.0016,
      "grad_norm": 0.7338816974677734,
      "learning_rate": 9.999992981616291e-05,
      "loss": 0.0811,
      "step": 500
    },
    {
      "epoch": 0.001664,
      "grad_norm": 0.5769006241899075,
      "learning_rate": 9.999992408916325e-05,
      "loss": 0.0832,
      "step": 520
    },
    {
      "epoch": 0.001728,
      "grad_norm": 0.5731625699804362,
      "learning_rate": 9.99999181375756e-05,
      "loss": 0.0822,
      "step": 540
    },
    {
      "epoch": 0.001792,
      "grad_norm": 1.4189600258630701,
      "learning_rate": 9.99999119614e-05,
      "loss": 0.0842,
      "step": 560
    },
    {
      "epoch": 0.001856,
      "grad_norm": 0.6998019471575104,
      "learning_rate": 9.999990556063644e-05,
      "loss": 0.0753,
      "step": 580
    },
    {
      "epoch": 0.00192,
      "grad_norm": 0.6720273927543539,
      "learning_rate": 9.999989893528499e-05,
      "loss": 0.07,
      "step": 600
    },
    {
      "epoch": 0.001984,
      "grad_norm": 0.7288495014910453,
      "learning_rate": 9.999989208534566e-05,
      "loss": 0.0674,
      "step": 620
    },
    {
      "epoch": 0.002048,
      "grad_norm": 0.4649112257401437,
      "learning_rate": 9.999988501081847e-05,
      "loss": 0.0677,
      "step": 640
    },
    {
      "epoch": 0.002112,
      "grad_norm": 0.46932076212536666,
      "learning_rate": 9.999987771170348e-05,
      "loss": 0.0697,
      "step": 660
    },
    {
      "epoch": 0.002176,
      "grad_norm": 0.48148538827058973,
      "learning_rate": 9.999987018800069e-05,
      "loss": 0.0606,
      "step": 680
    },
    {
      "epoch": 0.00224,
      "grad_norm": 0.4858179133601085,
      "learning_rate": 9.999986243971019e-05,
      "loss": 0.0725,
      "step": 700
    },
    {
      "epoch": 0.002304,
      "grad_norm": 0.38680134681776157,
      "learning_rate": 9.999985446683196e-05,
      "loss": 0.0681,
      "step": 720
    },
    {
      "epoch": 0.002368,
      "grad_norm": 0.416560992524678,
      "learning_rate": 9.999984626936603e-05,
      "loss": 0.0586,
      "step": 740
    },
    {
      "epoch": 0.002432,
      "grad_norm": 0.524010587110687,
      "learning_rate": 9.999983784731249e-05,
      "loss": 0.0689,
      "step": 760
    },
    {
      "epoch": 0.002496,
      "grad_norm": 0.4556443223311926,
      "learning_rate": 9.999982920067132e-05,
      "loss": 0.0625,
      "step": 780
    },
    {
      "epoch": 0.00256,
      "grad_norm": 0.364406963490877,
      "learning_rate": 9.99998203294426e-05,
      "loss": 0.0672,
      "step": 800
    },
    {
      "epoch": 0.002624,
      "grad_norm": 0.553135092718259,
      "learning_rate": 9.999981123362637e-05,
      "loss": 0.0624,
      "step": 820
    },
    {
      "epoch": 0.002688,
      "grad_norm": 0.42640017810938874,
      "learning_rate": 9.999980191322262e-05,
      "loss": 0.0608,
      "step": 840
    },
    {
      "epoch": 0.002752,
      "grad_norm": 0.5632745358471698,
      "learning_rate": 9.999979236823146e-05,
      "loss": 0.0583,
      "step": 860
    },
    {
      "epoch": 0.002816,
      "grad_norm": 0.4202387900044088,
      "learning_rate": 9.999978259865289e-05,
      "loss": 0.0615,
      "step": 880
    },
    {
      "epoch": 0.00288,
      "grad_norm": 0.4700746106046101,
      "learning_rate": 9.999977260448697e-05,
      "loss": 0.062,
      "step": 900
    },
    {
      "epoch": 0.002944,
      "grad_norm": 0.4710498557018385,
      "learning_rate": 9.999976238573373e-05,
      "loss": 0.0572,
      "step": 920
    },
    {
      "epoch": 0.003008,
      "grad_norm": 0.45091889977134386,
      "learning_rate": 9.999975194239324e-05,
      "loss": 0.0614,
      "step": 940
    },
    {
      "epoch": 0.003072,
      "grad_norm": 0.36502040200710034,
      "learning_rate": 9.999974127446552e-05,
      "loss": 0.0583,
      "step": 960
    },
    {
      "epoch": 0.003136,
      "grad_norm": 0.4407353477570368,
      "learning_rate": 9.999973038195064e-05,
      "loss": 0.0656,
      "step": 980
    },
    {
      "epoch": 0.0032,
      "grad_norm": 0.42026896152067805,
      "learning_rate": 9.999971926484864e-05,
      "loss": 0.0577,
      "step": 1000
    },
    {
      "epoch": 0.003264,
      "grad_norm": 0.3680496837271321,
      "learning_rate": 9.999970792315956e-05,
      "loss": 0.0603,
      "step": 1020
    },
    {
      "epoch": 0.003328,
      "grad_norm": 0.5256310833583023,
      "learning_rate": 9.999969635688347e-05,
      "loss": 0.0578,
      "step": 1040
    },
    {
      "epoch": 0.003392,
      "grad_norm": 0.4010549915932494,
      "learning_rate": 9.999968456602041e-05,
      "loss": 0.0535,
      "step": 1060
    },
    {
      "epoch": 0.003456,
      "grad_norm": 0.3569301669948006,
      "learning_rate": 9.999967255057043e-05,
      "loss": 0.0544,
      "step": 1080
    },
    {
      "epoch": 0.00352,
      "grad_norm": 0.4085529298881325,
      "learning_rate": 9.99996603105336e-05,
      "loss": 0.0593,
      "step": 1100
    },
    {
      "epoch": 0.003584,
      "grad_norm": 0.5275335628342391,
      "learning_rate": 9.999964784590996e-05,
      "loss": 0.0578,
      "step": 1120
    },
    {
      "epoch": 0.003648,
      "grad_norm": 0.330644175208153,
      "learning_rate": 9.999963515669956e-05,
      "loss": 0.0528,
      "step": 1140
    },
    {
      "epoch": 0.003712,
      "grad_norm": 0.341857691501769,
      "learning_rate": 9.99996222429025e-05,
      "loss": 0.0492,
      "step": 1160
    },
    {
      "epoch": 0.003776,
      "grad_norm": 0.43878658400878173,
      "learning_rate": 9.999960910451878e-05,
      "loss": 0.0499,
      "step": 1180
    },
    {
      "epoch": 0.00384,
      "grad_norm": 0.4402535076549671,
      "learning_rate": 9.999959574154849e-05,
      "loss": 0.0532,
      "step": 1200
    },
    {
      "epoch": 0.003904,
      "grad_norm": 0.45547637242325884,
      "learning_rate": 9.999958215399168e-05,
      "loss": 0.0659,
      "step": 1220
    },
    {
      "epoch": 0.003968,
      "grad_norm": 0.5965254253569031,
      "learning_rate": 9.999956834184843e-05,
      "loss": 0.0566,
      "step": 1240
    },
    {
      "epoch": 0.004032,
      "grad_norm": 0.4324405925069988,
      "learning_rate": 9.999955430511876e-05,
      "loss": 0.0538,
      "step": 1260
    },
    {
      "epoch": 0.004096,
      "grad_norm": 0.3827993868853947,
      "learning_rate": 9.999954004380278e-05,
      "loss": 0.052,
      "step": 1280
    },
    {
      "epoch": 0.00416,
      "grad_norm": 0.41059924493250727,
      "learning_rate": 9.999952555790053e-05,
      "loss": 0.0528,
      "step": 1300
    },
    {
      "epoch": 0.004224,
      "grad_norm": 0.3697787761089116,
      "learning_rate": 9.999951084741208e-05,
      "loss": 0.0547,
      "step": 1320
    },
    {
      "epoch": 0.004288,
      "grad_norm": 0.3518249551296642,
      "learning_rate": 9.999949591233751e-05,
      "loss": 0.0512,
      "step": 1340
    },
    {
      "epoch": 0.004352,
      "grad_norm": 0.3966048202962381,
      "learning_rate": 9.999948075267686e-05,
      "loss": 0.0483,
      "step": 1360
    },
    {
      "epoch": 0.004416,
      "grad_norm": 0.2992863917125513,
      "learning_rate": 9.999946536843021e-05,
      "loss": 0.0588,
      "step": 1380
    },
    {
      "epoch": 0.00448,
      "grad_norm": 0.3642430181347924,
      "learning_rate": 9.999944975959762e-05,
      "loss": 0.0559,
      "step": 1400
    },
    {
      "epoch": 0.004544,
      "grad_norm": 0.28428952786006667,
      "learning_rate": 9.99994339261792e-05,
      "loss": 0.0505,
      "step": 1420
    },
    {
      "epoch": 0.004608,
      "grad_norm": 0.27542639692431337,
      "learning_rate": 9.999941786817497e-05,
      "loss": 0.0503,
      "step": 1440
    },
    {
      "epoch": 0.004672,
      "grad_norm": 0.2893247944703916,
      "learning_rate": 9.999940158558503e-05,
      "loss": 0.0448,
      "step": 1460
    },
    {
      "epoch": 0.004736,
      "grad_norm": 0.3867132858602596,
      "learning_rate": 9.999938507840944e-05,
      "loss": 0.0531,
      "step": 1480
    },
    {
      "epoch": 0.0048,
      "grad_norm": 0.3123100305966905,
      "learning_rate": 9.99993683466483e-05,
      "loss": 0.0486,
      "step": 1500
    },
    {
      "epoch": 0.004864,
      "grad_norm": 0.6860642934875139,
      "learning_rate": 9.999935139030164e-05,
      "loss": 0.0508,
      "step": 1520
    },
    {
      "epoch": 0.004928,
      "grad_norm": 0.41895308691771405,
      "learning_rate": 9.999933420936957e-05,
      "loss": 0.0507,
      "step": 1540
    },
    {
      "epoch": 0.004992,
      "grad_norm": 0.2621600433718587,
      "learning_rate": 9.999931680385217e-05,
      "loss": 0.0504,
      "step": 1560
    },
    {
      "epoch": 0.005056,
      "grad_norm": 0.3815573262171931,
      "learning_rate": 9.999929917374951e-05,
      "loss": 0.05,
      "step": 1580
    },
    {
      "epoch": 0.00512,
      "grad_norm": 0.37620492419561863,
      "learning_rate": 9.999928131906165e-05,
      "loss": 0.0487,
      "step": 1600
    },
    {
      "epoch": 0.005184,
      "grad_norm": 0.2984053569602002,
      "learning_rate": 9.99992632397887e-05,
      "loss": 0.048,
      "step": 1620
    },
    {
      "epoch": 0.005248,
      "grad_norm": 0.27743837838217916,
      "learning_rate": 9.999924493593071e-05,
      "loss": 0.0479,
      "step": 1640
    },
    {
      "epoch": 0.005312,
      "grad_norm": 0.37400919550719863,
      "learning_rate": 9.99992264074878e-05,
      "loss": 0.0479,
      "step": 1660
    },
    {
      "epoch": 0.005376,
      "grad_norm": 0.3646151423541133,
      "learning_rate": 9.999920765446002e-05,
      "loss": 0.0478,
      "step": 1680
    },
    {
      "epoch": 0.00544,
      "grad_norm": 0.2530121165143808,
      "learning_rate": 9.999918867684749e-05,
      "loss": 0.0471,
      "step": 1700
    },
    {
      "epoch": 0.005504,
      "grad_norm": 0.3064041571959589,
      "learning_rate": 9.999916947465026e-05,
      "loss": 0.0479,
      "step": 1720
    },
    {
      "epoch": 0.005568,
      "grad_norm": 0.29995424831453693,
      "learning_rate": 9.999915004786842e-05,
      "loss": 0.0545,
      "step": 1740
    },
    {
      "epoch": 0.005632,
      "grad_norm": 0.2579628747140138,
      "learning_rate": 9.999913039650208e-05,
      "loss": 0.0481,
      "step": 1760
    },
    {
      "epoch": 0.005696,
      "grad_norm": 0.37679754143686134,
      "learning_rate": 9.99991105205513e-05,
      "loss": 0.0513,
      "step": 1780
    },
    {
      "epoch": 0.00576,
      "grad_norm": 0.3487000068380941,
      "learning_rate": 9.99990904200162e-05,
      "loss": 0.0485,
      "step": 1800
    },
    {
      "epoch": 0.005824,
      "grad_norm": 0.42128271498962744,
      "learning_rate": 9.999907009489684e-05,
      "loss": 0.0523,
      "step": 1820
    },
    {
      "epoch": 0.005888,
      "grad_norm": 0.24481172509209137,
      "learning_rate": 9.999904954519335e-05,
      "loss": 0.0483,
      "step": 1840
    },
    {
      "epoch": 0.005952,
      "grad_norm": 0.35512611115825016,
      "learning_rate": 9.999902877090577e-05,
      "loss": 0.0478,
      "step": 1860
    },
    {
      "epoch": 0.006016,
      "grad_norm": 0.43287405676025453,
      "learning_rate": 9.999900777203424e-05,
      "loss": 0.0461,
      "step": 1880
    },
    {
      "epoch": 0.00608,
      "grad_norm": 0.37065789856595455,
      "learning_rate": 9.999898654857882e-05,
      "loss": 0.0471,
      "step": 1900
    },
    {
      "epoch": 0.006144,
      "grad_norm": 0.6122637202631629,
      "learning_rate": 9.999896510053963e-05,
      "loss": 0.0477,
      "step": 1920
    },
    {
      "epoch": 0.006208,
      "grad_norm": 0.41343656699008435,
      "learning_rate": 9.999894342791676e-05,
      "loss": 0.0471,
      "step": 1940
    },
    {
      "epoch": 0.006272,
      "grad_norm": 0.3880497393670191,
      "learning_rate": 9.99989215307103e-05,
      "loss": 0.0458,
      "step": 1960
    },
    {
      "epoch": 0.006336,
      "grad_norm": 0.413446669357271,
      "learning_rate": 9.999889940892036e-05,
      "loss": 0.0471,
      "step": 1980
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.37063142738634886,
      "learning_rate": 9.999887706254702e-05,
      "loss": 0.0461,
      "step": 2000
    },
    {
      "epoch": 0.006464,
      "grad_norm": 0.3263873803790246,
      "learning_rate": 9.999885449159041e-05,
      "loss": 0.0433,
      "step": 2020
    },
    {
      "epoch": 0.006528,
      "grad_norm": 0.2751689144898591,
      "learning_rate": 9.99988316960506e-05,
      "loss": 0.0472,
      "step": 2040
    },
    {
      "epoch": 0.006592,
      "grad_norm": 0.26563699407934044,
      "learning_rate": 9.999880867592771e-05,
      "loss": 0.0457,
      "step": 2060
    },
    {
      "epoch": 0.006656,
      "grad_norm": 0.3185404492461951,
      "learning_rate": 9.999878543122183e-05,
      "loss": 0.0491,
      "step": 2080
    },
    {
      "epoch": 0.00672,
      "grad_norm": 0.37960846473683246,
      "learning_rate": 9.99987619619331e-05,
      "loss": 0.0469,
      "step": 2100
    },
    {
      "epoch": 0.006784,
      "grad_norm": 0.44510790225490077,
      "learning_rate": 9.999873826806158e-05,
      "loss": 0.0486,
      "step": 2120
    },
    {
      "epoch": 0.006848,
      "grad_norm": 0.30839445947280475,
      "learning_rate": 9.99987143496074e-05,
      "loss": 0.0485,
      "step": 2140
    },
    {
      "epoch": 0.006912,
      "grad_norm": 0.37056855516657783,
      "learning_rate": 9.999869020657066e-05,
      "loss": 0.0511,
      "step": 2160
    },
    {
      "epoch": 0.006976,
      "grad_norm": 0.33190594018897246,
      "learning_rate": 9.999866583895148e-05,
      "loss": 0.0509,
      "step": 2180
    },
    {
      "epoch": 0.00704,
      "grad_norm": 0.34153839602614805,
      "learning_rate": 9.999864124674995e-05,
      "loss": 0.0488,
      "step": 2200
    },
    {
      "epoch": 0.007104,
      "grad_norm": 0.2342491607350666,
      "learning_rate": 9.999861642996621e-05,
      "loss": 0.0443,
      "step": 2220
    },
    {
      "epoch": 0.007168,
      "grad_norm": 0.27549764195771853,
      "learning_rate": 9.999859138860035e-05,
      "loss": 0.0458,
      "step": 2240
    },
    {
      "epoch": 0.007232,
      "grad_norm": 0.2974959541271812,
      "learning_rate": 9.999856612265247e-05,
      "loss": 0.0473,
      "step": 2260
    },
    {
      "epoch": 0.007296,
      "grad_norm": 0.41245560801263564,
      "learning_rate": 9.99985406321227e-05,
      "loss": 0.0463,
      "step": 2280
    },
    {
      "epoch": 0.00736,
      "grad_norm": 0.2970723727113926,
      "learning_rate": 9.999851491701117e-05,
      "loss": 0.046,
      "step": 2300
    },
    {
      "epoch": 0.007424,
      "grad_norm": 0.26443168057948846,
      "learning_rate": 9.999848897731799e-05,
      "loss": 0.0464,
      "step": 2320
    },
    {
      "epoch": 0.007488,
      "grad_norm": 0.30004642759969996,
      "learning_rate": 9.999846281304323e-05,
      "loss": 0.0437,
      "step": 2340
    },
    {
      "epoch": 0.007552,
      "grad_norm": 0.2159707528687582,
      "learning_rate": 9.999843642418707e-05,
      "loss": 0.0434,
      "step": 2360
    },
    {
      "epoch": 0.007616,
      "grad_norm": 0.5966198334346415,
      "learning_rate": 9.99984098107496e-05,
      "loss": 0.0498,
      "step": 2380
    },
    {
      "epoch": 0.00768,
      "grad_norm": 0.30750128328976645,
      "learning_rate": 9.999838297273093e-05,
      "loss": 0.0506,
      "step": 2400
    },
    {
      "epoch": 0.007744,
      "grad_norm": 0.3207344606253422,
      "learning_rate": 9.99983559101312e-05,
      "loss": 0.0451,
      "step": 2420
    },
    {
      "epoch": 0.007808,
      "grad_norm": 0.2525032200615989,
      "learning_rate": 9.999832862295052e-05,
      "loss": 0.0473,
      "step": 2440
    },
    {
      "epoch": 0.007872,
      "grad_norm": 0.27054214063577636,
      "learning_rate": 9.999830111118902e-05,
      "loss": 0.0395,
      "step": 2460
    },
    {
      "epoch": 0.007936,
      "grad_norm": 0.3408326046676982,
      "learning_rate": 9.999827337484682e-05,
      "loss": 0.045,
      "step": 2480
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.6005376063531308,
      "learning_rate": 9.999824541392405e-05,
      "loss": 0.0461,
      "step": 2500
    },
    {
      "epoch": 0.008064,
      "grad_norm": 0.24918037914823757,
      "learning_rate": 9.999821722842081e-05,
      "loss": 0.0502,
      "step": 2520
    },
    {
      "epoch": 0.008128,
      "grad_norm": 0.37328523769528615,
      "learning_rate": 9.999818881833725e-05,
      "loss": 0.0485,
      "step": 2540
    },
    {
      "epoch": 0.008192,
      "grad_norm": 0.28591965288964116,
      "learning_rate": 9.999816018367352e-05,
      "loss": 0.0493,
      "step": 2560
    },
    {
      "epoch": 0.008256,
      "grad_norm": 0.38472921576940955,
      "learning_rate": 9.99981313244297e-05,
      "loss": 0.0476,
      "step": 2580
    },
    {
      "epoch": 0.00832,
      "grad_norm": 0.46374225735695795,
      "learning_rate": 9.999810224060596e-05,
      "loss": 0.0485,
      "step": 2600
    },
    {
      "epoch": 0.008384,
      "grad_norm": 0.328505186320803,
      "learning_rate": 9.999807293220238e-05,
      "loss": 0.0517,
      "step": 2620
    },
    {
      "epoch": 0.008448,
      "grad_norm": 0.24695111199862108,
      "learning_rate": 9.999804339921916e-05,
      "loss": 0.0472,
      "step": 2640
    },
    {
      "epoch": 0.008512,
      "grad_norm": 0.46294031072187397,
      "learning_rate": 9.999801364165637e-05,
      "loss": 0.0449,
      "step": 2660
    },
    {
      "epoch": 0.008576,
      "grad_norm": 0.45946547377431657,
      "learning_rate": 9.999798365951419e-05,
      "loss": 0.0476,
      "step": 2680
    },
    {
      "epoch": 0.00864,
      "grad_norm": 0.30287823630874633,
      "learning_rate": 9.999795345279272e-05,
      "loss": 0.0464,
      "step": 2700
    },
    {
      "epoch": 0.008704,
      "grad_norm": 0.2581325811736559,
      "learning_rate": 9.999792302149214e-05,
      "loss": 0.045,
      "step": 2720
    },
    {
      "epoch": 0.008768,
      "grad_norm": 0.24522591219084197,
      "learning_rate": 9.999789236561253e-05,
      "loss": 0.046,
      "step": 2740
    },
    {
      "epoch": 0.008832,
      "grad_norm": 0.3112382154972075,
      "learning_rate": 9.999786148515406e-05,
      "loss": 0.0452,
      "step": 2760
    },
    {
      "epoch": 0.008896,
      "grad_norm": 0.4420397695481255,
      "learning_rate": 9.999783038011688e-05,
      "loss": 0.0463,
      "step": 2780
    },
    {
      "epoch": 0.00896,
      "grad_norm": 0.2621404198263619,
      "learning_rate": 9.999779905050111e-05,
      "loss": 0.0461,
      "step": 2800
    },
    {
      "epoch": 0.009024,
      "grad_norm": 0.28164987956647225,
      "learning_rate": 9.999776749630688e-05,
      "loss": 0.0481,
      "step": 2820
    },
    {
      "epoch": 0.009088,
      "grad_norm": 0.32147247660009226,
      "learning_rate": 9.999773571753436e-05,
      "loss": 0.0492,
      "step": 2840
    },
    {
      "epoch": 0.009152,
      "grad_norm": 0.35106777153444557,
      "learning_rate": 9.999770371418367e-05,
      "loss": 0.0459,
      "step": 2860
    },
    {
      "epoch": 0.009216,
      "grad_norm": 0.2577991408051769,
      "learning_rate": 9.999767148625497e-05,
      "loss": 0.046,
      "step": 2880
    },
    {
      "epoch": 0.00928,
      "grad_norm": 0.2849087970131688,
      "learning_rate": 9.99976390337484e-05,
      "loss": 0.0453,
      "step": 2900
    },
    {
      "epoch": 0.009344,
      "grad_norm": 0.28871568176698986,
      "learning_rate": 9.999760635666411e-05,
      "loss": 0.0437,
      "step": 2920
    },
    {
      "epoch": 0.009408,
      "grad_norm": 0.21064694200733436,
      "learning_rate": 9.999757345500222e-05,
      "loss": 0.0437,
      "step": 2940
    },
    {
      "epoch": 0.009472,
      "grad_norm": 0.2732553089403749,
      "learning_rate": 9.999754032876292e-05,
      "loss": 0.0406,
      "step": 2960
    },
    {
      "epoch": 0.009536,
      "grad_norm": 0.30320702190166154,
      "learning_rate": 9.999750697794632e-05,
      "loss": 0.0442,
      "step": 2980
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.21447400795709393,
      "learning_rate": 9.999747340255259e-05,
      "loss": 0.0411,
      "step": 3000
    },
    {
      "epoch": 0.009664,
      "grad_norm": 0.20772844528317766,
      "learning_rate": 9.999743960258189e-05,
      "loss": 0.0401,
      "step": 3020
    },
    {
      "epoch": 0.009728,
      "grad_norm": 0.23471573180575642,
      "learning_rate": 9.999740557803434e-05,
      "loss": 0.0437,
      "step": 3040
    },
    {
      "epoch": 0.009792,
      "grad_norm": 0.2157948447807665,
      "learning_rate": 9.999737132891012e-05,
      "loss": 0.0456,
      "step": 3060
    },
    {
      "epoch": 0.009856,
      "grad_norm": 0.18599773670342115,
      "learning_rate": 9.999733685520939e-05,
      "loss": 0.039,
      "step": 3080
    },
    {
      "epoch": 0.00992,
      "grad_norm": 0.2248349803131493,
      "learning_rate": 9.999730215693229e-05,
      "loss": 0.0492,
      "step": 3100
    },
    {
      "epoch": 0.009984,
      "grad_norm": 0.20645943875782566,
      "learning_rate": 9.999726723407897e-05,
      "loss": 0.0457,
      "step": 3120
    },
    {
      "epoch": 0.010048,
      "grad_norm": 0.28197950285780193,
      "learning_rate": 9.999723208664957e-05,
      "loss": 0.0446,
      "step": 3140
    },
    {
      "epoch": 0.010112,
      "grad_norm": 0.18527584324677912,
      "learning_rate": 9.99971967146443e-05,
      "loss": 0.0427,
      "step": 3160
    },
    {
      "epoch": 0.010176,
      "grad_norm": 0.208287885693757,
      "learning_rate": 9.999716111806328e-05,
      "loss": 0.0445,
      "step": 3180
    },
    {
      "epoch": 0.01024,
      "grad_norm": 0.20606070303281376,
      "learning_rate": 9.999712529690668e-05,
      "loss": 0.0442,
      "step": 3200
    },
    {
      "epoch": 0.010304,
      "grad_norm": 0.3110099728418316,
      "learning_rate": 9.999708925117469e-05,
      "loss": 0.0451,
      "step": 3220
    },
    {
      "epoch": 0.010368,
      "grad_norm": 0.24973917455019162,
      "learning_rate": 9.99970529808674e-05,
      "loss": 0.0452,
      "step": 3240
    },
    {
      "epoch": 0.010432,
      "grad_norm": 0.17422485941160815,
      "learning_rate": 9.999701648598503e-05,
      "loss": 0.0386,
      "step": 3260
    },
    {
      "epoch": 0.010496,
      "grad_norm": 0.19446294414429377,
      "learning_rate": 9.999697976652774e-05,
      "loss": 0.0408,
      "step": 3280
    },
    {
      "epoch": 0.01056,
      "grad_norm": 0.2628607393100338,
      "learning_rate": 9.999694282249568e-05,
      "loss": 0.0465,
      "step": 3300
    },
    {
      "epoch": 0.010624,
      "grad_norm": 0.1914174609030993,
      "learning_rate": 9.999690565388902e-05,
      "loss": 0.0446,
      "step": 3320
    },
    {
      "epoch": 0.010688,
      "grad_norm": 0.15268927179149996,
      "learning_rate": 9.999686826070793e-05,
      "loss": 0.0419,
      "step": 3340
    },
    {
      "epoch": 0.010752,
      "grad_norm": 0.21281810264609846,
      "learning_rate": 9.999683064295258e-05,
      "loss": 0.0416,
      "step": 3360
    },
    {
      "epoch": 0.010816,
      "grad_norm": 0.21419375538025656,
      "learning_rate": 9.999679280062312e-05,
      "loss": 0.0395,
      "step": 3380
    },
    {
      "epoch": 0.01088,
      "grad_norm": 0.2601202748382088,
      "learning_rate": 9.999675473371974e-05,
      "loss": 0.0368,
      "step": 3400
    },
    {
      "epoch": 0.010944,
      "grad_norm": 0.22383079056064387,
      "learning_rate": 9.999671644224262e-05,
      "loss": 0.0415,
      "step": 3420
    },
    {
      "epoch": 0.011008,
      "grad_norm": 0.29560811142064425,
      "learning_rate": 9.999667792619189e-05,
      "loss": 0.0426,
      "step": 3440
    },
    {
      "epoch": 0.011072,
      "grad_norm": 0.3469329488354822,
      "learning_rate": 9.999663918556779e-05,
      "loss": 0.0436,
      "step": 3460
    },
    {
      "epoch": 0.011136,
      "grad_norm": 0.22744520444727298,
      "learning_rate": 9.999660022037043e-05,
      "loss": 0.05,
      "step": 3480
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.20211426841890542,
      "learning_rate": 9.99965610306e-05,
      "loss": 0.0484,
      "step": 3500
    },
    {
      "epoch": 0.011264,
      "grad_norm": 0.2946741835938952,
      "learning_rate": 9.99965216162567e-05,
      "loss": 0.046,
      "step": 3520
    },
    {
      "epoch": 0.011328,
      "grad_norm": 0.21850279078131474,
      "learning_rate": 9.99964819773407e-05,
      "loss": 0.0437,
      "step": 3540
    },
    {
      "epoch": 0.011392,
      "grad_norm": 0.2311073289897065,
      "learning_rate": 9.999644211385216e-05,
      "loss": 0.0415,
      "step": 3560
    },
    {
      "epoch": 0.011456,
      "grad_norm": 0.2976609274852421,
      "learning_rate": 9.999640202579127e-05,
      "loss": 0.039,
      "step": 3580
    },
    {
      "epoch": 0.01152,
      "grad_norm": 0.22258823993173257,
      "learning_rate": 9.999636171315821e-05,
      "loss": 0.041,
      "step": 3600
    },
    {
      "epoch": 0.011584,
      "grad_norm": 0.28317382795178586,
      "learning_rate": 9.999632117595317e-05,
      "loss": 0.0445,
      "step": 3620
    },
    {
      "epoch": 0.011648,
      "grad_norm": 0.20428252496144694,
      "learning_rate": 9.999628041417632e-05,
      "loss": 0.0422,
      "step": 3640
    },
    {
      "epoch": 0.011712,
      "grad_norm": 0.21189307987201558,
      "learning_rate": 9.999623942782783e-05,
      "loss": 0.0394,
      "step": 3660
    },
    {
      "epoch": 0.011776,
      "grad_norm": 0.31346858028822167,
      "learning_rate": 9.999619821690792e-05,
      "loss": 0.0437,
      "step": 3680
    },
    {
      "epoch": 0.01184,
      "grad_norm": 0.24739476338473063,
      "learning_rate": 9.999615678141674e-05,
      "loss": 0.0441,
      "step": 3700
    },
    {
      "epoch": 0.011904,
      "grad_norm": 0.26145402735451817,
      "learning_rate": 9.999611512135452e-05,
      "loss": 0.0419,
      "step": 3720
    },
    {
      "epoch": 0.011968,
      "grad_norm": 0.24413853904942098,
      "learning_rate": 9.99960732367214e-05,
      "loss": 0.0447,
      "step": 3740
    },
    {
      "epoch": 0.012032,
      "grad_norm": 0.5526540933212379,
      "learning_rate": 9.999603112751759e-05,
      "loss": 0.0409,
      "step": 3760
    },
    {
      "epoch": 0.012096,
      "grad_norm": 0.23850799794253388,
      "learning_rate": 9.999598879374326e-05,
      "loss": 0.043,
      "step": 3780
    },
    {
      "epoch": 0.01216,
      "grad_norm": 0.31969676291937266,
      "learning_rate": 9.999594623539862e-05,
      "loss": 0.0441,
      "step": 3800
    },
    {
      "epoch": 0.012224,
      "grad_norm": 0.20951360956925488,
      "learning_rate": 9.999590345248388e-05,
      "loss": 0.0463,
      "step": 3820
    },
    {
      "epoch": 0.012288,
      "grad_norm": 0.25793718921030695,
      "learning_rate": 9.999586044499921e-05,
      "loss": 0.0446,
      "step": 3840
    },
    {
      "epoch": 0.012352,
      "grad_norm": 0.2297692199750354,
      "learning_rate": 9.999581721294477e-05,
      "loss": 0.0439,
      "step": 3860
    },
    {
      "epoch": 0.012416,
      "grad_norm": 0.19218350487770397,
      "learning_rate": 9.999577375632081e-05,
      "loss": 0.0449,
      "step": 3880
    },
    {
      "epoch": 0.01248,
      "grad_norm": 0.3033648329528053,
      "learning_rate": 9.99957300751275e-05,
      "loss": 0.0428,
      "step": 3900
    },
    {
      "epoch": 0.012544,
      "grad_norm": 0.40250617976922864,
      "learning_rate": 9.999568616936503e-05,
      "loss": 0.0417,
      "step": 3920
    },
    {
      "epoch": 0.012608,
      "grad_norm": 0.24185351566600372,
      "learning_rate": 9.999564203903363e-05,
      "loss": 0.0452,
      "step": 3940
    },
    {
      "epoch": 0.012672,
      "grad_norm": 0.2276674393893432,
      "learning_rate": 9.999559768413345e-05,
      "loss": 0.045,
      "step": 3960
    },
    {
      "epoch": 0.012736,
      "grad_norm": 0.22042326158393796,
      "learning_rate": 9.999555310466471e-05,
      "loss": 0.0388,
      "step": 3980
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.2160343386870399,
      "learning_rate": 9.999550830062763e-05,
      "loss": 0.0389,
      "step": 4000
    },
    {
      "epoch": 0.012864,
      "grad_norm": 0.5155755250188268,
      "learning_rate": 9.999546327202238e-05,
      "loss": 0.0433,
      "step": 4020
    },
    {
      "epoch": 0.012928,
      "grad_norm": 0.2890268759735471,
      "learning_rate": 9.999541801884917e-05,
      "loss": 0.0445,
      "step": 4040
    },
    {
      "epoch": 0.012992,
      "grad_norm": 0.27385775279312136,
      "learning_rate": 9.999537254110824e-05,
      "loss": 0.0461,
      "step": 4060
    },
    {
      "epoch": 0.013056,
      "grad_norm": 0.2020938348958419,
      "learning_rate": 9.999532683879974e-05,
      "loss": 0.0457,
      "step": 4080
    },
    {
      "epoch": 0.01312,
      "grad_norm": 0.26852894636721175,
      "learning_rate": 9.999528091192391e-05,
      "loss": 0.0497,
      "step": 4100
    },
    {
      "epoch": 0.013184,
      "grad_norm": 0.2261581058171256,
      "learning_rate": 9.999523476048093e-05,
      "loss": 0.0433,
      "step": 4120
    },
    {
      "epoch": 0.013248,
      "grad_norm": 0.20294697552399188,
      "learning_rate": 9.999518838447103e-05,
      "loss": 0.045,
      "step": 4140
    },
    {
      "epoch": 0.013312,
      "grad_norm": 0.25503703498212965,
      "learning_rate": 9.999514178389443e-05,
      "loss": 0.0468,
      "step": 4160
    },
    {
      "epoch": 0.013376,
      "grad_norm": 0.31416615760545596,
      "learning_rate": 9.99950949587513e-05,
      "loss": 0.044,
      "step": 4180
    },
    {
      "epoch": 0.01344,
      "grad_norm": 0.3127318682513348,
      "learning_rate": 9.999504790904188e-05,
      "loss": 0.0421,
      "step": 4200
    },
    {
      "epoch": 0.013504,
      "grad_norm": 0.3883954329946083,
      "learning_rate": 9.999500063476639e-05,
      "loss": 0.0448,
      "step": 4220
    },
    {
      "epoch": 0.013568,
      "grad_norm": 0.3584302284803773,
      "learning_rate": 9.9994953135925e-05,
      "loss": 0.0436,
      "step": 4240
    },
    {
      "epoch": 0.013632,
      "grad_norm": 0.2432655417897402,
      "learning_rate": 9.999490541251794e-05,
      "loss": 0.0441,
      "step": 4260
    },
    {
      "epoch": 0.013696,
      "grad_norm": 0.246759048088496,
      "learning_rate": 9.999485746454547e-05,
      "loss": 0.0452,
      "step": 4280
    },
    {
      "epoch": 0.01376,
      "grad_norm": 0.32387285050358106,
      "learning_rate": 9.999480929200774e-05,
      "loss": 0.0391,
      "step": 4300
    },
    {
      "epoch": 0.013824,
      "grad_norm": 0.25562150582991233,
      "learning_rate": 9.999476089490499e-05,
      "loss": 0.0391,
      "step": 4320
    },
    {
      "epoch": 0.013888,
      "grad_norm": 0.2558228907057912,
      "learning_rate": 9.999471227323745e-05,
      "loss": 0.0449,
      "step": 4340
    },
    {
      "epoch": 0.013952,
      "grad_norm": 0.20002668791572958,
      "learning_rate": 9.999466342700534e-05,
      "loss": 0.0413,
      "step": 4360
    },
    {
      "epoch": 0.014016,
      "grad_norm": 0.12224090068082925,
      "learning_rate": 9.999461435620886e-05,
      "loss": 0.0414,
      "step": 4380
    },
    {
      "epoch": 0.01408,
      "grad_norm": 0.24528343133145106,
      "learning_rate": 9.999456506084823e-05,
      "loss": 0.0382,
      "step": 4400
    },
    {
      "epoch": 0.014144,
      "grad_norm": 0.20452480266090878,
      "learning_rate": 9.999451554092369e-05,
      "loss": 0.0452,
      "step": 4420
    },
    {
      "epoch": 0.014208,
      "grad_norm": 0.18483919695658882,
      "learning_rate": 9.999446579643547e-05,
      "loss": 0.0385,
      "step": 4440
    },
    {
      "epoch": 0.014272,
      "grad_norm": 0.2182194295469889,
      "learning_rate": 9.999441582738376e-05,
      "loss": 0.0393,
      "step": 4460
    },
    {
      "epoch": 0.014336,
      "grad_norm": 0.23876712224949892,
      "learning_rate": 9.99943656337688e-05,
      "loss": 0.0407,
      "step": 4480
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.4384447884289934,
      "learning_rate": 9.999431521559082e-05,
      "loss": 0.043,
      "step": 4500
    },
    {
      "epoch": 0.014464,
      "grad_norm": 0.30307471328960556,
      "learning_rate": 9.999426457285004e-05,
      "loss": 0.0437,
      "step": 4520
    },
    {
      "epoch": 0.014528,
      "grad_norm": 0.227436400634274,
      "learning_rate": 9.99942137055467e-05,
      "loss": 0.0392,
      "step": 4540
    },
    {
      "epoch": 0.014592,
      "grad_norm": 0.15097773797353434,
      "learning_rate": 9.999416261368102e-05,
      "loss": 0.0437,
      "step": 4560
    },
    {
      "epoch": 0.014656,
      "grad_norm": 0.18980501687573087,
      "learning_rate": 9.999411129725322e-05,
      "loss": 0.0425,
      "step": 4580
    },
    {
      "epoch": 0.01472,
      "grad_norm": 0.3055583272822677,
      "learning_rate": 9.999405975626354e-05,
      "loss": 0.0441,
      "step": 4600
    },
    {
      "epoch": 0.014784,
      "grad_norm": 0.16265185830882983,
      "learning_rate": 9.999400799071222e-05,
      "loss": 0.0422,
      "step": 4620
    },
    {
      "epoch": 0.014848,
      "grad_norm": 0.2678225156503953,
      "learning_rate": 9.999395600059949e-05,
      "loss": 0.0445,
      "step": 4640
    },
    {
      "epoch": 0.014912,
      "grad_norm": 0.3136899388950313,
      "learning_rate": 9.999390378592556e-05,
      "loss": 0.0423,
      "step": 4660
    },
    {
      "epoch": 0.014976,
      "grad_norm": 0.2240918298251088,
      "learning_rate": 9.999385134669068e-05,
      "loss": 0.041,
      "step": 4680
    },
    {
      "epoch": 0.01504,
      "grad_norm": 0.21254312631985064,
      "learning_rate": 9.999379868289509e-05,
      "loss": 0.0436,
      "step": 4700
    },
    {
      "epoch": 0.015104,
      "grad_norm": 0.2231332870847772,
      "learning_rate": 9.999374579453904e-05,
      "loss": 0.0419,
      "step": 4720
    },
    {
      "epoch": 0.015168,
      "grad_norm": 0.18493137319251832,
      "learning_rate": 9.999369268162273e-05,
      "loss": 0.0383,
      "step": 4740
    },
    {
      "epoch": 0.015232,
      "grad_norm": 0.27489319131281786,
      "learning_rate": 9.999363934414643e-05,
      "loss": 0.0423,
      "step": 4760
    },
    {
      "epoch": 0.015296,
      "grad_norm": 0.2075167028312529,
      "learning_rate": 9.999358578211038e-05,
      "loss": 0.0426,
      "step": 4780
    },
    {
      "epoch": 0.01536,
      "grad_norm": 0.22680209361651998,
      "learning_rate": 9.999353199551478e-05,
      "loss": 0.0437,
      "step": 4800
    },
    {
      "epoch": 0.015424,
      "grad_norm": 0.18543121483976474,
      "learning_rate": 9.999347798435993e-05,
      "loss": 0.0389,
      "step": 4820
    },
    {
      "epoch": 0.015488,
      "grad_norm": 0.1615790423989882,
      "learning_rate": 9.999342374864604e-05,
      "loss": 0.0419,
      "step": 4840
    },
    {
      "epoch": 0.015552,
      "grad_norm": 0.21311733127805854,
      "learning_rate": 9.999336928837335e-05,
      "loss": 0.0449,
      "step": 4860
    },
    {
      "epoch": 0.015616,
      "grad_norm": 0.2223299603170898,
      "learning_rate": 9.999331460354211e-05,
      "loss": 0.0441,
      "step": 4880
    },
    {
      "epoch": 0.01568,
      "grad_norm": 0.24234271182173017,
      "learning_rate": 9.999325969415258e-05,
      "loss": 0.038,
      "step": 4900
    },
    {
      "epoch": 0.015744,
      "grad_norm": 0.24654813714023002,
      "learning_rate": 9.999320456020497e-05,
      "loss": 0.043,
      "step": 4920
    },
    {
      "epoch": 0.015808,
      "grad_norm": 0.1699244490825696,
      "learning_rate": 9.999314920169958e-05,
      "loss": 0.0406,
      "step": 4940
    },
    {
      "epoch": 0.015872,
      "grad_norm": 0.18883656468115048,
      "learning_rate": 9.999309361863662e-05,
      "loss": 0.0432,
      "step": 4960
    },
    {
      "epoch": 0.015936,
      "grad_norm": 0.2272491945599065,
      "learning_rate": 9.999303781101635e-05,
      "loss": 0.0386,
      "step": 4980
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.24488576388609443,
      "learning_rate": 9.999298177883903e-05,
      "loss": 0.0462,
      "step": 5000
    },
    {
      "epoch": 0.016064,
      "grad_norm": 0.21481279115518054,
      "learning_rate": 9.999292552210488e-05,
      "loss": 0.0415,
      "step": 5020
    },
    {
      "epoch": 0.016128,
      "grad_norm": 0.23192172350908144,
      "learning_rate": 9.999286904081419e-05,
      "loss": 0.0424,
      "step": 5040
    },
    {
      "epoch": 0.016192,
      "grad_norm": 0.2482611258735945,
      "learning_rate": 9.999281233496721e-05,
      "loss": 0.0408,
      "step": 5060
    },
    {
      "epoch": 0.016256,
      "grad_norm": 0.14798751306640967,
      "learning_rate": 9.999275540456419e-05,
      "loss": 0.0381,
      "step": 5080
    },
    {
      "epoch": 0.01632,
      "grad_norm": 0.24469681469863944,
      "learning_rate": 9.999269824960535e-05,
      "loss": 0.0401,
      "step": 5100
    },
    {
      "epoch": 0.016384,
      "grad_norm": 0.1811077009922402,
      "learning_rate": 9.999264087009099e-05,
      "loss": 0.041,
      "step": 5120
    },
    {
      "epoch": 0.016448,
      "grad_norm": 0.336911717206514,
      "learning_rate": 9.999258326602137e-05,
      "loss": 0.043,
      "step": 5140
    },
    {
      "epoch": 0.016512,
      "grad_norm": 0.20643988761597026,
      "learning_rate": 9.99925254373967e-05,
      "loss": 0.0407,
      "step": 5160
    },
    {
      "epoch": 0.016576,
      "grad_norm": 0.31888498684656585,
      "learning_rate": 9.999246738421731e-05,
      "loss": 0.0393,
      "step": 5180
    },
    {
      "epoch": 0.01664,
      "grad_norm": 0.23181655374071092,
      "learning_rate": 9.999240910648339e-05,
      "loss": 0.0392,
      "step": 5200
    },
    {
      "epoch": 0.016704,
      "grad_norm": 0.1386213007577926,
      "learning_rate": 9.999235060419525e-05,
      "loss": 0.0389,
      "step": 5220
    },
    {
      "epoch": 0.016768,
      "grad_norm": 0.18883798238282606,
      "learning_rate": 9.999229187735315e-05,
      "loss": 0.0423,
      "step": 5240
    },
    {
      "epoch": 0.016832,
      "grad_norm": 0.14006642257018215,
      "learning_rate": 9.999223292595732e-05,
      "loss": 0.0382,
      "step": 5260
    },
    {
      "epoch": 0.016896,
      "grad_norm": 0.18435441787783818,
      "learning_rate": 9.999217375000806e-05,
      "loss": 0.042,
      "step": 5280
    },
    {
      "epoch": 0.01696,
      "grad_norm": 0.17959844094692956,
      "learning_rate": 9.999211434950561e-05,
      "loss": 0.0402,
      "step": 5300
    },
    {
      "epoch": 0.017024,
      "grad_norm": 0.23849786171144446,
      "learning_rate": 9.999205472445027e-05,
      "loss": 0.0443,
      "step": 5320
    },
    {
      "epoch": 0.017088,
      "grad_norm": 0.21335476597643852,
      "learning_rate": 9.999199487484227e-05,
      "loss": 0.0415,
      "step": 5340
    },
    {
      "epoch": 0.017152,
      "grad_norm": 0.1803485361980176,
      "learning_rate": 9.99919348006819e-05,
      "loss": 0.0427,
      "step": 5360
    },
    {
      "epoch": 0.017216,
      "grad_norm": 0.33385981792085784,
      "learning_rate": 9.999187450196944e-05,
      "loss": 0.0424,
      "step": 5380
    },
    {
      "epoch": 0.01728,
      "grad_norm": 0.1945367708380311,
      "learning_rate": 9.999181397870514e-05,
      "loss": 0.0428,
      "step": 5400
    },
    {
      "epoch": 0.017344,
      "grad_norm": 0.1349909456906324,
      "learning_rate": 9.999175323088927e-05,
      "loss": 0.0415,
      "step": 5420
    },
    {
      "epoch": 0.017408,
      "grad_norm": 0.15270263987731508,
      "learning_rate": 9.999169225852212e-05,
      "loss": 0.0363,
      "step": 5440
    },
    {
      "epoch": 0.017472,
      "grad_norm": 0.20076037788130052,
      "learning_rate": 9.999163106160395e-05,
      "loss": 0.04,
      "step": 5460
    },
    {
      "epoch": 0.017536,
      "grad_norm": 0.17645278922324295,
      "learning_rate": 9.999156964013503e-05,
      "loss": 0.0414,
      "step": 5480
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.2572144123888314,
      "learning_rate": 9.999150799411566e-05,
      "loss": 0.0425,
      "step": 5500
    },
    {
      "epoch": 0.017664,
      "grad_norm": 0.20447774147657222,
      "learning_rate": 9.999144612354609e-05,
      "loss": 0.0417,
      "step": 5520
    },
    {
      "epoch": 0.017728,
      "grad_norm": 0.2984887585657629,
      "learning_rate": 9.999138402842662e-05,
      "loss": 0.0397,
      "step": 5540
    },
    {
      "epoch": 0.017792,
      "grad_norm": 0.27722018367891504,
      "learning_rate": 9.999132170875752e-05,
      "loss": 0.0443,
      "step": 5560
    },
    {
      "epoch": 0.017856,
      "grad_norm": 0.18656399917273497,
      "learning_rate": 9.999125916453907e-05,
      "loss": 0.0422,
      "step": 5580
    },
    {
      "epoch": 0.01792,
      "grad_norm": 0.38911082939661396,
      "learning_rate": 9.999119639577155e-05,
      "loss": 0.0427,
      "step": 5600
    },
    {
      "epoch": 0.017984,
      "grad_norm": 0.2426718821770736,
      "learning_rate": 9.999113340245525e-05,
      "loss": 0.0409,
      "step": 5620
    },
    {
      "epoch": 0.018048,
      "grad_norm": 0.2142934344961841,
      "learning_rate": 9.999107018459044e-05,
      "loss": 0.0407,
      "step": 5640
    },
    {
      "epoch": 0.018112,
      "grad_norm": 0.2217788598087543,
      "learning_rate": 9.999100674217741e-05,
      "loss": 0.0404,
      "step": 5660
    },
    {
      "epoch": 0.018176,
      "grad_norm": 0.18367822859673974,
      "learning_rate": 9.999094307521644e-05,
      "loss": 0.0403,
      "step": 5680
    },
    {
      "epoch": 0.01824,
      "grad_norm": 0.20063131701247866,
      "learning_rate": 9.999087918370782e-05,
      "loss": 0.0429,
      "step": 5700
    },
    {
      "epoch": 0.018304,
      "grad_norm": 0.32225956276545603,
      "learning_rate": 9.999081506765185e-05,
      "loss": 0.041,
      "step": 5720
    },
    {
      "epoch": 0.018368,
      "grad_norm": 0.18808449918030978,
      "learning_rate": 9.999075072704877e-05,
      "loss": 0.0404,
      "step": 5740
    },
    {
      "epoch": 0.018432,
      "grad_norm": 0.3853663405580428,
      "learning_rate": 9.999068616189894e-05,
      "loss": 0.0431,
      "step": 5760
    },
    {
      "epoch": 0.018496,
      "grad_norm": 0.1644007944200343,
      "learning_rate": 9.99906213722026e-05,
      "loss": 0.0431,
      "step": 5780
    },
    {
      "epoch": 0.01856,
      "grad_norm": 0.17517977327002154,
      "learning_rate": 9.999055635796006e-05,
      "loss": 0.0425,
      "step": 5800
    },
    {
      "epoch": 0.018624,
      "grad_norm": 0.18088428451899596,
      "learning_rate": 9.99904911191716e-05,
      "loss": 0.0398,
      "step": 5820
    },
    {
      "epoch": 0.018688,
      "grad_norm": 0.17297858743179007,
      "learning_rate": 9.999042565583753e-05,
      "loss": 0.0422,
      "step": 5840
    },
    {
      "epoch": 0.018752,
      "grad_norm": 0.2286153813558773,
      "learning_rate": 9.999035996795813e-05,
      "loss": 0.0428,
      "step": 5860
    },
    {
      "epoch": 0.018816,
      "grad_norm": 0.19546619504183593,
      "learning_rate": 9.99902940555337e-05,
      "loss": 0.0407,
      "step": 5880
    },
    {
      "epoch": 0.01888,
      "grad_norm": 0.14551806226358296,
      "learning_rate": 9.999022791856455e-05,
      "loss": 0.0387,
      "step": 5900
    },
    {
      "epoch": 0.018944,
      "grad_norm": 0.2711865188746732,
      "learning_rate": 9.999016155705094e-05,
      "loss": 0.0382,
      "step": 5920
    },
    {
      "epoch": 0.019008,
      "grad_norm": 0.21706897910593828,
      "learning_rate": 9.999009497099321e-05,
      "loss": 0.0415,
      "step": 5940
    },
    {
      "epoch": 0.019072,
      "grad_norm": 0.20105105793004252,
      "learning_rate": 9.999002816039163e-05,
      "loss": 0.0385,
      "step": 5960
    },
    {
      "epoch": 0.019136,
      "grad_norm": 0.17709142206799572,
      "learning_rate": 9.998996112524651e-05,
      "loss": 0.0387,
      "step": 5980
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.16370566946488016,
      "learning_rate": 9.998989386555814e-05,
      "loss": 0.0387,
      "step": 6000
    },
    {
      "epoch": 0.019264,
      "grad_norm": 0.2239297193863687,
      "learning_rate": 9.998982638132686e-05,
      "loss": 0.0413,
      "step": 6020
    },
    {
      "epoch": 0.019328,
      "grad_norm": 0.3014416034611583,
      "learning_rate": 9.998975867255293e-05,
      "loss": 0.039,
      "step": 6040
    },
    {
      "epoch": 0.019392,
      "grad_norm": 0.24120513811169209,
      "learning_rate": 9.998969073923668e-05,
      "loss": 0.0397,
      "step": 6060
    },
    {
      "epoch": 0.019456,
      "grad_norm": 0.23249714054344267,
      "learning_rate": 9.998962258137839e-05,
      "loss": 0.0403,
      "step": 6080
    },
    {
      "epoch": 0.01952,
      "grad_norm": 0.14600511813355524,
      "learning_rate": 9.998955419897838e-05,
      "loss": 0.042,
      "step": 6100
    },
    {
      "epoch": 0.019584,
      "grad_norm": 0.16695656150129792,
      "learning_rate": 9.998948559203698e-05,
      "loss": 0.0409,
      "step": 6120
    },
    {
      "epoch": 0.019648,
      "grad_norm": 0.1696923052821074,
      "learning_rate": 9.998941676055446e-05,
      "loss": 0.0408,
      "step": 6140
    },
    {
      "epoch": 0.019712,
      "grad_norm": 0.2053437439327295,
      "learning_rate": 9.998934770453115e-05,
      "loss": 0.0412,
      "step": 6160
    },
    {
      "epoch": 0.019776,
      "grad_norm": 0.19747318155213014,
      "learning_rate": 9.998927842396736e-05,
      "loss": 0.0376,
      "step": 6180
    },
    {
      "epoch": 0.01984,
      "grad_norm": 0.15256686727763652,
      "learning_rate": 9.998920891886339e-05,
      "loss": 0.0368,
      "step": 6200
    },
    {
      "epoch": 0.019904,
      "grad_norm": 0.3770590943630661,
      "learning_rate": 9.998913918921957e-05,
      "loss": 0.0416,
      "step": 6220
    },
    {
      "epoch": 0.019968,
      "grad_norm": 0.2532149056971487,
      "learning_rate": 9.99890692350362e-05,
      "loss": 0.0404,
      "step": 6240
    },
    {
      "epoch": 0.020032,
      "grad_norm": 0.15435449373864438,
      "learning_rate": 9.99889990563136e-05,
      "loss": 0.0404,
      "step": 6260
    },
    {
      "epoch": 0.020096,
      "grad_norm": 0.147340626498922,
      "learning_rate": 9.998892865305207e-05,
      "loss": 0.0369,
      "step": 6280
    },
    {
      "epoch": 0.02016,
      "grad_norm": 0.2402419073635215,
      "learning_rate": 9.998885802525196e-05,
      "loss": 0.0365,
      "step": 6300
    },
    {
      "epoch": 0.020224,
      "grad_norm": 0.1506992405168411,
      "learning_rate": 9.998878717291353e-05,
      "loss": 0.0382,
      "step": 6320
    },
    {
      "epoch": 0.020288,
      "grad_norm": 0.2410919238356268,
      "learning_rate": 9.998871609603717e-05,
      "loss": 0.0395,
      "step": 6340
    },
    {
      "epoch": 0.020352,
      "grad_norm": 0.1541154314193387,
      "learning_rate": 9.998864479462315e-05,
      "loss": 0.0401,
      "step": 6360
    },
    {
      "epoch": 0.020416,
      "grad_norm": 0.20636861820767585,
      "learning_rate": 9.998857326867181e-05,
      "loss": 0.038,
      "step": 6380
    },
    {
      "epoch": 0.02048,
      "grad_norm": 0.22320932302135035,
      "learning_rate": 9.998850151818345e-05,
      "loss": 0.0436,
      "step": 6400
    },
    {
      "epoch": 0.020544,
      "grad_norm": 0.16962600707739206,
      "learning_rate": 9.998842954315841e-05,
      "loss": 0.0469,
      "step": 6420
    },
    {
      "epoch": 0.020608,
      "grad_norm": 0.20530797039322027,
      "learning_rate": 9.998835734359703e-05,
      "loss": 0.041,
      "step": 6440
    },
    {
      "epoch": 0.020672,
      "grad_norm": 0.2231020758948462,
      "learning_rate": 9.998828491949959e-05,
      "loss": 0.0467,
      "step": 6460
    },
    {
      "epoch": 0.020736,
      "grad_norm": 0.21324966056479905,
      "learning_rate": 9.998821227086646e-05,
      "loss": 0.0423,
      "step": 6480
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.19911824709229392,
      "learning_rate": 9.998813939769794e-05,
      "loss": 0.0425,
      "step": 6500
    },
    {
      "epoch": 0.020864,
      "grad_norm": 0.2440791218660832,
      "learning_rate": 9.998806629999435e-05,
      "loss": 0.0428,
      "step": 6520
    },
    {
      "epoch": 0.020928,
      "grad_norm": 0.16981866057097575,
      "learning_rate": 9.998799297775605e-05,
      "loss": 0.0402,
      "step": 6540
    },
    {
      "epoch": 0.020992,
      "grad_norm": 0.165807532742159,
      "learning_rate": 9.998791943098335e-05,
      "loss": 0.0402,
      "step": 6560
    },
    {
      "epoch": 0.021056,
      "grad_norm": 0.1952217880524122,
      "learning_rate": 9.998784565967658e-05,
      "loss": 0.0414,
      "step": 6580
    },
    {
      "epoch": 0.02112,
      "grad_norm": 0.19654614011630828,
      "learning_rate": 9.998777166383608e-05,
      "loss": 0.0387,
      "step": 6600
    },
    {
      "epoch": 0.021184,
      "grad_norm": 0.2863565740611335,
      "learning_rate": 9.998769744346216e-05,
      "loss": 0.038,
      "step": 6620
    },
    {
      "epoch": 0.021248,
      "grad_norm": 0.2124879422748257,
      "learning_rate": 9.998762299855517e-05,
      "loss": 0.0417,
      "step": 6640
    },
    {
      "epoch": 0.021312,
      "grad_norm": 0.1636953639928248,
      "learning_rate": 9.998754832911546e-05,
      "loss": 0.0422,
      "step": 6660
    },
    {
      "epoch": 0.021376,
      "grad_norm": 0.23601133270974403,
      "learning_rate": 9.998747343514335e-05,
      "loss": 0.0366,
      "step": 6680
    },
    {
      "epoch": 0.02144,
      "grad_norm": 0.21408800613272436,
      "learning_rate": 9.998739831663914e-05,
      "loss": 0.0353,
      "step": 6700
    },
    {
      "epoch": 0.021504,
      "grad_norm": 0.18052832043307795,
      "learning_rate": 9.998732297360324e-05,
      "loss": 0.0399,
      "step": 6720
    },
    {
      "epoch": 0.021568,
      "grad_norm": 0.3525481496934496,
      "learning_rate": 9.998724740603593e-05,
      "loss": 0.0395,
      "step": 6740
    },
    {
      "epoch": 0.021632,
      "grad_norm": 0.2369571668099414,
      "learning_rate": 9.998717161393758e-05,
      "loss": 0.0404,
      "step": 6760
    },
    {
      "epoch": 0.021696,
      "grad_norm": 0.16161923330036226,
      "learning_rate": 9.998709559730853e-05,
      "loss": 0.0374,
      "step": 6780
    },
    {
      "epoch": 0.02176,
      "grad_norm": 0.14137582646219507,
      "learning_rate": 9.998701935614909e-05,
      "loss": 0.038,
      "step": 6800
    },
    {
      "epoch": 0.021824,
      "grad_norm": 0.1471023915556908,
      "learning_rate": 9.998694289045964e-05,
      "loss": 0.0364,
      "step": 6820
    },
    {
      "epoch": 0.021888,
      "grad_norm": 0.1766636345498869,
      "learning_rate": 9.998686620024051e-05,
      "loss": 0.0398,
      "step": 6840
    },
    {
      "epoch": 0.021952,
      "grad_norm": 0.1980008598583829,
      "learning_rate": 9.998678928549203e-05,
      "loss": 0.0372,
      "step": 6860
    },
    {
      "epoch": 0.022016,
      "grad_norm": 0.1568671064686567,
      "learning_rate": 9.998671214621457e-05,
      "loss": 0.0443,
      "step": 6880
    },
    {
      "epoch": 0.02208,
      "grad_norm": 0.15536838591377639,
      "learning_rate": 9.998663478240846e-05,
      "loss": 0.0405,
      "step": 6900
    },
    {
      "epoch": 0.022144,
      "grad_norm": 0.2564998022152435,
      "learning_rate": 9.998655719407404e-05,
      "loss": 0.0427,
      "step": 6920
    },
    {
      "epoch": 0.022208,
      "grad_norm": 0.29646525478774344,
      "learning_rate": 9.998647938121169e-05,
      "loss": 0.0374,
      "step": 6940
    },
    {
      "epoch": 0.022272,
      "grad_norm": 0.1508464411429471,
      "learning_rate": 9.998640134382173e-05,
      "loss": 0.0363,
      "step": 6960
    },
    {
      "epoch": 0.022336,
      "grad_norm": 0.2213965947537837,
      "learning_rate": 9.998632308190453e-05,
      "loss": 0.035,
      "step": 6980
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.19188403122898182,
      "learning_rate": 9.998624459546044e-05,
      "loss": 0.0426,
      "step": 7000
    },
    {
      "epoch": 0.022464,
      "grad_norm": 0.18823547847862185,
      "learning_rate": 9.998616588448978e-05,
      "loss": 0.0393,
      "step": 7020
    },
    {
      "epoch": 0.022528,
      "grad_norm": 0.16949788210042196,
      "learning_rate": 9.998608694899294e-05,
      "loss": 0.0398,
      "step": 7040
    },
    {
      "epoch": 0.022592,
      "grad_norm": 0.16212726739622002,
      "learning_rate": 9.998600778897028e-05,
      "loss": 0.0392,
      "step": 7060
    },
    {
      "epoch": 0.022656,
      "grad_norm": 0.18536407225773302,
      "learning_rate": 9.998592840442212e-05,
      "loss": 0.038,
      "step": 7080
    },
    {
      "epoch": 0.02272,
      "grad_norm": 0.18130925969004766,
      "learning_rate": 9.998584879534883e-05,
      "loss": 0.038,
      "step": 7100
    },
    {
      "epoch": 0.022784,
      "grad_norm": 0.17676041070087142,
      "learning_rate": 9.998576896175079e-05,
      "loss": 0.0399,
      "step": 7120
    },
    {
      "epoch": 0.022848,
      "grad_norm": 0.34645445981393896,
      "learning_rate": 9.998568890362832e-05,
      "loss": 0.039,
      "step": 7140
    },
    {
      "epoch": 0.022912,
      "grad_norm": 0.1280697447157394,
      "learning_rate": 9.99856086209818e-05,
      "loss": 0.0428,
      "step": 7160
    },
    {
      "epoch": 0.022976,
      "grad_norm": 0.16093425836224232,
      "learning_rate": 9.99855281138116e-05,
      "loss": 0.0426,
      "step": 7180
    },
    {
      "epoch": 0.02304,
      "grad_norm": 0.18112548072255152,
      "learning_rate": 9.998544738211809e-05,
      "loss": 0.0375,
      "step": 7200
    },
    {
      "epoch": 0.023104,
      "grad_norm": 0.2015163130939942,
      "learning_rate": 9.99853664259016e-05,
      "loss": 0.0409,
      "step": 7220
    },
    {
      "epoch": 0.023168,
      "grad_norm": 0.20587117079531728,
      "learning_rate": 9.99852852451625e-05,
      "loss": 0.0412,
      "step": 7240
    },
    {
      "epoch": 0.023232,
      "grad_norm": 0.15914815285760722,
      "learning_rate": 9.998520383990119e-05,
      "loss": 0.0387,
      "step": 7260
    },
    {
      "epoch": 0.023296,
      "grad_norm": 0.22595317914120058,
      "learning_rate": 9.9985122210118e-05,
      "loss": 0.0377,
      "step": 7280
    },
    {
      "epoch": 0.02336,
      "grad_norm": 0.1786837340367665,
      "learning_rate": 9.99850403558133e-05,
      "loss": 0.0359,
      "step": 7300
    },
    {
      "epoch": 0.023424,
      "grad_norm": 0.14531005857609933,
      "learning_rate": 9.998495827698746e-05,
      "loss": 0.04,
      "step": 7320
    },
    {
      "epoch": 0.023488,
      "grad_norm": 0.20487801260748323,
      "learning_rate": 9.998487597364086e-05,
      "loss": 0.0409,
      "step": 7340
    },
    {
      "epoch": 0.023552,
      "grad_norm": 0.16658937820195704,
      "learning_rate": 9.998479344577386e-05,
      "loss": 0.0394,
      "step": 7360
    },
    {
      "epoch": 0.023616,
      "grad_norm": 0.19146991618045886,
      "learning_rate": 9.998471069338684e-05,
      "loss": 0.0369,
      "step": 7380
    },
    {
      "epoch": 0.02368,
      "grad_norm": 0.2147646001103393,
      "learning_rate": 9.998462771648016e-05,
      "loss": 0.0408,
      "step": 7400
    },
    {
      "epoch": 0.023744,
      "grad_norm": 0.20719117655318012,
      "learning_rate": 9.998454451505419e-05,
      "loss": 0.0389,
      "step": 7420
    },
    {
      "epoch": 0.023808,
      "grad_norm": 0.2737724250233668,
      "learning_rate": 9.998446108910933e-05,
      "loss": 0.0426,
      "step": 7440
    },
    {
      "epoch": 0.023872,
      "grad_norm": 0.21919387559271272,
      "learning_rate": 9.998437743864591e-05,
      "loss": 0.0394,
      "step": 7460
    },
    {
      "epoch": 0.023936,
      "grad_norm": 0.28979932750223103,
      "learning_rate": 9.998429356366434e-05,
      "loss": 0.0372,
      "step": 7480
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.18453598226987689,
      "learning_rate": 9.9984209464165e-05,
      "loss": 0.0351,
      "step": 7500
    },
    {
      "epoch": 0.024064,
      "grad_norm": 0.13414968051956097,
      "learning_rate": 9.998412514014825e-05,
      "loss": 0.0379,
      "step": 7520
    },
    {
      "epoch": 0.024128,
      "grad_norm": 0.20059131884245548,
      "learning_rate": 9.998404059161448e-05,
      "loss": 0.0388,
      "step": 7540
    },
    {
      "epoch": 0.024192,
      "grad_norm": 0.149587738216436,
      "learning_rate": 9.998395581856406e-05,
      "loss": 0.0361,
      "step": 7560
    },
    {
      "epoch": 0.024256,
      "grad_norm": 0.15132694347285827,
      "learning_rate": 9.998387082099738e-05,
      "loss": 0.0411,
      "step": 7580
    },
    {
      "epoch": 0.02432,
      "grad_norm": 0.13219501095161013,
      "learning_rate": 9.998378559891481e-05,
      "loss": 0.0384,
      "step": 7600
    },
    {
      "epoch": 0.024384,
      "grad_norm": 0.16080473548995142,
      "learning_rate": 9.998370015231673e-05,
      "loss": 0.0382,
      "step": 7620
    },
    {
      "epoch": 0.024448,
      "grad_norm": 0.17207286319953086,
      "learning_rate": 9.998361448120356e-05,
      "loss": 0.0376,
      "step": 7640
    },
    {
      "epoch": 0.024512,
      "grad_norm": 0.14924823509590857,
      "learning_rate": 9.998352858557565e-05,
      "loss": 0.0401,
      "step": 7660
    },
    {
      "epoch": 0.024576,
      "grad_norm": 0.3419475288653469,
      "learning_rate": 9.998344246543339e-05,
      "loss": 0.0413,
      "step": 7680
    },
    {
      "epoch": 0.02464,
      "grad_norm": 0.26280630339510985,
      "learning_rate": 9.998335612077716e-05,
      "loss": 0.0402,
      "step": 7700
    },
    {
      "epoch": 0.024704,
      "grad_norm": 0.12230540892969835,
      "learning_rate": 9.998326955160737e-05,
      "loss": 0.0374,
      "step": 7720
    },
    {
      "epoch": 0.024768,
      "grad_norm": 0.17481274082557954,
      "learning_rate": 9.998318275792442e-05,
      "loss": 0.0376,
      "step": 7740
    },
    {
      "epoch": 0.024832,
      "grad_norm": 0.19630034225196766,
      "learning_rate": 9.998309573972864e-05,
      "loss": 0.0412,
      "step": 7760
    },
    {
      "epoch": 0.024896,
      "grad_norm": 0.1729501761934857,
      "learning_rate": 9.998300849702048e-05,
      "loss": 0.0382,
      "step": 7780
    },
    {
      "epoch": 0.02496,
      "grad_norm": 0.27691757705187797,
      "learning_rate": 9.998292102980031e-05,
      "loss": 0.0379,
      "step": 7800
    },
    {
      "epoch": 0.025024,
      "grad_norm": 0.1384105412534315,
      "learning_rate": 9.998283333806852e-05,
      "loss": 0.0376,
      "step": 7820
    },
    {
      "epoch": 0.025088,
      "grad_norm": 0.13370795970288152,
      "learning_rate": 9.998274542182551e-05,
      "loss": 0.0372,
      "step": 7840
    },
    {
      "epoch": 0.025152,
      "grad_norm": 0.18799996409722464,
      "learning_rate": 9.998265728107167e-05,
      "loss": 0.0376,
      "step": 7860
    },
    {
      "epoch": 0.025216,
      "grad_norm": 0.12437865151919679,
      "learning_rate": 9.99825689158074e-05,
      "loss": 0.0388,
      "step": 7880
    },
    {
      "epoch": 0.02528,
      "grad_norm": 0.18808500042301343,
      "learning_rate": 9.998248032603308e-05,
      "loss": 0.0343,
      "step": 7900
    },
    {
      "epoch": 0.025344,
      "grad_norm": 0.16854270089489595,
      "learning_rate": 9.998239151174915e-05,
      "loss": 0.0381,
      "step": 7920
    },
    {
      "epoch": 0.025408,
      "grad_norm": 0.17016575138075457,
      "learning_rate": 9.998230247295596e-05,
      "loss": 0.037,
      "step": 7940
    },
    {
      "epoch": 0.025472,
      "grad_norm": 0.204708594855192,
      "learning_rate": 9.998221320965394e-05,
      "loss": 0.0379,
      "step": 7960
    },
    {
      "epoch": 0.025536,
      "grad_norm": 0.11019640506024206,
      "learning_rate": 9.998212372184349e-05,
      "loss": 0.0386,
      "step": 7980
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.15693975940046118,
      "learning_rate": 9.998203400952499e-05,
      "loss": 0.0366,
      "step": 8000
    },
    {
      "epoch": 0.025664,
      "grad_norm": 0.15951215332821633,
      "learning_rate": 9.998194407269887e-05,
      "loss": 0.0397,
      "step": 8020
    },
    {
      "epoch": 0.025728,
      "grad_norm": 0.30023143474409775,
      "learning_rate": 9.998185391136552e-05,
      "loss": 0.0369,
      "step": 8040
    },
    {
      "epoch": 0.025792,
      "grad_norm": 0.21837937223919168,
      "learning_rate": 9.998176352552535e-05,
      "loss": 0.0396,
      "step": 8060
    },
    {
      "epoch": 0.025856,
      "grad_norm": 0.17674465551606347,
      "learning_rate": 9.998167291517874e-05,
      "loss": 0.0429,
      "step": 8080
    },
    {
      "epoch": 0.02592,
      "grad_norm": 0.16606144926047411,
      "learning_rate": 9.998158208032615e-05,
      "loss": 0.0405,
      "step": 8100
    },
    {
      "epoch": 0.025984,
      "grad_norm": 0.18430384947600362,
      "learning_rate": 9.998149102096795e-05,
      "loss": 0.0405,
      "step": 8120
    },
    {
      "epoch": 0.026048,
      "grad_norm": 0.17739809487671832,
      "learning_rate": 9.998139973710455e-05,
      "loss": 0.0379,
      "step": 8140
    },
    {
      "epoch": 0.026112,
      "grad_norm": 0.13967700675768496,
      "learning_rate": 9.998130822873637e-05,
      "loss": 0.0367,
      "step": 8160
    },
    {
      "epoch": 0.026176,
      "grad_norm": 0.15716813865496018,
      "learning_rate": 9.998121649586382e-05,
      "loss": 0.0392,
      "step": 8180
    },
    {
      "epoch": 0.02624,
      "grad_norm": 0.13644381755385415,
      "learning_rate": 9.99811245384873e-05,
      "loss": 0.038,
      "step": 8200
    },
    {
      "epoch": 0.026304,
      "grad_norm": 0.2134126230450536,
      "learning_rate": 9.998103235660724e-05,
      "loss": 0.0367,
      "step": 8220
    },
    {
      "epoch": 0.026368,
      "grad_norm": 0.14877877092020975,
      "learning_rate": 9.998093995022403e-05,
      "loss": 0.0387,
      "step": 8240
    },
    {
      "epoch": 0.026432,
      "grad_norm": 0.1574770279730747,
      "learning_rate": 9.998084731933815e-05,
      "loss": 0.039,
      "step": 8260
    },
    {
      "epoch": 0.026496,
      "grad_norm": 0.21415945708222908,
      "learning_rate": 9.998075446394992e-05,
      "loss": 0.0322,
      "step": 8280
    },
    {
      "epoch": 0.02656,
      "grad_norm": 0.1707549916825457,
      "learning_rate": 9.998066138405983e-05,
      "loss": 0.0381,
      "step": 8300
    },
    {
      "epoch": 0.026624,
      "grad_norm": 0.18731397436693656,
      "learning_rate": 9.998056807966827e-05,
      "loss": 0.0437,
      "step": 8320
    },
    {
      "epoch": 0.026688,
      "grad_norm": 0.2451754877072321,
      "learning_rate": 9.998047455077564e-05,
      "loss": 0.0408,
      "step": 8340
    },
    {
      "epoch": 0.026752,
      "grad_norm": 0.15413952206375178,
      "learning_rate": 9.998038079738241e-05,
      "loss": 0.0431,
      "step": 8360
    },
    {
      "epoch": 0.026816,
      "grad_norm": 0.1974076754612933,
      "learning_rate": 9.998028681948896e-05,
      "loss": 0.0394,
      "step": 8380
    },
    {
      "epoch": 0.02688,
      "grad_norm": 0.19210860113879746,
      "learning_rate": 9.998019261709574e-05,
      "loss": 0.0432,
      "step": 8400
    },
    {
      "epoch": 0.026944,
      "grad_norm": 0.14295884132936892,
      "learning_rate": 9.998009819020315e-05,
      "loss": 0.0401,
      "step": 8420
    },
    {
      "epoch": 0.027008,
      "grad_norm": 0.17476265676964364,
      "learning_rate": 9.998000353881162e-05,
      "loss": 0.0371,
      "step": 8440
    },
    {
      "epoch": 0.027072,
      "grad_norm": 0.15915165497965256,
      "learning_rate": 9.997990866292157e-05,
      "loss": 0.0392,
      "step": 8460
    },
    {
      "epoch": 0.027136,
      "grad_norm": 0.13774363945823467,
      "learning_rate": 9.997981356253345e-05,
      "loss": 0.039,
      "step": 8480
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.28410370337918944,
      "learning_rate": 9.997971823764767e-05,
      "loss": 0.0381,
      "step": 8500
    },
    {
      "epoch": 0.027264,
      "grad_norm": 0.18124112354414013,
      "learning_rate": 9.997962268826467e-05,
      "loss": 0.0413,
      "step": 8520
    },
    {
      "epoch": 0.027328,
      "grad_norm": 0.17321053945877202,
      "learning_rate": 9.997952691438484e-05,
      "loss": 0.0402,
      "step": 8540
    },
    {
      "epoch": 0.027392,
      "grad_norm": 0.15767849101385414,
      "learning_rate": 9.997943091600866e-05,
      "loss": 0.0428,
      "step": 8560
    },
    {
      "epoch": 0.027456,
      "grad_norm": 0.155224464417075,
      "learning_rate": 9.997933469313654e-05,
      "loss": 0.0383,
      "step": 8580
    },
    {
      "epoch": 0.02752,
      "grad_norm": 0.14158622548456798,
      "learning_rate": 9.99792382457689e-05,
      "loss": 0.0382,
      "step": 8600
    },
    {
      "epoch": 0.027584,
      "grad_norm": 0.2390044793087199,
      "learning_rate": 9.99791415739062e-05,
      "loss": 0.0392,
      "step": 8620
    },
    {
      "epoch": 0.027648,
      "grad_norm": 0.21038678550703277,
      "learning_rate": 9.997904467754885e-05,
      "loss": 0.0394,
      "step": 8640
    },
    {
      "epoch": 0.027712,
      "grad_norm": 0.24385811808529365,
      "learning_rate": 9.99789475566973e-05,
      "loss": 0.0373,
      "step": 8660
    },
    {
      "epoch": 0.027776,
      "grad_norm": 0.3065415083307644,
      "learning_rate": 9.997885021135199e-05,
      "loss": 0.0385,
      "step": 8680
    },
    {
      "epoch": 0.02784,
      "grad_norm": 0.2437758277740535,
      "learning_rate": 9.997875264151333e-05,
      "loss": 0.0375,
      "step": 8700
    },
    {
      "epoch": 0.027904,
      "grad_norm": 0.22502419788610184,
      "learning_rate": 9.997865484718178e-05,
      "loss": 0.0411,
      "step": 8720
    },
    {
      "epoch": 0.027968,
      "grad_norm": 0.12443278311736895,
      "learning_rate": 9.997855682835778e-05,
      "loss": 0.0397,
      "step": 8740
    },
    {
      "epoch": 0.028032,
      "grad_norm": 0.21490873610268243,
      "learning_rate": 9.997845858504178e-05,
      "loss": 0.0383,
      "step": 8760
    },
    {
      "epoch": 0.028096,
      "grad_norm": 0.14231181795440467,
      "learning_rate": 9.99783601172342e-05,
      "loss": 0.0368,
      "step": 8780
    },
    {
      "epoch": 0.02816,
      "grad_norm": 0.1771891828770871,
      "learning_rate": 9.997826142493548e-05,
      "loss": 0.0392,
      "step": 8800
    },
    {
      "epoch": 0.028224,
      "grad_norm": 0.18913571762356016,
      "learning_rate": 9.997816250814608e-05,
      "loss": 0.0362,
      "step": 8820
    },
    {
      "epoch": 0.028288,
      "grad_norm": 0.14155565298737752,
      "learning_rate": 9.997806336686644e-05,
      "loss": 0.0374,
      "step": 8840
    },
    {
      "epoch": 0.028352,
      "grad_norm": 0.1873384930843841,
      "learning_rate": 9.9977964001097e-05,
      "loss": 0.0354,
      "step": 8860
    },
    {
      "epoch": 0.028416,
      "grad_norm": 0.1679821623780715,
      "learning_rate": 9.99778644108382e-05,
      "loss": 0.0419,
      "step": 8880
    },
    {
      "epoch": 0.02848,
      "grad_norm": 0.1289712299068771,
      "learning_rate": 9.997776459609051e-05,
      "loss": 0.043,
      "step": 8900
    },
    {
      "epoch": 0.028544,
      "grad_norm": 0.2378486193314008,
      "learning_rate": 9.997766455685437e-05,
      "loss": 0.0395,
      "step": 8920
    },
    {
      "epoch": 0.028608,
      "grad_norm": 0.10613320877752269,
      "learning_rate": 9.997756429313022e-05,
      "loss": 0.0372,
      "step": 8940
    },
    {
      "epoch": 0.028672,
      "grad_norm": 0.16267468353089712,
      "learning_rate": 9.99774638049185e-05,
      "loss": 0.0357,
      "step": 8960
    },
    {
      "epoch": 0.028736,
      "grad_norm": 0.15059497685739207,
      "learning_rate": 9.997736309221968e-05,
      "loss": 0.0381,
      "step": 8980
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.25015484198531057,
      "learning_rate": 9.997726215503422e-05,
      "loss": 0.0407,
      "step": 9000
    },
    {
      "epoch": 0.028864,
      "grad_norm": 0.14633043222278574,
      "learning_rate": 9.997716099336256e-05,
      "loss": 0.0394,
      "step": 9020
    },
    {
      "epoch": 0.028928,
      "grad_norm": 0.18167086780261996,
      "learning_rate": 9.997705960720515e-05,
      "loss": 0.0351,
      "step": 9040
    },
    {
      "epoch": 0.028992,
      "grad_norm": 0.1350599645487261,
      "learning_rate": 9.997695799656246e-05,
      "loss": 0.0351,
      "step": 9060
    },
    {
      "epoch": 0.029056,
      "grad_norm": 0.17440248677045417,
      "learning_rate": 9.997685616143494e-05,
      "loss": 0.0351,
      "step": 9080
    },
    {
      "epoch": 0.02912,
      "grad_norm": 0.28942625686833,
      "learning_rate": 9.997675410182304e-05,
      "loss": 0.0413,
      "step": 9100
    },
    {
      "epoch": 0.029184,
      "grad_norm": 0.19129688991313012,
      "learning_rate": 9.997665181772721e-05,
      "loss": 0.0369,
      "step": 9120
    },
    {
      "epoch": 0.029248,
      "grad_norm": 0.15554348801230075,
      "learning_rate": 9.997654930914795e-05,
      "loss": 0.0358,
      "step": 9140
    },
    {
      "epoch": 0.029312,
      "grad_norm": 0.25689889209454647,
      "learning_rate": 9.997644657608567e-05,
      "loss": 0.0357,
      "step": 9160
    },
    {
      "epoch": 0.029376,
      "grad_norm": 0.27661745046985725,
      "learning_rate": 9.997634361854088e-05,
      "loss": 0.0373,
      "step": 9180
    },
    {
      "epoch": 0.02944,
      "grad_norm": 0.2158671648172072,
      "learning_rate": 9.997624043651401e-05,
      "loss": 0.0347,
      "step": 9200
    },
    {
      "epoch": 0.029504,
      "grad_norm": 0.192431325011243,
      "learning_rate": 9.997613703000553e-05,
      "loss": 0.0381,
      "step": 9220
    },
    {
      "epoch": 0.029568,
      "grad_norm": 0.13233573902299448,
      "learning_rate": 9.997603339901589e-05,
      "loss": 0.0375,
      "step": 9240
    },
    {
      "epoch": 0.029632,
      "grad_norm": 0.1359099622895592,
      "learning_rate": 9.997592954354557e-05,
      "loss": 0.039,
      "step": 9260
    },
    {
      "epoch": 0.029696,
      "grad_norm": 0.1347300367526654,
      "learning_rate": 9.997582546359505e-05,
      "loss": 0.0369,
      "step": 9280
    },
    {
      "epoch": 0.02976,
      "grad_norm": 0.14671149560533228,
      "learning_rate": 9.997572115916479e-05,
      "loss": 0.0374,
      "step": 9300
    },
    {
      "epoch": 0.029824,
      "grad_norm": 0.13799985667916329,
      "learning_rate": 9.997561663025526e-05,
      "loss": 0.0363,
      "step": 9320
    },
    {
      "epoch": 0.029888,
      "grad_norm": 0.10795437865207656,
      "learning_rate": 9.99755118768669e-05,
      "loss": 0.0353,
      "step": 9340
    },
    {
      "epoch": 0.029952,
      "grad_norm": 0.19104706273275876,
      "learning_rate": 9.997540689900023e-05,
      "loss": 0.0361,
      "step": 9360
    },
    {
      "epoch": 0.030016,
      "grad_norm": 0.21605051433949538,
      "learning_rate": 9.997530169665567e-05,
      "loss": 0.0406,
      "step": 9380
    },
    {
      "epoch": 0.03008,
      "grad_norm": 0.19465621931296648,
      "learning_rate": 9.997519626983374e-05,
      "loss": 0.0371,
      "step": 9400
    },
    {
      "epoch": 0.030144,
      "grad_norm": 0.19409049230766007,
      "learning_rate": 9.997509061853487e-05,
      "loss": 0.0379,
      "step": 9420
    },
    {
      "epoch": 0.030208,
      "grad_norm": 0.15345945855081358,
      "learning_rate": 9.997498474275957e-05,
      "loss": 0.0383,
      "step": 9440
    },
    {
      "epoch": 0.030272,
      "grad_norm": 0.16478275561675032,
      "learning_rate": 9.99748786425083e-05,
      "loss": 0.0383,
      "step": 9460
    },
    {
      "epoch": 0.030336,
      "grad_norm": 0.2534259922530058,
      "learning_rate": 9.997477231778153e-05,
      "loss": 0.0355,
      "step": 9480
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.18691581183631234,
      "learning_rate": 9.997466576857974e-05,
      "loss": 0.0343,
      "step": 9500
    },
    {
      "epoch": 0.030464,
      "grad_norm": 0.1750066759437617,
      "learning_rate": 9.997455899490344e-05,
      "loss": 0.0365,
      "step": 9520
    },
    {
      "epoch": 0.030528,
      "grad_norm": 0.11360784873379157,
      "learning_rate": 9.997445199675306e-05,
      "loss": 0.0361,
      "step": 9540
    },
    {
      "epoch": 0.030592,
      "grad_norm": 0.12241917270243875,
      "learning_rate": 9.997434477412913e-05,
      "loss": 0.0374,
      "step": 9560
    },
    {
      "epoch": 0.030656,
      "grad_norm": 0.14738392487864718,
      "learning_rate": 9.997423732703208e-05,
      "loss": 0.0338,
      "step": 9580
    },
    {
      "epoch": 0.03072,
      "grad_norm": 0.15717460291283827,
      "learning_rate": 9.997412965546242e-05,
      "loss": 0.0362,
      "step": 9600
    },
    {
      "epoch": 0.030784,
      "grad_norm": 0.17186483049770637,
      "learning_rate": 9.997402175942066e-05,
      "loss": 0.0375,
      "step": 9620
    },
    {
      "epoch": 0.030848,
      "grad_norm": 0.17770942497995662,
      "learning_rate": 9.997391363890722e-05,
      "loss": 0.0386,
      "step": 9640
    },
    {
      "epoch": 0.030912,
      "grad_norm": 0.12487498849791605,
      "learning_rate": 9.997380529392265e-05,
      "loss": 0.0344,
      "step": 9660
    },
    {
      "epoch": 0.030976,
      "grad_norm": 0.22024664688168222,
      "learning_rate": 9.99736967244674e-05,
      "loss": 0.0403,
      "step": 9680
    },
    {
      "epoch": 0.03104,
      "grad_norm": 0.1476486142479031,
      "learning_rate": 9.997358793054197e-05,
      "loss": 0.0387,
      "step": 9700
    },
    {
      "epoch": 0.031104,
      "grad_norm": 0.17321645693606985,
      "learning_rate": 9.997347891214684e-05,
      "loss": 0.0382,
      "step": 9720
    },
    {
      "epoch": 0.031168,
      "grad_norm": 0.17721735776386274,
      "learning_rate": 9.997336966928252e-05,
      "loss": 0.0322,
      "step": 9740
    },
    {
      "epoch": 0.031232,
      "grad_norm": 0.1426680554326767,
      "learning_rate": 9.997326020194946e-05,
      "loss": 0.0344,
      "step": 9760
    },
    {
      "epoch": 0.031296,
      "grad_norm": 0.17827572540853703,
      "learning_rate": 9.99731505101482e-05,
      "loss": 0.0345,
      "step": 9780
    },
    {
      "epoch": 0.03136,
      "grad_norm": 0.13427295705265216,
      "learning_rate": 9.99730405938792e-05,
      "loss": 0.0361,
      "step": 9800
    },
    {
      "epoch": 0.031424,
      "grad_norm": 0.14884346388748904,
      "learning_rate": 9.997293045314297e-05,
      "loss": 0.0384,
      "step": 9820
    },
    {
      "epoch": 0.031488,
      "grad_norm": 0.15837656694355667,
      "learning_rate": 9.997282008794e-05,
      "loss": 0.0381,
      "step": 9840
    },
    {
      "epoch": 0.031552,
      "grad_norm": 0.19414602443576,
      "learning_rate": 9.997270949827077e-05,
      "loss": 0.0346,
      "step": 9860
    },
    {
      "epoch": 0.031616,
      "grad_norm": 0.12885342143744724,
      "learning_rate": 9.997259868413579e-05,
      "loss": 0.0402,
      "step": 9880
    },
    {
      "epoch": 0.03168,
      "grad_norm": 0.12212417344477669,
      "learning_rate": 9.997248764553559e-05,
      "loss": 0.0395,
      "step": 9900
    },
    {
      "epoch": 0.031744,
      "grad_norm": 0.19405930298485896,
      "learning_rate": 9.997237638247061e-05,
      "loss": 0.0344,
      "step": 9920
    },
    {
      "epoch": 0.031808,
      "grad_norm": 0.13231332051530995,
      "learning_rate": 9.997226489494139e-05,
      "loss": 0.0359,
      "step": 9940
    },
    {
      "epoch": 0.031872,
      "grad_norm": 0.27203157110079923,
      "learning_rate": 9.997215318294842e-05,
      "loss": 0.0393,
      "step": 9960
    },
    {
      "epoch": 0.031936,
      "grad_norm": 0.20637275638754626,
      "learning_rate": 9.99720412464922e-05,
      "loss": 0.0372,
      "step": 9980
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.2958814261986718,
      "learning_rate": 9.997192908557323e-05,
      "loss": 0.0351,
      "step": 10000
    },
    {
      "epoch": 0.032064,
      "grad_norm": 0.12364219590025602,
      "learning_rate": 9.9971816700192e-05,
      "loss": 0.0383,
      "step": 10020
    },
    {
      "epoch": 0.032128,
      "grad_norm": 0.17885229131911337,
      "learning_rate": 9.997170409034905e-05,
      "loss": 0.0431,
      "step": 10040
    },
    {
      "epoch": 0.032192,
      "grad_norm": 0.13989907836322624,
      "learning_rate": 9.997159125604487e-05,
      "loss": 0.0429,
      "step": 10060
    },
    {
      "epoch": 0.032256,
      "grad_norm": 0.22538516370013106,
      "learning_rate": 9.997147819727996e-05,
      "loss": 0.0423,
      "step": 10080
    },
    {
      "epoch": 0.03232,
      "grad_norm": 0.24523823598018699,
      "learning_rate": 9.997136491405482e-05,
      "loss": 0.0374,
      "step": 10100
    },
    {
      "epoch": 0.032384,
      "grad_norm": 0.16486170543283055,
      "learning_rate": 9.997125140636999e-05,
      "loss": 0.0371,
      "step": 10120
    },
    {
      "epoch": 0.032448,
      "grad_norm": 0.12265271421309225,
      "learning_rate": 9.997113767422595e-05,
      "loss": 0.0365,
      "step": 10140
    },
    {
      "epoch": 0.032512,
      "grad_norm": 0.10543952055200029,
      "learning_rate": 9.997102371762321e-05,
      "loss": 0.0381,
      "step": 10160
    },
    {
      "epoch": 0.032576,
      "grad_norm": 0.13709696412143763,
      "learning_rate": 9.997090953656232e-05,
      "loss": 0.038,
      "step": 10180
    },
    {
      "epoch": 0.03264,
      "grad_norm": 0.20515581508288788,
      "learning_rate": 9.997079513104375e-05,
      "loss": 0.0357,
      "step": 10200
    },
    {
      "epoch": 0.032704,
      "grad_norm": 0.11840899918486995,
      "learning_rate": 9.997068050106803e-05,
      "loss": 0.0386,
      "step": 10220
    },
    {
      "epoch": 0.032768,
      "grad_norm": 0.15197883471104304,
      "learning_rate": 9.997056564663568e-05,
      "loss": 0.0397,
      "step": 10240
    },
    {
      "epoch": 0.032832,
      "grad_norm": 0.11968339947972821,
      "learning_rate": 9.997045056774721e-05,
      "loss": 0.0387,
      "step": 10260
    },
    {
      "epoch": 0.032896,
      "grad_norm": 0.11173079165222735,
      "learning_rate": 9.997033526440313e-05,
      "loss": 0.0366,
      "step": 10280
    },
    {
      "epoch": 0.03296,
      "grad_norm": 0.21754134746478943,
      "learning_rate": 9.997021973660399e-05,
      "loss": 0.038,
      "step": 10300
    },
    {
      "epoch": 0.033024,
      "grad_norm": 0.11098360085700987,
      "learning_rate": 9.997010398435027e-05,
      "loss": 0.0349,
      "step": 10320
    },
    {
      "epoch": 0.033088,
      "grad_norm": 0.18338490217913303,
      "learning_rate": 9.99699880076425e-05,
      "loss": 0.0348,
      "step": 10340
    },
    {
      "epoch": 0.033152,
      "grad_norm": 0.125163022746929,
      "learning_rate": 9.99698718064812e-05,
      "loss": 0.0373,
      "step": 10360
    },
    {
      "epoch": 0.033216,
      "grad_norm": 0.15270035747162478,
      "learning_rate": 9.996975538086692e-05,
      "loss": 0.0412,
      "step": 10380
    },
    {
      "epoch": 0.03328,
      "grad_norm": 0.21127911707115204,
      "learning_rate": 9.996963873080013e-05,
      "loss": 0.0402,
      "step": 10400
    },
    {
      "epoch": 0.033344,
      "grad_norm": 0.20163107835361802,
      "learning_rate": 9.996952185628142e-05,
      "loss": 0.0404,
      "step": 10420
    },
    {
      "epoch": 0.033408,
      "grad_norm": 0.16634817109058345,
      "learning_rate": 9.996940475731126e-05,
      "loss": 0.0345,
      "step": 10440
    },
    {
      "epoch": 0.033472,
      "grad_norm": 0.15359154199442276,
      "learning_rate": 9.99692874338902e-05,
      "loss": 0.0385,
      "step": 10460
    },
    {
      "epoch": 0.033536,
      "grad_norm": 0.13446380160504812,
      "learning_rate": 9.996916988601875e-05,
      "loss": 0.0394,
      "step": 10480
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.13905733768668546,
      "learning_rate": 9.996905211369748e-05,
      "loss": 0.0349,
      "step": 10500
    },
    {
      "epoch": 0.033664,
      "grad_norm": 0.12568947357166596,
      "learning_rate": 9.996893411692685e-05,
      "loss": 0.0361,
      "step": 10520
    },
    {
      "epoch": 0.033728,
      "grad_norm": 0.14670008087388123,
      "learning_rate": 9.996881589570746e-05,
      "loss": 0.0361,
      "step": 10540
    },
    {
      "epoch": 0.033792,
      "grad_norm": 0.20401259733301266,
      "learning_rate": 9.99686974500398e-05,
      "loss": 0.0373,
      "step": 10560
    },
    {
      "epoch": 0.033856,
      "grad_norm": 0.13135706559737265,
      "learning_rate": 9.996857877992441e-05,
      "loss": 0.0385,
      "step": 10580
    },
    {
      "epoch": 0.03392,
      "grad_norm": 0.1589052289554786,
      "learning_rate": 9.996845988536184e-05,
      "loss": 0.0368,
      "step": 10600
    },
    {
      "epoch": 0.033984,
      "grad_norm": 0.11622772158064934,
      "learning_rate": 9.996834076635258e-05,
      "loss": 0.0408,
      "step": 10620
    },
    {
      "epoch": 0.034048,
      "grad_norm": 0.11941090947601589,
      "learning_rate": 9.996822142289722e-05,
      "loss": 0.0447,
      "step": 10640
    },
    {
      "epoch": 0.034112,
      "grad_norm": 0.15993170096621553,
      "learning_rate": 9.996810185499625e-05,
      "loss": 0.042,
      "step": 10660
    },
    {
      "epoch": 0.034176,
      "grad_norm": 0.11993579024688374,
      "learning_rate": 9.996798206265025e-05,
      "loss": 0.04,
      "step": 10680
    },
    {
      "epoch": 0.03424,
      "grad_norm": 0.16345538737576662,
      "learning_rate": 9.996786204585973e-05,
      "loss": 0.0366,
      "step": 10700
    },
    {
      "epoch": 0.034304,
      "grad_norm": 0.1517473128315017,
      "learning_rate": 9.996774180462523e-05,
      "loss": 0.038,
      "step": 10720
    },
    {
      "epoch": 0.034368,
      "grad_norm": 0.15938278679162105,
      "learning_rate": 9.996762133894731e-05,
      "loss": 0.0369,
      "step": 10740
    },
    {
      "epoch": 0.034432,
      "grad_norm": 0.20983278814290815,
      "learning_rate": 9.996750064882647e-05,
      "loss": 0.0367,
      "step": 10760
    },
    {
      "epoch": 0.034496,
      "grad_norm": 0.17542033624357714,
      "learning_rate": 9.99673797342633e-05,
      "loss": 0.0394,
      "step": 10780
    },
    {
      "epoch": 0.03456,
      "grad_norm": 0.14427713679071308,
      "learning_rate": 9.996725859525831e-05,
      "loss": 0.0397,
      "step": 10800
    },
    {
      "epoch": 0.034624,
      "grad_norm": 0.22470113899554028,
      "learning_rate": 9.996713723181206e-05,
      "loss": 0.0401,
      "step": 10820
    },
    {
      "epoch": 0.034688,
      "grad_norm": 0.1279397128228936,
      "learning_rate": 9.996701564392508e-05,
      "loss": 0.0344,
      "step": 10840
    },
    {
      "epoch": 0.034752,
      "grad_norm": 0.20466611619925004,
      "learning_rate": 9.996689383159794e-05,
      "loss": 0.0377,
      "step": 10860
    },
    {
      "epoch": 0.034816,
      "grad_norm": 0.13577572864114776,
      "learning_rate": 9.996677179483117e-05,
      "loss": 0.0378,
      "step": 10880
    },
    {
      "epoch": 0.03488,
      "grad_norm": 0.15008175303778848,
      "learning_rate": 9.996664953362533e-05,
      "loss": 0.0376,
      "step": 10900
    },
    {
      "epoch": 0.034944,
      "grad_norm": 0.11314388449011832,
      "learning_rate": 9.996652704798095e-05,
      "loss": 0.0387,
      "step": 10920
    },
    {
      "epoch": 0.035008,
      "grad_norm": 0.11986157460647344,
      "learning_rate": 9.996640433789858e-05,
      "loss": 0.0364,
      "step": 10940
    },
    {
      "epoch": 0.035072,
      "grad_norm": 0.1463074937022462,
      "learning_rate": 9.99662814033788e-05,
      "loss": 0.0367,
      "step": 10960
    },
    {
      "epoch": 0.035136,
      "grad_norm": 0.15043332572236226,
      "learning_rate": 9.996615824442215e-05,
      "loss": 0.0396,
      "step": 10980
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.10099443767247628,
      "learning_rate": 9.996603486102918e-05,
      "loss": 0.0375,
      "step": 11000
    },
    {
      "epoch": 0.035264,
      "grad_norm": 0.15083972003614504,
      "learning_rate": 9.996591125320043e-05,
      "loss": 0.0351,
      "step": 11020
    },
    {
      "epoch": 0.035328,
      "grad_norm": 0.1644775886015293,
      "learning_rate": 9.996578742093646e-05,
      "loss": 0.0339,
      "step": 11040
    },
    {
      "epoch": 0.035392,
      "grad_norm": 0.13842930352494692,
      "learning_rate": 9.996566336423784e-05,
      "loss": 0.0351,
      "step": 11060
    },
    {
      "epoch": 0.035456,
      "grad_norm": 0.2209448933078816,
      "learning_rate": 9.996553908310514e-05,
      "loss": 0.0369,
      "step": 11080
    },
    {
      "epoch": 0.03552,
      "grad_norm": 0.1155365569576674,
      "learning_rate": 9.996541457753888e-05,
      "loss": 0.0373,
      "step": 11100
    },
    {
      "epoch": 0.035584,
      "grad_norm": 0.2853021855451896,
      "learning_rate": 9.996528984753964e-05,
      "loss": 0.0378,
      "step": 11120
    },
    {
      "epoch": 0.035648,
      "grad_norm": 0.20305993618994458,
      "learning_rate": 9.9965164893108e-05,
      "loss": 0.0354,
      "step": 11140
    },
    {
      "epoch": 0.035712,
      "grad_norm": 0.17255199154270306,
      "learning_rate": 9.996503971424446e-05,
      "loss": 0.0367,
      "step": 11160
    },
    {
      "epoch": 0.035776,
      "grad_norm": 0.12756373090930814,
      "learning_rate": 9.996491431094966e-05,
      "loss": 0.0346,
      "step": 11180
    },
    {
      "epoch": 0.03584,
      "grad_norm": 0.15187899484098727,
      "learning_rate": 9.99647886832241e-05,
      "loss": 0.0375,
      "step": 11200
    },
    {
      "epoch": 0.035904,
      "grad_norm": 0.11290906265087604,
      "learning_rate": 9.996466283106837e-05,
      "loss": 0.0338,
      "step": 11220
    },
    {
      "epoch": 0.035968,
      "grad_norm": 0.26856536016750016,
      "learning_rate": 9.996453675448306e-05,
      "loss": 0.0335,
      "step": 11240
    },
    {
      "epoch": 0.036032,
      "grad_norm": 0.18351464787025443,
      "learning_rate": 9.996441045346869e-05,
      "loss": 0.0353,
      "step": 11260
    },
    {
      "epoch": 0.036096,
      "grad_norm": 0.1398278453650458,
      "learning_rate": 9.996428392802586e-05,
      "loss": 0.0393,
      "step": 11280
    },
    {
      "epoch": 0.03616,
      "grad_norm": 0.22785679669373496,
      "learning_rate": 9.996415717815511e-05,
      "loss": 0.0378,
      "step": 11300
    },
    {
      "epoch": 0.036224,
      "grad_norm": 0.1491796734652503,
      "learning_rate": 9.996403020385705e-05,
      "loss": 0.032,
      "step": 11320
    },
    {
      "epoch": 0.036288,
      "grad_norm": 0.13241352469233025,
      "learning_rate": 9.996390300513221e-05,
      "loss": 0.036,
      "step": 11340
    },
    {
      "epoch": 0.036352,
      "grad_norm": 0.18554557508019476,
      "learning_rate": 9.996377558198118e-05,
      "loss": 0.0397,
      "step": 11360
    },
    {
      "epoch": 0.036416,
      "grad_norm": 0.12922688276727173,
      "learning_rate": 9.996364793440454e-05,
      "loss": 0.0361,
      "step": 11380
    },
    {
      "epoch": 0.03648,
      "grad_norm": 0.1331412041661368,
      "learning_rate": 9.996352006240284e-05,
      "loss": 0.0406,
      "step": 11400
    },
    {
      "epoch": 0.036544,
      "grad_norm": 0.18744377168059323,
      "learning_rate": 9.996339196597668e-05,
      "loss": 0.0358,
      "step": 11420
    },
    {
      "epoch": 0.036608,
      "grad_norm": 0.1250934733546199,
      "learning_rate": 9.996326364512662e-05,
      "loss": 0.0371,
      "step": 11440
    },
    {
      "epoch": 0.036672,
      "grad_norm": 0.17539652306727843,
      "learning_rate": 9.996313509985324e-05,
      "loss": 0.0354,
      "step": 11460
    },
    {
      "epoch": 0.036736,
      "grad_norm": 0.15043986350528155,
      "learning_rate": 9.996300633015712e-05,
      "loss": 0.0362,
      "step": 11480
    },
    {
      "epoch": 0.0368,
      "grad_norm": 0.1501145494743168,
      "learning_rate": 9.996287733603884e-05,
      "loss": 0.0381,
      "step": 11500
    },
    {
      "epoch": 0.036864,
      "grad_norm": 0.14278778458523822,
      "learning_rate": 9.996274811749896e-05,
      "loss": 0.0368,
      "step": 11520
    },
    {
      "epoch": 0.036928,
      "grad_norm": 0.11566950436731031,
      "learning_rate": 9.996261867453808e-05,
      "loss": 0.0378,
      "step": 11540
    },
    {
      "epoch": 0.036992,
      "grad_norm": 0.10269585619883936,
      "learning_rate": 9.996248900715678e-05,
      "loss": 0.0345,
      "step": 11560
    },
    {
      "epoch": 0.037056,
      "grad_norm": 0.1189438585435548,
      "learning_rate": 9.996235911535563e-05,
      "loss": 0.033,
      "step": 11580
    },
    {
      "epoch": 0.03712,
      "grad_norm": 0.14472258498493745,
      "learning_rate": 9.996222899913525e-05,
      "loss": 0.0369,
      "step": 11600
    },
    {
      "epoch": 0.037184,
      "grad_norm": 0.14041796430376102,
      "learning_rate": 9.996209865849617e-05,
      "loss": 0.0376,
      "step": 11620
    },
    {
      "epoch": 0.037248,
      "grad_norm": 0.17879560074533937,
      "learning_rate": 9.9961968093439e-05,
      "loss": 0.035,
      "step": 11640
    },
    {
      "epoch": 0.037312,
      "grad_norm": 0.13379985074251763,
      "learning_rate": 9.996183730396435e-05,
      "loss": 0.0378,
      "step": 11660
    },
    {
      "epoch": 0.037376,
      "grad_norm": 0.16341117755702472,
      "learning_rate": 9.996170629007277e-05,
      "loss": 0.0371,
      "step": 11680
    },
    {
      "epoch": 0.03744,
      "grad_norm": 0.10811802761049413,
      "learning_rate": 9.996157505176489e-05,
      "loss": 0.0363,
      "step": 11700
    },
    {
      "epoch": 0.037504,
      "grad_norm": 0.19865000377822636,
      "learning_rate": 9.996144358904125e-05,
      "loss": 0.0415,
      "step": 11720
    },
    {
      "epoch": 0.037568,
      "grad_norm": 0.1743233130132439,
      "learning_rate": 9.996131190190247e-05,
      "loss": 0.0385,
      "step": 11740
    },
    {
      "epoch": 0.037632,
      "grad_norm": 0.1937270097260595,
      "learning_rate": 9.996117999034915e-05,
      "loss": 0.0377,
      "step": 11760
    },
    {
      "epoch": 0.037696,
      "grad_norm": 0.1389416843095414,
      "learning_rate": 9.996104785438186e-05,
      "loss": 0.0411,
      "step": 11780
    },
    {
      "epoch": 0.03776,
      "grad_norm": 0.22105704341503526,
      "learning_rate": 9.996091549400119e-05,
      "loss": 0.0377,
      "step": 11800
    },
    {
      "epoch": 0.037824,
      "grad_norm": 0.2151287638414484,
      "learning_rate": 9.996078290920777e-05,
      "loss": 0.0345,
      "step": 11820
    },
    {
      "epoch": 0.037888,
      "grad_norm": 0.29197368667274337,
      "learning_rate": 9.996065010000216e-05,
      "loss": 0.0387,
      "step": 11840
    },
    {
      "epoch": 0.037952,
      "grad_norm": 0.1858849790645508,
      "learning_rate": 9.996051706638499e-05,
      "loss": 0.0378,
      "step": 11860
    },
    {
      "epoch": 0.038016,
      "grad_norm": 0.1490594040314182,
      "learning_rate": 9.99603838083568e-05,
      "loss": 0.0389,
      "step": 11880
    },
    {
      "epoch": 0.03808,
      "grad_norm": 0.12239341154660383,
      "learning_rate": 9.996025032591825e-05,
      "loss": 0.0394,
      "step": 11900
    },
    {
      "epoch": 0.038144,
      "grad_norm": 0.16957183037525053,
      "learning_rate": 9.996011661906991e-05,
      "loss": 0.035,
      "step": 11920
    },
    {
      "epoch": 0.038208,
      "grad_norm": 0.2487795404791005,
      "learning_rate": 9.99599826878124e-05,
      "loss": 0.0347,
      "step": 11940
    },
    {
      "epoch": 0.038272,
      "grad_norm": 0.15786567308373664,
      "learning_rate": 9.995984853214628e-05,
      "loss": 0.0349,
      "step": 11960
    },
    {
      "epoch": 0.038336,
      "grad_norm": 0.1668357575367027,
      "learning_rate": 9.995971415207219e-05,
      "loss": 0.0402,
      "step": 11980
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.09726897130178946,
      "learning_rate": 9.995957954759071e-05,
      "loss": 0.0381,
      "step": 12000
    },
    {
      "epoch": 0.038464,
      "grad_norm": 0.12913885345677378,
      "learning_rate": 9.995944471870249e-05,
      "loss": 0.0325,
      "step": 12020
    },
    {
      "epoch": 0.038528,
      "grad_norm": 0.12487863571128327,
      "learning_rate": 9.995930966540809e-05,
      "loss": 0.0344,
      "step": 12040
    },
    {
      "epoch": 0.038592,
      "grad_norm": 0.10778044087186125,
      "learning_rate": 9.995917438770813e-05,
      "loss": 0.0385,
      "step": 12060
    },
    {
      "epoch": 0.038656,
      "grad_norm": 0.11646116029395205,
      "learning_rate": 9.99590388856032e-05,
      "loss": 0.037,
      "step": 12080
    },
    {
      "epoch": 0.03872,
      "grad_norm": 0.15839744786525423,
      "learning_rate": 9.995890315909395e-05,
      "loss": 0.0409,
      "step": 12100
    },
    {
      "epoch": 0.038784,
      "grad_norm": 0.09747908143672461,
      "learning_rate": 9.995876720818096e-05,
      "loss": 0.0355,
      "step": 12120
    },
    {
      "epoch": 0.038848,
      "grad_norm": 0.096243765031423,
      "learning_rate": 9.995863103286484e-05,
      "loss": 0.0362,
      "step": 12140
    },
    {
      "epoch": 0.038912,
      "grad_norm": 0.1607641957298064,
      "learning_rate": 9.995849463314622e-05,
      "loss": 0.0355,
      "step": 12160
    },
    {
      "epoch": 0.038976,
      "grad_norm": 0.16114503053227267,
      "learning_rate": 9.99583580090257e-05,
      "loss": 0.0372,
      "step": 12180
    },
    {
      "epoch": 0.03904,
      "grad_norm": 0.10821751829934675,
      "learning_rate": 9.995822116050389e-05,
      "loss": 0.0353,
      "step": 12200
    },
    {
      "epoch": 0.039104,
      "grad_norm": 0.1446137506165817,
      "learning_rate": 9.99580840875814e-05,
      "loss": 0.0353,
      "step": 12220
    },
    {
      "epoch": 0.039168,
      "grad_norm": 0.21004650125979177,
      "learning_rate": 9.995794679025887e-05,
      "loss": 0.0385,
      "step": 12240
    },
    {
      "epoch": 0.039232,
      "grad_norm": 0.13314580921705313,
      "learning_rate": 9.99578092685369e-05,
      "loss": 0.0368,
      "step": 12260
    },
    {
      "epoch": 0.039296,
      "grad_norm": 0.1784081782963823,
      "learning_rate": 9.99576715224161e-05,
      "loss": 0.0359,
      "step": 12280
    },
    {
      "epoch": 0.03936,
      "grad_norm": 0.11129020315145771,
      "learning_rate": 9.995753355189711e-05,
      "loss": 0.0404,
      "step": 12300
    },
    {
      "epoch": 0.039424,
      "grad_norm": 0.130097130773632,
      "learning_rate": 9.995739535698054e-05,
      "loss": 0.0348,
      "step": 12320
    },
    {
      "epoch": 0.039488,
      "grad_norm": 0.10320651192456066,
      "learning_rate": 9.9957256937667e-05,
      "loss": 0.0367,
      "step": 12340
    },
    {
      "epoch": 0.039552,
      "grad_norm": 0.15977153292603796,
      "learning_rate": 9.995711829395711e-05,
      "loss": 0.0397,
      "step": 12360
    },
    {
      "epoch": 0.039616,
      "grad_norm": 0.11581780973697793,
      "learning_rate": 9.995697942585153e-05,
      "loss": 0.0356,
      "step": 12380
    },
    {
      "epoch": 0.03968,
      "grad_norm": 0.18987360767579936,
      "learning_rate": 9.995684033335084e-05,
      "loss": 0.0384,
      "step": 12400
    },
    {
      "epoch": 0.039744,
      "grad_norm": 0.35354079442981895,
      "learning_rate": 9.995670101645569e-05,
      "loss": 0.0357,
      "step": 12420
    },
    {
      "epoch": 0.039808,
      "grad_norm": 0.1314357442217599,
      "learning_rate": 9.99565614751667e-05,
      "loss": 0.0387,
      "step": 12440
    },
    {
      "epoch": 0.039872,
      "grad_norm": 0.13040224392602923,
      "learning_rate": 9.995642170948449e-05,
      "loss": 0.0351,
      "step": 12460
    },
    {
      "epoch": 0.039936,
      "grad_norm": 0.11769237969923194,
      "learning_rate": 9.995628171940967e-05,
      "loss": 0.0405,
      "step": 12480
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11511343998788336,
      "learning_rate": 9.995614150494293e-05,
      "loss": 0.0352,
      "step": 12500
    },
    {
      "epoch": 0.040064,
      "grad_norm": 0.18369832965536284,
      "learning_rate": 9.995600106608483e-05,
      "loss": 0.0339,
      "step": 12520
    },
    {
      "epoch": 0.040128,
      "grad_norm": 0.12883805811225815,
      "learning_rate": 9.995586040283604e-05,
      "loss": 0.0342,
      "step": 12540
    },
    {
      "epoch": 0.040192,
      "grad_norm": 0.15636426694886893,
      "learning_rate": 9.99557195151972e-05,
      "loss": 0.0346,
      "step": 12560
    },
    {
      "epoch": 0.040256,
      "grad_norm": 0.18796133373192,
      "learning_rate": 9.995557840316891e-05,
      "loss": 0.032,
      "step": 12580
    },
    {
      "epoch": 0.04032,
      "grad_norm": 0.0909389337159971,
      "learning_rate": 9.995543706675184e-05,
      "loss": 0.0371,
      "step": 12600
    },
    {
      "epoch": 0.040384,
      "grad_norm": 0.12759561965612742,
      "learning_rate": 9.995529550594658e-05,
      "loss": 0.0361,
      "step": 12620
    },
    {
      "epoch": 0.040448,
      "grad_norm": 0.242362791840337,
      "learning_rate": 9.995515372075379e-05,
      "loss": 0.0353,
      "step": 12640
    },
    {
      "epoch": 0.040512,
      "grad_norm": 0.11302460623556791,
      "learning_rate": 9.995501171117412e-05,
      "loss": 0.0334,
      "step": 12660
    },
    {
      "epoch": 0.040576,
      "grad_norm": 0.1050608081530142,
      "learning_rate": 9.995486947720821e-05,
      "loss": 0.036,
      "step": 12680
    },
    {
      "epoch": 0.04064,
      "grad_norm": 0.13333935924497028,
      "learning_rate": 9.995472701885667e-05,
      "loss": 0.0336,
      "step": 12700
    },
    {
      "epoch": 0.040704,
      "grad_norm": 0.11206509928816853,
      "learning_rate": 9.995458433612015e-05,
      "loss": 0.0354,
      "step": 12720
    },
    {
      "epoch": 0.040768,
      "grad_norm": 0.12775654590168317,
      "learning_rate": 9.99544414289993e-05,
      "loss": 0.0367,
      "step": 12740
    },
    {
      "epoch": 0.040832,
      "grad_norm": 0.3598468765640993,
      "learning_rate": 9.995429829749474e-05,
      "loss": 0.0344,
      "step": 12760
    },
    {
      "epoch": 0.040896,
      "grad_norm": 0.21642176816991943,
      "learning_rate": 9.995415494160716e-05,
      "loss": 0.0325,
      "step": 12780
    },
    {
      "epoch": 0.04096,
      "grad_norm": 0.10037960341475474,
      "learning_rate": 9.995401136133715e-05,
      "loss": 0.034,
      "step": 12800
    },
    {
      "epoch": 0.041024,
      "grad_norm": 0.09821299251650809,
      "learning_rate": 9.995386755668538e-05,
      "loss": 0.0377,
      "step": 12820
    },
    {
      "epoch": 0.041088,
      "grad_norm": 0.10789084474365261,
      "learning_rate": 9.995372352765251e-05,
      "loss": 0.0329,
      "step": 12840
    },
    {
      "epoch": 0.041152,
      "grad_norm": 0.1374612015625052,
      "learning_rate": 9.995357927423917e-05,
      "loss": 0.032,
      "step": 12860
    },
    {
      "epoch": 0.041216,
      "grad_norm": 0.17383480275837235,
      "learning_rate": 9.995343479644601e-05,
      "loss": 0.035,
      "step": 12880
    },
    {
      "epoch": 0.04128,
      "grad_norm": 0.1852959768761994,
      "learning_rate": 9.995329009427367e-05,
      "loss": 0.0378,
      "step": 12900
    },
    {
      "epoch": 0.041344,
      "grad_norm": 0.09687821646109633,
      "learning_rate": 9.995314516772282e-05,
      "loss": 0.0354,
      "step": 12920
    },
    {
      "epoch": 0.041408,
      "grad_norm": 0.1267931723534882,
      "learning_rate": 9.99530000167941e-05,
      "loss": 0.0352,
      "step": 12940
    },
    {
      "epoch": 0.041472,
      "grad_norm": 0.1682029816171222,
      "learning_rate": 9.995285464148815e-05,
      "loss": 0.036,
      "step": 12960
    },
    {
      "epoch": 0.041536,
      "grad_norm": 0.1579164970140408,
      "learning_rate": 9.995270904180564e-05,
      "loss": 0.0361,
      "step": 12980
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.19650454272083956,
      "learning_rate": 9.995256321774722e-05,
      "loss": 0.035,
      "step": 13000
    },
    {
      "epoch": 0.041664,
      "grad_norm": 0.10202358779641256,
      "learning_rate": 9.995241716931353e-05,
      "loss": 0.0321,
      "step": 13020
    },
    {
      "epoch": 0.041728,
      "grad_norm": 0.09262351926472484,
      "learning_rate": 9.995227089650527e-05,
      "loss": 0.0339,
      "step": 13040
    },
    {
      "epoch": 0.041792,
      "grad_norm": 0.12508529077650649,
      "learning_rate": 9.995212439932304e-05,
      "loss": 0.038,
      "step": 13060
    },
    {
      "epoch": 0.041856,
      "grad_norm": 0.17747845396967746,
      "learning_rate": 9.995197767776754e-05,
      "loss": 0.0366,
      "step": 13080
    },
    {
      "epoch": 0.04192,
      "grad_norm": 0.13880164195357586,
      "learning_rate": 9.99518307318394e-05,
      "loss": 0.0364,
      "step": 13100
    },
    {
      "epoch": 0.041984,
      "grad_norm": 0.16069790135376683,
      "learning_rate": 9.99516835615393e-05,
      "loss": 0.0336,
      "step": 13120
    },
    {
      "epoch": 0.042048,
      "grad_norm": 0.26908374553814524,
      "learning_rate": 9.99515361668679e-05,
      "loss": 0.0399,
      "step": 13140
    },
    {
      "epoch": 0.042112,
      "grad_norm": 0.09586578069757219,
      "learning_rate": 9.995138854782586e-05,
      "loss": 0.0378,
      "step": 13160
    },
    {
      "epoch": 0.042176,
      "grad_norm": 0.09558556058525725,
      "learning_rate": 9.995124070441384e-05,
      "loss": 0.0381,
      "step": 13180
    },
    {
      "epoch": 0.04224,
      "grad_norm": 0.10318675545129466,
      "learning_rate": 9.995109263663249e-05,
      "loss": 0.0335,
      "step": 13200
    },
    {
      "epoch": 0.042304,
      "grad_norm": 0.12935872362020825,
      "learning_rate": 9.99509443444825e-05,
      "loss": 0.0334,
      "step": 13220
    },
    {
      "epoch": 0.042368,
      "grad_norm": 0.10901057323532523,
      "learning_rate": 9.995079582796451e-05,
      "loss": 0.0382,
      "step": 13240
    },
    {
      "epoch": 0.042432,
      "grad_norm": 0.17519822237595992,
      "learning_rate": 9.995064708707924e-05,
      "loss": 0.0364,
      "step": 13260
    },
    {
      "epoch": 0.042496,
      "grad_norm": 0.10232396388378308,
      "learning_rate": 9.995049812182729e-05,
      "loss": 0.0334,
      "step": 13280
    },
    {
      "epoch": 0.04256,
      "grad_norm": 0.0868475409499182,
      "learning_rate": 9.995034893220936e-05,
      "loss": 0.0327,
      "step": 13300
    },
    {
      "epoch": 0.042624,
      "grad_norm": 0.18061253806674193,
      "learning_rate": 9.995019951822612e-05,
      "loss": 0.0356,
      "step": 13320
    },
    {
      "epoch": 0.042688,
      "grad_norm": 0.13032878041209478,
      "learning_rate": 9.995004987987827e-05,
      "loss": 0.035,
      "step": 13340
    },
    {
      "epoch": 0.042752,
      "grad_norm": 0.15027911411969905,
      "learning_rate": 9.994990001716641e-05,
      "loss": 0.0371,
      "step": 13360
    },
    {
      "epoch": 0.042816,
      "grad_norm": 0.191858693639075,
      "learning_rate": 9.994974993009128e-05,
      "loss": 0.0374,
      "step": 13380
    },
    {
      "epoch": 0.04288,
      "grad_norm": 0.09444734453085897,
      "learning_rate": 9.994959961865353e-05,
      "loss": 0.0336,
      "step": 13400
    },
    {
      "epoch": 0.042944,
      "grad_norm": 0.14032247873655493,
      "learning_rate": 9.994944908285383e-05,
      "loss": 0.032,
      "step": 13420
    },
    {
      "epoch": 0.043008,
      "grad_norm": 0.1461852221174766,
      "learning_rate": 9.994929832269286e-05,
      "loss": 0.0345,
      "step": 13440
    },
    {
      "epoch": 0.043072,
      "grad_norm": 0.12743633095403814,
      "learning_rate": 9.994914733817131e-05,
      "loss": 0.0381,
      "step": 13460
    },
    {
      "epoch": 0.043136,
      "grad_norm": 0.13410929776721572,
      "learning_rate": 9.994899612928983e-05,
      "loss": 0.0357,
      "step": 13480
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.11803197962502458,
      "learning_rate": 9.994884469604912e-05,
      "loss": 0.032,
      "step": 13500
    },
    {
      "epoch": 0.043264,
      "grad_norm": 0.1413821949222677,
      "learning_rate": 9.994869303844987e-05,
      "loss": 0.0367,
      "step": 13520
    },
    {
      "epoch": 0.043328,
      "grad_norm": 0.09181712940747241,
      "learning_rate": 9.994854115649274e-05,
      "loss": 0.035,
      "step": 13540
    },
    {
      "epoch": 0.043392,
      "grad_norm": 0.23561126650673253,
      "learning_rate": 9.994838905017842e-05,
      "loss": 0.0327,
      "step": 13560
    },
    {
      "epoch": 0.043456,
      "grad_norm": 0.11374922712779337,
      "learning_rate": 9.994823671950759e-05,
      "loss": 0.0413,
      "step": 13580
    },
    {
      "epoch": 0.04352,
      "grad_norm": 0.10043334848056061,
      "learning_rate": 9.994808416448095e-05,
      "loss": 0.0376,
      "step": 13600
    },
    {
      "epoch": 0.043584,
      "grad_norm": 0.17734292779521313,
      "learning_rate": 9.994793138509917e-05,
      "loss": 0.0372,
      "step": 13620
    },
    {
      "epoch": 0.043648,
      "grad_norm": 0.17902198716609471,
      "learning_rate": 9.994777838136293e-05,
      "loss": 0.0368,
      "step": 13640
    },
    {
      "epoch": 0.043712,
      "grad_norm": 0.14588501975238247,
      "learning_rate": 9.994762515327292e-05,
      "loss": 0.0366,
      "step": 13660
    },
    {
      "epoch": 0.043776,
      "grad_norm": 0.12233879784232168,
      "learning_rate": 9.994747170082986e-05,
      "loss": 0.0355,
      "step": 13680
    },
    {
      "epoch": 0.04384,
      "grad_norm": 0.11398598235919205,
      "learning_rate": 9.994731802403439e-05,
      "loss": 0.0401,
      "step": 13700
    },
    {
      "epoch": 0.043904,
      "grad_norm": 0.1847482394489853,
      "learning_rate": 9.994716412288722e-05,
      "loss": 0.0397,
      "step": 13720
    },
    {
      "epoch": 0.043968,
      "grad_norm": 0.16329704379135582,
      "learning_rate": 9.994700999738906e-05,
      "loss": 0.0356,
      "step": 13740
    },
    {
      "epoch": 0.044032,
      "grad_norm": 0.1160686238200498,
      "learning_rate": 9.994685564754058e-05,
      "loss": 0.0366,
      "step": 13760
    },
    {
      "epoch": 0.044096,
      "grad_norm": 0.1372646910801222,
      "learning_rate": 9.994670107334248e-05,
      "loss": 0.0342,
      "step": 13780
    },
    {
      "epoch": 0.04416,
      "grad_norm": 0.1310602022417257,
      "learning_rate": 9.994654627479547e-05,
      "loss": 0.0334,
      "step": 13800
    },
    {
      "epoch": 0.044224,
      "grad_norm": 0.12200065350511755,
      "learning_rate": 9.994639125190022e-05,
      "loss": 0.0343,
      "step": 13820
    },
    {
      "epoch": 0.044288,
      "grad_norm": 0.11151222748733197,
      "learning_rate": 9.994623600465743e-05,
      "loss": 0.0349,
      "step": 13840
    },
    {
      "epoch": 0.044352,
      "grad_norm": 0.13968436398067596,
      "learning_rate": 9.994608053306783e-05,
      "loss": 0.0372,
      "step": 13860
    },
    {
      "epoch": 0.044416,
      "grad_norm": 0.1647327315652881,
      "learning_rate": 9.994592483713205e-05,
      "loss": 0.0362,
      "step": 13880
    },
    {
      "epoch": 0.04448,
      "grad_norm": 0.12389698187463422,
      "learning_rate": 9.994576891685085e-05,
      "loss": 0.0373,
      "step": 13900
    },
    {
      "epoch": 0.044544,
      "grad_norm": 0.14478315360450453,
      "learning_rate": 9.994561277222494e-05,
      "loss": 0.0361,
      "step": 13920
    },
    {
      "epoch": 0.044608,
      "grad_norm": 0.1055836990591201,
      "learning_rate": 9.994545640325497e-05,
      "loss": 0.0371,
      "step": 13940
    },
    {
      "epoch": 0.044672,
      "grad_norm": 0.1356064229542883,
      "learning_rate": 9.994529980994166e-05,
      "loss": 0.0399,
      "step": 13960
    },
    {
      "epoch": 0.044736,
      "grad_norm": 0.20308119362177499,
      "learning_rate": 9.994514299228573e-05,
      "loss": 0.0354,
      "step": 13980
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.14355315034028093,
      "learning_rate": 9.994498595028787e-05,
      "loss": 0.0361,
      "step": 14000
    },
    {
      "epoch": 0.044864,
      "grad_norm": 0.17914259544217181,
      "learning_rate": 9.994482868394879e-05,
      "loss": 0.0369,
      "step": 14020
    },
    {
      "epoch": 0.044928,
      "grad_norm": 0.12291462569602868,
      "learning_rate": 9.99446711932692e-05,
      "loss": 0.0374,
      "step": 14040
    },
    {
      "epoch": 0.044992,
      "grad_norm": 0.09498172058438609,
      "learning_rate": 9.994451347824978e-05,
      "loss": 0.0336,
      "step": 14060
    },
    {
      "epoch": 0.045056,
      "grad_norm": 0.12742807010797344,
      "learning_rate": 9.994435553889127e-05,
      "loss": 0.0335,
      "step": 14080
    },
    {
      "epoch": 0.04512,
      "grad_norm": 0.11235963487548496,
      "learning_rate": 9.99441973751944e-05,
      "loss": 0.0332,
      "step": 14100
    },
    {
      "epoch": 0.045184,
      "grad_norm": 0.09177863575589583,
      "learning_rate": 9.994403898715983e-05,
      "loss": 0.0326,
      "step": 14120
    },
    {
      "epoch": 0.045248,
      "grad_norm": 0.10782303549293681,
      "learning_rate": 9.994388037478829e-05,
      "loss": 0.0315,
      "step": 14140
    },
    {
      "epoch": 0.045312,
      "grad_norm": 0.21523747883605912,
      "learning_rate": 9.994372153808049e-05,
      "loss": 0.0339,
      "step": 14160
    },
    {
      "epoch": 0.045376,
      "grad_norm": 0.2380971217420063,
      "learning_rate": 9.994356247703716e-05,
      "loss": 0.0381,
      "step": 14180
    },
    {
      "epoch": 0.04544,
      "grad_norm": 0.12826389598161775,
      "learning_rate": 9.9943403191659e-05,
      "loss": 0.0322,
      "step": 14200
    },
    {
      "epoch": 0.045504,
      "grad_norm": 0.09826603130800766,
      "learning_rate": 9.994324368194673e-05,
      "loss": 0.0328,
      "step": 14220
    },
    {
      "epoch": 0.045568,
      "grad_norm": 0.14196179017636382,
      "learning_rate": 9.994308394790107e-05,
      "loss": 0.0367,
      "step": 14240
    },
    {
      "epoch": 0.045632,
      "grad_norm": 0.1591334904686358,
      "learning_rate": 9.994292398952272e-05,
      "loss": 0.0385,
      "step": 14260
    },
    {
      "epoch": 0.045696,
      "grad_norm": 0.4321749968113467,
      "learning_rate": 9.994276380681242e-05,
      "loss": 0.0378,
      "step": 14280
    },
    {
      "epoch": 0.04576,
      "grad_norm": 0.1301194571474574,
      "learning_rate": 9.994260339977088e-05,
      "loss": 0.0373,
      "step": 14300
    },
    {
      "epoch": 0.045824,
      "grad_norm": 0.3169208377800778,
      "learning_rate": 9.994244276839881e-05,
      "loss": 0.0385,
      "step": 14320
    },
    {
      "epoch": 0.045888,
      "grad_norm": 0.13982955942076783,
      "learning_rate": 9.994228191269696e-05,
      "loss": 0.0383,
      "step": 14340
    },
    {
      "epoch": 0.045952,
      "grad_norm": 0.2025238367521379,
      "learning_rate": 9.994212083266602e-05,
      "loss": 0.0396,
      "step": 14360
    },
    {
      "epoch": 0.046016,
      "grad_norm": 0.20905358691622072,
      "learning_rate": 9.994195952830674e-05,
      "loss": 0.0365,
      "step": 14380
    },
    {
      "epoch": 0.04608,
      "grad_norm": 0.16460702466994437,
      "learning_rate": 9.994179799961982e-05,
      "loss": 0.0368,
      "step": 14400
    },
    {
      "epoch": 0.046144,
      "grad_norm": 0.10136251861787189,
      "learning_rate": 9.9941636246606e-05,
      "loss": 0.0357,
      "step": 14420
    },
    {
      "epoch": 0.046208,
      "grad_norm": 0.10912423146219984,
      "learning_rate": 9.994147426926601e-05,
      "loss": 0.0352,
      "step": 14440
    },
    {
      "epoch": 0.046272,
      "grad_norm": 0.1518821927874365,
      "learning_rate": 9.994131206760057e-05,
      "loss": 0.0337,
      "step": 14460
    },
    {
      "epoch": 0.046336,
      "grad_norm": 0.15836923553734494,
      "learning_rate": 9.994114964161043e-05,
      "loss": 0.0366,
      "step": 14480
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.12628893714016717,
      "learning_rate": 9.994098699129628e-05,
      "loss": 0.0374,
      "step": 14500
    },
    {
      "epoch": 0.046464,
      "grad_norm": 0.19217939962580072,
      "learning_rate": 9.994082411665888e-05,
      "loss": 0.0385,
      "step": 14520
    },
    {
      "epoch": 0.046528,
      "grad_norm": 0.22718867155352931,
      "learning_rate": 9.994066101769895e-05,
      "loss": 0.036,
      "step": 14540
    },
    {
      "epoch": 0.046592,
      "grad_norm": 0.1308520625037308,
      "learning_rate": 9.994049769441722e-05,
      "loss": 0.0395,
      "step": 14560
    },
    {
      "epoch": 0.046656,
      "grad_norm": 0.129888659257907,
      "learning_rate": 9.994033414681445e-05,
      "loss": 0.0365,
      "step": 14580
    },
    {
      "epoch": 0.04672,
      "grad_norm": 0.15055996336200528,
      "learning_rate": 9.994017037489134e-05,
      "loss": 0.0324,
      "step": 14600
    },
    {
      "epoch": 0.046784,
      "grad_norm": 0.13747723026693087,
      "learning_rate": 9.994000637864864e-05,
      "loss": 0.0388,
      "step": 14620
    },
    {
      "epoch": 0.046848,
      "grad_norm": 0.09469958422152938,
      "learning_rate": 9.993984215808707e-05,
      "loss": 0.035,
      "step": 14640
    },
    {
      "epoch": 0.046912,
      "grad_norm": 0.13825783147489862,
      "learning_rate": 9.99396777132074e-05,
      "loss": 0.0352,
      "step": 14660
    },
    {
      "epoch": 0.046976,
      "grad_norm": 0.17996395216847563,
      "learning_rate": 9.993951304401036e-05,
      "loss": 0.036,
      "step": 14680
    },
    {
      "epoch": 0.04704,
      "grad_norm": 0.10124427782083134,
      "learning_rate": 9.993934815049667e-05,
      "loss": 0.036,
      "step": 14700
    },
    {
      "epoch": 0.047104,
      "grad_norm": 0.1360054352481604,
      "learning_rate": 9.99391830326671e-05,
      "loss": 0.0359,
      "step": 14720
    },
    {
      "epoch": 0.047168,
      "grad_norm": 0.2222718662485625,
      "learning_rate": 9.993901769052235e-05,
      "loss": 0.0391,
      "step": 14740
    },
    {
      "epoch": 0.047232,
      "grad_norm": 0.1248655666639231,
      "learning_rate": 9.99388521240632e-05,
      "loss": 0.0342,
      "step": 14760
    },
    {
      "epoch": 0.047296,
      "grad_norm": 0.17962824406238426,
      "learning_rate": 9.993868633329038e-05,
      "loss": 0.0334,
      "step": 14780
    },
    {
      "epoch": 0.04736,
      "grad_norm": 0.12405559762782221,
      "learning_rate": 9.993852031820464e-05,
      "loss": 0.0352,
      "step": 14800
    },
    {
      "epoch": 0.047424,
      "grad_norm": 0.19324765245046804,
      "learning_rate": 9.993835407880671e-05,
      "loss": 0.0365,
      "step": 14820
    },
    {
      "epoch": 0.047488,
      "grad_norm": 0.10180881429208166,
      "learning_rate": 9.993818761509734e-05,
      "loss": 0.0353,
      "step": 14840
    },
    {
      "epoch": 0.047552,
      "grad_norm": 0.11535669705078191,
      "learning_rate": 9.993802092707731e-05,
      "loss": 0.0339,
      "step": 14860
    },
    {
      "epoch": 0.047616,
      "grad_norm": 0.12658588356783088,
      "learning_rate": 9.993785401474734e-05,
      "loss": 0.0323,
      "step": 14880
    },
    {
      "epoch": 0.04768,
      "grad_norm": 0.29463867532835775,
      "learning_rate": 9.993768687810817e-05,
      "loss": 0.035,
      "step": 14900
    },
    {
      "epoch": 0.047744,
      "grad_norm": 0.11828806598573192,
      "learning_rate": 9.993751951716058e-05,
      "loss": 0.0342,
      "step": 14920
    },
    {
      "epoch": 0.047808,
      "grad_norm": 0.1434447125662265,
      "learning_rate": 9.99373519319053e-05,
      "loss": 0.0348,
      "step": 14940
    },
    {
      "epoch": 0.047872,
      "grad_norm": 0.1140664304308181,
      "learning_rate": 9.993718412234308e-05,
      "loss": 0.0334,
      "step": 14960
    },
    {
      "epoch": 0.047936,
      "grad_norm": 0.16457879081691087,
      "learning_rate": 9.993701608847468e-05,
      "loss": 0.0348,
      "step": 14980
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.0872050972778628,
      "learning_rate": 9.993684783030088e-05,
      "loss": 0.0321,
      "step": 15000
    },
    {
      "epoch": 0.048064,
      "grad_norm": 0.10489291283346126,
      "learning_rate": 9.993667934782241e-05,
      "loss": 0.0355,
      "step": 15020
    },
    {
      "epoch": 0.048128,
      "grad_norm": 0.1549662440470864,
      "learning_rate": 9.993651064104002e-05,
      "loss": 0.0342,
      "step": 15040
    },
    {
      "epoch": 0.048192,
      "grad_norm": 0.14218942896035872,
      "learning_rate": 9.993634170995447e-05,
      "loss": 0.0357,
      "step": 15060
    },
    {
      "epoch": 0.048256,
      "grad_norm": 0.17901894353111553,
      "learning_rate": 9.993617255456654e-05,
      "loss": 0.0377,
      "step": 15080
    },
    {
      "epoch": 0.04832,
      "grad_norm": 0.11490904691496781,
      "learning_rate": 9.993600317487697e-05,
      "loss": 0.0396,
      "step": 15100
    },
    {
      "epoch": 0.048384,
      "grad_norm": 0.10158856657014537,
      "learning_rate": 9.993583357088654e-05,
      "loss": 0.0356,
      "step": 15120
    },
    {
      "epoch": 0.048448,
      "grad_norm": 0.14616911007947328,
      "learning_rate": 9.9935663742596e-05,
      "loss": 0.0344,
      "step": 15140
    },
    {
      "epoch": 0.048512,
      "grad_norm": 0.08066204896655678,
      "learning_rate": 9.99354936900061e-05,
      "loss": 0.0326,
      "step": 15160
    },
    {
      "epoch": 0.048576,
      "grad_norm": 0.15488480425431767,
      "learning_rate": 9.993532341311761e-05,
      "loss": 0.0374,
      "step": 15180
    },
    {
      "epoch": 0.04864,
      "grad_norm": 0.08807594781960085,
      "learning_rate": 9.993515291193132e-05,
      "loss": 0.0343,
      "step": 15200
    },
    {
      "epoch": 0.048704,
      "grad_norm": 0.10621529203093809,
      "learning_rate": 9.993498218644797e-05,
      "loss": 0.0347,
      "step": 15220
    },
    {
      "epoch": 0.048768,
      "grad_norm": 0.11430639371672982,
      "learning_rate": 9.993481123666833e-05,
      "loss": 0.0408,
      "step": 15240
    },
    {
      "epoch": 0.048832,
      "grad_norm": 0.36945995391943465,
      "learning_rate": 9.993464006259317e-05,
      "loss": 0.0348,
      "step": 15260
    },
    {
      "epoch": 0.048896,
      "grad_norm": 0.13269058485384,
      "learning_rate": 9.993446866422327e-05,
      "loss": 0.0349,
      "step": 15280
    },
    {
      "epoch": 0.04896,
      "grad_norm": 0.10589843117561257,
      "learning_rate": 9.993429704155938e-05,
      "loss": 0.038,
      "step": 15300
    },
    {
      "epoch": 0.049024,
      "grad_norm": 0.15700902680365109,
      "learning_rate": 9.99341251946023e-05,
      "loss": 0.0383,
      "step": 15320
    },
    {
      "epoch": 0.049088,
      "grad_norm": 0.15040423058070657,
      "learning_rate": 9.993395312335276e-05,
      "loss": 0.0376,
      "step": 15340
    },
    {
      "epoch": 0.049152,
      "grad_norm": 0.21553576747824754,
      "learning_rate": 9.993378082781157e-05,
      "loss": 0.0372,
      "step": 15360
    },
    {
      "epoch": 0.049216,
      "grad_norm": 0.18650799795645834,
      "learning_rate": 9.993360830797949e-05,
      "loss": 0.0411,
      "step": 15380
    },
    {
      "epoch": 0.04928,
      "grad_norm": 0.30238755134344447,
      "learning_rate": 9.993343556385729e-05,
      "loss": 0.0372,
      "step": 15400
    },
    {
      "epoch": 0.049344,
      "grad_norm": 0.1107334102287796,
      "learning_rate": 9.993326259544573e-05,
      "loss": 0.0364,
      "step": 15420
    },
    {
      "epoch": 0.049408,
      "grad_norm": 0.16987525598901113,
      "learning_rate": 9.993308940274564e-05,
      "loss": 0.0349,
      "step": 15440
    },
    {
      "epoch": 0.049472,
      "grad_norm": 0.14271833030442146,
      "learning_rate": 9.993291598575775e-05,
      "loss": 0.0355,
      "step": 15460
    },
    {
      "epoch": 0.049536,
      "grad_norm": 0.12424955808241304,
      "learning_rate": 9.993274234448286e-05,
      "loss": 0.0336,
      "step": 15480
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.1252983660891284,
      "learning_rate": 9.993256847892174e-05,
      "loss": 0.0329,
      "step": 15500
    },
    {
      "epoch": 0.049664,
      "grad_norm": 0.1632271914944957,
      "learning_rate": 9.993239438907518e-05,
      "loss": 0.0364,
      "step": 15520
    },
    {
      "epoch": 0.049728,
      "grad_norm": 0.11146834649657573,
      "learning_rate": 9.993222007494396e-05,
      "loss": 0.0348,
      "step": 15540
    },
    {
      "epoch": 0.049792,
      "grad_norm": 0.19790605842087128,
      "learning_rate": 9.993204553652886e-05,
      "loss": 0.0326,
      "step": 15560
    },
    {
      "epoch": 0.049856,
      "grad_norm": 0.15819604089219855,
      "learning_rate": 9.993187077383065e-05,
      "loss": 0.0361,
      "step": 15580
    },
    {
      "epoch": 0.04992,
      "grad_norm": 0.16831492818404428,
      "learning_rate": 9.993169578685014e-05,
      "loss": 0.0364,
      "step": 15600
    },
    {
      "epoch": 0.049984,
      "grad_norm": 0.1366440587770829,
      "learning_rate": 9.99315205755881e-05,
      "loss": 0.033,
      "step": 15620
    },
    {
      "epoch": 0.050048,
      "grad_norm": 0.15495610051348688,
      "learning_rate": 9.993134514004533e-05,
      "loss": 0.033,
      "step": 15640
    },
    {
      "epoch": 0.050112,
      "grad_norm": 0.18647477227661124,
      "learning_rate": 9.993116948022261e-05,
      "loss": 0.0348,
      "step": 15660
    },
    {
      "epoch": 0.050176,
      "grad_norm": 0.15840719768365794,
      "learning_rate": 9.993099359612073e-05,
      "loss": 0.0378,
      "step": 15680
    },
    {
      "epoch": 0.05024,
      "grad_norm": 0.112873839185945,
      "learning_rate": 9.993081748774047e-05,
      "loss": 0.0341,
      "step": 15700
    },
    {
      "epoch": 0.050304,
      "grad_norm": 0.12090058286256929,
      "learning_rate": 9.993064115508264e-05,
      "loss": 0.0343,
      "step": 15720
    },
    {
      "epoch": 0.050368,
      "grad_norm": 0.24511854702843727,
      "learning_rate": 9.993046459814803e-05,
      "loss": 0.037,
      "step": 15740
    },
    {
      "epoch": 0.050432,
      "grad_norm": 0.12455998067408601,
      "learning_rate": 9.993028781693741e-05,
      "loss": 0.0339,
      "step": 15760
    },
    {
      "epoch": 0.050496,
      "grad_norm": 0.18205914901228507,
      "learning_rate": 9.993011081145158e-05,
      "loss": 0.0391,
      "step": 15780
    },
    {
      "epoch": 0.05056,
      "grad_norm": 0.11097677551840077,
      "learning_rate": 9.992993358169138e-05,
      "loss": 0.0338,
      "step": 15800
    },
    {
      "epoch": 0.050624,
      "grad_norm": 0.1132496056670998,
      "learning_rate": 9.992975612765754e-05,
      "loss": 0.0338,
      "step": 15820
    },
    {
      "epoch": 0.050688,
      "grad_norm": 0.14910594194944238,
      "learning_rate": 9.99295784493509e-05,
      "loss": 0.0366,
      "step": 15840
    },
    {
      "epoch": 0.050752,
      "grad_norm": 0.1641586497159284,
      "learning_rate": 9.992940054677225e-05,
      "loss": 0.0334,
      "step": 15860
    },
    {
      "epoch": 0.050816,
      "grad_norm": 0.14373013659326545,
      "learning_rate": 9.992922241992238e-05,
      "loss": 0.0341,
      "step": 15880
    },
    {
      "epoch": 0.05088,
      "grad_norm": 0.1171140793958473,
      "learning_rate": 9.992904406880209e-05,
      "loss": 0.0354,
      "step": 15900
    },
    {
      "epoch": 0.050944,
      "grad_norm": 0.13939465906525142,
      "learning_rate": 9.992886549341218e-05,
      "loss": 0.0388,
      "step": 15920
    },
    {
      "epoch": 0.051008,
      "grad_norm": 0.1190659403202558,
      "learning_rate": 9.992868669375348e-05,
      "loss": 0.0405,
      "step": 15940
    },
    {
      "epoch": 0.051072,
      "grad_norm": 0.12612388356621773,
      "learning_rate": 9.992850766982676e-05,
      "loss": 0.036,
      "step": 15960
    },
    {
      "epoch": 0.051136,
      "grad_norm": 0.1762925196097625,
      "learning_rate": 9.992832842163285e-05,
      "loss": 0.0356,
      "step": 15980
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.09386019706490482,
      "learning_rate": 9.992814894917252e-05,
      "loss": 0.0328,
      "step": 16000
    },
    {
      "epoch": 0.051264,
      "grad_norm": 0.09684560935513954,
      "learning_rate": 9.992796925244661e-05,
      "loss": 0.034,
      "step": 16020
    },
    {
      "epoch": 0.051328,
      "grad_norm": 0.14426183253418937,
      "learning_rate": 9.99277893314559e-05,
      "loss": 0.0347,
      "step": 16040
    },
    {
      "epoch": 0.051392,
      "grad_norm": 0.09442640243966588,
      "learning_rate": 9.992760918620122e-05,
      "loss": 0.0391,
      "step": 16060
    },
    {
      "epoch": 0.051456,
      "grad_norm": 0.12465464806603783,
      "learning_rate": 9.992742881668338e-05,
      "loss": 0.036,
      "step": 16080
    },
    {
      "epoch": 0.05152,
      "grad_norm": 0.11096561198850499,
      "learning_rate": 9.992724822290316e-05,
      "loss": 0.0336,
      "step": 16100
    },
    {
      "epoch": 0.051584,
      "grad_norm": 0.09714232482847845,
      "learning_rate": 9.992706740486142e-05,
      "loss": 0.0338,
      "step": 16120
    },
    {
      "epoch": 0.051648,
      "grad_norm": 0.10576988176927238,
      "learning_rate": 9.992688636255893e-05,
      "loss": 0.0347,
      "step": 16140
    },
    {
      "epoch": 0.051712,
      "grad_norm": 0.10228366839813258,
      "learning_rate": 9.992670509599651e-05,
      "loss": 0.0342,
      "step": 16160
    },
    {
      "epoch": 0.051776,
      "grad_norm": 0.10277090936468604,
      "learning_rate": 9.992652360517501e-05,
      "loss": 0.0296,
      "step": 16180
    },
    {
      "epoch": 0.05184,
      "grad_norm": 0.10747004890666984,
      "learning_rate": 9.992634189009519e-05,
      "loss": 0.0355,
      "step": 16200
    },
    {
      "epoch": 0.051904,
      "grad_norm": 0.12535374949337835,
      "learning_rate": 9.99261599507579e-05,
      "loss": 0.0338,
      "step": 16220
    },
    {
      "epoch": 0.051968,
      "grad_norm": 0.12490182924855917,
      "learning_rate": 9.992597778716396e-05,
      "loss": 0.0371,
      "step": 16240
    },
    {
      "epoch": 0.052032,
      "grad_norm": 0.11732838580516043,
      "learning_rate": 9.992579539931416e-05,
      "loss": 0.0387,
      "step": 16260
    },
    {
      "epoch": 0.052096,
      "grad_norm": 0.11692296773059428,
      "learning_rate": 9.992561278720937e-05,
      "loss": 0.0392,
      "step": 16280
    },
    {
      "epoch": 0.05216,
      "grad_norm": 0.17919967223252306,
      "learning_rate": 9.992542995085036e-05,
      "loss": 0.0361,
      "step": 16300
    },
    {
      "epoch": 0.052224,
      "grad_norm": 0.11856582687977317,
      "learning_rate": 9.992524689023797e-05,
      "loss": 0.0374,
      "step": 16320
    },
    {
      "epoch": 0.052288,
      "grad_norm": 0.14212369362365593,
      "learning_rate": 9.992506360537302e-05,
      "loss": 0.033,
      "step": 16340
    },
    {
      "epoch": 0.052352,
      "grad_norm": 0.13905784273136748,
      "learning_rate": 9.992488009625634e-05,
      "loss": 0.0319,
      "step": 16360
    },
    {
      "epoch": 0.052416,
      "grad_norm": 0.11361108413183314,
      "learning_rate": 9.992469636288875e-05,
      "loss": 0.036,
      "step": 16380
    },
    {
      "epoch": 0.05248,
      "grad_norm": 0.1759092588731618,
      "learning_rate": 9.992451240527107e-05,
      "loss": 0.04,
      "step": 16400
    },
    {
      "epoch": 0.052544,
      "grad_norm": 0.10997941270962663,
      "learning_rate": 9.992432822340414e-05,
      "loss": 0.0337,
      "step": 16420
    },
    {
      "epoch": 0.052608,
      "grad_norm": 0.17191687384169788,
      "learning_rate": 9.992414381728878e-05,
      "loss": 0.0361,
      "step": 16440
    },
    {
      "epoch": 0.052672,
      "grad_norm": 0.11953244747490259,
      "learning_rate": 9.992395918692581e-05,
      "loss": 0.0355,
      "step": 16460
    },
    {
      "epoch": 0.052736,
      "grad_norm": 0.17495329768503157,
      "learning_rate": 9.992377433231608e-05,
      "loss": 0.0367,
      "step": 16480
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.17048154953811825,
      "learning_rate": 9.99235892534604e-05,
      "loss": 0.0355,
      "step": 16500
    },
    {
      "epoch": 0.052864,
      "grad_norm": 0.10606593110473865,
      "learning_rate": 9.99234039503596e-05,
      "loss": 0.0354,
      "step": 16520
    },
    {
      "epoch": 0.052928,
      "grad_norm": 0.20442947092222155,
      "learning_rate": 9.992321842301452e-05,
      "loss": 0.0351,
      "step": 16540
    },
    {
      "epoch": 0.052992,
      "grad_norm": 0.2528353337432819,
      "learning_rate": 9.9923032671426e-05,
      "loss": 0.0338,
      "step": 16560
    },
    {
      "epoch": 0.053056,
      "grad_norm": 0.10064657000485325,
      "learning_rate": 9.992284669559486e-05,
      "loss": 0.0378,
      "step": 16580
    },
    {
      "epoch": 0.05312,
      "grad_norm": 0.1044129813357252,
      "learning_rate": 9.992266049552195e-05,
      "loss": 0.0331,
      "step": 16600
    },
    {
      "epoch": 0.053184,
      "grad_norm": 0.18230274076501582,
      "learning_rate": 9.99224740712081e-05,
      "loss": 0.0369,
      "step": 16620
    },
    {
      "epoch": 0.053248,
      "grad_norm": 0.1938957673283127,
      "learning_rate": 9.992228742265415e-05,
      "loss": 0.0378,
      "step": 16640
    },
    {
      "epoch": 0.053312,
      "grad_norm": 0.12146508602103125,
      "learning_rate": 9.992210054986093e-05,
      "loss": 0.0379,
      "step": 16660
    },
    {
      "epoch": 0.053376,
      "grad_norm": 0.07889922663367899,
      "learning_rate": 9.992191345282928e-05,
      "loss": 0.0336,
      "step": 16680
    },
    {
      "epoch": 0.05344,
      "grad_norm": 0.1728184818958167,
      "learning_rate": 9.992172613156005e-05,
      "loss": 0.0354,
      "step": 16700
    },
    {
      "epoch": 0.053504,
      "grad_norm": 0.10213543307742655,
      "learning_rate": 9.992153858605409e-05,
      "loss": 0.0331,
      "step": 16720
    },
    {
      "epoch": 0.053568,
      "grad_norm": 0.09680245345420041,
      "learning_rate": 9.992135081631222e-05,
      "loss": 0.0309,
      "step": 16740
    },
    {
      "epoch": 0.053632,
      "grad_norm": 0.16081126956732297,
      "learning_rate": 9.99211628223353e-05,
      "loss": 0.0332,
      "step": 16760
    },
    {
      "epoch": 0.053696,
      "grad_norm": 0.11728220164945362,
      "learning_rate": 9.992097460412415e-05,
      "loss": 0.0377,
      "step": 16780
    },
    {
      "epoch": 0.05376,
      "grad_norm": 0.08584639631267706,
      "learning_rate": 9.992078616167964e-05,
      "loss": 0.0365,
      "step": 16800
    },
    {
      "epoch": 0.053824,
      "grad_norm": 0.20963288379467385,
      "learning_rate": 9.99205974950026e-05,
      "loss": 0.0354,
      "step": 16820
    },
    {
      "epoch": 0.053888,
      "grad_norm": 0.15742272252431652,
      "learning_rate": 9.992040860409391e-05,
      "loss": 0.035,
      "step": 16840
    },
    {
      "epoch": 0.053952,
      "grad_norm": 0.1278751078021988,
      "learning_rate": 9.992021948895437e-05,
      "loss": 0.0357,
      "step": 16860
    },
    {
      "epoch": 0.054016,
      "grad_norm": 0.13241155385690026,
      "learning_rate": 9.992003014958486e-05,
      "loss": 0.0329,
      "step": 16880
    },
    {
      "epoch": 0.05408,
      "grad_norm": 0.10715627650243452,
      "learning_rate": 9.991984058598624e-05,
      "loss": 0.0333,
      "step": 16900
    },
    {
      "epoch": 0.054144,
      "grad_norm": 0.10234875719834678,
      "learning_rate": 9.991965079815933e-05,
      "loss": 0.034,
      "step": 16920
    },
    {
      "epoch": 0.054208,
      "grad_norm": 0.1025761271480278,
      "learning_rate": 9.991946078610501e-05,
      "loss": 0.0317,
      "step": 16940
    },
    {
      "epoch": 0.054272,
      "grad_norm": 0.13086966810693465,
      "learning_rate": 9.991927054982411e-05,
      "loss": 0.0375,
      "step": 16960
    },
    {
      "epoch": 0.054336,
      "grad_norm": 0.10365092790857679,
      "learning_rate": 9.99190800893175e-05,
      "loss": 0.0329,
      "step": 16980
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.09961402826283518,
      "learning_rate": 9.991888940458605e-05,
      "loss": 0.0335,
      "step": 17000
    },
    {
      "epoch": 0.054464,
      "grad_norm": 0.10957491947883129,
      "learning_rate": 9.991869849563059e-05,
      "loss": 0.0332,
      "step": 17020
    },
    {
      "epoch": 0.054528,
      "grad_norm": 0.0927093316773643,
      "learning_rate": 9.991850736245197e-05,
      "loss": 0.0365,
      "step": 17040
    },
    {
      "epoch": 0.054592,
      "grad_norm": 0.1017137067642453,
      "learning_rate": 9.991831600505107e-05,
      "loss": 0.0371,
      "step": 17060
    },
    {
      "epoch": 0.054656,
      "grad_norm": 0.13317395720989603,
      "learning_rate": 9.991812442342876e-05,
      "loss": 0.0343,
      "step": 17080
    },
    {
      "epoch": 0.05472,
      "grad_norm": 0.16406970670368645,
      "learning_rate": 9.991793261758586e-05,
      "loss": 0.0367,
      "step": 17100
    },
    {
      "epoch": 0.054784,
      "grad_norm": 0.23944718482766253,
      "learning_rate": 9.991774058752327e-05,
      "loss": 0.0333,
      "step": 17120
    },
    {
      "epoch": 0.054848,
      "grad_norm": 0.12307568774973436,
      "learning_rate": 9.991754833324185e-05,
      "loss": 0.0375,
      "step": 17140
    },
    {
      "epoch": 0.054912,
      "grad_norm": 0.12020699304756892,
      "learning_rate": 9.991735585474244e-05,
      "loss": 0.0366,
      "step": 17160
    },
    {
      "epoch": 0.054976,
      "grad_norm": 0.09029017893806349,
      "learning_rate": 9.991716315202592e-05,
      "loss": 0.0345,
      "step": 17180
    },
    {
      "epoch": 0.05504,
      "grad_norm": 0.10679322352203884,
      "learning_rate": 9.991697022509315e-05,
      "loss": 0.0342,
      "step": 17200
    },
    {
      "epoch": 0.055104,
      "grad_norm": 0.10696593739887994,
      "learning_rate": 9.9916777073945e-05,
      "loss": 0.0336,
      "step": 17220
    },
    {
      "epoch": 0.055168,
      "grad_norm": 0.16167680756239386,
      "learning_rate": 9.991658369858233e-05,
      "loss": 0.0305,
      "step": 17240
    },
    {
      "epoch": 0.055232,
      "grad_norm": 0.1352538602908927,
      "learning_rate": 9.991639009900603e-05,
      "loss": 0.0331,
      "step": 17260
    },
    {
      "epoch": 0.055296,
      "grad_norm": 0.09905252698789209,
      "learning_rate": 9.991619627521694e-05,
      "loss": 0.0321,
      "step": 17280
    },
    {
      "epoch": 0.05536,
      "grad_norm": 0.15155107834389772,
      "learning_rate": 9.991600222721595e-05,
      "loss": 0.0342,
      "step": 17300
    },
    {
      "epoch": 0.055424,
      "grad_norm": 0.19671934535639352,
      "learning_rate": 9.991580795500395e-05,
      "loss": 0.0379,
      "step": 17320
    },
    {
      "epoch": 0.055488,
      "grad_norm": 0.10023397181395324,
      "learning_rate": 9.991561345858175e-05,
      "loss": 0.0336,
      "step": 17340
    },
    {
      "epoch": 0.055552,
      "grad_norm": 0.09636066886480535,
      "learning_rate": 9.99154187379503e-05,
      "loss": 0.0332,
      "step": 17360
    },
    {
      "epoch": 0.055616,
      "grad_norm": 0.10439982204314885,
      "learning_rate": 9.991522379311042e-05,
      "loss": 0.0347,
      "step": 17380
    },
    {
      "epoch": 0.05568,
      "grad_norm": 0.11928952316721914,
      "learning_rate": 9.9915028624063e-05,
      "loss": 0.0316,
      "step": 17400
    },
    {
      "epoch": 0.055744,
      "grad_norm": 0.20672585824959547,
      "learning_rate": 9.991483323080893e-05,
      "loss": 0.0341,
      "step": 17420
    },
    {
      "epoch": 0.055808,
      "grad_norm": 0.12002024866559705,
      "learning_rate": 9.991463761334907e-05,
      "loss": 0.0366,
      "step": 17440
    },
    {
      "epoch": 0.055872,
      "grad_norm": 0.1498603835658597,
      "learning_rate": 9.991444177168432e-05,
      "loss": 0.0348,
      "step": 17460
    },
    {
      "epoch": 0.055936,
      "grad_norm": 0.11949422669049035,
      "learning_rate": 9.991424570581554e-05,
      "loss": 0.0333,
      "step": 17480
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.15552596340785763,
      "learning_rate": 9.991404941574361e-05,
      "loss": 0.0365,
      "step": 17500
    },
    {
      "epoch": 0.056064,
      "grad_norm": 0.24390940092927904,
      "learning_rate": 9.991385290146942e-05,
      "loss": 0.0319,
      "step": 17520
    },
    {
      "epoch": 0.056128,
      "grad_norm": 0.1769937720225227,
      "learning_rate": 9.991365616299386e-05,
      "loss": 0.0383,
      "step": 17540
    },
    {
      "epoch": 0.056192,
      "grad_norm": 0.12683272355407324,
      "learning_rate": 9.991345920031779e-05,
      "loss": 0.0329,
      "step": 17560
    },
    {
      "epoch": 0.056256,
      "grad_norm": 0.18849631934236188,
      "learning_rate": 9.991326201344213e-05,
      "loss": 0.0325,
      "step": 17580
    },
    {
      "epoch": 0.05632,
      "grad_norm": 0.2108928972656276,
      "learning_rate": 9.991306460236773e-05,
      "loss": 0.0331,
      "step": 17600
    },
    {
      "epoch": 0.056384,
      "grad_norm": 0.1059909125245483,
      "learning_rate": 9.99128669670955e-05,
      "loss": 0.0365,
      "step": 17620
    },
    {
      "epoch": 0.056448,
      "grad_norm": 0.11824659774716664,
      "learning_rate": 9.991266910762631e-05,
      "loss": 0.0311,
      "step": 17640
    },
    {
      "epoch": 0.056512,
      "grad_norm": 0.11115965499941091,
      "learning_rate": 9.991247102396107e-05,
      "loss": 0.032,
      "step": 17660
    },
    {
      "epoch": 0.056576,
      "grad_norm": 0.1358715975746066,
      "learning_rate": 9.991227271610067e-05,
      "loss": 0.0321,
      "step": 17680
    },
    {
      "epoch": 0.05664,
      "grad_norm": 0.16275223242757147,
      "learning_rate": 9.991207418404595e-05,
      "loss": 0.0353,
      "step": 17700
    },
    {
      "epoch": 0.056704,
      "grad_norm": 0.09493439795229432,
      "learning_rate": 9.991187542779788e-05,
      "loss": 0.036,
      "step": 17720
    },
    {
      "epoch": 0.056768,
      "grad_norm": 0.3175580496763981,
      "learning_rate": 9.99116764473573e-05,
      "loss": 0.0354,
      "step": 17740
    },
    {
      "epoch": 0.056832,
      "grad_norm": 0.09553338760934682,
      "learning_rate": 9.991147724272512e-05,
      "loss": 0.0352,
      "step": 17760
    },
    {
      "epoch": 0.056896,
      "grad_norm": 0.14651912804465514,
      "learning_rate": 9.991127781390223e-05,
      "loss": 0.0339,
      "step": 17780
    },
    {
      "epoch": 0.05696,
      "grad_norm": 0.147031438858404,
      "learning_rate": 9.991107816088952e-05,
      "loss": 0.0329,
      "step": 17800
    },
    {
      "epoch": 0.057024,
      "grad_norm": 0.09185898143616375,
      "learning_rate": 9.991087828368791e-05,
      "loss": 0.0334,
      "step": 17820
    },
    {
      "epoch": 0.057088,
      "grad_norm": 0.13551425112936327,
      "learning_rate": 9.991067818229827e-05,
      "loss": 0.0383,
      "step": 17840
    },
    {
      "epoch": 0.057152,
      "grad_norm": 0.2794838092789423,
      "learning_rate": 9.991047785672152e-05,
      "loss": 0.0371,
      "step": 17860
    },
    {
      "epoch": 0.057216,
      "grad_norm": 0.11449254977615445,
      "learning_rate": 9.991027730695855e-05,
      "loss": 0.0349,
      "step": 17880
    },
    {
      "epoch": 0.05728,
      "grad_norm": 0.0811229114081402,
      "learning_rate": 9.991007653301026e-05,
      "loss": 0.0314,
      "step": 17900
    },
    {
      "epoch": 0.057344,
      "grad_norm": 0.10862861432977336,
      "learning_rate": 9.990987553487754e-05,
      "loss": 0.0331,
      "step": 17920
    },
    {
      "epoch": 0.057408,
      "grad_norm": 0.15745378169901814,
      "learning_rate": 9.990967431256134e-05,
      "loss": 0.0349,
      "step": 17940
    },
    {
      "epoch": 0.057472,
      "grad_norm": 0.10544788632370294,
      "learning_rate": 9.990947286606252e-05,
      "loss": 0.0337,
      "step": 17960
    },
    {
      "epoch": 0.057536,
      "grad_norm": 0.13942015689736034,
      "learning_rate": 9.990927119538198e-05,
      "loss": 0.0332,
      "step": 17980
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.17505802424697345,
      "learning_rate": 9.990906930052064e-05,
      "loss": 0.0375,
      "step": 18000
    },
    {
      "epoch": 0.057664,
      "grad_norm": 0.1515367875798829,
      "learning_rate": 9.990886718147942e-05,
      "loss": 0.0343,
      "step": 18020
    },
    {
      "epoch": 0.057728,
      "grad_norm": 0.12768374745547934,
      "learning_rate": 9.990866483825921e-05,
      "loss": 0.0324,
      "step": 18040
    },
    {
      "epoch": 0.057792,
      "grad_norm": 0.09434701899970553,
      "learning_rate": 9.990846227086093e-05,
      "loss": 0.0328,
      "step": 18060
    },
    {
      "epoch": 0.057856,
      "grad_norm": 0.13908542152899867,
      "learning_rate": 9.990825947928548e-05,
      "loss": 0.0364,
      "step": 18080
    },
    {
      "epoch": 0.05792,
      "grad_norm": 0.11917830543521794,
      "learning_rate": 9.990805646353378e-05,
      "loss": 0.0327,
      "step": 18100
    },
    {
      "epoch": 0.057984,
      "grad_norm": 0.15256780533481193,
      "learning_rate": 9.990785322360673e-05,
      "loss": 0.0355,
      "step": 18120
    },
    {
      "epoch": 0.058048,
      "grad_norm": 0.12672488473883228,
      "learning_rate": 9.990764975950528e-05,
      "loss": 0.0338,
      "step": 18140
    },
    {
      "epoch": 0.058112,
      "grad_norm": 0.12297585140230674,
      "learning_rate": 9.990744607123028e-05,
      "loss": 0.0329,
      "step": 18160
    },
    {
      "epoch": 0.058176,
      "grad_norm": 0.14255308838932138,
      "learning_rate": 9.99072421587827e-05,
      "loss": 0.0355,
      "step": 18180
    },
    {
      "epoch": 0.05824,
      "grad_norm": 0.11200753000960445,
      "learning_rate": 9.990703802216342e-05,
      "loss": 0.0386,
      "step": 18200
    },
    {
      "epoch": 0.058304,
      "grad_norm": 0.11355356355874739,
      "learning_rate": 9.990683366137339e-05,
      "loss": 0.0323,
      "step": 18220
    },
    {
      "epoch": 0.058368,
      "grad_norm": 0.12034569126015282,
      "learning_rate": 9.99066290764135e-05,
      "loss": 0.0342,
      "step": 18240
    },
    {
      "epoch": 0.058432,
      "grad_norm": 0.1285653876365367,
      "learning_rate": 9.990642426728468e-05,
      "loss": 0.0359,
      "step": 18260
    },
    {
      "epoch": 0.058496,
      "grad_norm": 0.11112692004872396,
      "learning_rate": 9.990621923398785e-05,
      "loss": 0.0339,
      "step": 18280
    },
    {
      "epoch": 0.05856,
      "grad_norm": 0.1563565342642215,
      "learning_rate": 9.990601397652393e-05,
      "loss": 0.0354,
      "step": 18300
    },
    {
      "epoch": 0.058624,
      "grad_norm": 0.14043547131885564,
      "learning_rate": 9.990580849489384e-05,
      "loss": 0.0313,
      "step": 18320
    },
    {
      "epoch": 0.058688,
      "grad_norm": 0.10193902540028733,
      "learning_rate": 9.99056027890985e-05,
      "loss": 0.0335,
      "step": 18340
    },
    {
      "epoch": 0.058752,
      "grad_norm": 0.12202435610224495,
      "learning_rate": 9.990539685913884e-05,
      "loss": 0.0311,
      "step": 18360
    },
    {
      "epoch": 0.058816,
      "grad_norm": 0.10023472155745906,
      "learning_rate": 9.99051907050158e-05,
      "loss": 0.0324,
      "step": 18380
    },
    {
      "epoch": 0.05888,
      "grad_norm": 0.11928000676105618,
      "learning_rate": 9.990498432673028e-05,
      "loss": 0.0335,
      "step": 18400
    },
    {
      "epoch": 0.058944,
      "grad_norm": 0.12134339926636085,
      "learning_rate": 9.990477772428322e-05,
      "loss": 0.0349,
      "step": 18420
    },
    {
      "epoch": 0.059008,
      "grad_norm": 0.09979515553952921,
      "learning_rate": 9.990457089767553e-05,
      "loss": 0.0325,
      "step": 18440
    },
    {
      "epoch": 0.059072,
      "grad_norm": 0.11769755778188208,
      "learning_rate": 9.990436384690817e-05,
      "loss": 0.0364,
      "step": 18460
    },
    {
      "epoch": 0.059136,
      "grad_norm": 0.13767932583506837,
      "learning_rate": 9.990415657198205e-05,
      "loss": 0.036,
      "step": 18480
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.11612865143666769,
      "learning_rate": 9.99039490728981e-05,
      "loss": 0.0339,
      "step": 18500
    },
    {
      "epoch": 0.059264,
      "grad_norm": 0.08181794200159138,
      "learning_rate": 9.990374134965725e-05,
      "loss": 0.0312,
      "step": 18520
    },
    {
      "epoch": 0.059328,
      "grad_norm": 0.12236719829746981,
      "learning_rate": 9.990353340226047e-05,
      "loss": 0.0331,
      "step": 18540
    },
    {
      "epoch": 0.059392,
      "grad_norm": 0.10898679635604598,
      "learning_rate": 9.990332523070864e-05,
      "loss": 0.0406,
      "step": 18560
    },
    {
      "epoch": 0.059456,
      "grad_norm": 0.12233154935507864,
      "learning_rate": 9.990311683500273e-05,
      "loss": 0.0366,
      "step": 18580
    },
    {
      "epoch": 0.05952,
      "grad_norm": 0.2600631094332187,
      "learning_rate": 9.990290821514366e-05,
      "loss": 0.0387,
      "step": 18600
    },
    {
      "epoch": 0.059584,
      "grad_norm": 0.15469006122046597,
      "learning_rate": 9.990269937113237e-05,
      "loss": 0.0361,
      "step": 18620
    },
    {
      "epoch": 0.059648,
      "grad_norm": 0.08252625811538122,
      "learning_rate": 9.990249030296981e-05,
      "loss": 0.031,
      "step": 18640
    },
    {
      "epoch": 0.059712,
      "grad_norm": 0.1414663873773736,
      "learning_rate": 9.990228101065689e-05,
      "loss": 0.0339,
      "step": 18660
    },
    {
      "epoch": 0.059776,
      "grad_norm": 0.1465211520646684,
      "learning_rate": 9.990207149419459e-05,
      "loss": 0.0346,
      "step": 18680
    },
    {
      "epoch": 0.05984,
      "grad_norm": 0.12121307661126639,
      "learning_rate": 9.990186175358382e-05,
      "loss": 0.0348,
      "step": 18700
    },
    {
      "epoch": 0.059904,
      "grad_norm": 0.08996386444771336,
      "learning_rate": 9.990165178882554e-05,
      "loss": 0.0341,
      "step": 18720
    },
    {
      "epoch": 0.059968,
      "grad_norm": 0.15569067738532616,
      "learning_rate": 9.990144159992067e-05,
      "loss": 0.031,
      "step": 18740
    },
    {
      "epoch": 0.060032,
      "grad_norm": 0.12224068009247853,
      "learning_rate": 9.990123118687019e-05,
      "loss": 0.0342,
      "step": 18760
    },
    {
      "epoch": 0.060096,
      "grad_norm": 0.09792409711888014,
      "learning_rate": 9.990102054967503e-05,
      "loss": 0.0355,
      "step": 18780
    },
    {
      "epoch": 0.06016,
      "grad_norm": 0.11012316352934545,
      "learning_rate": 9.99008096883361e-05,
      "loss": 0.035,
      "step": 18800
    },
    {
      "epoch": 0.060224,
      "grad_norm": 0.20201513967656096,
      "learning_rate": 9.990059860285441e-05,
      "loss": 0.0344,
      "step": 18820
    },
    {
      "epoch": 0.060288,
      "grad_norm": 0.1285491299987621,
      "learning_rate": 9.990038729323087e-05,
      "loss": 0.033,
      "step": 18840
    },
    {
      "epoch": 0.060352,
      "grad_norm": 0.1357075823107087,
      "learning_rate": 9.990017575946643e-05,
      "loss": 0.0396,
      "step": 18860
    },
    {
      "epoch": 0.060416,
      "grad_norm": 0.10438735211225703,
      "learning_rate": 9.989996400156205e-05,
      "loss": 0.0364,
      "step": 18880
    },
    {
      "epoch": 0.06048,
      "grad_norm": 0.10779371945686081,
      "learning_rate": 9.989975201951867e-05,
      "loss": 0.0358,
      "step": 18900
    },
    {
      "epoch": 0.060544,
      "grad_norm": 0.10849754518475155,
      "learning_rate": 9.989953981333725e-05,
      "loss": 0.0323,
      "step": 18920
    },
    {
      "epoch": 0.060608,
      "grad_norm": 0.13785281612711664,
      "learning_rate": 9.989932738301875e-05,
      "loss": 0.0357,
      "step": 18940
    },
    {
      "epoch": 0.060672,
      "grad_norm": 0.12359944220096011,
      "learning_rate": 9.98991147285641e-05,
      "loss": 0.034,
      "step": 18960
    },
    {
      "epoch": 0.060736,
      "grad_norm": 0.2119481391949673,
      "learning_rate": 9.98989018499743e-05,
      "loss": 0.0348,
      "step": 18980
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.1515189682298724,
      "learning_rate": 9.989868874725026e-05,
      "loss": 0.0379,
      "step": 19000
    },
    {
      "epoch": 0.060864,
      "grad_norm": 0.18079383528520512,
      "learning_rate": 9.989847542039295e-05,
      "loss": 0.0375,
      "step": 19020
    },
    {
      "epoch": 0.060928,
      "grad_norm": 0.14575406379674052,
      "learning_rate": 9.989826186940334e-05,
      "loss": 0.0344,
      "step": 19040
    },
    {
      "epoch": 0.060992,
      "grad_norm": 0.11003266959984635,
      "learning_rate": 9.989804809428239e-05,
      "loss": 0.0364,
      "step": 19060
    },
    {
      "epoch": 0.061056,
      "grad_norm": 0.11052559837587579,
      "learning_rate": 9.989783409503105e-05,
      "loss": 0.0335,
      "step": 19080
    },
    {
      "epoch": 0.06112,
      "grad_norm": 0.09700513267560862,
      "learning_rate": 9.989761987165029e-05,
      "loss": 0.0301,
      "step": 19100
    },
    {
      "epoch": 0.061184,
      "grad_norm": 0.14182378064807033,
      "learning_rate": 9.989740542414106e-05,
      "loss": 0.0341,
      "step": 19120
    },
    {
      "epoch": 0.061248,
      "grad_norm": 0.15805631954007268,
      "learning_rate": 9.989719075250432e-05,
      "loss": 0.0335,
      "step": 19140
    },
    {
      "epoch": 0.061312,
      "grad_norm": 0.10875748968299204,
      "learning_rate": 9.989697585674104e-05,
      "loss": 0.0346,
      "step": 19160
    },
    {
      "epoch": 0.061376,
      "grad_norm": 0.1274906198316659,
      "learning_rate": 9.989676073685221e-05,
      "loss": 0.0339,
      "step": 19180
    },
    {
      "epoch": 0.06144,
      "grad_norm": 0.12903792917248563,
      "learning_rate": 9.989654539283877e-05,
      "loss": 0.0333,
      "step": 19200
    },
    {
      "epoch": 0.061504,
      "grad_norm": 0.09074888178912414,
      "learning_rate": 9.989632982470168e-05,
      "loss": 0.033,
      "step": 19220
    },
    {
      "epoch": 0.061568,
      "grad_norm": 0.09875004952977967,
      "learning_rate": 9.989611403244193e-05,
      "loss": 0.0305,
      "step": 19240
    },
    {
      "epoch": 0.061632,
      "grad_norm": 0.20204301572168246,
      "learning_rate": 9.989589801606048e-05,
      "loss": 0.0329,
      "step": 19260
    },
    {
      "epoch": 0.061696,
      "grad_norm": 0.11847988152062885,
      "learning_rate": 9.989568177555831e-05,
      "loss": 0.0348,
      "step": 19280
    },
    {
      "epoch": 0.06176,
      "grad_norm": 0.16655053475710985,
      "learning_rate": 9.989546531093637e-05,
      "loss": 0.0383,
      "step": 19300
    },
    {
      "epoch": 0.061824,
      "grad_norm": 0.10908687928662378,
      "learning_rate": 9.989524862219564e-05,
      "loss": 0.0358,
      "step": 19320
    },
    {
      "epoch": 0.061888,
      "grad_norm": 0.09543858236886209,
      "learning_rate": 9.989503170933712e-05,
      "loss": 0.0337,
      "step": 19340
    },
    {
      "epoch": 0.061952,
      "grad_norm": 0.11407101112427125,
      "learning_rate": 9.989481457236174e-05,
      "loss": 0.0332,
      "step": 19360
    },
    {
      "epoch": 0.062016,
      "grad_norm": 0.09410146795718764,
      "learning_rate": 9.98945972112705e-05,
      "loss": 0.0362,
      "step": 19380
    },
    {
      "epoch": 0.06208,
      "grad_norm": 0.07725218433624248,
      "learning_rate": 9.989437962606438e-05,
      "loss": 0.0302,
      "step": 19400
    },
    {
      "epoch": 0.062144,
      "grad_norm": 0.18434246358118317,
      "learning_rate": 9.989416181674436e-05,
      "loss": 0.0354,
      "step": 19420
    },
    {
      "epoch": 0.062208,
      "grad_norm": 0.17122153378559052,
      "learning_rate": 9.989394378331138e-05,
      "loss": 0.0385,
      "step": 19440
    },
    {
      "epoch": 0.062272,
      "grad_norm": 0.10789202301142051,
      "learning_rate": 9.989372552576647e-05,
      "loss": 0.0361,
      "step": 19460
    },
    {
      "epoch": 0.062336,
      "grad_norm": 0.11885968726974544,
      "learning_rate": 9.98935070441106e-05,
      "loss": 0.033,
      "step": 19480
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.10569790900373464,
      "learning_rate": 9.989328833834471e-05,
      "loss": 0.0317,
      "step": 19500
    },
    {
      "epoch": 0.062464,
      "grad_norm": 0.10959879014067173,
      "learning_rate": 9.989306940846983e-05,
      "loss": 0.0344,
      "step": 19520
    },
    {
      "epoch": 0.062528,
      "grad_norm": 0.10323561374459209,
      "learning_rate": 9.989285025448693e-05,
      "loss": 0.0361,
      "step": 19540
    },
    {
      "epoch": 0.062592,
      "grad_norm": 0.2907752444232,
      "learning_rate": 9.989263087639699e-05,
      "loss": 0.0357,
      "step": 19560
    },
    {
      "epoch": 0.062656,
      "grad_norm": 0.1542904560576345,
      "learning_rate": 9.989241127420099e-05,
      "loss": 0.0376,
      "step": 19580
    },
    {
      "epoch": 0.06272,
      "grad_norm": 0.1271029489308482,
      "learning_rate": 9.989219144789992e-05,
      "loss": 0.0311,
      "step": 19600
    },
    {
      "epoch": 0.062784,
      "grad_norm": 0.08087576796257898,
      "learning_rate": 9.989197139749477e-05,
      "loss": 0.0337,
      "step": 19620
    },
    {
      "epoch": 0.062848,
      "grad_norm": 0.10085037238919506,
      "learning_rate": 9.989175112298653e-05,
      "loss": 0.0346,
      "step": 19640
    },
    {
      "epoch": 0.062912,
      "grad_norm": 0.09812021730250585,
      "learning_rate": 9.98915306243762e-05,
      "loss": 0.0321,
      "step": 19660
    },
    {
      "epoch": 0.062976,
      "grad_norm": 0.09159899537227678,
      "learning_rate": 9.989130990166474e-05,
      "loss": 0.0332,
      "step": 19680
    },
    {
      "epoch": 0.06304,
      "grad_norm": 0.10701633815863598,
      "learning_rate": 9.989108895485316e-05,
      "loss": 0.034,
      "step": 19700
    },
    {
      "epoch": 0.063104,
      "grad_norm": 0.09230289785687283,
      "learning_rate": 9.989086778394245e-05,
      "loss": 0.0309,
      "step": 19720
    },
    {
      "epoch": 0.063168,
      "grad_norm": 0.2073410268663692,
      "learning_rate": 9.989064638893362e-05,
      "loss": 0.0344,
      "step": 19740
    },
    {
      "epoch": 0.063232,
      "grad_norm": 0.10908774468773007,
      "learning_rate": 9.989042476982764e-05,
      "loss": 0.0362,
      "step": 19760
    },
    {
      "epoch": 0.063296,
      "grad_norm": 0.10169583237968459,
      "learning_rate": 9.989020292662552e-05,
      "loss": 0.0369,
      "step": 19780
    },
    {
      "epoch": 0.06336,
      "grad_norm": 0.10489209772688647,
      "learning_rate": 9.988998085932825e-05,
      "loss": 0.0334,
      "step": 19800
    },
    {
      "epoch": 0.063424,
      "grad_norm": 0.10941213416882212,
      "learning_rate": 9.988975856793684e-05,
      "loss": 0.0333,
      "step": 19820
    },
    {
      "epoch": 0.063488,
      "grad_norm": 0.1259127245349666,
      "learning_rate": 9.988953605245226e-05,
      "loss": 0.0362,
      "step": 19840
    },
    {
      "epoch": 0.063552,
      "grad_norm": 0.1029882494876567,
      "learning_rate": 9.988931331287553e-05,
      "loss": 0.0351,
      "step": 19860
    },
    {
      "epoch": 0.063616,
      "grad_norm": 0.1196303714125552,
      "learning_rate": 9.988909034920765e-05,
      "loss": 0.037,
      "step": 19880
    },
    {
      "epoch": 0.06368,
      "grad_norm": 0.09711534888553547,
      "learning_rate": 9.988886716144962e-05,
      "loss": 0.0348,
      "step": 19900
    },
    {
      "epoch": 0.063744,
      "grad_norm": 0.08308703847779922,
      "learning_rate": 9.988864374960246e-05,
      "loss": 0.0312,
      "step": 19920
    },
    {
      "epoch": 0.063808,
      "grad_norm": 0.09251636468438884,
      "learning_rate": 9.988842011366712e-05,
      "loss": 0.0318,
      "step": 19940
    },
    {
      "epoch": 0.063872,
      "grad_norm": 0.111629445438068,
      "learning_rate": 9.988819625364465e-05,
      "loss": 0.032,
      "step": 19960
    },
    {
      "epoch": 0.063936,
      "grad_norm": 0.09312178642101106,
      "learning_rate": 9.988797216953606e-05,
      "loss": 0.0338,
      "step": 19980
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.13281444009553867,
      "learning_rate": 9.988774786134234e-05,
      "loss": 0.0342,
      "step": 20000
    },
    {
      "epoch": 0.064064,
      "grad_norm": 0.1946919488956573,
      "learning_rate": 9.988752332906448e-05,
      "loss": 0.035,
      "step": 20020
    },
    {
      "epoch": 0.064128,
      "grad_norm": 0.10905724480159042,
      "learning_rate": 9.988729857270352e-05,
      "loss": 0.0373,
      "step": 20040
    },
    {
      "epoch": 0.064192,
      "grad_norm": 0.10228399147734746,
      "learning_rate": 9.988707359226046e-05,
      "loss": 0.0352,
      "step": 20060
    },
    {
      "epoch": 0.064256,
      "grad_norm": 0.1613613337891287,
      "learning_rate": 9.988684838773631e-05,
      "loss": 0.036,
      "step": 20080
    },
    {
      "epoch": 0.06432,
      "grad_norm": 0.1442467397823259,
      "learning_rate": 9.988662295913207e-05,
      "loss": 0.0348,
      "step": 20100
    },
    {
      "epoch": 0.064384,
      "grad_norm": 0.11227551650506154,
      "learning_rate": 9.988639730644878e-05,
      "loss": 0.038,
      "step": 20120
    },
    {
      "epoch": 0.064448,
      "grad_norm": 0.09236238289097193,
      "learning_rate": 9.988617142968742e-05,
      "loss": 0.0374,
      "step": 20140
    },
    {
      "epoch": 0.064512,
      "grad_norm": 0.11519695919059426,
      "learning_rate": 9.988594532884901e-05,
      "loss": 0.0357,
      "step": 20160
    },
    {
      "epoch": 0.064576,
      "grad_norm": 0.14688764367745852,
      "learning_rate": 9.98857190039346e-05,
      "loss": 0.0339,
      "step": 20180
    },
    {
      "epoch": 0.06464,
      "grad_norm": 0.13612490655294107,
      "learning_rate": 9.988549245494516e-05,
      "loss": 0.0305,
      "step": 20200
    },
    {
      "epoch": 0.064704,
      "grad_norm": 0.0881082733425425,
      "learning_rate": 9.988526568188175e-05,
      "loss": 0.0342,
      "step": 20220
    },
    {
      "epoch": 0.064768,
      "grad_norm": 0.09019350939902039,
      "learning_rate": 9.988503868474535e-05,
      "loss": 0.0347,
      "step": 20240
    },
    {
      "epoch": 0.064832,
      "grad_norm": 0.0672491035083009,
      "learning_rate": 9.988481146353701e-05,
      "loss": 0.0311,
      "step": 20260
    },
    {
      "epoch": 0.064896,
      "grad_norm": 0.08533985351303365,
      "learning_rate": 9.988458401825773e-05,
      "loss": 0.0294,
      "step": 20280
    },
    {
      "epoch": 0.06496,
      "grad_norm": 0.1412247276950405,
      "learning_rate": 9.988435634890856e-05,
      "loss": 0.0322,
      "step": 20300
    },
    {
      "epoch": 0.065024,
      "grad_norm": 0.11688902620279017,
      "learning_rate": 9.988412845549049e-05,
      "loss": 0.0338,
      "step": 20320
    },
    {
      "epoch": 0.065088,
      "grad_norm": 0.12587925805163994,
      "learning_rate": 9.988390033800455e-05,
      "loss": 0.034,
      "step": 20340
    },
    {
      "epoch": 0.065152,
      "grad_norm": 0.09200386765094475,
      "learning_rate": 9.988367199645179e-05,
      "loss": 0.0376,
      "step": 20360
    },
    {
      "epoch": 0.065216,
      "grad_norm": 0.08709078078675637,
      "learning_rate": 9.98834434308332e-05,
      "loss": 0.0339,
      "step": 20380
    },
    {
      "epoch": 0.06528,
      "grad_norm": 0.10377614256196271,
      "learning_rate": 9.988321464114983e-05,
      "loss": 0.0337,
      "step": 20400
    },
    {
      "epoch": 0.065344,
      "grad_norm": 0.1102509101769412,
      "learning_rate": 9.988298562740271e-05,
      "loss": 0.0347,
      "step": 20420
    },
    {
      "epoch": 0.065408,
      "grad_norm": 0.12764401531714004,
      "learning_rate": 9.988275638959284e-05,
      "loss": 0.0344,
      "step": 20440
    },
    {
      "epoch": 0.065472,
      "grad_norm": 0.12437730988637337,
      "learning_rate": 9.988252692772128e-05,
      "loss": 0.0368,
      "step": 20460
    },
    {
      "epoch": 0.065536,
      "grad_norm": 0.12975743178571492,
      "learning_rate": 9.988229724178905e-05,
      "loss": 0.0351,
      "step": 20480
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.09155438986807551,
      "learning_rate": 9.988206733179718e-05,
      "loss": 0.034,
      "step": 20500
    },
    {
      "epoch": 0.065664,
      "grad_norm": 0.1349778081408989,
      "learning_rate": 9.98818371977467e-05,
      "loss": 0.0346,
      "step": 20520
    },
    {
      "epoch": 0.065728,
      "grad_norm": 0.10545188394964498,
      "learning_rate": 9.988160683963867e-05,
      "loss": 0.0365,
      "step": 20540
    },
    {
      "epoch": 0.065792,
      "grad_norm": 0.10622394849619642,
      "learning_rate": 9.988137625747409e-05,
      "loss": 0.0364,
      "step": 20560
    },
    {
      "epoch": 0.065856,
      "grad_norm": 0.15379194517094838,
      "learning_rate": 9.9881145451254e-05,
      "loss": 0.0346,
      "step": 20580
    },
    {
      "epoch": 0.06592,
      "grad_norm": 0.11170316528472428,
      "learning_rate": 9.988091442097946e-05,
      "loss": 0.0366,
      "step": 20600
    },
    {
      "epoch": 0.065984,
      "grad_norm": 0.09986089160740233,
      "learning_rate": 9.988068316665149e-05,
      "loss": 0.0315,
      "step": 20620
    },
    {
      "epoch": 0.066048,
      "grad_norm": 0.0960743040914773,
      "learning_rate": 9.988045168827112e-05,
      "loss": 0.0341,
      "step": 20640
    },
    {
      "epoch": 0.066112,
      "grad_norm": 0.08902895311018785,
      "learning_rate": 9.988021998583941e-05,
      "loss": 0.035,
      "step": 20660
    },
    {
      "epoch": 0.066176,
      "grad_norm": 0.12481248581810564,
      "learning_rate": 9.98799880593574e-05,
      "loss": 0.0312,
      "step": 20680
    },
    {
      "epoch": 0.06624,
      "grad_norm": 0.1311086498766472,
      "learning_rate": 9.987975590882612e-05,
      "loss": 0.0312,
      "step": 20700
    },
    {
      "epoch": 0.066304,
      "grad_norm": 0.11081441380894388,
      "learning_rate": 9.98795235342466e-05,
      "loss": 0.0345,
      "step": 20720
    },
    {
      "epoch": 0.066368,
      "grad_norm": 0.12249528680320658,
      "learning_rate": 9.987929093561994e-05,
      "loss": 0.0322,
      "step": 20740
    },
    {
      "epoch": 0.066432,
      "grad_norm": 0.08542131645152584,
      "learning_rate": 9.987905811294711e-05,
      "loss": 0.0322,
      "step": 20760
    },
    {
      "epoch": 0.066496,
      "grad_norm": 0.1019385843912144,
      "learning_rate": 9.987882506622921e-05,
      "loss": 0.0304,
      "step": 20780
    },
    {
      "epoch": 0.06656,
      "grad_norm": 0.08357225682733553,
      "learning_rate": 9.987859179546725e-05,
      "loss": 0.0301,
      "step": 20800
    },
    {
      "epoch": 0.066624,
      "grad_norm": 0.09715634803833328,
      "learning_rate": 9.987835830066233e-05,
      "loss": 0.0345,
      "step": 20820
    },
    {
      "epoch": 0.066688,
      "grad_norm": 0.11742762304027937,
      "learning_rate": 9.987812458181544e-05,
      "loss": 0.0366,
      "step": 20840
    },
    {
      "epoch": 0.066752,
      "grad_norm": 0.13633109161076418,
      "learning_rate": 9.987789063892765e-05,
      "loss": 0.0375,
      "step": 20860
    },
    {
      "epoch": 0.066816,
      "grad_norm": 0.0905279376663852,
      "learning_rate": 9.987765647200003e-05,
      "loss": 0.032,
      "step": 20880
    },
    {
      "epoch": 0.06688,
      "grad_norm": 0.09638298452586012,
      "learning_rate": 9.987742208103361e-05,
      "loss": 0.0337,
      "step": 20900
    },
    {
      "epoch": 0.066944,
      "grad_norm": 0.10902499220861699,
      "learning_rate": 9.987718746602945e-05,
      "loss": 0.0367,
      "step": 20920
    },
    {
      "epoch": 0.067008,
      "grad_norm": 0.17972055697479955,
      "learning_rate": 9.987695262698862e-05,
      "loss": 0.0325,
      "step": 20940
    },
    {
      "epoch": 0.067072,
      "grad_norm": 0.0934453518671778,
      "learning_rate": 9.987671756391214e-05,
      "loss": 0.0358,
      "step": 20960
    },
    {
      "epoch": 0.067136,
      "grad_norm": 0.10079677565414472,
      "learning_rate": 9.987648227680109e-05,
      "loss": 0.0353,
      "step": 20980
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.1456544004330609,
      "learning_rate": 9.987624676565652e-05,
      "loss": 0.0349,
      "step": 21000
    },
    {
      "epoch": 0.067264,
      "grad_norm": 0.13223111664664167,
      "learning_rate": 9.987601103047949e-05,
      "loss": 0.0337,
      "step": 21020
    },
    {
      "epoch": 0.067328,
      "grad_norm": 0.11760018238690675,
      "learning_rate": 9.987577507127105e-05,
      "loss": 0.0349,
      "step": 21040
    },
    {
      "epoch": 0.067392,
      "grad_norm": 0.09636714559316599,
      "learning_rate": 9.987553888803228e-05,
      "loss": 0.0346,
      "step": 21060
    },
    {
      "epoch": 0.067456,
      "grad_norm": 0.12435365321895789,
      "learning_rate": 9.987530248076423e-05,
      "loss": 0.0309,
      "step": 21080
    },
    {
      "epoch": 0.06752,
      "grad_norm": 0.08448745877960774,
      "learning_rate": 9.987506584946796e-05,
      "loss": 0.0326,
      "step": 21100
    },
    {
      "epoch": 0.067584,
      "grad_norm": 0.07675594074264326,
      "learning_rate": 9.987482899414453e-05,
      "loss": 0.0304,
      "step": 21120
    },
    {
      "epoch": 0.067648,
      "grad_norm": 0.2142432419660501,
      "learning_rate": 9.9874591914795e-05,
      "loss": 0.0349,
      "step": 21140
    },
    {
      "epoch": 0.067712,
      "grad_norm": 0.15751114395153415,
      "learning_rate": 9.987435461142047e-05,
      "loss": 0.0359,
      "step": 21160
    },
    {
      "epoch": 0.067776,
      "grad_norm": 0.08525954219411724,
      "learning_rate": 9.987411708402195e-05,
      "loss": 0.0285,
      "step": 21180
    },
    {
      "epoch": 0.06784,
      "grad_norm": 0.09373727876751091,
      "learning_rate": 9.987387933260055e-05,
      "loss": 0.0312,
      "step": 21200
    },
    {
      "epoch": 0.067904,
      "grad_norm": 0.16463788252822245,
      "learning_rate": 9.987364135715731e-05,
      "loss": 0.0358,
      "step": 21220
    },
    {
      "epoch": 0.067968,
      "grad_norm": 0.1940625663842927,
      "learning_rate": 9.987340315769333e-05,
      "loss": 0.0353,
      "step": 21240
    },
    {
      "epoch": 0.068032,
      "grad_norm": 0.2866789336405311,
      "learning_rate": 9.987316473420964e-05,
      "loss": 0.0351,
      "step": 21260
    },
    {
      "epoch": 0.068096,
      "grad_norm": 0.09824261910585896,
      "learning_rate": 9.987292608670736e-05,
      "loss": 0.0354,
      "step": 21280
    },
    {
      "epoch": 0.06816,
      "grad_norm": 0.16362017010972113,
      "learning_rate": 9.987268721518752e-05,
      "loss": 0.0347,
      "step": 21300
    },
    {
      "epoch": 0.068224,
      "grad_norm": 0.11255524733216665,
      "learning_rate": 9.987244811965122e-05,
      "loss": 0.0337,
      "step": 21320
    },
    {
      "epoch": 0.068288,
      "grad_norm": 0.1727631612070328,
      "learning_rate": 9.98722088000995e-05,
      "loss": 0.0369,
      "step": 21340
    },
    {
      "epoch": 0.068352,
      "grad_norm": 0.1467422232451959,
      "learning_rate": 9.987196925653347e-05,
      "loss": 0.0323,
      "step": 21360
    },
    {
      "epoch": 0.068416,
      "grad_norm": 0.08780110882080794,
      "learning_rate": 9.987172948895421e-05,
      "loss": 0.0331,
      "step": 21380
    },
    {
      "epoch": 0.06848,
      "grad_norm": 0.07612285922676479,
      "learning_rate": 9.987148949736275e-05,
      "loss": 0.0335,
      "step": 21400
    },
    {
      "epoch": 0.068544,
      "grad_norm": 0.08400785906600124,
      "learning_rate": 9.987124928176021e-05,
      "loss": 0.0326,
      "step": 21420
    },
    {
      "epoch": 0.068608,
      "grad_norm": 0.10804813391983129,
      "learning_rate": 9.987100884214766e-05,
      "loss": 0.0325,
      "step": 21440
    },
    {
      "epoch": 0.068672,
      "grad_norm": 0.10586249085626774,
      "learning_rate": 9.987076817852616e-05,
      "loss": 0.0331,
      "step": 21460
    },
    {
      "epoch": 0.068736,
      "grad_norm": 0.09005642456938082,
      "learning_rate": 9.987052729089684e-05,
      "loss": 0.0309,
      "step": 21480
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.13534579842689604,
      "learning_rate": 9.987028617926073e-05,
      "loss": 0.0359,
      "step": 21500
    },
    {
      "epoch": 0.068864,
      "grad_norm": 0.13799601442537843,
      "learning_rate": 9.987004484361892e-05,
      "loss": 0.0366,
      "step": 21520
    },
    {
      "epoch": 0.068928,
      "grad_norm": 0.11352284235976513,
      "learning_rate": 9.986980328397253e-05,
      "loss": 0.0344,
      "step": 21540
    },
    {
      "epoch": 0.068992,
      "grad_norm": 0.13959411558621687,
      "learning_rate": 9.986956150032263e-05,
      "loss": 0.0364,
      "step": 21560
    },
    {
      "epoch": 0.069056,
      "grad_norm": 0.1580014252229343,
      "learning_rate": 9.986931949267026e-05,
      "loss": 0.0348,
      "step": 21580
    },
    {
      "epoch": 0.06912,
      "grad_norm": 0.08915989419157275,
      "learning_rate": 9.986907726101657e-05,
      "loss": 0.0316,
      "step": 21600
    },
    {
      "epoch": 0.069184,
      "grad_norm": 0.14700341291082408,
      "learning_rate": 9.986883480536263e-05,
      "loss": 0.0298,
      "step": 21620
    },
    {
      "epoch": 0.069248,
      "grad_norm": 0.168560323619228,
      "learning_rate": 9.986859212570952e-05,
      "loss": 0.0346,
      "step": 21640
    },
    {
      "epoch": 0.069312,
      "grad_norm": 0.17136835262565733,
      "learning_rate": 9.986834922205832e-05,
      "loss": 0.0349,
      "step": 21660
    },
    {
      "epoch": 0.069376,
      "grad_norm": 0.1172351523982956,
      "learning_rate": 9.986810609441014e-05,
      "loss": 0.0374,
      "step": 21680
    },
    {
      "epoch": 0.06944,
      "grad_norm": 0.17154488357160136,
      "learning_rate": 9.986786274276607e-05,
      "loss": 0.0351,
      "step": 21700
    },
    {
      "epoch": 0.069504,
      "grad_norm": 0.11076887481087162,
      "learning_rate": 9.98676191671272e-05,
      "loss": 0.0391,
      "step": 21720
    },
    {
      "epoch": 0.069568,
      "grad_norm": 0.11195043193378462,
      "learning_rate": 9.986737536749461e-05,
      "loss": 0.0312,
      "step": 21740
    },
    {
      "epoch": 0.069632,
      "grad_norm": 0.10691111031399213,
      "learning_rate": 9.98671313438694e-05,
      "loss": 0.035,
      "step": 21760
    },
    {
      "epoch": 0.069696,
      "grad_norm": 0.17322516095407947,
      "learning_rate": 9.986688709625269e-05,
      "loss": 0.0337,
      "step": 21780
    },
    {
      "epoch": 0.06976,
      "grad_norm": 0.08928676928025138,
      "learning_rate": 9.986664262464556e-05,
      "loss": 0.0312,
      "step": 21800
    },
    {
      "epoch": 0.069824,
      "grad_norm": 0.10028794145740745,
      "learning_rate": 9.986639792904911e-05,
      "loss": 0.0313,
      "step": 21820
    },
    {
      "epoch": 0.069888,
      "grad_norm": 0.07475651342883703,
      "learning_rate": 9.986615300946444e-05,
      "loss": 0.0324,
      "step": 21840
    },
    {
      "epoch": 0.069952,
      "grad_norm": 0.1791172822011138,
      "learning_rate": 9.986590786589265e-05,
      "loss": 0.0333,
      "step": 21860
    },
    {
      "epoch": 0.070016,
      "grad_norm": 0.17374840945085895,
      "learning_rate": 9.986566249833482e-05,
      "loss": 0.0374,
      "step": 21880
    },
    {
      "epoch": 0.07008,
      "grad_norm": 0.11277387828941446,
      "learning_rate": 9.98654169067921e-05,
      "loss": 0.0366,
      "step": 21900
    },
    {
      "epoch": 0.070144,
      "grad_norm": 0.09136608426004007,
      "learning_rate": 9.986517109126554e-05,
      "loss": 0.034,
      "step": 21920
    },
    {
      "epoch": 0.070208,
      "grad_norm": 0.07601115825397944,
      "learning_rate": 9.986492505175628e-05,
      "loss": 0.0329,
      "step": 21940
    },
    {
      "epoch": 0.070272,
      "grad_norm": 0.11780046182188607,
      "learning_rate": 9.986467878826541e-05,
      "loss": 0.0336,
      "step": 21960
    },
    {
      "epoch": 0.070336,
      "grad_norm": 0.10988987242826376,
      "learning_rate": 9.986443230079404e-05,
      "loss": 0.0338,
      "step": 21980
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.09965298417804483,
      "learning_rate": 9.986418558934328e-05,
      "loss": 0.0322,
      "step": 22000
    },
    {
      "epoch": 0.070464,
      "grad_norm": 0.15290961064091546,
      "learning_rate": 9.986393865391424e-05,
      "loss": 0.0338,
      "step": 22020
    },
    {
      "epoch": 0.070528,
      "grad_norm": 0.11983624100752203,
      "learning_rate": 9.986369149450803e-05,
      "loss": 0.0328,
      "step": 22040
    },
    {
      "epoch": 0.070592,
      "grad_norm": 0.10846236021220694,
      "learning_rate": 9.986344411112574e-05,
      "loss": 0.035,
      "step": 22060
    },
    {
      "epoch": 0.070656,
      "grad_norm": 0.09480335695068524,
      "learning_rate": 9.98631965037685e-05,
      "loss": 0.0356,
      "step": 22080
    },
    {
      "epoch": 0.07072,
      "grad_norm": 0.08494547047690275,
      "learning_rate": 9.986294867243741e-05,
      "loss": 0.0328,
      "step": 22100
    },
    {
      "epoch": 0.070784,
      "grad_norm": 0.08927285255544838,
      "learning_rate": 9.98627006171336e-05,
      "loss": 0.0358,
      "step": 22120
    },
    {
      "epoch": 0.070848,
      "grad_norm": 0.1118799919087846,
      "learning_rate": 9.986245233785818e-05,
      "loss": 0.0352,
      "step": 22140
    },
    {
      "epoch": 0.070912,
      "grad_norm": 0.10905824083152592,
      "learning_rate": 9.986220383461226e-05,
      "loss": 0.035,
      "step": 22160
    },
    {
      "epoch": 0.070976,
      "grad_norm": 0.08710638804272211,
      "learning_rate": 9.986195510739695e-05,
      "loss": 0.0337,
      "step": 22180
    },
    {
      "epoch": 0.07104,
      "grad_norm": 0.25457471012115274,
      "learning_rate": 9.986170615621338e-05,
      "loss": 0.0336,
      "step": 22200
    },
    {
      "epoch": 0.071104,
      "grad_norm": 0.12381429533408675,
      "learning_rate": 9.986145698106266e-05,
      "loss": 0.0356,
      "step": 22220
    },
    {
      "epoch": 0.071168,
      "grad_norm": 0.11927002446767047,
      "learning_rate": 9.986120758194591e-05,
      "loss": 0.0363,
      "step": 22240
    },
    {
      "epoch": 0.071232,
      "grad_norm": 0.15291653038749115,
      "learning_rate": 9.986095795886425e-05,
      "loss": 0.0357,
      "step": 22260
    },
    {
      "epoch": 0.071296,
      "grad_norm": 0.1620245988658392,
      "learning_rate": 9.986070811181881e-05,
      "loss": 0.0355,
      "step": 22280
    },
    {
      "epoch": 0.07136,
      "grad_norm": 0.11677865005241177,
      "learning_rate": 9.986045804081071e-05,
      "loss": 0.0329,
      "step": 22300
    },
    {
      "epoch": 0.071424,
      "grad_norm": 0.14375380888355657,
      "learning_rate": 9.986020774584106e-05,
      "loss": 0.0336,
      "step": 22320
    },
    {
      "epoch": 0.071488,
      "grad_norm": 0.09387330341130333,
      "learning_rate": 9.9859957226911e-05,
      "loss": 0.0306,
      "step": 22340
    },
    {
      "epoch": 0.071552,
      "grad_norm": 0.10192429603829761,
      "learning_rate": 9.985970648402163e-05,
      "loss": 0.0345,
      "step": 22360
    },
    {
      "epoch": 0.071616,
      "grad_norm": 0.16854455715990768,
      "learning_rate": 9.98594555171741e-05,
      "loss": 0.0379,
      "step": 22380
    },
    {
      "epoch": 0.07168,
      "grad_norm": 0.08577447965454207,
      "learning_rate": 9.985920432636955e-05,
      "loss": 0.0341,
      "step": 22400
    },
    {
      "epoch": 0.071744,
      "grad_norm": 0.12286390524066537,
      "learning_rate": 9.985895291160908e-05,
      "loss": 0.0359,
      "step": 22420
    },
    {
      "epoch": 0.071808,
      "grad_norm": 0.14869475655142642,
      "learning_rate": 9.985870127289383e-05,
      "loss": 0.0354,
      "step": 22440
    },
    {
      "epoch": 0.071872,
      "grad_norm": 0.1042488730088998,
      "learning_rate": 9.985844941022493e-05,
      "loss": 0.0364,
      "step": 22460
    },
    {
      "epoch": 0.071936,
      "grad_norm": 0.10789509209694285,
      "learning_rate": 9.985819732360351e-05,
      "loss": 0.0344,
      "step": 22480
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.10894234387116458,
      "learning_rate": 9.98579450130307e-05,
      "loss": 0.0349,
      "step": 22500
    },
    {
      "epoch": 0.072064,
      "grad_norm": 0.11867946751278823,
      "learning_rate": 9.985769247850764e-05,
      "loss": 0.0291,
      "step": 22520
    },
    {
      "epoch": 0.072128,
      "grad_norm": 0.09705695618330211,
      "learning_rate": 9.985743972003546e-05,
      "loss": 0.0344,
      "step": 22540
    },
    {
      "epoch": 0.072192,
      "grad_norm": 0.10786022442059426,
      "learning_rate": 9.985718673761531e-05,
      "loss": 0.0346,
      "step": 22560
    },
    {
      "epoch": 0.072256,
      "grad_norm": 0.11144097486663002,
      "learning_rate": 9.985693353124829e-05,
      "loss": 0.0331,
      "step": 22580
    },
    {
      "epoch": 0.07232,
      "grad_norm": 0.08289402728592855,
      "learning_rate": 9.985668010093556e-05,
      "loss": 0.0314,
      "step": 22600
    },
    {
      "epoch": 0.072384,
      "grad_norm": 0.0822978678733783,
      "learning_rate": 9.985642644667828e-05,
      "loss": 0.0328,
      "step": 22620
    },
    {
      "epoch": 0.072448,
      "grad_norm": 0.1543036128413852,
      "learning_rate": 9.985617256847755e-05,
      "loss": 0.0352,
      "step": 22640
    },
    {
      "epoch": 0.072512,
      "grad_norm": 0.14063184336609527,
      "learning_rate": 9.985591846633453e-05,
      "loss": 0.0342,
      "step": 22660
    },
    {
      "epoch": 0.072576,
      "grad_norm": 0.1495811644007825,
      "learning_rate": 9.985566414025038e-05,
      "loss": 0.0379,
      "step": 22680
    },
    {
      "epoch": 0.07264,
      "grad_norm": 0.106790204224623,
      "learning_rate": 9.98554095902262e-05,
      "loss": 0.0374,
      "step": 22700
    },
    {
      "epoch": 0.072704,
      "grad_norm": 0.111100937567488,
      "learning_rate": 9.985515481626315e-05,
      "loss": 0.0346,
      "step": 22720
    },
    {
      "epoch": 0.072768,
      "grad_norm": 0.13819359649565374,
      "learning_rate": 9.98548998183624e-05,
      "loss": 0.0337,
      "step": 22740
    },
    {
      "epoch": 0.072832,
      "grad_norm": 0.07944071253155681,
      "learning_rate": 9.985464459652507e-05,
      "loss": 0.0312,
      "step": 22760
    },
    {
      "epoch": 0.072896,
      "grad_norm": 0.1096125354403516,
      "learning_rate": 9.98543891507523e-05,
      "loss": 0.033,
      "step": 22780
    },
    {
      "epoch": 0.07296,
      "grad_norm": 0.13947531737669475,
      "learning_rate": 9.985413348104525e-05,
      "loss": 0.0368,
      "step": 22800
    },
    {
      "epoch": 0.073024,
      "grad_norm": 0.15737557657548285,
      "learning_rate": 9.985387758740507e-05,
      "loss": 0.0369,
      "step": 22820
    },
    {
      "epoch": 0.073088,
      "grad_norm": 0.1301242895645652,
      "learning_rate": 9.985362146983292e-05,
      "loss": 0.0356,
      "step": 22840
    },
    {
      "epoch": 0.073152,
      "grad_norm": 0.11475803176252446,
      "learning_rate": 9.985336512832992e-05,
      "loss": 0.0334,
      "step": 22860
    },
    {
      "epoch": 0.073216,
      "grad_norm": 0.12927507541802974,
      "learning_rate": 9.985310856289725e-05,
      "loss": 0.0332,
      "step": 22880
    },
    {
      "epoch": 0.07328,
      "grad_norm": 0.11828562186544112,
      "learning_rate": 9.985285177353604e-05,
      "loss": 0.038,
      "step": 22900
    },
    {
      "epoch": 0.073344,
      "grad_norm": 0.20484958284916652,
      "learning_rate": 9.985259476024746e-05,
      "loss": 0.0354,
      "step": 22920
    },
    {
      "epoch": 0.073408,
      "grad_norm": 0.1352763810071271,
      "learning_rate": 9.985233752303265e-05,
      "loss": 0.0368,
      "step": 22940
    },
    {
      "epoch": 0.073472,
      "grad_norm": 0.09721109652072536,
      "learning_rate": 9.985208006189279e-05,
      "loss": 0.0379,
      "step": 22960
    },
    {
      "epoch": 0.073536,
      "grad_norm": 0.1280728472700533,
      "learning_rate": 9.985182237682902e-05,
      "loss": 0.0354,
      "step": 22980
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.17153856382797025,
      "learning_rate": 9.985156446784248e-05,
      "loss": 0.0345,
      "step": 23000
    },
    {
      "epoch": 0.073664,
      "grad_norm": 0.16049632666044922,
      "learning_rate": 9.985130633493436e-05,
      "loss": 0.0367,
      "step": 23020
    },
    {
      "epoch": 0.073728,
      "grad_norm": 0.10668301542994196,
      "learning_rate": 9.98510479781058e-05,
      "loss": 0.0353,
      "step": 23040
    },
    {
      "epoch": 0.073792,
      "grad_norm": 0.12396053721861013,
      "learning_rate": 9.985078939735797e-05,
      "loss": 0.0372,
      "step": 23060
    },
    {
      "epoch": 0.073856,
      "grad_norm": 0.1559179467497307,
      "learning_rate": 9.985053059269203e-05,
      "loss": 0.037,
      "step": 23080
    },
    {
      "epoch": 0.07392,
      "grad_norm": 0.13852000977347076,
      "learning_rate": 9.985027156410915e-05,
      "loss": 0.0361,
      "step": 23100
    },
    {
      "epoch": 0.073984,
      "grad_norm": 0.1383224024822978,
      "learning_rate": 9.985001231161046e-05,
      "loss": 0.0334,
      "step": 23120
    },
    {
      "epoch": 0.074048,
      "grad_norm": 0.12230929256897073,
      "learning_rate": 9.984975283519718e-05,
      "loss": 0.0357,
      "step": 23140
    },
    {
      "epoch": 0.074112,
      "grad_norm": 0.13142021168582768,
      "learning_rate": 9.984949313487042e-05,
      "loss": 0.0324,
      "step": 23160
    },
    {
      "epoch": 0.074176,
      "grad_norm": 0.10858457301389712,
      "learning_rate": 9.984923321063136e-05,
      "loss": 0.0347,
      "step": 23180
    },
    {
      "epoch": 0.07424,
      "grad_norm": 0.1657101590786394,
      "learning_rate": 9.98489730624812e-05,
      "loss": 0.0311,
      "step": 23200
    },
    {
      "epoch": 0.074304,
      "grad_norm": 0.11723274373611986,
      "learning_rate": 9.984871269042109e-05,
      "loss": 0.0306,
      "step": 23220
    },
    {
      "epoch": 0.074368,
      "grad_norm": 0.11639365922378339,
      "learning_rate": 9.984845209445218e-05,
      "loss": 0.0322,
      "step": 23240
    },
    {
      "epoch": 0.074432,
      "grad_norm": 0.15288932894379312,
      "learning_rate": 9.984819127457567e-05,
      "loss": 0.0327,
      "step": 23260
    },
    {
      "epoch": 0.074496,
      "grad_norm": 0.07563649275887233,
      "learning_rate": 9.984793023079271e-05,
      "loss": 0.0284,
      "step": 23280
    },
    {
      "epoch": 0.07456,
      "grad_norm": 0.0809438123424736,
      "learning_rate": 9.984766896310448e-05,
      "loss": 0.0308,
      "step": 23300
    },
    {
      "epoch": 0.074624,
      "grad_norm": 0.1350131396258057,
      "learning_rate": 9.984740747151216e-05,
      "loss": 0.0383,
      "step": 23320
    },
    {
      "epoch": 0.074688,
      "grad_norm": 0.1860276689511777,
      "learning_rate": 9.98471457560169e-05,
      "loss": 0.031,
      "step": 23340
    },
    {
      "epoch": 0.074752,
      "grad_norm": 0.11324969659650413,
      "learning_rate": 9.984688381661991e-05,
      "loss": 0.0334,
      "step": 23360
    },
    {
      "epoch": 0.074816,
      "grad_norm": 0.11570226230839156,
      "learning_rate": 9.984662165332236e-05,
      "loss": 0.0355,
      "step": 23380
    },
    {
      "epoch": 0.07488,
      "grad_norm": 0.12287423140811278,
      "learning_rate": 9.984635926612541e-05,
      "loss": 0.0315,
      "step": 23400
    },
    {
      "epoch": 0.074944,
      "grad_norm": 0.1085045436875802,
      "learning_rate": 9.984609665503024e-05,
      "loss": 0.0347,
      "step": 23420
    },
    {
      "epoch": 0.075008,
      "grad_norm": 0.15013649434954515,
      "learning_rate": 9.984583382003804e-05,
      "loss": 0.0354,
      "step": 23440
    },
    {
      "epoch": 0.075072,
      "grad_norm": 0.10011970851404092,
      "learning_rate": 9.984557076115e-05,
      "loss": 0.0349,
      "step": 23460
    },
    {
      "epoch": 0.075136,
      "grad_norm": 0.11176852377881148,
      "learning_rate": 9.984530747836727e-05,
      "loss": 0.0318,
      "step": 23480
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.10452527078675526,
      "learning_rate": 9.984504397169108e-05,
      "loss": 0.0333,
      "step": 23500
    },
    {
      "epoch": 0.075264,
      "grad_norm": 0.1575744902047966,
      "learning_rate": 9.984478024112255e-05,
      "loss": 0.0334,
      "step": 23520
    },
    {
      "epoch": 0.075328,
      "grad_norm": 0.090154081985554,
      "learning_rate": 9.984451628666293e-05,
      "loss": 0.0335,
      "step": 23540
    },
    {
      "epoch": 0.075392,
      "grad_norm": 0.10652200170072235,
      "learning_rate": 9.984425210831337e-05,
      "loss": 0.0331,
      "step": 23560
    },
    {
      "epoch": 0.075456,
      "grad_norm": 0.1433303180431082,
      "learning_rate": 9.984398770607504e-05,
      "loss": 0.0388,
      "step": 23580
    },
    {
      "epoch": 0.07552,
      "grad_norm": 0.09450120284550108,
      "learning_rate": 9.984372307994916e-05,
      "loss": 0.0345,
      "step": 23600
    },
    {
      "epoch": 0.075584,
      "grad_norm": 0.07776704489299817,
      "learning_rate": 9.984345822993692e-05,
      "loss": 0.0358,
      "step": 23620
    },
    {
      "epoch": 0.075648,
      "grad_norm": 0.09212792972449117,
      "learning_rate": 9.984319315603949e-05,
      "loss": 0.0333,
      "step": 23640
    },
    {
      "epoch": 0.075712,
      "grad_norm": 0.11412755202708111,
      "learning_rate": 9.984292785825806e-05,
      "loss": 0.0348,
      "step": 23660
    },
    {
      "epoch": 0.075776,
      "grad_norm": 0.0855586312714624,
      "learning_rate": 9.984266233659384e-05,
      "loss": 0.0354,
      "step": 23680
    },
    {
      "epoch": 0.07584,
      "grad_norm": 0.10354229239345891,
      "learning_rate": 9.984239659104802e-05,
      "loss": 0.0336,
      "step": 23700
    },
    {
      "epoch": 0.075904,
      "grad_norm": 0.1227634082449925,
      "learning_rate": 9.984213062162177e-05,
      "loss": 0.0318,
      "step": 23720
    },
    {
      "epoch": 0.075968,
      "grad_norm": 0.07977200879308788,
      "learning_rate": 9.984186442831632e-05,
      "loss": 0.0332,
      "step": 23740
    },
    {
      "epoch": 0.076032,
      "grad_norm": 0.09641596188427982,
      "learning_rate": 9.984159801113282e-05,
      "loss": 0.0366,
      "step": 23760
    },
    {
      "epoch": 0.076096,
      "grad_norm": 0.09422931252018964,
      "learning_rate": 9.984133137007252e-05,
      "loss": 0.0326,
      "step": 23780
    },
    {
      "epoch": 0.07616,
      "grad_norm": 0.09866807114573506,
      "learning_rate": 9.984106450513658e-05,
      "loss": 0.0323,
      "step": 23800
    },
    {
      "epoch": 0.076224,
      "grad_norm": 0.08813252213801066,
      "learning_rate": 9.98407974163262e-05,
      "loss": 0.0346,
      "step": 23820
    },
    {
      "epoch": 0.076288,
      "grad_norm": 0.08657876504824362,
      "learning_rate": 9.98405301036426e-05,
      "loss": 0.0297,
      "step": 23840
    },
    {
      "epoch": 0.076352,
      "grad_norm": 0.11692729636424436,
      "learning_rate": 9.984026256708698e-05,
      "loss": 0.0301,
      "step": 23860
    },
    {
      "epoch": 0.076416,
      "grad_norm": 0.12023463530061697,
      "learning_rate": 9.983999480666051e-05,
      "loss": 0.033,
      "step": 23880
    },
    {
      "epoch": 0.07648,
      "grad_norm": 0.09727304732318916,
      "learning_rate": 9.983972682236444e-05,
      "loss": 0.0303,
      "step": 23900
    },
    {
      "epoch": 0.076544,
      "grad_norm": 0.0881919324293794,
      "learning_rate": 9.983945861419992e-05,
      "loss": 0.0337,
      "step": 23920
    },
    {
      "epoch": 0.076608,
      "grad_norm": 0.08178845006946162,
      "learning_rate": 9.983919018216821e-05,
      "loss": 0.0403,
      "step": 23940
    },
    {
      "epoch": 0.076672,
      "grad_norm": 0.09172218751808453,
      "learning_rate": 9.983892152627048e-05,
      "loss": 0.0341,
      "step": 23960
    },
    {
      "epoch": 0.076736,
      "grad_norm": 0.09422215462398728,
      "learning_rate": 9.983865264650794e-05,
      "loss": 0.0345,
      "step": 23980
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.09164471308796546,
      "learning_rate": 9.983838354288181e-05,
      "loss": 0.0335,
      "step": 24000
    },
    {
      "epoch": 0.076864,
      "grad_norm": 0.09370380265865201,
      "learning_rate": 9.983811421539329e-05,
      "loss": 0.0337,
      "step": 24020
    },
    {
      "epoch": 0.076928,
      "grad_norm": 0.08397203228215365,
      "learning_rate": 9.983784466404358e-05,
      "loss": 0.0313,
      "step": 24040
    },
    {
      "epoch": 0.076992,
      "grad_norm": 0.16319011558463653,
      "learning_rate": 9.983757488883391e-05,
      "loss": 0.0298,
      "step": 24060
    },
    {
      "epoch": 0.077056,
      "grad_norm": 0.13577492284955922,
      "learning_rate": 9.98373048897655e-05,
      "loss": 0.0326,
      "step": 24080
    },
    {
      "epoch": 0.07712,
      "grad_norm": 0.2080289049387854,
      "learning_rate": 9.983703466683953e-05,
      "loss": 0.0321,
      "step": 24100
    },
    {
      "epoch": 0.077184,
      "grad_norm": 0.10349573589620358,
      "learning_rate": 9.983676422005726e-05,
      "loss": 0.0381,
      "step": 24120
    },
    {
      "epoch": 0.077248,
      "grad_norm": 0.09485697956727139,
      "learning_rate": 9.983649354941984e-05,
      "loss": 0.0329,
      "step": 24140
    },
    {
      "epoch": 0.077312,
      "grad_norm": 0.14470244111587938,
      "learning_rate": 9.983622265492854e-05,
      "loss": 0.0346,
      "step": 24160
    },
    {
      "epoch": 0.077376,
      "grad_norm": 0.247931010251161,
      "learning_rate": 9.983595153658455e-05,
      "loss": 0.0325,
      "step": 24180
    },
    {
      "epoch": 0.07744,
      "grad_norm": 0.1160921992607393,
      "learning_rate": 9.983568019438909e-05,
      "loss": 0.0336,
      "step": 24200
    },
    {
      "epoch": 0.077504,
      "grad_norm": 0.12236922485558886,
      "learning_rate": 9.98354086283434e-05,
      "loss": 0.0305,
      "step": 24220
    },
    {
      "epoch": 0.077568,
      "grad_norm": 0.10852443449328167,
      "learning_rate": 9.983513683844869e-05,
      "loss": 0.0339,
      "step": 24240
    },
    {
      "epoch": 0.077632,
      "grad_norm": 0.11681069345985914,
      "learning_rate": 9.983486482470616e-05,
      "loss": 0.0341,
      "step": 24260
    },
    {
      "epoch": 0.077696,
      "grad_norm": 0.12221354147434337,
      "learning_rate": 9.983459258711705e-05,
      "loss": 0.036,
      "step": 24280
    },
    {
      "epoch": 0.07776,
      "grad_norm": 0.08925623808077693,
      "learning_rate": 9.983432012568259e-05,
      "loss": 0.0345,
      "step": 24300
    },
    {
      "epoch": 0.077824,
      "grad_norm": 0.15232534757616956,
      "learning_rate": 9.983404744040397e-05,
      "loss": 0.0346,
      "step": 24320
    },
    {
      "epoch": 0.077888,
      "grad_norm": 0.1153236023925341,
      "learning_rate": 9.983377453128246e-05,
      "loss": 0.0348,
      "step": 24340
    },
    {
      "epoch": 0.077952,
      "grad_norm": 0.11645857817320884,
      "learning_rate": 9.983350139831926e-05,
      "loss": 0.0332,
      "step": 24360
    },
    {
      "epoch": 0.078016,
      "grad_norm": 0.15716213539521012,
      "learning_rate": 9.983322804151561e-05,
      "loss": 0.0308,
      "step": 24380
    },
    {
      "epoch": 0.07808,
      "grad_norm": 0.09582219389460982,
      "learning_rate": 9.983295446087271e-05,
      "loss": 0.0389,
      "step": 24400
    },
    {
      "epoch": 0.078144,
      "grad_norm": 0.18008561224826747,
      "learning_rate": 9.983268065639183e-05,
      "loss": 0.0374,
      "step": 24420
    },
    {
      "epoch": 0.078208,
      "grad_norm": 0.09700448424048778,
      "learning_rate": 9.983240662807416e-05,
      "loss": 0.0373,
      "step": 24440
    },
    {
      "epoch": 0.078272,
      "grad_norm": 0.09433722466504182,
      "learning_rate": 9.983213237592098e-05,
      "loss": 0.0362,
      "step": 24460
    },
    {
      "epoch": 0.078336,
      "grad_norm": 0.09844078926611434,
      "learning_rate": 9.983185789993345e-05,
      "loss": 0.0362,
      "step": 24480
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.12133351355001834,
      "learning_rate": 9.983158320011288e-05,
      "loss": 0.0347,
      "step": 24500
    },
    {
      "epoch": 0.078464,
      "grad_norm": 0.10226172322273738,
      "learning_rate": 9.983130827646043e-05,
      "loss": 0.0318,
      "step": 24520
    },
    {
      "epoch": 0.078528,
      "grad_norm": 0.13081582584461734,
      "learning_rate": 9.98310331289774e-05,
      "loss": 0.0346,
      "step": 24540
    },
    {
      "epoch": 0.078592,
      "grad_norm": 0.11509693404078751,
      "learning_rate": 9.983075775766499e-05,
      "loss": 0.0335,
      "step": 24560
    },
    {
      "epoch": 0.078656,
      "grad_norm": 0.10002770801727752,
      "learning_rate": 9.983048216252445e-05,
      "loss": 0.032,
      "step": 24580
    },
    {
      "epoch": 0.07872,
      "grad_norm": 0.097801171498897,
      "learning_rate": 9.983020634355703e-05,
      "loss": 0.033,
      "step": 24600
    },
    {
      "epoch": 0.078784,
      "grad_norm": 0.15618786819963487,
      "learning_rate": 9.982993030076392e-05,
      "loss": 0.0343,
      "step": 24620
    },
    {
      "epoch": 0.078848,
      "grad_norm": 0.1439849322435853,
      "learning_rate": 9.98296540341464e-05,
      "loss": 0.0333,
      "step": 24640
    },
    {
      "epoch": 0.078912,
      "grad_norm": 0.0841734480477287,
      "learning_rate": 9.982937754370571e-05,
      "loss": 0.0343,
      "step": 24660
    },
    {
      "epoch": 0.078976,
      "grad_norm": 0.0964035108175424,
      "learning_rate": 9.982910082944308e-05,
      "loss": 0.0329,
      "step": 24680
    },
    {
      "epoch": 0.07904,
      "grad_norm": 0.12902371162110443,
      "learning_rate": 9.982882389135977e-05,
      "loss": 0.032,
      "step": 24700
    },
    {
      "epoch": 0.079104,
      "grad_norm": 0.13634758754882226,
      "learning_rate": 9.9828546729457e-05,
      "loss": 0.0321,
      "step": 24720
    },
    {
      "epoch": 0.079168,
      "grad_norm": 0.11364374593349984,
      "learning_rate": 9.982826934373604e-05,
      "loss": 0.0356,
      "step": 24740
    },
    {
      "epoch": 0.079232,
      "grad_norm": 0.11119432247672688,
      "learning_rate": 9.98279917341981e-05,
      "loss": 0.0382,
      "step": 24760
    },
    {
      "epoch": 0.079296,
      "grad_norm": 0.10298859948437575,
      "learning_rate": 9.982771390084446e-05,
      "loss": 0.0333,
      "step": 24780
    },
    {
      "epoch": 0.07936,
      "grad_norm": 0.12396091007150137,
      "learning_rate": 9.982743584367637e-05,
      "loss": 0.0332,
      "step": 24800
    },
    {
      "epoch": 0.079424,
      "grad_norm": 0.09996606536090746,
      "learning_rate": 9.982715756269505e-05,
      "loss": 0.0332,
      "step": 24820
    },
    {
      "epoch": 0.079488,
      "grad_norm": 0.13933585614323685,
      "learning_rate": 9.982687905790178e-05,
      "loss": 0.0329,
      "step": 24840
    },
    {
      "epoch": 0.079552,
      "grad_norm": 0.09471685794063534,
      "learning_rate": 9.982660032929778e-05,
      "loss": 0.0298,
      "step": 24860
    },
    {
      "epoch": 0.079616,
      "grad_norm": 0.1374380867744802,
      "learning_rate": 9.982632137688435e-05,
      "loss": 0.0344,
      "step": 24880
    },
    {
      "epoch": 0.07968,
      "grad_norm": 0.08803363447017606,
      "learning_rate": 9.982604220066269e-05,
      "loss": 0.0364,
      "step": 24900
    },
    {
      "epoch": 0.079744,
      "grad_norm": 0.1386970521201084,
      "learning_rate": 9.982576280063407e-05,
      "loss": 0.0335,
      "step": 24920
    },
    {
      "epoch": 0.079808,
      "grad_norm": 0.14197989770467562,
      "learning_rate": 9.982548317679976e-05,
      "loss": 0.0315,
      "step": 24940
    },
    {
      "epoch": 0.079872,
      "grad_norm": 0.09712238102162671,
      "learning_rate": 9.982520332916102e-05,
      "loss": 0.0321,
      "step": 24960
    },
    {
      "epoch": 0.079936,
      "grad_norm": 0.09227798757015492,
      "learning_rate": 9.982492325771908e-05,
      "loss": 0.0303,
      "step": 24980
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10211406590987661,
      "learning_rate": 9.982464296247522e-05,
      "loss": 0.0342,
      "step": 25000
    },
    {
      "epoch": 0.080064,
      "grad_norm": 0.18082385185905728,
      "learning_rate": 9.98243624434307e-05,
      "loss": 0.0318,
      "step": 25020
    },
    {
      "epoch": 0.080128,
      "grad_norm": 0.07103310374430172,
      "learning_rate": 9.982408170058675e-05,
      "loss": 0.0356,
      "step": 25040
    },
    {
      "epoch": 0.080192,
      "grad_norm": 0.10584007822092685,
      "learning_rate": 9.982380073394465e-05,
      "loss": 0.0363,
      "step": 25060
    },
    {
      "epoch": 0.080256,
      "grad_norm": 0.09522641144881656,
      "learning_rate": 9.982351954350569e-05,
      "loss": 0.0351,
      "step": 25080
    },
    {
      "epoch": 0.08032,
      "grad_norm": 0.1425724898902192,
      "learning_rate": 9.98232381292711e-05,
      "loss": 0.0364,
      "step": 25100
    },
    {
      "epoch": 0.080384,
      "grad_norm": 0.2089148016770719,
      "learning_rate": 9.982295649124215e-05,
      "loss": 0.0365,
      "step": 25120
    },
    {
      "epoch": 0.080448,
      "grad_norm": 0.2186503553193735,
      "learning_rate": 9.98226746294201e-05,
      "loss": 0.0312,
      "step": 25140
    },
    {
      "epoch": 0.080512,
      "grad_norm": 0.13424573188961297,
      "learning_rate": 9.982239254380624e-05,
      "loss": 0.0315,
      "step": 25160
    },
    {
      "epoch": 0.080576,
      "grad_norm": 0.15442275500620958,
      "learning_rate": 9.98221102344018e-05,
      "loss": 0.0368,
      "step": 25180
    },
    {
      "epoch": 0.08064,
      "grad_norm": 0.1139235449092795,
      "learning_rate": 9.982182770120807e-05,
      "loss": 0.0365,
      "step": 25200
    },
    {
      "epoch": 0.080704,
      "grad_norm": 0.07326654247311916,
      "learning_rate": 9.982154494422633e-05,
      "loss": 0.0343,
      "step": 25220
    },
    {
      "epoch": 0.080768,
      "grad_norm": 0.11521027938534616,
      "learning_rate": 9.982126196345784e-05,
      "loss": 0.0329,
      "step": 25240
    },
    {
      "epoch": 0.080832,
      "grad_norm": 0.09615136105389115,
      "learning_rate": 9.982097875890386e-05,
      "loss": 0.036,
      "step": 25260
    },
    {
      "epoch": 0.080896,
      "grad_norm": 0.1091019555906166,
      "learning_rate": 9.982069533056566e-05,
      "loss": 0.0374,
      "step": 25280
    },
    {
      "epoch": 0.08096,
      "grad_norm": 0.10089828094391107,
      "learning_rate": 9.982041167844454e-05,
      "loss": 0.033,
      "step": 25300
    },
    {
      "epoch": 0.081024,
      "grad_norm": 0.0666994908594565,
      "learning_rate": 9.982012780254175e-05,
      "loss": 0.0305,
      "step": 25320
    },
    {
      "epoch": 0.081088,
      "grad_norm": 0.10244077735697388,
      "learning_rate": 9.981984370285857e-05,
      "loss": 0.0356,
      "step": 25340
    },
    {
      "epoch": 0.081152,
      "grad_norm": 0.09437752237104859,
      "learning_rate": 9.981955937939629e-05,
      "loss": 0.0352,
      "step": 25360
    },
    {
      "epoch": 0.081216,
      "grad_norm": 0.11200821455002646,
      "learning_rate": 9.981927483215617e-05,
      "loss": 0.0309,
      "step": 25380
    },
    {
      "epoch": 0.08128,
      "grad_norm": 0.08896521758843787,
      "learning_rate": 9.981899006113949e-05,
      "loss": 0.0335,
      "step": 25400
    },
    {
      "epoch": 0.081344,
      "grad_norm": 0.1644478330031223,
      "learning_rate": 9.981870506634752e-05,
      "loss": 0.0373,
      "step": 25420
    },
    {
      "epoch": 0.081408,
      "grad_norm": 0.07971674925906712,
      "learning_rate": 9.981841984778158e-05,
      "loss": 0.0343,
      "step": 25440
    },
    {
      "epoch": 0.081472,
      "grad_norm": 0.10442652834495857,
      "learning_rate": 9.981813440544292e-05,
      "loss": 0.0317,
      "step": 25460
    },
    {
      "epoch": 0.081536,
      "grad_norm": 0.07785670732939133,
      "learning_rate": 9.981784873933283e-05,
      "loss": 0.0339,
      "step": 25480
    },
    {
      "epoch": 0.0816,
      "grad_norm": 0.07163519821657759,
      "learning_rate": 9.981756284945256e-05,
      "loss": 0.0343,
      "step": 25500
    },
    {
      "epoch": 0.081664,
      "grad_norm": 0.3101263292137316,
      "learning_rate": 9.981727673580346e-05,
      "loss": 0.037,
      "step": 25520
    },
    {
      "epoch": 0.081728,
      "grad_norm": 0.12408034693958458,
      "learning_rate": 9.981699039838675e-05,
      "loss": 0.0341,
      "step": 25540
    },
    {
      "epoch": 0.081792,
      "grad_norm": 0.10668163958916406,
      "learning_rate": 9.981670383720376e-05,
      "loss": 0.0354,
      "step": 25560
    },
    {
      "epoch": 0.081856,
      "grad_norm": 0.11666162452583224,
      "learning_rate": 9.981641705225576e-05,
      "loss": 0.0337,
      "step": 25580
    },
    {
      "epoch": 0.08192,
      "grad_norm": 0.1266754357784379,
      "learning_rate": 9.981613004354404e-05,
      "loss": 0.0324,
      "step": 25600
    },
    {
      "epoch": 0.081984,
      "grad_norm": 0.13636621417411812,
      "learning_rate": 9.98158428110699e-05,
      "loss": 0.0309,
      "step": 25620
    },
    {
      "epoch": 0.082048,
      "grad_norm": 0.07406653052635553,
      "learning_rate": 9.98155553548346e-05,
      "loss": 0.0353,
      "step": 25640
    },
    {
      "epoch": 0.082112,
      "grad_norm": 0.11723635656900046,
      "learning_rate": 9.981526767483947e-05,
      "loss": 0.0363,
      "step": 25660
    },
    {
      "epoch": 0.082176,
      "grad_norm": 0.09303343243487204,
      "learning_rate": 9.981497977108579e-05,
      "loss": 0.0337,
      "step": 25680
    },
    {
      "epoch": 0.08224,
      "grad_norm": 0.11279445881566842,
      "learning_rate": 9.981469164357481e-05,
      "loss": 0.034,
      "step": 25700
    },
    {
      "epoch": 0.082304,
      "grad_norm": 0.13762903968721363,
      "learning_rate": 9.981440329230789e-05,
      "loss": 0.0343,
      "step": 25720
    },
    {
      "epoch": 0.082368,
      "grad_norm": 0.09792825509024976,
      "learning_rate": 9.981411471728629e-05,
      "loss": 0.0353,
      "step": 25740
    },
    {
      "epoch": 0.082432,
      "grad_norm": 0.12201563666901388,
      "learning_rate": 9.98138259185113e-05,
      "loss": 0.0362,
      "step": 25760
    },
    {
      "epoch": 0.082496,
      "grad_norm": 0.09758342960261081,
      "learning_rate": 9.981353689598426e-05,
      "loss": 0.0345,
      "step": 25780
    },
    {
      "epoch": 0.08256,
      "grad_norm": 0.08516873877131799,
      "learning_rate": 9.981324764970641e-05,
      "loss": 0.0341,
      "step": 25800
    },
    {
      "epoch": 0.082624,
      "grad_norm": 0.08884866170475066,
      "learning_rate": 9.981295817967909e-05,
      "loss": 0.0377,
      "step": 25820
    },
    {
      "epoch": 0.082688,
      "grad_norm": 0.17891002467190936,
      "learning_rate": 9.981266848590357e-05,
      "loss": 0.0328,
      "step": 25840
    },
    {
      "epoch": 0.082752,
      "grad_norm": 0.16415233599777201,
      "learning_rate": 9.981237856838118e-05,
      "loss": 0.0349,
      "step": 25860
    },
    {
      "epoch": 0.082816,
      "grad_norm": 0.15304691700742276,
      "learning_rate": 9.981208842711322e-05,
      "loss": 0.0326,
      "step": 25880
    },
    {
      "epoch": 0.08288,
      "grad_norm": 0.098739681703439,
      "learning_rate": 9.981179806210097e-05,
      "loss": 0.0303,
      "step": 25900
    },
    {
      "epoch": 0.082944,
      "grad_norm": 0.10394103448642981,
      "learning_rate": 9.981150747334576e-05,
      "loss": 0.0325,
      "step": 25920
    },
    {
      "epoch": 0.083008,
      "grad_norm": 0.09534363779630273,
      "learning_rate": 9.981121666084887e-05,
      "loss": 0.0343,
      "step": 25940
    },
    {
      "epoch": 0.083072,
      "grad_norm": 0.09794184663173701,
      "learning_rate": 9.981092562461162e-05,
      "loss": 0.0316,
      "step": 25960
    },
    {
      "epoch": 0.083136,
      "grad_norm": 0.12107921328403581,
      "learning_rate": 9.981063436463532e-05,
      "loss": 0.0333,
      "step": 25980
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.12276145898120404,
      "learning_rate": 9.981034288092128e-05,
      "loss": 0.0354,
      "step": 26000
    },
    {
      "epoch": 0.083264,
      "grad_norm": 0.0728990808026228,
      "learning_rate": 9.98100511734708e-05,
      "loss": 0.0344,
      "step": 26020
    },
    {
      "epoch": 0.083328,
      "grad_norm": 0.09309040905069606,
      "learning_rate": 9.980975924228519e-05,
      "loss": 0.03,
      "step": 26040
    },
    {
      "epoch": 0.083392,
      "grad_norm": 0.09601135061338163,
      "learning_rate": 9.980946708736578e-05,
      "loss": 0.0343,
      "step": 26060
    },
    {
      "epoch": 0.083456,
      "grad_norm": 0.11404231901998185,
      "learning_rate": 9.980917470871386e-05,
      "loss": 0.0321,
      "step": 26080
    },
    {
      "epoch": 0.08352,
      "grad_norm": 0.14810312951620502,
      "learning_rate": 9.980888210633075e-05,
      "loss": 0.0358,
      "step": 26100
    },
    {
      "epoch": 0.083584,
      "grad_norm": 0.07238199047553598,
      "learning_rate": 9.980858928021777e-05,
      "loss": 0.0373,
      "step": 26120
    },
    {
      "epoch": 0.083648,
      "grad_norm": 0.11099168381219922,
      "learning_rate": 9.980829623037622e-05,
      "loss": 0.0337,
      "step": 26140
    },
    {
      "epoch": 0.083712,
      "grad_norm": 0.09036704843816833,
      "learning_rate": 9.980800295680744e-05,
      "loss": 0.0324,
      "step": 26160
    },
    {
      "epoch": 0.083776,
      "grad_norm": 0.09777126950432659,
      "learning_rate": 9.980770945951273e-05,
      "loss": 0.037,
      "step": 26180
    },
    {
      "epoch": 0.08384,
      "grad_norm": 0.13363436890903405,
      "learning_rate": 9.980741573849341e-05,
      "loss": 0.0349,
      "step": 26200
    },
    {
      "epoch": 0.083904,
      "grad_norm": 0.09468560758356773,
      "learning_rate": 9.98071217937508e-05,
      "loss": 0.0334,
      "step": 26220
    },
    {
      "epoch": 0.083968,
      "grad_norm": 0.1594617038830298,
      "learning_rate": 9.980682762528624e-05,
      "loss": 0.0329,
      "step": 26240
    },
    {
      "epoch": 0.084032,
      "grad_norm": 0.09945591035403296,
      "learning_rate": 9.980653323310103e-05,
      "loss": 0.0336,
      "step": 26260
    },
    {
      "epoch": 0.084096,
      "grad_norm": 0.1364787574294266,
      "learning_rate": 9.980623861719648e-05,
      "loss": 0.0352,
      "step": 26280
    },
    {
      "epoch": 0.08416,
      "grad_norm": 0.07860179760009363,
      "learning_rate": 9.980594377757394e-05,
      "loss": 0.0373,
      "step": 26300
    },
    {
      "epoch": 0.084224,
      "grad_norm": 0.08982282756780344,
      "learning_rate": 9.980564871423473e-05,
      "loss": 0.032,
      "step": 26320
    },
    {
      "epoch": 0.084288,
      "grad_norm": 0.0750707072305192,
      "learning_rate": 9.980535342718017e-05,
      "loss": 0.034,
      "step": 26340
    },
    {
      "epoch": 0.084352,
      "grad_norm": 0.06625939120329474,
      "learning_rate": 9.980505791641157e-05,
      "loss": 0.0349,
      "step": 26360
    },
    {
      "epoch": 0.084416,
      "grad_norm": 0.16785140802536722,
      "learning_rate": 9.980476218193026e-05,
      "loss": 0.0349,
      "step": 26380
    },
    {
      "epoch": 0.08448,
      "grad_norm": 0.2214128378608345,
      "learning_rate": 9.980446622373763e-05,
      "loss": 0.0341,
      "step": 26400
    },
    {
      "epoch": 0.084544,
      "grad_norm": 0.248307276431833,
      "learning_rate": 9.980417004183492e-05,
      "loss": 0.0318,
      "step": 26420
    },
    {
      "epoch": 0.084608,
      "grad_norm": 0.18916924104820848,
      "learning_rate": 9.980387363622352e-05,
      "loss": 0.0353,
      "step": 26440
    },
    {
      "epoch": 0.084672,
      "grad_norm": 0.13319409896760004,
      "learning_rate": 9.980357700690473e-05,
      "loss": 0.0353,
      "step": 26460
    },
    {
      "epoch": 0.084736,
      "grad_norm": 0.1784927564508636,
      "learning_rate": 9.98032801538799e-05,
      "loss": 0.034,
      "step": 26480
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.09985811554126596,
      "learning_rate": 9.980298307715037e-05,
      "loss": 0.029,
      "step": 26500
    },
    {
      "epoch": 0.084864,
      "grad_norm": 0.1042248250719875,
      "learning_rate": 9.980268577671745e-05,
      "loss": 0.031,
      "step": 26520
    },
    {
      "epoch": 0.084928,
      "grad_norm": 0.12675606112647853,
      "learning_rate": 9.98023882525825e-05,
      "loss": 0.0347,
      "step": 26540
    },
    {
      "epoch": 0.084992,
      "grad_norm": 0.1555947064913012,
      "learning_rate": 9.980209050474682e-05,
      "loss": 0.0338,
      "step": 26560
    },
    {
      "epoch": 0.085056,
      "grad_norm": 0.2002696071643262,
      "learning_rate": 9.98017925332118e-05,
      "loss": 0.0334,
      "step": 26580
    },
    {
      "epoch": 0.08512,
      "grad_norm": 0.16145064552152683,
      "learning_rate": 9.980149433797874e-05,
      "loss": 0.0359,
      "step": 26600
    },
    {
      "epoch": 0.085184,
      "grad_norm": 0.12937012871863116,
      "learning_rate": 9.9801195919049e-05,
      "loss": 0.0343,
      "step": 26620
    },
    {
      "epoch": 0.085248,
      "grad_norm": 0.125592760727966,
      "learning_rate": 9.980089727642388e-05,
      "loss": 0.0342,
      "step": 26640
    },
    {
      "epoch": 0.085312,
      "grad_norm": 0.10607587741499251,
      "learning_rate": 9.980059841010478e-05,
      "loss": 0.0317,
      "step": 26660
    },
    {
      "epoch": 0.085376,
      "grad_norm": 0.09229833577966556,
      "learning_rate": 9.9800299320093e-05,
      "loss": 0.0346,
      "step": 26680
    },
    {
      "epoch": 0.08544,
      "grad_norm": 0.121626444886051,
      "learning_rate": 9.980000000638992e-05,
      "loss": 0.0316,
      "step": 26700
    },
    {
      "epoch": 0.085504,
      "grad_norm": 0.14013946994825283,
      "learning_rate": 9.979970046899684e-05,
      "loss": 0.0325,
      "step": 26720
    },
    {
      "epoch": 0.085568,
      "grad_norm": 0.0898637998612099,
      "learning_rate": 9.979940070791513e-05,
      "loss": 0.0354,
      "step": 26740
    },
    {
      "epoch": 0.085632,
      "grad_norm": 0.17266235695287616,
      "learning_rate": 9.979910072314613e-05,
      "loss": 0.0348,
      "step": 26760
    },
    {
      "epoch": 0.085696,
      "grad_norm": 0.18300040009353344,
      "learning_rate": 9.97988005146912e-05,
      "loss": 0.0368,
      "step": 26780
    },
    {
      "epoch": 0.08576,
      "grad_norm": 0.09865968202329661,
      "learning_rate": 9.979850008255169e-05,
      "loss": 0.0373,
      "step": 26800
    },
    {
      "epoch": 0.085824,
      "grad_norm": 0.1192016983445076,
      "learning_rate": 9.979819942672892e-05,
      "loss": 0.0342,
      "step": 26820
    },
    {
      "epoch": 0.085888,
      "grad_norm": 0.07038640132499667,
      "learning_rate": 9.979789854722428e-05,
      "loss": 0.0323,
      "step": 26840
    },
    {
      "epoch": 0.085952,
      "grad_norm": 0.09984638227835767,
      "learning_rate": 9.979759744403909e-05,
      "loss": 0.0328,
      "step": 26860
    },
    {
      "epoch": 0.086016,
      "grad_norm": 0.08778506527520731,
      "learning_rate": 9.979729611717469e-05,
      "loss": 0.0343,
      "step": 26880
    },
    {
      "epoch": 0.08608,
      "grad_norm": 0.16102979882329513,
      "learning_rate": 9.979699456663249e-05,
      "loss": 0.0355,
      "step": 26900
    },
    {
      "epoch": 0.086144,
      "grad_norm": 0.10599790081675076,
      "learning_rate": 9.979669279241381e-05,
      "loss": 0.0323,
      "step": 26920
    },
    {
      "epoch": 0.086208,
      "grad_norm": 0.17778375969959734,
      "learning_rate": 9.979639079451999e-05,
      "loss": 0.0324,
      "step": 26940
    },
    {
      "epoch": 0.086272,
      "grad_norm": 0.13130108629491347,
      "learning_rate": 9.979608857295242e-05,
      "loss": 0.0333,
      "step": 26960
    },
    {
      "epoch": 0.086336,
      "grad_norm": 0.1332503811098483,
      "learning_rate": 9.979578612771244e-05,
      "loss": 0.0289,
      "step": 26980
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.10135866634209033,
      "learning_rate": 9.979548345880141e-05,
      "loss": 0.0355,
      "step": 27000
    },
    {
      "epoch": 0.086464,
      "grad_norm": 0.08881258103630237,
      "learning_rate": 9.979518056622068e-05,
      "loss": 0.0361,
      "step": 27020
    },
    {
      "epoch": 0.086528,
      "grad_norm": 0.10500893021948983,
      "learning_rate": 9.979487744997162e-05,
      "loss": 0.0311,
      "step": 27040
    },
    {
      "epoch": 0.086592,
      "grad_norm": 0.08634608811932463,
      "learning_rate": 9.97945741100556e-05,
      "loss": 0.0325,
      "step": 27060
    },
    {
      "epoch": 0.086656,
      "grad_norm": 0.11201637936309917,
      "learning_rate": 9.979427054647396e-05,
      "loss": 0.0338,
      "step": 27080
    },
    {
      "epoch": 0.08672,
      "grad_norm": 0.09044858487049827,
      "learning_rate": 9.97939667592281e-05,
      "loss": 0.0311,
      "step": 27100
    },
    {
      "epoch": 0.086784,
      "grad_norm": 0.1775563615034672,
      "learning_rate": 9.979366274831934e-05,
      "loss": 0.0317,
      "step": 27120
    },
    {
      "epoch": 0.086848,
      "grad_norm": 0.09649282813404556,
      "learning_rate": 9.979335851374908e-05,
      "loss": 0.0325,
      "step": 27140
    },
    {
      "epoch": 0.086912,
      "grad_norm": 0.08654850027011385,
      "learning_rate": 9.979305405551866e-05,
      "loss": 0.033,
      "step": 27160
    },
    {
      "epoch": 0.086976,
      "grad_norm": 0.21517557322627548,
      "learning_rate": 9.979274937362948e-05,
      "loss": 0.0328,
      "step": 27180
    },
    {
      "epoch": 0.08704,
      "grad_norm": 0.08473273610198778,
      "learning_rate": 9.979244446808289e-05,
      "loss": 0.0329,
      "step": 27200
    },
    {
      "epoch": 0.087104,
      "grad_norm": 0.1397192087903003,
      "learning_rate": 9.979213933888025e-05,
      "loss": 0.0319,
      "step": 27220
    },
    {
      "epoch": 0.087168,
      "grad_norm": 0.08650307730105586,
      "learning_rate": 9.979183398602295e-05,
      "loss": 0.0345,
      "step": 27240
    },
    {
      "epoch": 0.087232,
      "grad_norm": 0.16456251715354028,
      "learning_rate": 9.979152840951233e-05,
      "loss": 0.0313,
      "step": 27260
    },
    {
      "epoch": 0.087296,
      "grad_norm": 0.13599818947399986,
      "learning_rate": 9.979122260934981e-05,
      "loss": 0.0337,
      "step": 27280
    },
    {
      "epoch": 0.08736,
      "grad_norm": 0.10749821023105077,
      "learning_rate": 9.979091658553672e-05,
      "loss": 0.0322,
      "step": 27300
    },
    {
      "epoch": 0.087424,
      "grad_norm": 0.0865907975129192,
      "learning_rate": 9.979061033807446e-05,
      "loss": 0.0346,
      "step": 27320
    },
    {
      "epoch": 0.087488,
      "grad_norm": 0.11873638650971817,
      "learning_rate": 9.97903038669644e-05,
      "loss": 0.0345,
      "step": 27340
    },
    {
      "epoch": 0.087552,
      "grad_norm": 0.14414853511156653,
      "learning_rate": 9.978999717220791e-05,
      "loss": 0.0302,
      "step": 27360
    },
    {
      "epoch": 0.087616,
      "grad_norm": 0.10027434094727658,
      "learning_rate": 9.978969025380639e-05,
      "loss": 0.0335,
      "step": 27380
    },
    {
      "epoch": 0.08768,
      "grad_norm": 0.17439373895053134,
      "learning_rate": 9.978938311176118e-05,
      "loss": 0.0356,
      "step": 27400
    },
    {
      "epoch": 0.087744,
      "grad_norm": 0.0952652862053885,
      "learning_rate": 9.97890757460737e-05,
      "loss": 0.0342,
      "step": 27420
    },
    {
      "epoch": 0.087808,
      "grad_norm": 0.12062573839458407,
      "learning_rate": 9.97887681567453e-05,
      "loss": 0.0347,
      "step": 27440
    },
    {
      "epoch": 0.087872,
      "grad_norm": 0.08271422349877665,
      "learning_rate": 9.978846034377737e-05,
      "loss": 0.0326,
      "step": 27460
    },
    {
      "epoch": 0.087936,
      "grad_norm": 0.09099238308057277,
      "learning_rate": 9.978815230717128e-05,
      "loss": 0.0345,
      "step": 27480
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.08389020146211872,
      "learning_rate": 9.978784404692847e-05,
      "loss": 0.0323,
      "step": 27500
    },
    {
      "epoch": 0.088064,
      "grad_norm": 0.09318687815543503,
      "learning_rate": 9.978753556305025e-05,
      "loss": 0.0303,
      "step": 27520
    },
    {
      "epoch": 0.088128,
      "grad_norm": 0.1736526090809674,
      "learning_rate": 9.978722685553806e-05,
      "loss": 0.0342,
      "step": 27540
    },
    {
      "epoch": 0.088192,
      "grad_norm": 0.06556682594955504,
      "learning_rate": 9.978691792439326e-05,
      "loss": 0.0315,
      "step": 27560
    },
    {
      "epoch": 0.088256,
      "grad_norm": 0.16506186730723346,
      "learning_rate": 9.978660876961723e-05,
      "loss": 0.0334,
      "step": 27580
    },
    {
      "epoch": 0.08832,
      "grad_norm": 0.17320003960370256,
      "learning_rate": 9.978629939121138e-05,
      "loss": 0.0346,
      "step": 27600
    },
    {
      "epoch": 0.088384,
      "grad_norm": 0.06836463647767692,
      "learning_rate": 9.97859897891771e-05,
      "loss": 0.0312,
      "step": 27620
    },
    {
      "epoch": 0.088448,
      "grad_norm": 0.14102166469649105,
      "learning_rate": 9.978567996351577e-05,
      "loss": 0.0342,
      "step": 27640
    },
    {
      "epoch": 0.088512,
      "grad_norm": 0.11282781762951137,
      "learning_rate": 9.978536991422877e-05,
      "loss": 0.0297,
      "step": 27660
    },
    {
      "epoch": 0.088576,
      "grad_norm": 0.09442820131078558,
      "learning_rate": 9.978505964131753e-05,
      "loss": 0.0308,
      "step": 27680
    },
    {
      "epoch": 0.08864,
      "grad_norm": 0.06881502349206892,
      "learning_rate": 9.97847491447834e-05,
      "loss": 0.0338,
      "step": 27700
    },
    {
      "epoch": 0.088704,
      "grad_norm": 0.1661319892102743,
      "learning_rate": 9.978443842462781e-05,
      "loss": 0.0323,
      "step": 27720
    },
    {
      "epoch": 0.088768,
      "grad_norm": 0.12367270917427937,
      "learning_rate": 9.978412748085215e-05,
      "loss": 0.0317,
      "step": 27740
    },
    {
      "epoch": 0.088832,
      "grad_norm": 0.17380886112768024,
      "learning_rate": 9.978381631345779e-05,
      "loss": 0.0339,
      "step": 27760
    },
    {
      "epoch": 0.088896,
      "grad_norm": 0.09631126346224517,
      "learning_rate": 9.978350492244614e-05,
      "loss": 0.0309,
      "step": 27780
    },
    {
      "epoch": 0.08896,
      "grad_norm": 0.11097409012323432,
      "learning_rate": 9.978319330781862e-05,
      "loss": 0.0341,
      "step": 27800
    },
    {
      "epoch": 0.089024,
      "grad_norm": 0.10458043069137153,
      "learning_rate": 9.978288146957661e-05,
      "loss": 0.0357,
      "step": 27820
    },
    {
      "epoch": 0.089088,
      "grad_norm": 0.07451959272347594,
      "learning_rate": 9.978256940772151e-05,
      "loss": 0.0308,
      "step": 27840
    },
    {
      "epoch": 0.089152,
      "grad_norm": 0.07010272719535834,
      "learning_rate": 9.978225712225474e-05,
      "loss": 0.0342,
      "step": 27860
    },
    {
      "epoch": 0.089216,
      "grad_norm": 0.08730630513972729,
      "learning_rate": 9.978194461317768e-05,
      "loss": 0.0318,
      "step": 27880
    },
    {
      "epoch": 0.08928,
      "grad_norm": 0.11438032722933647,
      "learning_rate": 9.978163188049172e-05,
      "loss": 0.0346,
      "step": 27900
    },
    {
      "epoch": 0.089344,
      "grad_norm": 0.18069230727615407,
      "learning_rate": 9.978131892419832e-05,
      "loss": 0.033,
      "step": 27920
    },
    {
      "epoch": 0.089408,
      "grad_norm": 0.13817597701472376,
      "learning_rate": 9.978100574429883e-05,
      "loss": 0.0351,
      "step": 27940
    },
    {
      "epoch": 0.089472,
      "grad_norm": 0.16849240827331133,
      "learning_rate": 9.97806923407947e-05,
      "loss": 0.0349,
      "step": 27960
    },
    {
      "epoch": 0.089536,
      "grad_norm": 0.13684633978342267,
      "learning_rate": 9.97803787136873e-05,
      "loss": 0.0365,
      "step": 27980
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.12233710523359623,
      "learning_rate": 9.978006486297808e-05,
      "loss": 0.0379,
      "step": 28000
    },
    {
      "epoch": 0.089664,
      "grad_norm": 0.12054786214814472,
      "learning_rate": 9.977975078866841e-05,
      "loss": 0.033,
      "step": 28020
    },
    {
      "epoch": 0.089728,
      "grad_norm": 0.12509239778608508,
      "learning_rate": 9.977943649075971e-05,
      "loss": 0.0317,
      "step": 28040
    },
    {
      "epoch": 0.089792,
      "grad_norm": 0.12920034013048778,
      "learning_rate": 9.97791219692534e-05,
      "loss": 0.0313,
      "step": 28060
    },
    {
      "epoch": 0.089856,
      "grad_norm": 0.08254257453077578,
      "learning_rate": 9.977880722415092e-05,
      "loss": 0.0286,
      "step": 28080
    },
    {
      "epoch": 0.08992,
      "grad_norm": 0.07514165766367642,
      "learning_rate": 9.977849225545362e-05,
      "loss": 0.0316,
      "step": 28100
    },
    {
      "epoch": 0.089984,
      "grad_norm": 0.17487402618519027,
      "learning_rate": 9.977817706316297e-05,
      "loss": 0.0377,
      "step": 28120
    },
    {
      "epoch": 0.090048,
      "grad_norm": 0.15835032516827238,
      "learning_rate": 9.977786164728036e-05,
      "loss": 0.035,
      "step": 28140
    },
    {
      "epoch": 0.090112,
      "grad_norm": 0.07948123167654329,
      "learning_rate": 9.977754600780721e-05,
      "loss": 0.037,
      "step": 28160
    },
    {
      "epoch": 0.090176,
      "grad_norm": 0.16162832387698114,
      "learning_rate": 9.977723014474494e-05,
      "loss": 0.0297,
      "step": 28180
    },
    {
      "epoch": 0.09024,
      "grad_norm": 0.1089538191220854,
      "learning_rate": 9.977691405809498e-05,
      "loss": 0.04,
      "step": 28200
    },
    {
      "epoch": 0.090304,
      "grad_norm": 0.10656254509044752,
      "learning_rate": 9.977659774785873e-05,
      "loss": 0.0404,
      "step": 28220
    },
    {
      "epoch": 0.090368,
      "grad_norm": 0.10815279926617702,
      "learning_rate": 9.977628121403761e-05,
      "loss": 0.0343,
      "step": 28240
    },
    {
      "epoch": 0.090432,
      "grad_norm": 0.2002619528517407,
      "learning_rate": 9.977596445663306e-05,
      "loss": 0.032,
      "step": 28260
    },
    {
      "epoch": 0.090496,
      "grad_norm": 0.13876161554494884,
      "learning_rate": 9.977564747564649e-05,
      "loss": 0.0346,
      "step": 28280
    },
    {
      "epoch": 0.09056,
      "grad_norm": 0.11300051995159172,
      "learning_rate": 9.977533027107934e-05,
      "loss": 0.0342,
      "step": 28300
    },
    {
      "epoch": 0.090624,
      "grad_norm": 0.10960332432074564,
      "learning_rate": 9.977501284293302e-05,
      "loss": 0.036,
      "step": 28320
    },
    {
      "epoch": 0.090688,
      "grad_norm": 0.08914569078037383,
      "learning_rate": 9.977469519120894e-05,
      "loss": 0.0327,
      "step": 28340
    },
    {
      "epoch": 0.090752,
      "grad_norm": 0.11508348841481472,
      "learning_rate": 9.977437731590858e-05,
      "loss": 0.0306,
      "step": 28360
    },
    {
      "epoch": 0.090816,
      "grad_norm": 0.1742130513040511,
      "learning_rate": 9.97740592170333e-05,
      "loss": 0.0325,
      "step": 28380
    },
    {
      "epoch": 0.09088,
      "grad_norm": 0.2091599445411073,
      "learning_rate": 9.977374089458458e-05,
      "loss": 0.0332,
      "step": 28400
    },
    {
      "epoch": 0.090944,
      "grad_norm": 0.18037912833784317,
      "learning_rate": 9.977342234856382e-05,
      "loss": 0.0309,
      "step": 28420
    },
    {
      "epoch": 0.091008,
      "grad_norm": 0.0749426721472801,
      "learning_rate": 9.977310357897247e-05,
      "loss": 0.0307,
      "step": 28440
    },
    {
      "epoch": 0.091072,
      "grad_norm": 0.08944903794497892,
      "learning_rate": 9.977278458581196e-05,
      "loss": 0.0342,
      "step": 28460
    },
    {
      "epoch": 0.091136,
      "grad_norm": 0.10388976947840407,
      "learning_rate": 9.977246536908372e-05,
      "loss": 0.0321,
      "step": 28480
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.07075066927257913,
      "learning_rate": 9.977214592878916e-05,
      "loss": 0.0342,
      "step": 28500
    },
    {
      "epoch": 0.091264,
      "grad_norm": 0.12765818173255997,
      "learning_rate": 9.977182626492976e-05,
      "loss": 0.0339,
      "step": 28520
    },
    {
      "epoch": 0.091328,
      "grad_norm": 0.15251325618986036,
      "learning_rate": 9.977150637750692e-05,
      "loss": 0.0358,
      "step": 28540
    },
    {
      "epoch": 0.091392,
      "grad_norm": 0.09663667398433569,
      "learning_rate": 9.977118626652208e-05,
      "loss": 0.0368,
      "step": 28560
    },
    {
      "epoch": 0.091456,
      "grad_norm": 0.1051818396380922,
      "learning_rate": 9.97708659319767e-05,
      "loss": 0.0336,
      "step": 28580
    },
    {
      "epoch": 0.09152,
      "grad_norm": 0.07911653600016368,
      "learning_rate": 9.97705453738722e-05,
      "loss": 0.0336,
      "step": 28600
    },
    {
      "epoch": 0.091584,
      "grad_norm": 0.11767998133691641,
      "learning_rate": 9.977022459221004e-05,
      "loss": 0.0337,
      "step": 28620
    },
    {
      "epoch": 0.091648,
      "grad_norm": 0.11756485292877743,
      "learning_rate": 9.976990358699163e-05,
      "loss": 0.0335,
      "step": 28640
    },
    {
      "epoch": 0.091712,
      "grad_norm": 0.08021285901175416,
      "learning_rate": 9.976958235821842e-05,
      "loss": 0.0321,
      "step": 28660
    },
    {
      "epoch": 0.091776,
      "grad_norm": 0.0961326009363166,
      "learning_rate": 9.976926090589188e-05,
      "loss": 0.0307,
      "step": 28680
    },
    {
      "epoch": 0.09184,
      "grad_norm": 0.09043633771366169,
      "learning_rate": 9.976893923001342e-05,
      "loss": 0.0307,
      "step": 28700
    },
    {
      "epoch": 0.091904,
      "grad_norm": 0.09129606158111475,
      "learning_rate": 9.976861733058452e-05,
      "loss": 0.0321,
      "step": 28720
    },
    {
      "epoch": 0.091968,
      "grad_norm": 0.07641090636134419,
      "learning_rate": 9.97682952076066e-05,
      "loss": 0.0298,
      "step": 28740
    },
    {
      "epoch": 0.092032,
      "grad_norm": 0.16801390969116842,
      "learning_rate": 9.97679728610811e-05,
      "loss": 0.0309,
      "step": 28760
    },
    {
      "epoch": 0.092096,
      "grad_norm": 0.1418208675410538,
      "learning_rate": 9.976765029100949e-05,
      "loss": 0.0352,
      "step": 28780
    },
    {
      "epoch": 0.09216,
      "grad_norm": 0.11327348210813974,
      "learning_rate": 9.97673274973932e-05,
      "loss": 0.0343,
      "step": 28800
    },
    {
      "epoch": 0.092224,
      "grad_norm": 0.1771274889364176,
      "learning_rate": 9.976700448023371e-05,
      "loss": 0.0343,
      "step": 28820
    },
    {
      "epoch": 0.092288,
      "grad_norm": 0.08791349862441265,
      "learning_rate": 9.976668123953243e-05,
      "loss": 0.0313,
      "step": 28840
    },
    {
      "epoch": 0.092352,
      "grad_norm": 0.0966143717904765,
      "learning_rate": 9.976635777529085e-05,
      "loss": 0.0337,
      "step": 28860
    },
    {
      "epoch": 0.092416,
      "grad_norm": 0.11653646483985518,
      "learning_rate": 9.976603408751037e-05,
      "loss": 0.0309,
      "step": 28880
    },
    {
      "epoch": 0.09248,
      "grad_norm": 0.08189381578065129,
      "learning_rate": 9.976571017619252e-05,
      "loss": 0.0312,
      "step": 28900
    },
    {
      "epoch": 0.092544,
      "grad_norm": 0.08897685932052636,
      "learning_rate": 9.97653860413387e-05,
      "loss": 0.0306,
      "step": 28920
    },
    {
      "epoch": 0.092608,
      "grad_norm": 0.09438710625565576,
      "learning_rate": 9.976506168295036e-05,
      "loss": 0.0325,
      "step": 28940
    },
    {
      "epoch": 0.092672,
      "grad_norm": 0.10762498007009522,
      "learning_rate": 9.9764737101029e-05,
      "loss": 0.0328,
      "step": 28960
    },
    {
      "epoch": 0.092736,
      "grad_norm": 0.08529701631277038,
      "learning_rate": 9.976441229557605e-05,
      "loss": 0.0308,
      "step": 28980
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.19667944233611961,
      "learning_rate": 9.976408726659296e-05,
      "loss": 0.0319,
      "step": 29000
    },
    {
      "epoch": 0.092864,
      "grad_norm": 0.12465251366465091,
      "learning_rate": 9.976376201408123e-05,
      "loss": 0.0329,
      "step": 29020
    },
    {
      "epoch": 0.092928,
      "grad_norm": 0.08833566639217344,
      "learning_rate": 9.976343653804227e-05,
      "loss": 0.0327,
      "step": 29040
    },
    {
      "epoch": 0.092992,
      "grad_norm": 0.07028769280427428,
      "learning_rate": 9.97631108384776e-05,
      "loss": 0.0313,
      "step": 29060
    },
    {
      "epoch": 0.093056,
      "grad_norm": 0.1633563968048828,
      "learning_rate": 9.976278491538862e-05,
      "loss": 0.0311,
      "step": 29080
    },
    {
      "epoch": 0.09312,
      "grad_norm": 0.10146962029610429,
      "learning_rate": 9.976245876877683e-05,
      "loss": 0.0324,
      "step": 29100
    },
    {
      "epoch": 0.093184,
      "grad_norm": 0.18894036340895595,
      "learning_rate": 9.97621323986437e-05,
      "loss": 0.0338,
      "step": 29120
    },
    {
      "epoch": 0.093248,
      "grad_norm": 0.11496772381155952,
      "learning_rate": 9.976180580499065e-05,
      "loss": 0.0323,
      "step": 29140
    },
    {
      "epoch": 0.093312,
      "grad_norm": 0.1113054493261797,
      "learning_rate": 9.976147898781923e-05,
      "loss": 0.0302,
      "step": 29160
    },
    {
      "epoch": 0.093376,
      "grad_norm": 0.10759702933483582,
      "learning_rate": 9.976115194713083e-05,
      "loss": 0.029,
      "step": 29180
    },
    {
      "epoch": 0.09344,
      "grad_norm": 0.15409999986293257,
      "learning_rate": 9.976082468292695e-05,
      "loss": 0.0309,
      "step": 29200
    },
    {
      "epoch": 0.093504,
      "grad_norm": 0.16466247595901332,
      "learning_rate": 9.976049719520906e-05,
      "loss": 0.0328,
      "step": 29220
    },
    {
      "epoch": 0.093568,
      "grad_norm": 0.10255773618426264,
      "learning_rate": 9.976016948397864e-05,
      "loss": 0.0329,
      "step": 29240
    },
    {
      "epoch": 0.093632,
      "grad_norm": 0.08808547177020168,
      "learning_rate": 9.975984154923715e-05,
      "loss": 0.0322,
      "step": 29260
    },
    {
      "epoch": 0.093696,
      "grad_norm": 0.07704467978912141,
      "learning_rate": 9.975951339098603e-05,
      "loss": 0.031,
      "step": 29280
    },
    {
      "epoch": 0.09376,
      "grad_norm": 0.14188235382491463,
      "learning_rate": 9.975918500922683e-05,
      "loss": 0.0345,
      "step": 29300
    },
    {
      "epoch": 0.093824,
      "grad_norm": 0.08098600184545063,
      "learning_rate": 9.975885640396096e-05,
      "loss": 0.0316,
      "step": 29320
    },
    {
      "epoch": 0.093888,
      "grad_norm": 0.087989729625399,
      "learning_rate": 9.975852757518994e-05,
      "loss": 0.0347,
      "step": 29340
    },
    {
      "epoch": 0.093952,
      "grad_norm": 0.06656259638325708,
      "learning_rate": 9.975819852291522e-05,
      "loss": 0.0313,
      "step": 29360
    },
    {
      "epoch": 0.094016,
      "grad_norm": 0.10418907382044858,
      "learning_rate": 9.975786924713829e-05,
      "loss": 0.0341,
      "step": 29380
    },
    {
      "epoch": 0.09408,
      "grad_norm": 0.08513960067492725,
      "learning_rate": 9.97575397478606e-05,
      "loss": 0.0326,
      "step": 29400
    },
    {
      "epoch": 0.094144,
      "grad_norm": 0.14662119241223565,
      "learning_rate": 9.975721002508367e-05,
      "loss": 0.034,
      "step": 29420
    },
    {
      "epoch": 0.094208,
      "grad_norm": 0.08161096131364243,
      "learning_rate": 9.975688007880897e-05,
      "loss": 0.0335,
      "step": 29440
    },
    {
      "epoch": 0.094272,
      "grad_norm": 0.09768885462538904,
      "learning_rate": 9.975654990903797e-05,
      "loss": 0.0318,
      "step": 29460
    },
    {
      "epoch": 0.094336,
      "grad_norm": 0.10013869506692491,
      "learning_rate": 9.975621951577215e-05,
      "loss": 0.0335,
      "step": 29480
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.18187472433525523,
      "learning_rate": 9.975588889901301e-05,
      "loss": 0.0356,
      "step": 29500
    },
    {
      "epoch": 0.094464,
      "grad_norm": 0.18013832280643413,
      "learning_rate": 9.975555805876204e-05,
      "loss": 0.0328,
      "step": 29520
    },
    {
      "epoch": 0.094528,
      "grad_norm": 0.22365722801718557,
      "learning_rate": 9.975522699502072e-05,
      "loss": 0.0329,
      "step": 29540
    },
    {
      "epoch": 0.094592,
      "grad_norm": 0.16240296267371354,
      "learning_rate": 9.975489570779051e-05,
      "loss": 0.0331,
      "step": 29560
    },
    {
      "epoch": 0.094656,
      "grad_norm": 0.06403039487609805,
      "learning_rate": 9.975456419707293e-05,
      "loss": 0.0312,
      "step": 29580
    },
    {
      "epoch": 0.09472,
      "grad_norm": 0.08158239065980073,
      "learning_rate": 9.975423246286945e-05,
      "loss": 0.0309,
      "step": 29600
    },
    {
      "epoch": 0.094784,
      "grad_norm": 0.08281976552953248,
      "learning_rate": 9.975390050518159e-05,
      "loss": 0.0329,
      "step": 29620
    },
    {
      "epoch": 0.094848,
      "grad_norm": 0.07309871563540384,
      "learning_rate": 9.975356832401081e-05,
      "loss": 0.0343,
      "step": 29640
    },
    {
      "epoch": 0.094912,
      "grad_norm": 0.06656807189282106,
      "learning_rate": 9.97532359193586e-05,
      "loss": 0.0298,
      "step": 29660
    },
    {
      "epoch": 0.094976,
      "grad_norm": 0.07547274121983936,
      "learning_rate": 9.975290329122649e-05,
      "loss": 0.0357,
      "step": 29680
    },
    {
      "epoch": 0.09504,
      "grad_norm": 0.07419065009560412,
      "learning_rate": 9.975257043961592e-05,
      "loss": 0.0316,
      "step": 29700
    },
    {
      "epoch": 0.095104,
      "grad_norm": 0.11674756706305164,
      "learning_rate": 9.975223736452844e-05,
      "loss": 0.0321,
      "step": 29720
    },
    {
      "epoch": 0.095168,
      "grad_norm": 0.10451441946586823,
      "learning_rate": 9.975190406596551e-05,
      "loss": 0.0307,
      "step": 29740
    },
    {
      "epoch": 0.095232,
      "grad_norm": 0.11090248530285751,
      "learning_rate": 9.975157054392863e-05,
      "loss": 0.0346,
      "step": 29760
    },
    {
      "epoch": 0.095296,
      "grad_norm": 0.13180218896846468,
      "learning_rate": 9.975123679841932e-05,
      "loss": 0.0302,
      "step": 29780
    },
    {
      "epoch": 0.09536,
      "grad_norm": 0.08472926722005049,
      "learning_rate": 9.975090282943907e-05,
      "loss": 0.0307,
      "step": 29800
    },
    {
      "epoch": 0.095424,
      "grad_norm": 0.0985938092892877,
      "learning_rate": 9.975056863698935e-05,
      "loss": 0.0326,
      "step": 29820
    },
    {
      "epoch": 0.095488,
      "grad_norm": 0.07954722469561218,
      "learning_rate": 9.975023422107171e-05,
      "loss": 0.0335,
      "step": 29840
    },
    {
      "epoch": 0.095552,
      "grad_norm": 0.16150195929582079,
      "learning_rate": 9.974989958168761e-05,
      "loss": 0.0324,
      "step": 29860
    },
    {
      "epoch": 0.095616,
      "grad_norm": 0.07359550805670287,
      "learning_rate": 9.974956471883858e-05,
      "loss": 0.0338,
      "step": 29880
    },
    {
      "epoch": 0.09568,
      "grad_norm": 0.07277432181346337,
      "learning_rate": 9.974922963252613e-05,
      "loss": 0.0333,
      "step": 29900
    },
    {
      "epoch": 0.095744,
      "grad_norm": 0.09497379187279864,
      "learning_rate": 9.974889432275174e-05,
      "loss": 0.0308,
      "step": 29920
    },
    {
      "epoch": 0.095808,
      "grad_norm": 0.1016216923374487,
      "learning_rate": 9.974855878951692e-05,
      "loss": 0.0314,
      "step": 29940
    },
    {
      "epoch": 0.095872,
      "grad_norm": 0.08006787934574093,
      "learning_rate": 9.974822303282319e-05,
      "loss": 0.033,
      "step": 29960
    },
    {
      "epoch": 0.095936,
      "grad_norm": 0.09841682277856208,
      "learning_rate": 9.974788705267204e-05,
      "loss": 0.03,
      "step": 29980
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.1299511691686431,
      "learning_rate": 9.974755084906502e-05,
      "loss": 0.0362,
      "step": 30000
    },
    {
      "epoch": 0.096064,
      "grad_norm": 0.11063175251849341,
      "learning_rate": 9.974721442200358e-05,
      "loss": 0.035,
      "step": 30020
    },
    {
      "epoch": 0.096128,
      "grad_norm": 0.12220240545419464,
      "learning_rate": 9.974687777148927e-05,
      "loss": 0.0366,
      "step": 30040
    },
    {
      "epoch": 0.096192,
      "grad_norm": 0.14505486923419622,
      "learning_rate": 9.974654089752362e-05,
      "loss": 0.0391,
      "step": 30060
    },
    {
      "epoch": 0.096256,
      "grad_norm": 0.1408034557683459,
      "learning_rate": 9.97462038001081e-05,
      "loss": 0.0327,
      "step": 30080
    },
    {
      "epoch": 0.09632,
      "grad_norm": 0.06926726796572201,
      "learning_rate": 9.974586647924425e-05,
      "loss": 0.0325,
      "step": 30100
    },
    {
      "epoch": 0.096384,
      "grad_norm": 0.09017995341866855,
      "learning_rate": 9.974552893493356e-05,
      "loss": 0.0328,
      "step": 30120
    },
    {
      "epoch": 0.096448,
      "grad_norm": 0.1119004076803094,
      "learning_rate": 9.974519116717756e-05,
      "loss": 0.0297,
      "step": 30140
    },
    {
      "epoch": 0.096512,
      "grad_norm": 0.11721323960858096,
      "learning_rate": 9.97448531759778e-05,
      "loss": 0.0321,
      "step": 30160
    },
    {
      "epoch": 0.096576,
      "grad_norm": 0.10441897356059847,
      "learning_rate": 9.974451496133574e-05,
      "loss": 0.0406,
      "step": 30180
    },
    {
      "epoch": 0.09664,
      "grad_norm": 0.10254723092542828,
      "learning_rate": 9.974417652325294e-05,
      "loss": 0.0332,
      "step": 30200
    },
    {
      "epoch": 0.096704,
      "grad_norm": 0.09811760151465074,
      "learning_rate": 9.974383786173092e-05,
      "loss": 0.0308,
      "step": 30220
    },
    {
      "epoch": 0.096768,
      "grad_norm": 0.07097362160094467,
      "learning_rate": 9.974349897677117e-05,
      "loss": 0.0302,
      "step": 30240
    },
    {
      "epoch": 0.096832,
      "grad_norm": 0.07722830033705815,
      "learning_rate": 9.974315986837524e-05,
      "loss": 0.0343,
      "step": 30260
    },
    {
      "epoch": 0.096896,
      "grad_norm": 0.12609632338274587,
      "learning_rate": 9.974282053654464e-05,
      "loss": 0.0351,
      "step": 30280
    },
    {
      "epoch": 0.09696,
      "grad_norm": 0.09784417036985352,
      "learning_rate": 9.97424809812809e-05,
      "loss": 0.0343,
      "step": 30300
    },
    {
      "epoch": 0.097024,
      "grad_norm": 0.09960117309438471,
      "learning_rate": 9.974214120258555e-05,
      "loss": 0.0339,
      "step": 30320
    },
    {
      "epoch": 0.097088,
      "grad_norm": 0.08629327143705236,
      "learning_rate": 9.974180120046011e-05,
      "loss": 0.0336,
      "step": 30340
    },
    {
      "epoch": 0.097152,
      "grad_norm": 0.0752869721345672,
      "learning_rate": 9.97414609749061e-05,
      "loss": 0.0324,
      "step": 30360
    },
    {
      "epoch": 0.097216,
      "grad_norm": 0.08101292556319897,
      "learning_rate": 9.974112052592506e-05,
      "loss": 0.0342,
      "step": 30380
    },
    {
      "epoch": 0.09728,
      "grad_norm": 0.08173805715684286,
      "learning_rate": 9.974077985351852e-05,
      "loss": 0.0344,
      "step": 30400
    },
    {
      "epoch": 0.097344,
      "grad_norm": 0.08606590612359086,
      "learning_rate": 9.974043895768799e-05,
      "loss": 0.033,
      "step": 30420
    },
    {
      "epoch": 0.097408,
      "grad_norm": 0.06523703658176408,
      "learning_rate": 9.974009783843503e-05,
      "loss": 0.0345,
      "step": 30440
    },
    {
      "epoch": 0.097472,
      "grad_norm": 0.12499640988195328,
      "learning_rate": 9.973975649576116e-05,
      "loss": 0.0298,
      "step": 30460
    },
    {
      "epoch": 0.097536,
      "grad_norm": 0.09146758132871383,
      "learning_rate": 9.973941492966791e-05,
      "loss": 0.033,
      "step": 30480
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.16156016613907717,
      "learning_rate": 9.973907314015682e-05,
      "loss": 0.0342,
      "step": 30500
    },
    {
      "epoch": 0.097664,
      "grad_norm": 0.08884177256895638,
      "learning_rate": 9.97387311272294e-05,
      "loss": 0.0313,
      "step": 30520
    },
    {
      "epoch": 0.097728,
      "grad_norm": 0.13995932930251273,
      "learning_rate": 9.973838889088723e-05,
      "loss": 0.034,
      "step": 30540
    },
    {
      "epoch": 0.097792,
      "grad_norm": 0.10005411636876668,
      "learning_rate": 9.973804643113182e-05,
      "loss": 0.0357,
      "step": 30560
    },
    {
      "epoch": 0.097856,
      "grad_norm": 0.08642501294292054,
      "learning_rate": 9.973770374796471e-05,
      "loss": 0.033,
      "step": 30580
    },
    {
      "epoch": 0.09792,
      "grad_norm": 0.12865147405745314,
      "learning_rate": 9.973736084138743e-05,
      "loss": 0.0335,
      "step": 30600
    },
    {
      "epoch": 0.097984,
      "grad_norm": 0.06826955715166223,
      "learning_rate": 9.973701771140156e-05,
      "loss": 0.0376,
      "step": 30620
    },
    {
      "epoch": 0.098048,
      "grad_norm": 0.09868598194123517,
      "learning_rate": 9.97366743580086e-05,
      "loss": 0.036,
      "step": 30640
    },
    {
      "epoch": 0.098112,
      "grad_norm": 0.08439344263422871,
      "learning_rate": 9.97363307812101e-05,
      "loss": 0.0337,
      "step": 30660
    },
    {
      "epoch": 0.098176,
      "grad_norm": 0.07391584859175118,
      "learning_rate": 9.973598698100762e-05,
      "loss": 0.0306,
      "step": 30680
    },
    {
      "epoch": 0.09824,
      "grad_norm": 0.09012230273821684,
      "learning_rate": 9.973564295740268e-05,
      "loss": 0.0332,
      "step": 30700
    },
    {
      "epoch": 0.098304,
      "grad_norm": 0.12631475678175286,
      "learning_rate": 9.973529871039686e-05,
      "loss": 0.0294,
      "step": 30720
    },
    {
      "epoch": 0.098368,
      "grad_norm": 0.10932120299055234,
      "learning_rate": 9.973495423999166e-05,
      "loss": 0.0317,
      "step": 30740
    },
    {
      "epoch": 0.098432,
      "grad_norm": 0.11454530623070215,
      "learning_rate": 9.973460954618867e-05,
      "loss": 0.033,
      "step": 30760
    },
    {
      "epoch": 0.098496,
      "grad_norm": 0.06902786828537001,
      "learning_rate": 9.973426462898942e-05,
      "loss": 0.0302,
      "step": 30780
    },
    {
      "epoch": 0.09856,
      "grad_norm": 0.10871924397887624,
      "learning_rate": 9.973391948839546e-05,
      "loss": 0.0332,
      "step": 30800
    },
    {
      "epoch": 0.098624,
      "grad_norm": 0.07398374579414338,
      "learning_rate": 9.973357412440834e-05,
      "loss": 0.0333,
      "step": 30820
    },
    {
      "epoch": 0.098688,
      "grad_norm": 0.09719029350221942,
      "learning_rate": 9.97332285370296e-05,
      "loss": 0.0325,
      "step": 30840
    },
    {
      "epoch": 0.098752,
      "grad_norm": 0.14594596654596734,
      "learning_rate": 9.973288272626082e-05,
      "loss": 0.0338,
      "step": 30860
    },
    {
      "epoch": 0.098816,
      "grad_norm": 0.09268680677967088,
      "learning_rate": 9.973253669210353e-05,
      "loss": 0.0325,
      "step": 30880
    },
    {
      "epoch": 0.09888,
      "grad_norm": 0.09292739706459761,
      "learning_rate": 9.973219043455928e-05,
      "loss": 0.0352,
      "step": 30900
    },
    {
      "epoch": 0.098944,
      "grad_norm": 0.12021937902026852,
      "learning_rate": 9.973184395362966e-05,
      "loss": 0.0321,
      "step": 30920
    },
    {
      "epoch": 0.099008,
      "grad_norm": 0.09814273005889969,
      "learning_rate": 9.973149724931618e-05,
      "loss": 0.0319,
      "step": 30940
    },
    {
      "epoch": 0.099072,
      "grad_norm": 0.09078729836935798,
      "learning_rate": 9.973115032162044e-05,
      "loss": 0.0329,
      "step": 30960
    },
    {
      "epoch": 0.099136,
      "grad_norm": 0.10244850290445295,
      "learning_rate": 9.973080317054397e-05,
      "loss": 0.0309,
      "step": 30980
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.08346334696045318,
      "learning_rate": 9.973045579608834e-05,
      "loss": 0.0331,
      "step": 31000
    },
    {
      "epoch": 0.099264,
      "grad_norm": 0.18701047144730432,
      "learning_rate": 9.97301081982551e-05,
      "loss": 0.0326,
      "step": 31020
    },
    {
      "epoch": 0.099328,
      "grad_norm": 0.1201759892128287,
      "learning_rate": 9.972976037704584e-05,
      "loss": 0.0359,
      "step": 31040
    },
    {
      "epoch": 0.099392,
      "grad_norm": 0.10557937356352676,
      "learning_rate": 9.972941233246209e-05,
      "loss": 0.0393,
      "step": 31060
    },
    {
      "epoch": 0.099456,
      "grad_norm": 0.1743182975842921,
      "learning_rate": 9.972906406450542e-05,
      "loss": 0.0401,
      "step": 31080
    },
    {
      "epoch": 0.09952,
      "grad_norm": 0.16651371568548004,
      "learning_rate": 9.97287155731774e-05,
      "loss": 0.032,
      "step": 31100
    },
    {
      "epoch": 0.099584,
      "grad_norm": 0.1029534297549954,
      "learning_rate": 9.972836685847961e-05,
      "loss": 0.0335,
      "step": 31120
    },
    {
      "epoch": 0.099648,
      "grad_norm": 0.09420021180076553,
      "learning_rate": 9.972801792041358e-05,
      "loss": 0.0345,
      "step": 31140
    },
    {
      "epoch": 0.099712,
      "grad_norm": 0.29501769793216276,
      "learning_rate": 9.972766875898092e-05,
      "loss": 0.036,
      "step": 31160
    },
    {
      "epoch": 0.099776,
      "grad_norm": 0.11711789522606665,
      "learning_rate": 9.972731937418316e-05,
      "loss": 0.0341,
      "step": 31180
    },
    {
      "epoch": 0.09984,
      "grad_norm": 0.062420324862498024,
      "learning_rate": 9.97269697660219e-05,
      "loss": 0.0298,
      "step": 31200
    },
    {
      "epoch": 0.099904,
      "grad_norm": 0.12863230721467506,
      "learning_rate": 9.972661993449869e-05,
      "loss": 0.034,
      "step": 31220
    },
    {
      "epoch": 0.099968,
      "grad_norm": 0.10616451124060705,
      "learning_rate": 9.97262698796151e-05,
      "loss": 0.0337,
      "step": 31240
    },
    {
      "epoch": 0.100032,
      "grad_norm": 0.13852034714616301,
      "learning_rate": 9.972591960137272e-05,
      "loss": 0.0344,
      "step": 31260
    },
    {
      "epoch": 0.100096,
      "grad_norm": 0.10257609212541682,
      "learning_rate": 9.972556909977314e-05,
      "loss": 0.0338,
      "step": 31280
    },
    {
      "epoch": 0.10016,
      "grad_norm": 0.07845978051101761,
      "learning_rate": 9.972521837481786e-05,
      "loss": 0.0296,
      "step": 31300
    },
    {
      "epoch": 0.100224,
      "grad_norm": 0.1295534128482442,
      "learning_rate": 9.972486742650853e-05,
      "loss": 0.0329,
      "step": 31320
    },
    {
      "epoch": 0.100288,
      "grad_norm": 0.17114741558311236,
      "learning_rate": 9.97245162548467e-05,
      "loss": 0.0281,
      "step": 31340
    },
    {
      "epoch": 0.100352,
      "grad_norm": 0.15604593096718689,
      "learning_rate": 9.972416485983394e-05,
      "loss": 0.0315,
      "step": 31360
    },
    {
      "epoch": 0.100416,
      "grad_norm": 0.11453687445565204,
      "learning_rate": 9.972381324147184e-05,
      "loss": 0.0333,
      "step": 31380
    },
    {
      "epoch": 0.10048,
      "grad_norm": 0.19813852631502296,
      "learning_rate": 9.972346139976198e-05,
      "loss": 0.0321,
      "step": 31400
    },
    {
      "epoch": 0.100544,
      "grad_norm": 0.07619159093953906,
      "learning_rate": 9.972310933470593e-05,
      "loss": 0.0319,
      "step": 31420
    },
    {
      "epoch": 0.100608,
      "grad_norm": 0.11120032260155135,
      "learning_rate": 9.972275704630527e-05,
      "loss": 0.0318,
      "step": 31440
    },
    {
      "epoch": 0.100672,
      "grad_norm": 0.07653064989258833,
      "learning_rate": 9.97224045345616e-05,
      "loss": 0.0316,
      "step": 31460
    },
    {
      "epoch": 0.100736,
      "grad_norm": 0.20396186435101749,
      "learning_rate": 9.972205179947648e-05,
      "loss": 0.0306,
      "step": 31480
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.14984403938835592,
      "learning_rate": 9.972169884105153e-05,
      "loss": 0.0352,
      "step": 31500
    },
    {
      "epoch": 0.100864,
      "grad_norm": 0.20142167039486347,
      "learning_rate": 9.97213456592883e-05,
      "loss": 0.0332,
      "step": 31520
    },
    {
      "epoch": 0.100928,
      "grad_norm": 0.07890510145428499,
      "learning_rate": 9.972099225418839e-05,
      "loss": 0.0362,
      "step": 31540
    },
    {
      "epoch": 0.100992,
      "grad_norm": 0.10478354131211647,
      "learning_rate": 9.972063862575338e-05,
      "loss": 0.0337,
      "step": 31560
    },
    {
      "epoch": 0.101056,
      "grad_norm": 0.1295243565923376,
      "learning_rate": 9.972028477398487e-05,
      "loss": 0.0364,
      "step": 31580
    },
    {
      "epoch": 0.10112,
      "grad_norm": 0.08742814949909723,
      "learning_rate": 9.971993069888445e-05,
      "loss": 0.0323,
      "step": 31600
    },
    {
      "epoch": 0.101184,
      "grad_norm": 0.1428753093140812,
      "learning_rate": 9.97195764004537e-05,
      "loss": 0.0323,
      "step": 31620
    },
    {
      "epoch": 0.101248,
      "grad_norm": 0.09135146206237223,
      "learning_rate": 9.971922187869422e-05,
      "loss": 0.0306,
      "step": 31640
    },
    {
      "epoch": 0.101312,
      "grad_norm": 0.07758556572569282,
      "learning_rate": 9.971886713360759e-05,
      "loss": 0.0334,
      "step": 31660
    },
    {
      "epoch": 0.101376,
      "grad_norm": 0.10087444494625634,
      "learning_rate": 9.971851216519541e-05,
      "loss": 0.0331,
      "step": 31680
    },
    {
      "epoch": 0.10144,
      "grad_norm": 0.10065682086312257,
      "learning_rate": 9.971815697345929e-05,
      "loss": 0.0341,
      "step": 31700
    },
    {
      "epoch": 0.101504,
      "grad_norm": 0.07931571418665577,
      "learning_rate": 9.97178015584008e-05,
      "loss": 0.0339,
      "step": 31720
    },
    {
      "epoch": 0.101568,
      "grad_norm": 0.10192901342586078,
      "learning_rate": 9.971744592002155e-05,
      "loss": 0.0344,
      "step": 31740
    },
    {
      "epoch": 0.101632,
      "grad_norm": 0.1485328699566904,
      "learning_rate": 9.971709005832315e-05,
      "loss": 0.0337,
      "step": 31760
    },
    {
      "epoch": 0.101696,
      "grad_norm": 0.08277557937086895,
      "learning_rate": 9.971673397330716e-05,
      "loss": 0.036,
      "step": 31780
    },
    {
      "epoch": 0.10176,
      "grad_norm": 0.1114683699208906,
      "learning_rate": 9.971637766497524e-05,
      "loss": 0.0325,
      "step": 31800
    },
    {
      "epoch": 0.101824,
      "grad_norm": 0.14250413647309068,
      "learning_rate": 9.971602113332892e-05,
      "loss": 0.0305,
      "step": 31820
    },
    {
      "epoch": 0.101888,
      "grad_norm": 0.17243724950698003,
      "learning_rate": 9.971566437836984e-05,
      "loss": 0.0338,
      "step": 31840
    },
    {
      "epoch": 0.101952,
      "grad_norm": 0.15670319579651057,
      "learning_rate": 9.971530740009961e-05,
      "loss": 0.0344,
      "step": 31860
    },
    {
      "epoch": 0.102016,
      "grad_norm": 0.0734786091536894,
      "learning_rate": 9.971495019851982e-05,
      "loss": 0.0368,
      "step": 31880
    },
    {
      "epoch": 0.10208,
      "grad_norm": 0.08802697101686133,
      "learning_rate": 9.971459277363206e-05,
      "loss": 0.0306,
      "step": 31900
    },
    {
      "epoch": 0.102144,
      "grad_norm": 0.09228599436442161,
      "learning_rate": 9.971423512543797e-05,
      "loss": 0.0373,
      "step": 31920
    },
    {
      "epoch": 0.102208,
      "grad_norm": 0.12508734385439804,
      "learning_rate": 9.971387725393914e-05,
      "loss": 0.0361,
      "step": 31940
    },
    {
      "epoch": 0.102272,
      "grad_norm": 0.08632683525165707,
      "learning_rate": 9.971351915913716e-05,
      "loss": 0.0353,
      "step": 31960
    },
    {
      "epoch": 0.102336,
      "grad_norm": 0.16498754950621342,
      "learning_rate": 9.971316084103366e-05,
      "loss": 0.0326,
      "step": 31980
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.06996310024694859,
      "learning_rate": 9.971280229963025e-05,
      "loss": 0.0286,
      "step": 32000
    },
    {
      "epoch": 0.102464,
      "grad_norm": 0.1959545669771389,
      "learning_rate": 9.971244353492852e-05,
      "loss": 0.028,
      "step": 32020
    },
    {
      "epoch": 0.102528,
      "grad_norm": 0.09325637838238043,
      "learning_rate": 9.971208454693011e-05,
      "loss": 0.0339,
      "step": 32040
    },
    {
      "epoch": 0.102592,
      "grad_norm": 0.11300540522174304,
      "learning_rate": 9.971172533563661e-05,
      "loss": 0.0322,
      "step": 32060
    },
    {
      "epoch": 0.102656,
      "grad_norm": 0.0824585738862516,
      "learning_rate": 9.971136590104965e-05,
      "loss": 0.0342,
      "step": 32080
    },
    {
      "epoch": 0.10272,
      "grad_norm": 0.0827516492888346,
      "learning_rate": 9.971100624317082e-05,
      "loss": 0.0355,
      "step": 32100
    },
    {
      "epoch": 0.102784,
      "grad_norm": 0.10308376729648609,
      "learning_rate": 9.971064636200176e-05,
      "loss": 0.0303,
      "step": 32120
    },
    {
      "epoch": 0.102848,
      "grad_norm": 0.09506547669565192,
      "learning_rate": 9.971028625754408e-05,
      "loss": 0.0294,
      "step": 32140
    },
    {
      "epoch": 0.102912,
      "grad_norm": 0.09101885157069524,
      "learning_rate": 9.97099259297994e-05,
      "loss": 0.0322,
      "step": 32160
    },
    {
      "epoch": 0.102976,
      "grad_norm": 0.06872243741846114,
      "learning_rate": 9.970956537876932e-05,
      "loss": 0.0296,
      "step": 32180
    },
    {
      "epoch": 0.10304,
      "grad_norm": 0.1887249575493209,
      "learning_rate": 9.970920460445549e-05,
      "loss": 0.0297,
      "step": 32200
    },
    {
      "epoch": 0.103104,
      "grad_norm": 0.1839284389675204,
      "learning_rate": 9.97088436068595e-05,
      "loss": 0.0323,
      "step": 32220
    },
    {
      "epoch": 0.103168,
      "grad_norm": 0.10291338900401395,
      "learning_rate": 9.970848238598298e-05,
      "loss": 0.0334,
      "step": 32240
    },
    {
      "epoch": 0.103232,
      "grad_norm": 0.14004646147309438,
      "learning_rate": 9.970812094182757e-05,
      "loss": 0.0361,
      "step": 32260
    },
    {
      "epoch": 0.103296,
      "grad_norm": 0.1030451857376463,
      "learning_rate": 9.970775927439489e-05,
      "loss": 0.0327,
      "step": 32280
    },
    {
      "epoch": 0.10336,
      "grad_norm": 0.07923788655883904,
      "learning_rate": 9.970739738368654e-05,
      "loss": 0.0342,
      "step": 32300
    },
    {
      "epoch": 0.103424,
      "grad_norm": 0.08988754999390206,
      "learning_rate": 9.970703526970418e-05,
      "loss": 0.0328,
      "step": 32320
    },
    {
      "epoch": 0.103488,
      "grad_norm": 0.08908146425473301,
      "learning_rate": 9.97066729324494e-05,
      "loss": 0.0316,
      "step": 32340
    },
    {
      "epoch": 0.103552,
      "grad_norm": 0.08820222455230466,
      "learning_rate": 9.970631037192384e-05,
      "loss": 0.0348,
      "step": 32360
    },
    {
      "epoch": 0.103616,
      "grad_norm": 0.11135945319607804,
      "learning_rate": 9.970594758812915e-05,
      "loss": 0.0321,
      "step": 32380
    },
    {
      "epoch": 0.10368,
      "grad_norm": 0.07987088362927129,
      "learning_rate": 9.970558458106694e-05,
      "loss": 0.034,
      "step": 32400
    },
    {
      "epoch": 0.103744,
      "grad_norm": 0.13966720658590714,
      "learning_rate": 9.970522135073883e-05,
      "loss": 0.0332,
      "step": 32420
    },
    {
      "epoch": 0.103808,
      "grad_norm": 0.1688180175651959,
      "learning_rate": 9.970485789714649e-05,
      "loss": 0.0366,
      "step": 32440
    },
    {
      "epoch": 0.103872,
      "grad_norm": 0.08091115244919901,
      "learning_rate": 9.970449422029152e-05,
      "loss": 0.0321,
      "step": 32460
    },
    {
      "epoch": 0.103936,
      "grad_norm": 0.15209187212438552,
      "learning_rate": 9.970413032017554e-05,
      "loss": 0.0301,
      "step": 32480
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.11715534695341157,
      "learning_rate": 9.970376619680024e-05,
      "loss": 0.0299,
      "step": 32500
    },
    {
      "epoch": 0.104064,
      "grad_norm": 0.08962885447167879,
      "learning_rate": 9.97034018501672e-05,
      "loss": 0.033,
      "step": 32520
    },
    {
      "epoch": 0.104128,
      "grad_norm": 0.1755333415441921,
      "learning_rate": 9.970303728027807e-05,
      "loss": 0.0373,
      "step": 32540
    },
    {
      "epoch": 0.104192,
      "grad_norm": 0.10250655731561499,
      "learning_rate": 9.970267248713452e-05,
      "loss": 0.0354,
      "step": 32560
    },
    {
      "epoch": 0.104256,
      "grad_norm": 0.10846775825182003,
      "learning_rate": 9.970230747073816e-05,
      "loss": 0.0321,
      "step": 32580
    },
    {
      "epoch": 0.10432,
      "grad_norm": 0.08995467294873673,
      "learning_rate": 9.970194223109062e-05,
      "loss": 0.0349,
      "step": 32600
    },
    {
      "epoch": 0.104384,
      "grad_norm": 0.062579813936164,
      "learning_rate": 9.970157676819359e-05,
      "loss": 0.029,
      "step": 32620
    },
    {
      "epoch": 0.104448,
      "grad_norm": 0.12053434188012464,
      "learning_rate": 9.970121108204864e-05,
      "loss": 0.035,
      "step": 32640
    },
    {
      "epoch": 0.104512,
      "grad_norm": 0.1887429841241576,
      "learning_rate": 9.970084517265746e-05,
      "loss": 0.0337,
      "step": 32660
    },
    {
      "epoch": 0.104576,
      "grad_norm": 0.12505366206441224,
      "learning_rate": 9.970047904002168e-05,
      "loss": 0.0329,
      "step": 32680
    },
    {
      "epoch": 0.10464,
      "grad_norm": 0.07293221784420005,
      "learning_rate": 9.970011268414294e-05,
      "loss": 0.0305,
      "step": 32700
    },
    {
      "epoch": 0.104704,
      "grad_norm": 0.1056085582227811,
      "learning_rate": 9.96997461050229e-05,
      "loss": 0.0295,
      "step": 32720
    },
    {
      "epoch": 0.104768,
      "grad_norm": 0.07054947819850357,
      "learning_rate": 9.969937930266321e-05,
      "loss": 0.0322,
      "step": 32740
    },
    {
      "epoch": 0.104832,
      "grad_norm": 0.14336346691534652,
      "learning_rate": 9.96990122770655e-05,
      "loss": 0.0331,
      "step": 32760
    },
    {
      "epoch": 0.104896,
      "grad_norm": 0.08325060175072148,
      "learning_rate": 9.969864502823142e-05,
      "loss": 0.032,
      "step": 32780
    },
    {
      "epoch": 0.10496,
      "grad_norm": 0.09360226215051706,
      "learning_rate": 9.969827755616263e-05,
      "loss": 0.0332,
      "step": 32800
    },
    {
      "epoch": 0.105024,
      "grad_norm": 0.11962650958228059,
      "learning_rate": 9.969790986086077e-05,
      "loss": 0.0351,
      "step": 32820
    },
    {
      "epoch": 0.105088,
      "grad_norm": 0.08627066880413202,
      "learning_rate": 9.96975419423275e-05,
      "loss": 0.0333,
      "step": 32840
    },
    {
      "epoch": 0.105152,
      "grad_norm": 0.08027216234572701,
      "learning_rate": 9.969717380056447e-05,
      "loss": 0.034,
      "step": 32860
    },
    {
      "epoch": 0.105216,
      "grad_norm": 0.08070882854077836,
      "learning_rate": 9.969680543557334e-05,
      "loss": 0.0328,
      "step": 32880
    },
    {
      "epoch": 0.10528,
      "grad_norm": 0.10600425820625187,
      "learning_rate": 9.969643684735575e-05,
      "loss": 0.0323,
      "step": 32900
    },
    {
      "epoch": 0.105344,
      "grad_norm": 0.16128923418380592,
      "learning_rate": 9.969606803591337e-05,
      "loss": 0.0327,
      "step": 32920
    },
    {
      "epoch": 0.105408,
      "grad_norm": 0.07836433199847413,
      "learning_rate": 9.969569900124785e-05,
      "loss": 0.0333,
      "step": 32940
    },
    {
      "epoch": 0.105472,
      "grad_norm": 0.10380878829516048,
      "learning_rate": 9.969532974336084e-05,
      "loss": 0.0279,
      "step": 32960
    },
    {
      "epoch": 0.105536,
      "grad_norm": 0.12058564455509305,
      "learning_rate": 9.969496026225402e-05,
      "loss": 0.0359,
      "step": 32980
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.10336570306234161,
      "learning_rate": 9.969459055792903e-05,
      "loss": 0.032,
      "step": 33000
    },
    {
      "epoch": 0.105664,
      "grad_norm": 0.12713276969389362,
      "learning_rate": 9.969422063038752e-05,
      "loss": 0.0358,
      "step": 33020
    },
    {
      "epoch": 0.105728,
      "grad_norm": 0.08507008241790076,
      "learning_rate": 9.969385047963117e-05,
      "loss": 0.0345,
      "step": 33040
    },
    {
      "epoch": 0.105792,
      "grad_norm": 0.11181059018180205,
      "learning_rate": 9.969348010566166e-05,
      "loss": 0.0315,
      "step": 33060
    },
    {
      "epoch": 0.105856,
      "grad_norm": 0.0773846683008081,
      "learning_rate": 9.969310950848063e-05,
      "loss": 0.0352,
      "step": 33080
    },
    {
      "epoch": 0.10592,
      "grad_norm": 0.1481978459435784,
      "learning_rate": 9.969273868808975e-05,
      "loss": 0.0294,
      "step": 33100
    },
    {
      "epoch": 0.105984,
      "grad_norm": 0.13525502805229458,
      "learning_rate": 9.969236764449068e-05,
      "loss": 0.0297,
      "step": 33120
    },
    {
      "epoch": 0.106048,
      "grad_norm": 0.06224866886131812,
      "learning_rate": 9.969199637768509e-05,
      "loss": 0.0324,
      "step": 33140
    },
    {
      "epoch": 0.106112,
      "grad_norm": 0.07613885953979165,
      "learning_rate": 9.969162488767466e-05,
      "loss": 0.0355,
      "step": 33160
    },
    {
      "epoch": 0.106176,
      "grad_norm": 0.1726782339167767,
      "learning_rate": 9.969125317446104e-05,
      "loss": 0.0356,
      "step": 33180
    },
    {
      "epoch": 0.10624,
      "grad_norm": 0.11051892150508513,
      "learning_rate": 9.96908812380459e-05,
      "loss": 0.0326,
      "step": 33200
    },
    {
      "epoch": 0.106304,
      "grad_norm": 0.10447556693094644,
      "learning_rate": 9.969050907843094e-05,
      "loss": 0.0319,
      "step": 33220
    },
    {
      "epoch": 0.106368,
      "grad_norm": 0.06690868792437975,
      "learning_rate": 9.96901366956178e-05,
      "loss": 0.0329,
      "step": 33240
    },
    {
      "epoch": 0.106432,
      "grad_norm": 0.07707526650663946,
      "learning_rate": 9.968976408960815e-05,
      "loss": 0.0307,
      "step": 33260
    },
    {
      "epoch": 0.106496,
      "grad_norm": 0.11737144356253157,
      "learning_rate": 9.968939126040369e-05,
      "loss": 0.0304,
      "step": 33280
    },
    {
      "epoch": 0.10656,
      "grad_norm": 0.05806661669138139,
      "learning_rate": 9.968901820800607e-05,
      "loss": 0.0336,
      "step": 33300
    },
    {
      "epoch": 0.106624,
      "grad_norm": 0.10013813933793975,
      "learning_rate": 9.968864493241699e-05,
      "loss": 0.0303,
      "step": 33320
    },
    {
      "epoch": 0.106688,
      "grad_norm": 0.14041833909154006,
      "learning_rate": 9.96882714336381e-05,
      "loss": 0.0292,
      "step": 33340
    },
    {
      "epoch": 0.106752,
      "grad_norm": 0.08283870080160281,
      "learning_rate": 9.96878977116711e-05,
      "loss": 0.0294,
      "step": 33360
    },
    {
      "epoch": 0.106816,
      "grad_norm": 0.08957349081639356,
      "learning_rate": 9.968752376651765e-05,
      "loss": 0.033,
      "step": 33380
    },
    {
      "epoch": 0.10688,
      "grad_norm": 0.08710406866776232,
      "learning_rate": 9.968714959817943e-05,
      "loss": 0.0324,
      "step": 33400
    },
    {
      "epoch": 0.106944,
      "grad_norm": 0.16171824124635029,
      "learning_rate": 9.968677520665816e-05,
      "loss": 0.0302,
      "step": 33420
    },
    {
      "epoch": 0.107008,
      "grad_norm": 0.24924451076587933,
      "learning_rate": 9.968640059195548e-05,
      "loss": 0.0314,
      "step": 33440
    },
    {
      "epoch": 0.107072,
      "grad_norm": 0.07017396582488891,
      "learning_rate": 9.968602575407308e-05,
      "loss": 0.0325,
      "step": 33460
    },
    {
      "epoch": 0.107136,
      "grad_norm": 0.09703947429741804,
      "learning_rate": 9.968565069301265e-05,
      "loss": 0.0339,
      "step": 33480
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.10465812030668217,
      "learning_rate": 9.968527540877585e-05,
      "loss": 0.0331,
      "step": 33500
    },
    {
      "epoch": 0.107264,
      "grad_norm": 0.07203297551131219,
      "learning_rate": 9.968489990136442e-05,
      "loss": 0.0316,
      "step": 33520
    },
    {
      "epoch": 0.107328,
      "grad_norm": 0.09667343105003309,
      "learning_rate": 9.968452417078e-05,
      "loss": 0.0339,
      "step": 33540
    },
    {
      "epoch": 0.107392,
      "grad_norm": 0.1720302227945823,
      "learning_rate": 9.96841482170243e-05,
      "loss": 0.0316,
      "step": 33560
    },
    {
      "epoch": 0.107456,
      "grad_norm": 0.10641947252003983,
      "learning_rate": 9.968377204009899e-05,
      "loss": 0.0313,
      "step": 33580
    },
    {
      "epoch": 0.10752,
      "grad_norm": 0.09794552682883996,
      "learning_rate": 9.96833956400058e-05,
      "loss": 0.0318,
      "step": 33600
    },
    {
      "epoch": 0.107584,
      "grad_norm": 0.07959330488946803,
      "learning_rate": 9.968301901674636e-05,
      "loss": 0.0312,
      "step": 33620
    },
    {
      "epoch": 0.107648,
      "grad_norm": 0.07693175134815734,
      "learning_rate": 9.968264217032241e-05,
      "loss": 0.034,
      "step": 33640
    },
    {
      "epoch": 0.107712,
      "grad_norm": 0.0929141559379662,
      "learning_rate": 9.968226510073562e-05,
      "loss": 0.0315,
      "step": 33660
    },
    {
      "epoch": 0.107776,
      "grad_norm": 0.09129441259114457,
      "learning_rate": 9.968188780798769e-05,
      "loss": 0.0319,
      "step": 33680
    },
    {
      "epoch": 0.10784,
      "grad_norm": 0.09072830284950234,
      "learning_rate": 9.96815102920803e-05,
      "loss": 0.0338,
      "step": 33700
    },
    {
      "epoch": 0.107904,
      "grad_norm": 0.07342049888076141,
      "learning_rate": 9.968113255301519e-05,
      "loss": 0.0326,
      "step": 33720
    },
    {
      "epoch": 0.107968,
      "grad_norm": 0.07409497555249488,
      "learning_rate": 9.9680754590794e-05,
      "loss": 0.0298,
      "step": 33740
    },
    {
      "epoch": 0.108032,
      "grad_norm": 0.0978328077018129,
      "learning_rate": 9.968037640541848e-05,
      "loss": 0.0262,
      "step": 33760
    },
    {
      "epoch": 0.108096,
      "grad_norm": 0.11128091416467521,
      "learning_rate": 9.967999799689027e-05,
      "loss": 0.0312,
      "step": 33780
    },
    {
      "epoch": 0.10816,
      "grad_norm": 0.10022385382023519,
      "learning_rate": 9.967961936521113e-05,
      "loss": 0.0327,
      "step": 33800
    },
    {
      "epoch": 0.108224,
      "grad_norm": 0.07302531818086366,
      "learning_rate": 9.967924051038273e-05,
      "loss": 0.0332,
      "step": 33820
    },
    {
      "epoch": 0.108288,
      "grad_norm": 0.12851180443484947,
      "learning_rate": 9.967886143240676e-05,
      "loss": 0.0292,
      "step": 33840
    },
    {
      "epoch": 0.108352,
      "grad_norm": 0.07882324357049737,
      "learning_rate": 9.967848213128497e-05,
      "loss": 0.0349,
      "step": 33860
    },
    {
      "epoch": 0.108416,
      "grad_norm": 0.13464494201301158,
      "learning_rate": 9.9678102607019e-05,
      "loss": 0.0338,
      "step": 33880
    },
    {
      "epoch": 0.10848,
      "grad_norm": 0.12774870408321368,
      "learning_rate": 9.967772285961062e-05,
      "loss": 0.031,
      "step": 33900
    },
    {
      "epoch": 0.108544,
      "grad_norm": 0.09598308730747136,
      "learning_rate": 9.967734288906147e-05,
      "loss": 0.0344,
      "step": 33920
    },
    {
      "epoch": 0.108608,
      "grad_norm": 0.12656168429502637,
      "learning_rate": 9.96769626953733e-05,
      "loss": 0.0371,
      "step": 33940
    },
    {
      "epoch": 0.108672,
      "grad_norm": 0.130946236455287,
      "learning_rate": 9.96765822785478e-05,
      "loss": 0.0344,
      "step": 33960
    },
    {
      "epoch": 0.108736,
      "grad_norm": 0.12366195158099676,
      "learning_rate": 9.967620163858671e-05,
      "loss": 0.0318,
      "step": 33980
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.07279125101927159,
      "learning_rate": 9.967582077549169e-05,
      "loss": 0.0286,
      "step": 34000
    },
    {
      "epoch": 0.108864,
      "grad_norm": 0.1003430056347591,
      "learning_rate": 9.967543968926449e-05,
      "loss": 0.0317,
      "step": 34020
    },
    {
      "epoch": 0.108928,
      "grad_norm": 0.09260375306449617,
      "learning_rate": 9.967505837990681e-05,
      "loss": 0.0347,
      "step": 34040
    },
    {
      "epoch": 0.108992,
      "grad_norm": 0.0923801076434255,
      "learning_rate": 9.967467684742035e-05,
      "loss": 0.0325,
      "step": 34060
    },
    {
      "epoch": 0.109056,
      "grad_norm": 0.07379210551677713,
      "learning_rate": 9.967429509180683e-05,
      "loss": 0.0336,
      "step": 34080
    },
    {
      "epoch": 0.10912,
      "grad_norm": 0.09223495729107571,
      "learning_rate": 9.967391311306798e-05,
      "loss": 0.034,
      "step": 34100
    },
    {
      "epoch": 0.109184,
      "grad_norm": 0.10718609943583018,
      "learning_rate": 9.967353091120551e-05,
      "loss": 0.0366,
      "step": 34120
    },
    {
      "epoch": 0.109248,
      "grad_norm": 0.09348893997420958,
      "learning_rate": 9.967314848622111e-05,
      "loss": 0.0325,
      "step": 34140
    },
    {
      "epoch": 0.109312,
      "grad_norm": 0.08353324307011697,
      "learning_rate": 9.967276583811655e-05,
      "loss": 0.0352,
      "step": 34160
    },
    {
      "epoch": 0.109376,
      "grad_norm": 0.1119537263468282,
      "learning_rate": 9.96723829668935e-05,
      "loss": 0.033,
      "step": 34180
    },
    {
      "epoch": 0.10944,
      "grad_norm": 0.12949264012208023,
      "learning_rate": 9.967199987255369e-05,
      "loss": 0.0337,
      "step": 34200
    },
    {
      "epoch": 0.109504,
      "grad_norm": 0.09209263345116006,
      "learning_rate": 9.967161655509887e-05,
      "loss": 0.0355,
      "step": 34220
    },
    {
      "epoch": 0.109568,
      "grad_norm": 0.07456194193490664,
      "learning_rate": 9.967123301453073e-05,
      "loss": 0.0304,
      "step": 34240
    },
    {
      "epoch": 0.109632,
      "grad_norm": 0.17750935492475595,
      "learning_rate": 9.9670849250851e-05,
      "loss": 0.0297,
      "step": 34260
    },
    {
      "epoch": 0.109696,
      "grad_norm": 0.12496227220709985,
      "learning_rate": 9.967046526406141e-05,
      "loss": 0.0332,
      "step": 34280
    },
    {
      "epoch": 0.10976,
      "grad_norm": 0.0818117531943462,
      "learning_rate": 9.967008105416369e-05,
      "loss": 0.0311,
      "step": 34300
    },
    {
      "epoch": 0.109824,
      "grad_norm": 0.07763838151615514,
      "learning_rate": 9.966969662115954e-05,
      "loss": 0.0326,
      "step": 34320
    },
    {
      "epoch": 0.109888,
      "grad_norm": 0.13172104271306334,
      "learning_rate": 9.966931196505071e-05,
      "loss": 0.0326,
      "step": 34340
    },
    {
      "epoch": 0.109952,
      "grad_norm": 0.21239926546746965,
      "learning_rate": 9.966892708583893e-05,
      "loss": 0.0306,
      "step": 34360
    },
    {
      "epoch": 0.110016,
      "grad_norm": 0.16647877176508197,
      "learning_rate": 9.966854198352593e-05,
      "loss": 0.0323,
      "step": 34380
    },
    {
      "epoch": 0.11008,
      "grad_norm": 0.07954586211745605,
      "learning_rate": 9.966815665811342e-05,
      "loss": 0.0333,
      "step": 34400
    },
    {
      "epoch": 0.110144,
      "grad_norm": 0.098133363792694,
      "learning_rate": 9.966777110960314e-05,
      "loss": 0.0324,
      "step": 34420
    },
    {
      "epoch": 0.110208,
      "grad_norm": 0.12828955538729345,
      "learning_rate": 9.966738533799681e-05,
      "loss": 0.0324,
      "step": 34440
    },
    {
      "epoch": 0.110272,
      "grad_norm": 0.11635381428101654,
      "learning_rate": 9.96669993432962e-05,
      "loss": 0.033,
      "step": 34460
    },
    {
      "epoch": 0.110336,
      "grad_norm": 0.09765150742591423,
      "learning_rate": 9.966661312550302e-05,
      "loss": 0.036,
      "step": 34480
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.15987883697666064,
      "learning_rate": 9.9666226684619e-05,
      "loss": 0.0341,
      "step": 34500
    },
    {
      "epoch": 0.110464,
      "grad_norm": 0.20526422904389086,
      "learning_rate": 9.966584002064587e-05,
      "loss": 0.0351,
      "step": 34520
    },
    {
      "epoch": 0.110528,
      "grad_norm": 0.15687462622152515,
      "learning_rate": 9.966545313358537e-05,
      "loss": 0.0322,
      "step": 34540
    },
    {
      "epoch": 0.110592,
      "grad_norm": 0.06864821071203991,
      "learning_rate": 9.966506602343927e-05,
      "loss": 0.0307,
      "step": 34560
    },
    {
      "epoch": 0.110656,
      "grad_norm": 0.07954880762676457,
      "learning_rate": 9.966467869020928e-05,
      "loss": 0.035,
      "step": 34580
    },
    {
      "epoch": 0.11072,
      "grad_norm": 0.10272942143168402,
      "learning_rate": 9.966429113389713e-05,
      "loss": 0.0321,
      "step": 34600
    },
    {
      "epoch": 0.110784,
      "grad_norm": 0.10518813600091349,
      "learning_rate": 9.966390335450459e-05,
      "loss": 0.0334,
      "step": 34620
    },
    {
      "epoch": 0.110848,
      "grad_norm": 0.06577893727131802,
      "learning_rate": 9.966351535203337e-05,
      "loss": 0.0319,
      "step": 34640
    },
    {
      "epoch": 0.110912,
      "grad_norm": 0.11077496039335785,
      "learning_rate": 9.966312712648524e-05,
      "loss": 0.0347,
      "step": 34660
    },
    {
      "epoch": 0.110976,
      "grad_norm": 0.07653849681518922,
      "learning_rate": 9.966273867786193e-05,
      "loss": 0.0322,
      "step": 34680
    },
    {
      "epoch": 0.11104,
      "grad_norm": 0.19128802614444906,
      "learning_rate": 9.96623500061652e-05,
      "loss": 0.0343,
      "step": 34700
    },
    {
      "epoch": 0.111104,
      "grad_norm": 0.08112054172444903,
      "learning_rate": 9.966196111139676e-05,
      "loss": 0.0339,
      "step": 34720
    },
    {
      "epoch": 0.111168,
      "grad_norm": 0.06105611108146409,
      "learning_rate": 9.966157199355839e-05,
      "loss": 0.0309,
      "step": 34740
    },
    {
      "epoch": 0.111232,
      "grad_norm": 0.26120311270766583,
      "learning_rate": 9.966118265265183e-05,
      "loss": 0.0376,
      "step": 34760
    },
    {
      "epoch": 0.111296,
      "grad_norm": 0.10895669571422546,
      "learning_rate": 9.966079308867884e-05,
      "loss": 0.0327,
      "step": 34780
    },
    {
      "epoch": 0.11136,
      "grad_norm": 0.06621132672225348,
      "learning_rate": 9.966040330164115e-05,
      "loss": 0.0317,
      "step": 34800
    },
    {
      "epoch": 0.111424,
      "grad_norm": 0.2305520127981935,
      "learning_rate": 9.966001329154051e-05,
      "loss": 0.0326,
      "step": 34820
    },
    {
      "epoch": 0.111488,
      "grad_norm": 0.11599012336005006,
      "learning_rate": 9.965962305837868e-05,
      "loss": 0.0341,
      "step": 34840
    },
    {
      "epoch": 0.111552,
      "grad_norm": 0.21788500157529989,
      "learning_rate": 9.965923260215741e-05,
      "loss": 0.0305,
      "step": 34860
    },
    {
      "epoch": 0.111616,
      "grad_norm": 0.10354581493204382,
      "learning_rate": 9.965884192287846e-05,
      "loss": 0.0318,
      "step": 34880
    },
    {
      "epoch": 0.11168,
      "grad_norm": 0.07515625422843464,
      "learning_rate": 9.965845102054359e-05,
      "loss": 0.0338,
      "step": 34900
    },
    {
      "epoch": 0.111744,
      "grad_norm": 0.11032975800640689,
      "learning_rate": 9.965805989515454e-05,
      "loss": 0.0347,
      "step": 34920
    },
    {
      "epoch": 0.111808,
      "grad_norm": 0.13430200485598753,
      "learning_rate": 9.965766854671308e-05,
      "loss": 0.0303,
      "step": 34940
    },
    {
      "epoch": 0.111872,
      "grad_norm": 0.06716717698722977,
      "learning_rate": 9.965727697522095e-05,
      "loss": 0.0312,
      "step": 34960
    },
    {
      "epoch": 0.111936,
      "grad_norm": 0.14114153614142033,
      "learning_rate": 9.965688518067993e-05,
      "loss": 0.0327,
      "step": 34980
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.07414635211100958,
      "learning_rate": 9.965649316309178e-05,
      "loss": 0.0301,
      "step": 35000
    },
    {
      "epoch": 0.112064,
      "grad_norm": 0.07118471874140454,
      "learning_rate": 9.965610092245823e-05,
      "loss": 0.0345,
      "step": 35020
    },
    {
      "epoch": 0.112128,
      "grad_norm": 0.15535855751004604,
      "learning_rate": 9.965570845878107e-05,
      "loss": 0.0327,
      "step": 35040
    },
    {
      "epoch": 0.112192,
      "grad_norm": 0.08840878538254744,
      "learning_rate": 9.965531577206207e-05,
      "loss": 0.0338,
      "step": 35060
    },
    {
      "epoch": 0.112256,
      "grad_norm": 0.08740748618307703,
      "learning_rate": 9.965492286230295e-05,
      "loss": 0.0329,
      "step": 35080
    },
    {
      "epoch": 0.11232,
      "grad_norm": 0.09877432522625522,
      "learning_rate": 9.965452972950553e-05,
      "loss": 0.0315,
      "step": 35100
    },
    {
      "epoch": 0.112384,
      "grad_norm": 0.11235007788940649,
      "learning_rate": 9.965413637367156e-05,
      "loss": 0.0339,
      "step": 35120
    },
    {
      "epoch": 0.112448,
      "grad_norm": 0.09483559661774024,
      "learning_rate": 9.965374279480277e-05,
      "loss": 0.0285,
      "step": 35140
    },
    {
      "epoch": 0.112512,
      "grad_norm": 0.07621990173282894,
      "learning_rate": 9.965334899290097e-05,
      "loss": 0.0326,
      "step": 35160
    },
    {
      "epoch": 0.112576,
      "grad_norm": 0.11165487239161613,
      "learning_rate": 9.965295496796792e-05,
      "loss": 0.0329,
      "step": 35180
    },
    {
      "epoch": 0.11264,
      "grad_norm": 0.10867946658593554,
      "learning_rate": 9.965256072000537e-05,
      "loss": 0.0322,
      "step": 35200
    },
    {
      "epoch": 0.112704,
      "grad_norm": 0.09039177422645221,
      "learning_rate": 9.96521662490151e-05,
      "loss": 0.0323,
      "step": 35220
    },
    {
      "epoch": 0.112768,
      "grad_norm": 0.07797394265195395,
      "learning_rate": 9.96517715549989e-05,
      "loss": 0.0293,
      "step": 35240
    },
    {
      "epoch": 0.112832,
      "grad_norm": 0.08105110731593314,
      "learning_rate": 9.965137663795853e-05,
      "loss": 0.0305,
      "step": 35260
    },
    {
      "epoch": 0.112896,
      "grad_norm": 0.08529639252197711,
      "learning_rate": 9.965098149789576e-05,
      "loss": 0.0324,
      "step": 35280
    },
    {
      "epoch": 0.11296,
      "grad_norm": 0.09687399142071647,
      "learning_rate": 9.965058613481237e-05,
      "loss": 0.0346,
      "step": 35300
    },
    {
      "epoch": 0.113024,
      "grad_norm": 0.07898446868648812,
      "learning_rate": 9.965019054871015e-05,
      "loss": 0.0356,
      "step": 35320
    },
    {
      "epoch": 0.113088,
      "grad_norm": 0.11245333429759206,
      "learning_rate": 9.964979473959084e-05,
      "loss": 0.0311,
      "step": 35340
    },
    {
      "epoch": 0.113152,
      "grad_norm": 0.07992269739008,
      "learning_rate": 9.964939870745623e-05,
      "loss": 0.0301,
      "step": 35360
    },
    {
      "epoch": 0.113216,
      "grad_norm": 0.07071795690274804,
      "learning_rate": 9.964900245230813e-05,
      "loss": 0.032,
      "step": 35380
    },
    {
      "epoch": 0.11328,
      "grad_norm": 0.08593089022439952,
      "learning_rate": 9.96486059741483e-05,
      "loss": 0.0324,
      "step": 35400
    },
    {
      "epoch": 0.113344,
      "grad_norm": 0.07448160066411781,
      "learning_rate": 9.964820927297848e-05,
      "loss": 0.0298,
      "step": 35420
    },
    {
      "epoch": 0.113408,
      "grad_norm": 0.066267619079859,
      "learning_rate": 9.964781234880054e-05,
      "loss": 0.0307,
      "step": 35440
    },
    {
      "epoch": 0.113472,
      "grad_norm": 0.09633084242587177,
      "learning_rate": 9.964741520161617e-05,
      "loss": 0.0324,
      "step": 35460
    },
    {
      "epoch": 0.113536,
      "grad_norm": 0.12775898782951386,
      "learning_rate": 9.964701783142724e-05,
      "loss": 0.0369,
      "step": 35480
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.21781389689751313,
      "learning_rate": 9.964662023823547e-05,
      "loss": 0.0351,
      "step": 35500
    },
    {
      "epoch": 0.113664,
      "grad_norm": 0.0905405485420799,
      "learning_rate": 9.964622242204267e-05,
      "loss": 0.0342,
      "step": 35520
    },
    {
      "epoch": 0.113728,
      "grad_norm": 0.1050233415780439,
      "learning_rate": 9.964582438285062e-05,
      "loss": 0.0326,
      "step": 35540
    },
    {
      "epoch": 0.113792,
      "grad_norm": 0.21260365424920846,
      "learning_rate": 9.964542612066112e-05,
      "loss": 0.0313,
      "step": 35560
    },
    {
      "epoch": 0.113856,
      "grad_norm": 0.07598314771829522,
      "learning_rate": 9.964502763547596e-05,
      "loss": 0.0325,
      "step": 35580
    },
    {
      "epoch": 0.11392,
      "grad_norm": 0.08283825834079331,
      "learning_rate": 9.964462892729692e-05,
      "loss": 0.0295,
      "step": 35600
    },
    {
      "epoch": 0.113984,
      "grad_norm": 0.08606929264449002,
      "learning_rate": 9.964422999612577e-05,
      "loss": 0.0321,
      "step": 35620
    },
    {
      "epoch": 0.114048,
      "grad_norm": 0.08219155614431484,
      "learning_rate": 9.964383084196434e-05,
      "loss": 0.0334,
      "step": 35640
    },
    {
      "epoch": 0.114112,
      "grad_norm": 0.06889528570284775,
      "learning_rate": 9.96434314648144e-05,
      "loss": 0.0348,
      "step": 35660
    },
    {
      "epoch": 0.114176,
      "grad_norm": 0.10682171940961276,
      "learning_rate": 9.964303186467777e-05,
      "loss": 0.0322,
      "step": 35680
    },
    {
      "epoch": 0.11424,
      "grad_norm": 0.1188302082481202,
      "learning_rate": 9.964263204155621e-05,
      "loss": 0.0328,
      "step": 35700
    },
    {
      "epoch": 0.114304,
      "grad_norm": 0.1212317443299198,
      "learning_rate": 9.964223199545156e-05,
      "loss": 0.0324,
      "step": 35720
    },
    {
      "epoch": 0.114368,
      "grad_norm": 0.07206975891981421,
      "learning_rate": 9.964183172636556e-05,
      "loss": 0.0316,
      "step": 35740
    },
    {
      "epoch": 0.114432,
      "grad_norm": 0.10371238990275178,
      "learning_rate": 9.964143123430004e-05,
      "loss": 0.0326,
      "step": 35760
    },
    {
      "epoch": 0.114496,
      "grad_norm": 0.25222712982183304,
      "learning_rate": 9.964103051925679e-05,
      "loss": 0.0357,
      "step": 35780
    },
    {
      "epoch": 0.11456,
      "grad_norm": 0.08709101829855079,
      "learning_rate": 9.964062958123764e-05,
      "loss": 0.0321,
      "step": 35800
    },
    {
      "epoch": 0.114624,
      "grad_norm": 0.14738196313053575,
      "learning_rate": 9.964022842024434e-05,
      "loss": 0.0322,
      "step": 35820
    },
    {
      "epoch": 0.114688,
      "grad_norm": 0.0869109792239195,
      "learning_rate": 9.963982703627875e-05,
      "loss": 0.0318,
      "step": 35840
    },
    {
      "epoch": 0.114752,
      "grad_norm": 0.09289650622094349,
      "learning_rate": 9.963942542934262e-05,
      "loss": 0.032,
      "step": 35860
    },
    {
      "epoch": 0.114816,
      "grad_norm": 0.14603235538201367,
      "learning_rate": 9.963902359943778e-05,
      "loss": 0.0309,
      "step": 35880
    },
    {
      "epoch": 0.11488,
      "grad_norm": 0.11181447536126167,
      "learning_rate": 9.963862154656603e-05,
      "loss": 0.0304,
      "step": 35900
    },
    {
      "epoch": 0.114944,
      "grad_norm": 0.1201507731219381,
      "learning_rate": 9.963821927072917e-05,
      "loss": 0.0327,
      "step": 35920
    },
    {
      "epoch": 0.115008,
      "grad_norm": 0.11163069639406126,
      "learning_rate": 9.963781677192903e-05,
      "loss": 0.0349,
      "step": 35940
    },
    {
      "epoch": 0.115072,
      "grad_norm": 0.07784624014029493,
      "learning_rate": 9.963741405016737e-05,
      "loss": 0.0355,
      "step": 35960
    },
    {
      "epoch": 0.115136,
      "grad_norm": 0.13112807051339812,
      "learning_rate": 9.963701110544605e-05,
      "loss": 0.0341,
      "step": 35980
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.14163617665355058,
      "learning_rate": 9.963660793776688e-05,
      "loss": 0.0352,
      "step": 36000
    },
    {
      "epoch": 0.115264,
      "grad_norm": 0.08301227358743235,
      "learning_rate": 9.963620454713163e-05,
      "loss": 0.0299,
      "step": 36020
    },
    {
      "epoch": 0.115328,
      "grad_norm": 0.12552668809291267,
      "learning_rate": 9.963580093354214e-05,
      "loss": 0.0323,
      "step": 36040
    },
    {
      "epoch": 0.115392,
      "grad_norm": 0.11192323800132616,
      "learning_rate": 9.963539709700021e-05,
      "loss": 0.0292,
      "step": 36060
    },
    {
      "epoch": 0.115456,
      "grad_norm": 0.07689316691403217,
      "learning_rate": 9.963499303750765e-05,
      "loss": 0.0333,
      "step": 36080
    },
    {
      "epoch": 0.11552,
      "grad_norm": 0.12870685004086013,
      "learning_rate": 9.963458875506631e-05,
      "loss": 0.0351,
      "step": 36100
    },
    {
      "epoch": 0.115584,
      "grad_norm": 0.10286516033856004,
      "learning_rate": 9.963418424967796e-05,
      "loss": 0.0315,
      "step": 36120
    },
    {
      "epoch": 0.115648,
      "grad_norm": 0.1853140649213712,
      "learning_rate": 9.963377952134445e-05,
      "loss": 0.0334,
      "step": 36140
    },
    {
      "epoch": 0.115712,
      "grad_norm": 0.0816907492207387,
      "learning_rate": 9.963337457006759e-05,
      "loss": 0.0331,
      "step": 36160
    },
    {
      "epoch": 0.115776,
      "grad_norm": 0.12435708944252365,
      "learning_rate": 9.963296939584917e-05,
      "loss": 0.0332,
      "step": 36180
    },
    {
      "epoch": 0.11584,
      "grad_norm": 0.24126706543084164,
      "learning_rate": 9.963256399869105e-05,
      "loss": 0.0346,
      "step": 36200
    },
    {
      "epoch": 0.115904,
      "grad_norm": 0.09324461608543054,
      "learning_rate": 9.963215837859504e-05,
      "loss": 0.032,
      "step": 36220
    },
    {
      "epoch": 0.115968,
      "grad_norm": 0.07005958573983423,
      "learning_rate": 9.963175253556297e-05,
      "loss": 0.0326,
      "step": 36240
    },
    {
      "epoch": 0.116032,
      "grad_norm": 0.08482601348167765,
      "learning_rate": 9.963134646959662e-05,
      "loss": 0.0307,
      "step": 36260
    },
    {
      "epoch": 0.116096,
      "grad_norm": 0.09332993998237313,
      "learning_rate": 9.963094018069785e-05,
      "loss": 0.0335,
      "step": 36280
    },
    {
      "epoch": 0.11616,
      "grad_norm": 0.08102208392039635,
      "learning_rate": 9.96305336688685e-05,
      "loss": 0.0294,
      "step": 36300
    },
    {
      "epoch": 0.116224,
      "grad_norm": 0.07889400053020895,
      "learning_rate": 9.963012693411035e-05,
      "loss": 0.0315,
      "step": 36320
    },
    {
      "epoch": 0.116288,
      "grad_norm": 0.08290655900922446,
      "learning_rate": 9.962971997642527e-05,
      "loss": 0.0332,
      "step": 36340
    },
    {
      "epoch": 0.116352,
      "grad_norm": 0.16639584641596317,
      "learning_rate": 9.962931279581507e-05,
      "loss": 0.0323,
      "step": 36360
    },
    {
      "epoch": 0.116416,
      "grad_norm": 0.08624009025538779,
      "learning_rate": 9.962890539228158e-05,
      "loss": 0.0319,
      "step": 36380
    },
    {
      "epoch": 0.11648,
      "grad_norm": 0.09049129967569076,
      "learning_rate": 9.962849776582662e-05,
      "loss": 0.0333,
      "step": 36400
    },
    {
      "epoch": 0.116544,
      "grad_norm": 0.17054767438699914,
      "learning_rate": 9.962808991645203e-05,
      "loss": 0.0269,
      "step": 36420
    },
    {
      "epoch": 0.116608,
      "grad_norm": 0.10314869197136042,
      "learning_rate": 9.962768184415965e-05,
      "loss": 0.0348,
      "step": 36440
    },
    {
      "epoch": 0.116672,
      "grad_norm": 0.07988447338129137,
      "learning_rate": 9.96272735489513e-05,
      "loss": 0.0302,
      "step": 36460
    },
    {
      "epoch": 0.116736,
      "grad_norm": 0.10901812093562432,
      "learning_rate": 9.962686503082883e-05,
      "loss": 0.0316,
      "step": 36480
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.08448437307653514,
      "learning_rate": 9.962645628979406e-05,
      "loss": 0.0337,
      "step": 36500
    },
    {
      "epoch": 0.116864,
      "grad_norm": 0.09970780438779868,
      "learning_rate": 9.962604732584882e-05,
      "loss": 0.034,
      "step": 36520
    },
    {
      "epoch": 0.116928,
      "grad_norm": 0.08370613425580523,
      "learning_rate": 9.962563813899496e-05,
      "loss": 0.0285,
      "step": 36540
    },
    {
      "epoch": 0.116992,
      "grad_norm": 0.11498425229332991,
      "learning_rate": 9.962522872923432e-05,
      "loss": 0.0345,
      "step": 36560
    },
    {
      "epoch": 0.117056,
      "grad_norm": 0.07347575431659874,
      "learning_rate": 9.962481909656872e-05,
      "loss": 0.0334,
      "step": 36580
    },
    {
      "epoch": 0.11712,
      "grad_norm": 0.09847315221511913,
      "learning_rate": 9.962440924100002e-05,
      "loss": 0.0309,
      "step": 36600
    },
    {
      "epoch": 0.117184,
      "grad_norm": 0.11025392463376181,
      "learning_rate": 9.962399916253006e-05,
      "loss": 0.0333,
      "step": 36620
    },
    {
      "epoch": 0.117248,
      "grad_norm": 0.13344232688950747,
      "learning_rate": 9.962358886116067e-05,
      "loss": 0.0313,
      "step": 36640
    },
    {
      "epoch": 0.117312,
      "grad_norm": 0.1275129167201773,
      "learning_rate": 9.962317833689372e-05,
      "loss": 0.0294,
      "step": 36660
    },
    {
      "epoch": 0.117376,
      "grad_norm": 0.07249345607926054,
      "learning_rate": 9.962276758973101e-05,
      "loss": 0.0345,
      "step": 36680
    },
    {
      "epoch": 0.11744,
      "grad_norm": 0.09248714158655268,
      "learning_rate": 9.962235661967443e-05,
      "loss": 0.0336,
      "step": 36700
    },
    {
      "epoch": 0.117504,
      "grad_norm": 0.12860822382391035,
      "learning_rate": 9.96219454267258e-05,
      "loss": 0.0296,
      "step": 36720
    },
    {
      "epoch": 0.117568,
      "grad_norm": 0.07789809871865498,
      "learning_rate": 9.962153401088697e-05,
      "loss": 0.0328,
      "step": 36740
    },
    {
      "epoch": 0.117632,
      "grad_norm": 0.07069656804970778,
      "learning_rate": 9.962112237215977e-05,
      "loss": 0.0324,
      "step": 36760
    },
    {
      "epoch": 0.117696,
      "grad_norm": 0.09917526205337666,
      "learning_rate": 9.96207105105461e-05,
      "loss": 0.0342,
      "step": 36780
    },
    {
      "epoch": 0.11776,
      "grad_norm": 0.08874343309573036,
      "learning_rate": 9.962029842604775e-05,
      "loss": 0.0316,
      "step": 36800
    },
    {
      "epoch": 0.117824,
      "grad_norm": 0.1334900106199603,
      "learning_rate": 9.961988611866661e-05,
      "loss": 0.034,
      "step": 36820
    },
    {
      "epoch": 0.117888,
      "grad_norm": 0.08769284167520282,
      "learning_rate": 9.961947358840453e-05,
      "loss": 0.0318,
      "step": 36840
    },
    {
      "epoch": 0.117952,
      "grad_norm": 0.13450040532854868,
      "learning_rate": 9.961906083526335e-05,
      "loss": 0.0315,
      "step": 36860
    },
    {
      "epoch": 0.118016,
      "grad_norm": 0.1099362879940964,
      "learning_rate": 9.961864785924492e-05,
      "loss": 0.0328,
      "step": 36880
    },
    {
      "epoch": 0.11808,
      "grad_norm": 0.14485320645545152,
      "learning_rate": 9.961823466035112e-05,
      "loss": 0.0347,
      "step": 36900
    },
    {
      "epoch": 0.118144,
      "grad_norm": 0.116712882415643,
      "learning_rate": 9.961782123858376e-05,
      "loss": 0.0319,
      "step": 36920
    },
    {
      "epoch": 0.118208,
      "grad_norm": 0.08472762090815263,
      "learning_rate": 9.961740759394475e-05,
      "loss": 0.0326,
      "step": 36940
    },
    {
      "epoch": 0.118272,
      "grad_norm": 0.21433302859337203,
      "learning_rate": 9.961699372643594e-05,
      "loss": 0.0319,
      "step": 36960
    },
    {
      "epoch": 0.118336,
      "grad_norm": 0.15915141512032954,
      "learning_rate": 9.961657963605915e-05,
      "loss": 0.0319,
      "step": 36980
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.08825772952212092,
      "learning_rate": 9.961616532281626e-05,
      "loss": 0.0322,
      "step": 37000
    },
    {
      "epoch": 0.118464,
      "grad_norm": 0.11472558796082853,
      "learning_rate": 9.961575078670914e-05,
      "loss": 0.0357,
      "step": 37020
    },
    {
      "epoch": 0.118528,
      "grad_norm": 0.12525367084922528,
      "learning_rate": 9.961533602773966e-05,
      "loss": 0.0299,
      "step": 37040
    },
    {
      "epoch": 0.118592,
      "grad_norm": 0.07667885639208896,
      "learning_rate": 9.961492104590966e-05,
      "loss": 0.0313,
      "step": 37060
    },
    {
      "epoch": 0.118656,
      "grad_norm": 0.06394329628703295,
      "learning_rate": 9.9614505841221e-05,
      "loss": 0.0319,
      "step": 37080
    },
    {
      "epoch": 0.11872,
      "grad_norm": 0.08889329997105967,
      "learning_rate": 9.961409041367558e-05,
      "loss": 0.0324,
      "step": 37100
    },
    {
      "epoch": 0.118784,
      "grad_norm": 0.16448788335958803,
      "learning_rate": 9.961367476327524e-05,
      "loss": 0.0306,
      "step": 37120
    },
    {
      "epoch": 0.118848,
      "grad_norm": 0.07129643674223644,
      "learning_rate": 9.961325889002184e-05,
      "loss": 0.0314,
      "step": 37140
    },
    {
      "epoch": 0.118912,
      "grad_norm": 0.17996250742373984,
      "learning_rate": 9.961284279391728e-05,
      "loss": 0.0322,
      "step": 37160
    },
    {
      "epoch": 0.118976,
      "grad_norm": 0.08283863768422912,
      "learning_rate": 9.961242647496338e-05,
      "loss": 0.0336,
      "step": 37180
    },
    {
      "epoch": 0.11904,
      "grad_norm": 0.05928128878429634,
      "learning_rate": 9.961200993316206e-05,
      "loss": 0.0334,
      "step": 37200
    },
    {
      "epoch": 0.119104,
      "grad_norm": 0.0921784566230797,
      "learning_rate": 9.961159316851517e-05,
      "loss": 0.0289,
      "step": 37220
    },
    {
      "epoch": 0.119168,
      "grad_norm": 0.09774449373308244,
      "learning_rate": 9.961117618102458e-05,
      "loss": 0.0305,
      "step": 37240
    },
    {
      "epoch": 0.119232,
      "grad_norm": 0.07920167374695274,
      "learning_rate": 9.961075897069216e-05,
      "loss": 0.0296,
      "step": 37260
    },
    {
      "epoch": 0.119296,
      "grad_norm": 0.06814190272390024,
      "learning_rate": 9.961034153751979e-05,
      "loss": 0.03,
      "step": 37280
    },
    {
      "epoch": 0.11936,
      "grad_norm": 0.10863133391098156,
      "learning_rate": 9.960992388150934e-05,
      "loss": 0.0306,
      "step": 37300
    },
    {
      "epoch": 0.119424,
      "grad_norm": 0.10003355823270552,
      "learning_rate": 9.96095060026627e-05,
      "loss": 0.032,
      "step": 37320
    },
    {
      "epoch": 0.119488,
      "grad_norm": 0.07343144935971223,
      "learning_rate": 9.960908790098173e-05,
      "loss": 0.0345,
      "step": 37340
    },
    {
      "epoch": 0.119552,
      "grad_norm": 0.199754190942915,
      "learning_rate": 9.96086695764683e-05,
      "loss": 0.0362,
      "step": 37360
    },
    {
      "epoch": 0.119616,
      "grad_norm": 0.09478636483968902,
      "learning_rate": 9.960825102912433e-05,
      "loss": 0.0325,
      "step": 37380
    },
    {
      "epoch": 0.11968,
      "grad_norm": 0.08608315181705586,
      "learning_rate": 9.960783225895167e-05,
      "loss": 0.0311,
      "step": 37400
    },
    {
      "epoch": 0.119744,
      "grad_norm": 0.14099814528510562,
      "learning_rate": 9.960741326595219e-05,
      "loss": 0.03,
      "step": 37420
    },
    {
      "epoch": 0.119808,
      "grad_norm": 0.10023477835641532,
      "learning_rate": 9.960699405012778e-05,
      "loss": 0.0309,
      "step": 37440
    },
    {
      "epoch": 0.119872,
      "grad_norm": 0.08632691022757225,
      "learning_rate": 9.960657461148035e-05,
      "loss": 0.0314,
      "step": 37460
    },
    {
      "epoch": 0.119936,
      "grad_norm": 0.09088508742133818,
      "learning_rate": 9.960615495001176e-05,
      "loss": 0.0326,
      "step": 37480
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.08246502504082026,
      "learning_rate": 9.96057350657239e-05,
      "loss": 0.0327,
      "step": 37500
    },
    {
      "epoch": 0.120064,
      "grad_norm": 0.08889452829563031,
      "learning_rate": 9.960531495861864e-05,
      "loss": 0.0327,
      "step": 37520
    },
    {
      "epoch": 0.120128,
      "grad_norm": 0.1321810821875133,
      "learning_rate": 9.960489462869791e-05,
      "loss": 0.0317,
      "step": 37540
    },
    {
      "epoch": 0.120192,
      "grad_norm": 0.07901498676306969,
      "learning_rate": 9.960447407596353e-05,
      "loss": 0.0339,
      "step": 37560
    },
    {
      "epoch": 0.120256,
      "grad_norm": 0.11663780289091064,
      "learning_rate": 9.960405330041747e-05,
      "loss": 0.0329,
      "step": 37580
    },
    {
      "epoch": 0.12032,
      "grad_norm": 0.08682732591404133,
      "learning_rate": 9.960363230206155e-05,
      "loss": 0.0315,
      "step": 37600
    },
    {
      "epoch": 0.120384,
      "grad_norm": 0.0685551512663347,
      "learning_rate": 9.96032110808977e-05,
      "loss": 0.0327,
      "step": 37620
    },
    {
      "epoch": 0.120448,
      "grad_norm": 0.08001224602140601,
      "learning_rate": 9.960278963692781e-05,
      "loss": 0.0317,
      "step": 37640
    },
    {
      "epoch": 0.120512,
      "grad_norm": 0.11604695589436578,
      "learning_rate": 9.960236797015376e-05,
      "loss": 0.0312,
      "step": 37660
    },
    {
      "epoch": 0.120576,
      "grad_norm": 0.07781578153568748,
      "learning_rate": 9.960194608057744e-05,
      "loss": 0.03,
      "step": 37680
    },
    {
      "epoch": 0.12064,
      "grad_norm": 0.07393264932850753,
      "learning_rate": 9.960152396820077e-05,
      "loss": 0.0302,
      "step": 37700
    },
    {
      "epoch": 0.120704,
      "grad_norm": 0.09496256664945173,
      "learning_rate": 9.960110163302561e-05,
      "loss": 0.0321,
      "step": 37720
    },
    {
      "epoch": 0.120768,
      "grad_norm": 0.07869260080496425,
      "learning_rate": 9.96006790750539e-05,
      "loss": 0.0333,
      "step": 37740
    },
    {
      "epoch": 0.120832,
      "grad_norm": 0.08479614574939452,
      "learning_rate": 9.96002562942875e-05,
      "loss": 0.0312,
      "step": 37760
    },
    {
      "epoch": 0.120896,
      "grad_norm": 0.09627047464540824,
      "learning_rate": 9.959983329072832e-05,
      "loss": 0.0328,
      "step": 37780
    },
    {
      "epoch": 0.12096,
      "grad_norm": 0.07777341070169186,
      "learning_rate": 9.959941006437828e-05,
      "loss": 0.03,
      "step": 37800
    },
    {
      "epoch": 0.121024,
      "grad_norm": 0.08964891133063992,
      "learning_rate": 9.959898661523926e-05,
      "loss": 0.0302,
      "step": 37820
    },
    {
      "epoch": 0.121088,
      "grad_norm": 0.096323282291661,
      "learning_rate": 9.959856294331317e-05,
      "loss": 0.0304,
      "step": 37840
    },
    {
      "epoch": 0.121152,
      "grad_norm": 0.059413719899620195,
      "learning_rate": 9.95981390486019e-05,
      "loss": 0.0339,
      "step": 37860
    },
    {
      "epoch": 0.121216,
      "grad_norm": 0.18543590326411122,
      "learning_rate": 9.959771493110737e-05,
      "loss": 0.0335,
      "step": 37880
    },
    {
      "epoch": 0.12128,
      "grad_norm": 0.16241868184193745,
      "learning_rate": 9.959729059083148e-05,
      "loss": 0.0334,
      "step": 37900
    },
    {
      "epoch": 0.121344,
      "grad_norm": 0.07762208489545298,
      "learning_rate": 9.959686602777613e-05,
      "loss": 0.0327,
      "step": 37920
    },
    {
      "epoch": 0.121408,
      "grad_norm": 0.06391938325212523,
      "learning_rate": 9.959644124194325e-05,
      "loss": 0.0311,
      "step": 37940
    },
    {
      "epoch": 0.121472,
      "grad_norm": 0.08954332437290162,
      "learning_rate": 9.95960162333347e-05,
      "loss": 0.0306,
      "step": 37960
    },
    {
      "epoch": 0.121536,
      "grad_norm": 0.148763576552993,
      "learning_rate": 9.959559100195245e-05,
      "loss": 0.0319,
      "step": 37980
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.1455620143215255,
      "learning_rate": 9.959516554779838e-05,
      "loss": 0.0312,
      "step": 38000
    },
    {
      "epoch": 0.121664,
      "grad_norm": 0.09155855801499024,
      "learning_rate": 9.959473987087437e-05,
      "loss": 0.0342,
      "step": 38020
    },
    {
      "epoch": 0.121728,
      "grad_norm": 0.09010646402640614,
      "learning_rate": 9.959431397118238e-05,
      "loss": 0.0352,
      "step": 38040
    },
    {
      "epoch": 0.121792,
      "grad_norm": 0.11263007761936172,
      "learning_rate": 9.959388784872432e-05,
      "loss": 0.0341,
      "step": 38060
    },
    {
      "epoch": 0.121856,
      "grad_norm": 0.09073746559180812,
      "learning_rate": 9.959346150350206e-05,
      "loss": 0.0308,
      "step": 38080
    },
    {
      "epoch": 0.12192,
      "grad_norm": 0.0742683933049584,
      "learning_rate": 9.959303493551757e-05,
      "loss": 0.0299,
      "step": 38100
    },
    {
      "epoch": 0.121984,
      "grad_norm": 0.12539145298724186,
      "learning_rate": 9.959260814477273e-05,
      "loss": 0.029,
      "step": 38120
    },
    {
      "epoch": 0.122048,
      "grad_norm": 0.06248153998868201,
      "learning_rate": 9.959218113126947e-05,
      "loss": 0.0318,
      "step": 38140
    },
    {
      "epoch": 0.122112,
      "grad_norm": 0.11062921014169383,
      "learning_rate": 9.959175389500971e-05,
      "loss": 0.0325,
      "step": 38160
    },
    {
      "epoch": 0.122176,
      "grad_norm": 0.1320685806951766,
      "learning_rate": 9.959132643599536e-05,
      "loss": 0.0314,
      "step": 38180
    },
    {
      "epoch": 0.12224,
      "grad_norm": 0.14569165704338244,
      "learning_rate": 9.959089875422835e-05,
      "loss": 0.0323,
      "step": 38200
    },
    {
      "epoch": 0.122304,
      "grad_norm": 0.06420857359762702,
      "learning_rate": 9.959047084971058e-05,
      "loss": 0.0314,
      "step": 38220
    },
    {
      "epoch": 0.122368,
      "grad_norm": 0.13504041633184086,
      "learning_rate": 9.9590042722444e-05,
      "loss": 0.03,
      "step": 38240
    },
    {
      "epoch": 0.122432,
      "grad_norm": 0.15690759686030945,
      "learning_rate": 9.958961437243053e-05,
      "loss": 0.0337,
      "step": 38260
    },
    {
      "epoch": 0.122496,
      "grad_norm": 0.0866867000474349,
      "learning_rate": 9.958918579967209e-05,
      "loss": 0.0315,
      "step": 38280
    },
    {
      "epoch": 0.12256,
      "grad_norm": 0.10080800024064544,
      "learning_rate": 9.958875700417058e-05,
      "loss": 0.0333,
      "step": 38300
    },
    {
      "epoch": 0.122624,
      "grad_norm": 0.07058440310887037,
      "learning_rate": 9.958832798592794e-05,
      "loss": 0.0358,
      "step": 38320
    },
    {
      "epoch": 0.122688,
      "grad_norm": 0.0872821702594187,
      "learning_rate": 9.958789874494613e-05,
      "loss": 0.0305,
      "step": 38340
    },
    {
      "epoch": 0.122752,
      "grad_norm": 0.07691606593550346,
      "learning_rate": 9.958746928122704e-05,
      "loss": 0.034,
      "step": 38360
    },
    {
      "epoch": 0.122816,
      "grad_norm": 0.06526085192180134,
      "learning_rate": 9.95870395947726e-05,
      "loss": 0.0338,
      "step": 38380
    },
    {
      "epoch": 0.12288,
      "grad_norm": 0.07692751393944329,
      "learning_rate": 9.958660968558477e-05,
      "loss": 0.031,
      "step": 38400
    },
    {
      "epoch": 0.122944,
      "grad_norm": 0.07056905252964311,
      "learning_rate": 9.958617955366545e-05,
      "loss": 0.0332,
      "step": 38420
    },
    {
      "epoch": 0.123008,
      "grad_norm": 0.08106161963777715,
      "learning_rate": 9.958574919901658e-05,
      "loss": 0.0301,
      "step": 38440
    },
    {
      "epoch": 0.123072,
      "grad_norm": 0.10813464569357546,
      "learning_rate": 9.958531862164012e-05,
      "loss": 0.031,
      "step": 38460
    },
    {
      "epoch": 0.123136,
      "grad_norm": 0.09981836188862685,
      "learning_rate": 9.958488782153794e-05,
      "loss": 0.0313,
      "step": 38480
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.06453276326648512,
      "learning_rate": 9.958445679871204e-05,
      "loss": 0.0322,
      "step": 38500
    },
    {
      "epoch": 0.123264,
      "grad_norm": 0.1263919886806742,
      "learning_rate": 9.958402555316434e-05,
      "loss": 0.0277,
      "step": 38520
    },
    {
      "epoch": 0.123328,
      "grad_norm": 0.13657751013926692,
      "learning_rate": 9.958359408489675e-05,
      "loss": 0.0305,
      "step": 38540
    },
    {
      "epoch": 0.123392,
      "grad_norm": 0.07438643098926981,
      "learning_rate": 9.958316239391125e-05,
      "loss": 0.0293,
      "step": 38560
    },
    {
      "epoch": 0.123456,
      "grad_norm": 0.06962060373831257,
      "learning_rate": 9.958273048020974e-05,
      "loss": 0.027,
      "step": 38580
    },
    {
      "epoch": 0.12352,
      "grad_norm": 0.12479607813053446,
      "learning_rate": 9.958229834379418e-05,
      "loss": 0.0323,
      "step": 38600
    },
    {
      "epoch": 0.123584,
      "grad_norm": 0.08314557303219845,
      "learning_rate": 9.95818659846665e-05,
      "loss": 0.0328,
      "step": 38620
    },
    {
      "epoch": 0.123648,
      "grad_norm": 0.1578443272812555,
      "learning_rate": 9.958143340282866e-05,
      "loss": 0.0368,
      "step": 38640
    },
    {
      "epoch": 0.123712,
      "grad_norm": 0.08696029487331432,
      "learning_rate": 9.95810005982826e-05,
      "loss": 0.0305,
      "step": 38660
    },
    {
      "epoch": 0.123776,
      "grad_norm": 0.1479389415135321,
      "learning_rate": 9.958056757103022e-05,
      "loss": 0.0331,
      "step": 38680
    },
    {
      "epoch": 0.12384,
      "grad_norm": 0.08486353588233876,
      "learning_rate": 9.958013432107354e-05,
      "loss": 0.0361,
      "step": 38700
    },
    {
      "epoch": 0.123904,
      "grad_norm": 0.09787845679421414,
      "learning_rate": 9.957970084841445e-05,
      "loss": 0.0303,
      "step": 38720
    },
    {
      "epoch": 0.123968,
      "grad_norm": 0.07705037361936531,
      "learning_rate": 9.957926715305492e-05,
      "loss": 0.0324,
      "step": 38740
    },
    {
      "epoch": 0.124032,
      "grad_norm": 0.08841673125882069,
      "learning_rate": 9.957883323499688e-05,
      "loss": 0.0321,
      "step": 38760
    },
    {
      "epoch": 0.124096,
      "grad_norm": 0.13983398233631755,
      "learning_rate": 9.957839909424231e-05,
      "loss": 0.0297,
      "step": 38780
    },
    {
      "epoch": 0.12416,
      "grad_norm": 0.10339239535259723,
      "learning_rate": 9.957796473079312e-05,
      "loss": 0.0293,
      "step": 38800
    },
    {
      "epoch": 0.124224,
      "grad_norm": 0.0573774100847272,
      "learning_rate": 9.95775301446513e-05,
      "loss": 0.0341,
      "step": 38820
    },
    {
      "epoch": 0.124288,
      "grad_norm": 0.10976689924127478,
      "learning_rate": 9.957709533581879e-05,
      "loss": 0.0294,
      "step": 38840
    },
    {
      "epoch": 0.124352,
      "grad_norm": 0.09205294342991327,
      "learning_rate": 9.957666030429754e-05,
      "loss": 0.0324,
      "step": 38860
    },
    {
      "epoch": 0.124416,
      "grad_norm": 0.0951765953928565,
      "learning_rate": 9.957622505008948e-05,
      "loss": 0.0347,
      "step": 38880
    },
    {
      "epoch": 0.12448,
      "grad_norm": 0.13906652155605545,
      "learning_rate": 9.95757895731966e-05,
      "loss": 0.0319,
      "step": 38900
    },
    {
      "epoch": 0.124544,
      "grad_norm": 0.10560021604480169,
      "learning_rate": 9.957535387362083e-05,
      "loss": 0.0305,
      "step": 38920
    },
    {
      "epoch": 0.124608,
      "grad_norm": 0.16123240415331652,
      "learning_rate": 9.957491795136415e-05,
      "loss": 0.0338,
      "step": 38940
    },
    {
      "epoch": 0.124672,
      "grad_norm": 0.22815574383559675,
      "learning_rate": 9.957448180642853e-05,
      "loss": 0.033,
      "step": 38960
    },
    {
      "epoch": 0.124736,
      "grad_norm": 0.11937765593408194,
      "learning_rate": 9.957404543881588e-05,
      "loss": 0.0342,
      "step": 38980
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.13034239211092538,
      "learning_rate": 9.957360884852817e-05,
      "loss": 0.0339,
      "step": 39000
    },
    {
      "epoch": 0.124864,
      "grad_norm": 0.09409582360001219,
      "learning_rate": 9.957317203556742e-05,
      "loss": 0.0309,
      "step": 39020
    },
    {
      "epoch": 0.124928,
      "grad_norm": 0.11407115901027594,
      "learning_rate": 9.957273499993554e-05,
      "loss": 0.0325,
      "step": 39040
    },
    {
      "epoch": 0.124992,
      "grad_norm": 0.09297186598463913,
      "learning_rate": 9.957229774163448e-05,
      "loss": 0.0352,
      "step": 39060
    },
    {
      "epoch": 0.125056,
      "grad_norm": 0.07681236665967694,
      "learning_rate": 9.957186026066625e-05,
      "loss": 0.032,
      "step": 39080
    },
    {
      "epoch": 0.12512,
      "grad_norm": 0.07652828196392733,
      "learning_rate": 9.957142255703278e-05,
      "loss": 0.0324,
      "step": 39100
    },
    {
      "epoch": 0.125184,
      "grad_norm": 0.10642717663941928,
      "learning_rate": 9.957098463073606e-05,
      "loss": 0.0321,
      "step": 39120
    },
    {
      "epoch": 0.125248,
      "grad_norm": 0.09795610309229415,
      "learning_rate": 9.957054648177804e-05,
      "loss": 0.0339,
      "step": 39140
    },
    {
      "epoch": 0.125312,
      "grad_norm": 0.09449407885671815,
      "learning_rate": 9.95701081101607e-05,
      "loss": 0.0313,
      "step": 39160
    },
    {
      "epoch": 0.125376,
      "grad_norm": 0.05662477000546974,
      "learning_rate": 9.956966951588599e-05,
      "loss": 0.0316,
      "step": 39180
    },
    {
      "epoch": 0.12544,
      "grad_norm": 0.1073213635236539,
      "learning_rate": 9.956923069895589e-05,
      "loss": 0.0313,
      "step": 39200
    },
    {
      "epoch": 0.125504,
      "grad_norm": 0.15738653049903847,
      "learning_rate": 9.956879165937238e-05,
      "loss": 0.032,
      "step": 39220
    },
    {
      "epoch": 0.125568,
      "grad_norm": 0.10696302004775364,
      "learning_rate": 9.956835239713744e-05,
      "loss": 0.0352,
      "step": 39240
    },
    {
      "epoch": 0.125632,
      "grad_norm": 0.20304967423644743,
      "learning_rate": 9.956791291225303e-05,
      "loss": 0.0356,
      "step": 39260
    },
    {
      "epoch": 0.125696,
      "grad_norm": 0.1210661986368306,
      "learning_rate": 9.956747320472111e-05,
      "loss": 0.0318,
      "step": 39280
    },
    {
      "epoch": 0.12576,
      "grad_norm": 0.14886504929292205,
      "learning_rate": 9.956703327454366e-05,
      "loss": 0.0346,
      "step": 39300
    },
    {
      "epoch": 0.125824,
      "grad_norm": 0.08389351362792408,
      "learning_rate": 9.956659312172268e-05,
      "loss": 0.0321,
      "step": 39320
    },
    {
      "epoch": 0.125888,
      "grad_norm": 0.11878246431183871,
      "learning_rate": 9.956615274626013e-05,
      "loss": 0.0347,
      "step": 39340
    },
    {
      "epoch": 0.125952,
      "grad_norm": 0.07202256898378927,
      "learning_rate": 9.956571214815798e-05,
      "loss": 0.0282,
      "step": 39360
    },
    {
      "epoch": 0.126016,
      "grad_norm": 0.07720423852241791,
      "learning_rate": 9.956527132741822e-05,
      "loss": 0.0329,
      "step": 39380
    },
    {
      "epoch": 0.12608,
      "grad_norm": 0.14900831389737892,
      "learning_rate": 9.956483028404284e-05,
      "loss": 0.0314,
      "step": 39400
    },
    {
      "epoch": 0.126144,
      "grad_norm": 0.20536609035846695,
      "learning_rate": 9.95643890180338e-05,
      "loss": 0.0355,
      "step": 39420
    },
    {
      "epoch": 0.126208,
      "grad_norm": 0.0813143555221332,
      "learning_rate": 9.95639475293931e-05,
      "loss": 0.0309,
      "step": 39440
    },
    {
      "epoch": 0.126272,
      "grad_norm": 0.0764856648150978,
      "learning_rate": 9.95635058181227e-05,
      "loss": 0.0322,
      "step": 39460
    },
    {
      "epoch": 0.126336,
      "grad_norm": 0.07504408267757684,
      "learning_rate": 9.95630638842246e-05,
      "loss": 0.0317,
      "step": 39480
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.11457636337697667,
      "learning_rate": 9.956262172770081e-05,
      "loss": 0.0334,
      "step": 39500
    },
    {
      "epoch": 0.126464,
      "grad_norm": 0.08060679317289925,
      "learning_rate": 9.956217934855327e-05,
      "loss": 0.0326,
      "step": 39520
    },
    {
      "epoch": 0.126528,
      "grad_norm": 0.09030527663192844,
      "learning_rate": 9.956173674678399e-05,
      "loss": 0.0324,
      "step": 39540
    },
    {
      "epoch": 0.126592,
      "grad_norm": 0.10674975014923327,
      "learning_rate": 9.956129392239494e-05,
      "loss": 0.0322,
      "step": 39560
    },
    {
      "epoch": 0.126656,
      "grad_norm": 0.10411163035870083,
      "learning_rate": 9.956085087538815e-05,
      "loss": 0.0338,
      "step": 39580
    },
    {
      "epoch": 0.12672,
      "grad_norm": 0.09587562018185987,
      "learning_rate": 9.956040760576558e-05,
      "loss": 0.0365,
      "step": 39600
    },
    {
      "epoch": 0.126784,
      "grad_norm": 0.09678445233154945,
      "learning_rate": 9.95599641135292e-05,
      "loss": 0.0352,
      "step": 39620
    },
    {
      "epoch": 0.126848,
      "grad_norm": 0.06941188138290474,
      "learning_rate": 9.955952039868104e-05,
      "loss": 0.0355,
      "step": 39640
    },
    {
      "epoch": 0.126912,
      "grad_norm": 0.08906280805652561,
      "learning_rate": 9.95590764612231e-05,
      "loss": 0.0329,
      "step": 39660
    },
    {
      "epoch": 0.126976,
      "grad_norm": 0.12063572600007588,
      "learning_rate": 9.955863230115734e-05,
      "loss": 0.0296,
      "step": 39680
    },
    {
      "epoch": 0.12704,
      "grad_norm": 0.09593095220152408,
      "learning_rate": 9.955818791848577e-05,
      "loss": 0.0311,
      "step": 39700
    },
    {
      "epoch": 0.127104,
      "grad_norm": 0.06888410724636199,
      "learning_rate": 9.955774331321038e-05,
      "loss": 0.0352,
      "step": 39720
    },
    {
      "epoch": 0.127168,
      "grad_norm": 0.08267891878669127,
      "learning_rate": 9.955729848533317e-05,
      "loss": 0.0328,
      "step": 39740
    },
    {
      "epoch": 0.127232,
      "grad_norm": 0.05268751042868993,
      "learning_rate": 9.955685343485614e-05,
      "loss": 0.0304,
      "step": 39760
    },
    {
      "epoch": 0.127296,
      "grad_norm": 0.07457312714482409,
      "learning_rate": 9.955640816178132e-05,
      "loss": 0.0275,
      "step": 39780
    },
    {
      "epoch": 0.12736,
      "grad_norm": 0.09277668520421922,
      "learning_rate": 9.955596266611065e-05,
      "loss": 0.0308,
      "step": 39800
    },
    {
      "epoch": 0.127424,
      "grad_norm": 0.10209390127341922,
      "learning_rate": 9.955551694784617e-05,
      "loss": 0.0316,
      "step": 39820
    },
    {
      "epoch": 0.127488,
      "grad_norm": 0.08738138992487515,
      "learning_rate": 9.955507100698987e-05,
      "loss": 0.0337,
      "step": 39840
    },
    {
      "epoch": 0.127552,
      "grad_norm": 0.09458218213787102,
      "learning_rate": 9.955462484354376e-05,
      "loss": 0.0322,
      "step": 39860
    },
    {
      "epoch": 0.127616,
      "grad_norm": 0.10943637967201195,
      "learning_rate": 9.955417845750983e-05,
      "loss": 0.0323,
      "step": 39880
    },
    {
      "epoch": 0.12768,
      "grad_norm": 0.08951642128603933,
      "learning_rate": 9.95537318488901e-05,
      "loss": 0.0313,
      "step": 39900
    },
    {
      "epoch": 0.127744,
      "grad_norm": 0.09017747289827038,
      "learning_rate": 9.955328501768658e-05,
      "loss": 0.034,
      "step": 39920
    },
    {
      "epoch": 0.127808,
      "grad_norm": 0.0791438670043615,
      "learning_rate": 9.955283796390127e-05,
      "loss": 0.0308,
      "step": 39940
    },
    {
      "epoch": 0.127872,
      "grad_norm": 0.10182932469577603,
      "learning_rate": 9.955239068753615e-05,
      "loss": 0.0357,
      "step": 39960
    },
    {
      "epoch": 0.127936,
      "grad_norm": 0.10794714253061603,
      "learning_rate": 9.955194318859329e-05,
      "loss": 0.0334,
      "step": 39980
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.07775143816921318,
      "learning_rate": 9.955149546707465e-05,
      "loss": 0.0313,
      "step": 40000
    },
    {
      "epoch": 0.128064,
      "grad_norm": 0.12111415947423365,
      "learning_rate": 9.955104752298225e-05,
      "loss": 0.0326,
      "step": 40020
    },
    {
      "epoch": 0.128128,
      "grad_norm": 0.08521910863822091,
      "learning_rate": 9.955059935631812e-05,
      "loss": 0.0321,
      "step": 40040
    },
    {
      "epoch": 0.128192,
      "grad_norm": 0.22515017294982573,
      "learning_rate": 9.955015096708425e-05,
      "loss": 0.0333,
      "step": 40060
    },
    {
      "epoch": 0.128256,
      "grad_norm": 0.08638574572649986,
      "learning_rate": 9.954970235528268e-05,
      "loss": 0.0323,
      "step": 40080
    },
    {
      "epoch": 0.12832,
      "grad_norm": 0.08067480597548514,
      "learning_rate": 9.95492535209154e-05,
      "loss": 0.0338,
      "step": 40100
    },
    {
      "epoch": 0.128384,
      "grad_norm": 0.13912843348875104,
      "learning_rate": 9.954880446398443e-05,
      "loss": 0.0337,
      "step": 40120
    },
    {
      "epoch": 0.128448,
      "grad_norm": 0.19839692418848523,
      "learning_rate": 9.95483551844918e-05,
      "loss": 0.0311,
      "step": 40140
    },
    {
      "epoch": 0.128512,
      "grad_norm": 0.09460287034690226,
      "learning_rate": 9.954790568243953e-05,
      "loss": 0.0335,
      "step": 40160
    },
    {
      "epoch": 0.128576,
      "grad_norm": 0.08422258199923877,
      "learning_rate": 9.954745595782963e-05,
      "loss": 0.0346,
      "step": 40180
    },
    {
      "epoch": 0.12864,
      "grad_norm": 0.08237558677822139,
      "learning_rate": 9.954700601066411e-05,
      "loss": 0.0313,
      "step": 40200
    },
    {
      "epoch": 0.128704,
      "grad_norm": 0.11919659778323012,
      "learning_rate": 9.9546555840945e-05,
      "loss": 0.0299,
      "step": 40220
    },
    {
      "epoch": 0.128768,
      "grad_norm": 0.115897405389557,
      "learning_rate": 9.954610544867435e-05,
      "loss": 0.0319,
      "step": 40240
    },
    {
      "epoch": 0.128832,
      "grad_norm": 0.12702723257618226,
      "learning_rate": 9.954565483385414e-05,
      "loss": 0.0331,
      "step": 40260
    },
    {
      "epoch": 0.128896,
      "grad_norm": 0.07355593359197983,
      "learning_rate": 9.954520399648641e-05,
      "loss": 0.0333,
      "step": 40280
    },
    {
      "epoch": 0.12896,
      "grad_norm": 0.08201746668289486,
      "learning_rate": 9.954475293657319e-05,
      "loss": 0.0303,
      "step": 40300
    },
    {
      "epoch": 0.129024,
      "grad_norm": 0.09889558838267845,
      "learning_rate": 9.95443016541165e-05,
      "loss": 0.029,
      "step": 40320
    },
    {
      "epoch": 0.129088,
      "grad_norm": 0.10763538244875848,
      "learning_rate": 9.954385014911837e-05,
      "loss": 0.0293,
      "step": 40340
    },
    {
      "epoch": 0.129152,
      "grad_norm": 0.11300801484558425,
      "learning_rate": 9.954339842158082e-05,
      "loss": 0.035,
      "step": 40360
    },
    {
      "epoch": 0.129216,
      "grad_norm": 0.07770659894096697,
      "learning_rate": 9.954294647150591e-05,
      "loss": 0.0312,
      "step": 40380
    },
    {
      "epoch": 0.12928,
      "grad_norm": 0.11459264621942214,
      "learning_rate": 9.954249429889561e-05,
      "loss": 0.0297,
      "step": 40400
    },
    {
      "epoch": 0.129344,
      "grad_norm": 0.06555968557994865,
      "learning_rate": 9.954204190375202e-05,
      "loss": 0.027,
      "step": 40420
    },
    {
      "epoch": 0.129408,
      "grad_norm": 0.13224845796507306,
      "learning_rate": 9.954158928607713e-05,
      "loss": 0.0298,
      "step": 40440
    },
    {
      "epoch": 0.129472,
      "grad_norm": 0.08742638659981623,
      "learning_rate": 9.954113644587298e-05,
      "loss": 0.0323,
      "step": 40460
    },
    {
      "epoch": 0.129536,
      "grad_norm": 0.12258153162505332,
      "learning_rate": 9.954068338314159e-05,
      "loss": 0.0342,
      "step": 40480
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.08355400628367804,
      "learning_rate": 9.954023009788504e-05,
      "loss": 0.0297,
      "step": 40500
    },
    {
      "epoch": 0.129664,
      "grad_norm": 0.09128510119969128,
      "learning_rate": 9.953977659010534e-05,
      "loss": 0.0337,
      "step": 40520
    },
    {
      "epoch": 0.129728,
      "grad_norm": 0.0651543225995682,
      "learning_rate": 9.953932285980451e-05,
      "loss": 0.0331,
      "step": 40540
    },
    {
      "epoch": 0.129792,
      "grad_norm": 0.07929497868530182,
      "learning_rate": 9.953886890698461e-05,
      "loss": 0.0338,
      "step": 40560
    },
    {
      "epoch": 0.129856,
      "grad_norm": 0.111920551861392,
      "learning_rate": 9.953841473164766e-05,
      "loss": 0.0341,
      "step": 40580
    },
    {
      "epoch": 0.12992,
      "grad_norm": 0.09707478583199529,
      "learning_rate": 9.953796033379573e-05,
      "loss": 0.0331,
      "step": 40600
    },
    {
      "epoch": 0.129984,
      "grad_norm": 0.14714173343393702,
      "learning_rate": 9.953750571343081e-05,
      "loss": 0.0308,
      "step": 40620
    },
    {
      "epoch": 0.130048,
      "grad_norm": 0.0727203321767133,
      "learning_rate": 9.953705087055501e-05,
      "loss": 0.0311,
      "step": 40640
    },
    {
      "epoch": 0.130112,
      "grad_norm": 0.10667970624858604,
      "learning_rate": 9.953659580517031e-05,
      "loss": 0.0318,
      "step": 40660
    },
    {
      "epoch": 0.130176,
      "grad_norm": 0.20298499051017452,
      "learning_rate": 9.953614051727882e-05,
      "loss": 0.0373,
      "step": 40680
    },
    {
      "epoch": 0.13024,
      "grad_norm": 0.07999839292014595,
      "learning_rate": 9.953568500688252e-05,
      "loss": 0.0355,
      "step": 40700
    },
    {
      "epoch": 0.130304,
      "grad_norm": 0.14012249431879975,
      "learning_rate": 9.95352292739835e-05,
      "loss": 0.0317,
      "step": 40720
    },
    {
      "epoch": 0.130368,
      "grad_norm": 0.06263024342071373,
      "learning_rate": 9.953477331858377e-05,
      "loss": 0.0332,
      "step": 40740
    },
    {
      "epoch": 0.130432,
      "grad_norm": 0.10297498151540073,
      "learning_rate": 9.95343171406854e-05,
      "loss": 0.0306,
      "step": 40760
    },
    {
      "epoch": 0.130496,
      "grad_norm": 0.07485890939866761,
      "learning_rate": 9.953386074029045e-05,
      "loss": 0.0274,
      "step": 40780
    },
    {
      "epoch": 0.13056,
      "grad_norm": 0.07429640946719845,
      "learning_rate": 9.953340411740096e-05,
      "loss": 0.0275,
      "step": 40800
    },
    {
      "epoch": 0.130624,
      "grad_norm": 0.23583852939739408,
      "learning_rate": 9.953294727201896e-05,
      "loss": 0.0333,
      "step": 40820
    },
    {
      "epoch": 0.130688,
      "grad_norm": 0.08508782641201994,
      "learning_rate": 9.953249020414654e-05,
      "loss": 0.033,
      "step": 40840
    },
    {
      "epoch": 0.130752,
      "grad_norm": 0.17440456206079435,
      "learning_rate": 9.953203291378572e-05,
      "loss": 0.0336,
      "step": 40860
    },
    {
      "epoch": 0.130816,
      "grad_norm": 0.06961395672795713,
      "learning_rate": 9.953157540093859e-05,
      "loss": 0.0334,
      "step": 40880
    },
    {
      "epoch": 0.13088,
      "grad_norm": 0.05950703055074971,
      "learning_rate": 9.953111766560716e-05,
      "loss": 0.0335,
      "step": 40900
    },
    {
      "epoch": 0.130944,
      "grad_norm": 0.18999023219790784,
      "learning_rate": 9.953065970779351e-05,
      "loss": 0.0322,
      "step": 40920
    },
    {
      "epoch": 0.131008,
      "grad_norm": 0.06639355533746925,
      "learning_rate": 9.95302015274997e-05,
      "loss": 0.0291,
      "step": 40940
    },
    {
      "epoch": 0.131072,
      "grad_norm": 0.08358978434273276,
      "learning_rate": 9.95297431247278e-05,
      "loss": 0.032,
      "step": 40960
    },
    {
      "epoch": 0.131136,
      "grad_norm": 0.07943379235271977,
      "learning_rate": 9.952928449947983e-05,
      "loss": 0.0334,
      "step": 40980
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.06806733497470308,
      "learning_rate": 9.952882565175789e-05,
      "loss": 0.0322,
      "step": 41000
    },
    {
      "epoch": 0.131264,
      "grad_norm": 0.0648665308452779,
      "learning_rate": 9.952836658156401e-05,
      "loss": 0.0324,
      "step": 41020
    },
    {
      "epoch": 0.131328,
      "grad_norm": 0.07002203223405568,
      "learning_rate": 9.952790728890027e-05,
      "loss": 0.029,
      "step": 41040
    },
    {
      "epoch": 0.131392,
      "grad_norm": 0.0748918539643221,
      "learning_rate": 9.952744777376873e-05,
      "loss": 0.032,
      "step": 41060
    },
    {
      "epoch": 0.131456,
      "grad_norm": 0.09238244641923951,
      "learning_rate": 9.952698803617147e-05,
      "loss": 0.0323,
      "step": 41080
    },
    {
      "epoch": 0.13152,
      "grad_norm": 0.062078471827953834,
      "learning_rate": 9.952652807611052e-05,
      "loss": 0.0312,
      "step": 41100
    },
    {
      "epoch": 0.131584,
      "grad_norm": 0.08770868833681225,
      "learning_rate": 9.952606789358796e-05,
      "loss": 0.0304,
      "step": 41120
    },
    {
      "epoch": 0.131648,
      "grad_norm": 0.10807909703136269,
      "learning_rate": 9.952560748860587e-05,
      "loss": 0.031,
      "step": 41140
    },
    {
      "epoch": 0.131712,
      "grad_norm": 0.06724600260043818,
      "learning_rate": 9.95251468611663e-05,
      "loss": 0.0326,
      "step": 41160
    },
    {
      "epoch": 0.131776,
      "grad_norm": 0.08158097290400615,
      "learning_rate": 9.952468601127134e-05,
      "loss": 0.0322,
      "step": 41180
    },
    {
      "epoch": 0.13184,
      "grad_norm": 0.07752336067211266,
      "learning_rate": 9.952422493892304e-05,
      "loss": 0.0324,
      "step": 41200
    },
    {
      "epoch": 0.131904,
      "grad_norm": 0.11111410488218725,
      "learning_rate": 9.952376364412348e-05,
      "loss": 0.0326,
      "step": 41220
    },
    {
      "epoch": 0.131968,
      "grad_norm": 0.07944285509125448,
      "learning_rate": 9.952330212687472e-05,
      "loss": 0.0308,
      "step": 41240
    },
    {
      "epoch": 0.132032,
      "grad_norm": 0.08070038973666847,
      "learning_rate": 9.952284038717887e-05,
      "loss": 0.0303,
      "step": 41260
    },
    {
      "epoch": 0.132096,
      "grad_norm": 0.131691533058166,
      "learning_rate": 9.952237842503798e-05,
      "loss": 0.0331,
      "step": 41280
    },
    {
      "epoch": 0.13216,
      "grad_norm": 0.22978648246081593,
      "learning_rate": 9.952191624045411e-05,
      "loss": 0.032,
      "step": 41300
    },
    {
      "epoch": 0.132224,
      "grad_norm": 0.0861904800274661,
      "learning_rate": 9.952145383342934e-05,
      "loss": 0.032,
      "step": 41320
    },
    {
      "epoch": 0.132288,
      "grad_norm": 0.07280841264117215,
      "learning_rate": 9.952099120396576e-05,
      "loss": 0.0322,
      "step": 41340
    },
    {
      "epoch": 0.132352,
      "grad_norm": 0.07048205299628756,
      "learning_rate": 9.952052835206546e-05,
      "loss": 0.0294,
      "step": 41360
    },
    {
      "epoch": 0.132416,
      "grad_norm": 0.0997919809083768,
      "learning_rate": 9.95200652777305e-05,
      "loss": 0.0334,
      "step": 41380
    },
    {
      "epoch": 0.13248,
      "grad_norm": 0.07144235842499633,
      "learning_rate": 9.951960198096296e-05,
      "loss": 0.0313,
      "step": 41400
    },
    {
      "epoch": 0.132544,
      "grad_norm": 0.08824468736820908,
      "learning_rate": 9.951913846176492e-05,
      "loss": 0.0342,
      "step": 41420
    },
    {
      "epoch": 0.132608,
      "grad_norm": 0.060014634858746425,
      "learning_rate": 9.951867472013848e-05,
      "loss": 0.0321,
      "step": 41440
    },
    {
      "epoch": 0.132672,
      "grad_norm": 0.12746693409814322,
      "learning_rate": 9.95182107560857e-05,
      "loss": 0.0303,
      "step": 41460
    },
    {
      "epoch": 0.132736,
      "grad_norm": 0.1538932321892048,
      "learning_rate": 9.951774656960865e-05,
      "loss": 0.0298,
      "step": 41480
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.12397825274647074,
      "learning_rate": 9.951728216070949e-05,
      "loss": 0.0329,
      "step": 41500
    },
    {
      "epoch": 0.132864,
      "grad_norm": 0.06783913794611994,
      "learning_rate": 9.951681752939021e-05,
      "loss": 0.035,
      "step": 41520
    },
    {
      "epoch": 0.132928,
      "grad_norm": 0.0702825387893834,
      "learning_rate": 9.951635267565295e-05,
      "loss": 0.029,
      "step": 41540
    },
    {
      "epoch": 0.132992,
      "grad_norm": 0.07343306539410793,
      "learning_rate": 9.95158875994998e-05,
      "loss": 0.0308,
      "step": 41560
    },
    {
      "epoch": 0.133056,
      "grad_norm": 0.07584369111465726,
      "learning_rate": 9.951542230093284e-05,
      "loss": 0.032,
      "step": 41580
    },
    {
      "epoch": 0.13312,
      "grad_norm": 0.08880768066946325,
      "learning_rate": 9.951495677995414e-05,
      "loss": 0.0314,
      "step": 41600
    },
    {
      "epoch": 0.133184,
      "grad_norm": 0.16975034326910918,
      "learning_rate": 9.951449103656584e-05,
      "loss": 0.0346,
      "step": 41620
    },
    {
      "epoch": 0.133248,
      "grad_norm": 0.0577467205446295,
      "learning_rate": 9.951402507076999e-05,
      "loss": 0.0317,
      "step": 41640
    },
    {
      "epoch": 0.133312,
      "grad_norm": 0.07589329179612517,
      "learning_rate": 9.951355888256869e-05,
      "loss": 0.0296,
      "step": 41660
    },
    {
      "epoch": 0.133376,
      "grad_norm": 0.06336742000894736,
      "learning_rate": 9.951309247196404e-05,
      "loss": 0.0281,
      "step": 41680
    },
    {
      "epoch": 0.13344,
      "grad_norm": 0.09963940332126157,
      "learning_rate": 9.951262583895812e-05,
      "loss": 0.033,
      "step": 41700
    },
    {
      "epoch": 0.133504,
      "grad_norm": 0.06087502563937401,
      "learning_rate": 9.951215898355307e-05,
      "loss": 0.0314,
      "step": 41720
    },
    {
      "epoch": 0.133568,
      "grad_norm": 0.09783276673902244,
      "learning_rate": 9.951169190575093e-05,
      "loss": 0.0288,
      "step": 41740
    },
    {
      "epoch": 0.133632,
      "grad_norm": 0.05466824878409184,
      "learning_rate": 9.951122460555384e-05,
      "loss": 0.0318,
      "step": 41760
    },
    {
      "epoch": 0.133696,
      "grad_norm": 0.10075859099411093,
      "learning_rate": 9.95107570829639e-05,
      "loss": 0.0316,
      "step": 41780
    },
    {
      "epoch": 0.13376,
      "grad_norm": 0.09833902692780028,
      "learning_rate": 9.951028933798317e-05,
      "loss": 0.0333,
      "step": 41800
    },
    {
      "epoch": 0.133824,
      "grad_norm": 0.22321415562834282,
      "learning_rate": 9.950982137061376e-05,
      "loss": 0.0339,
      "step": 41820
    },
    {
      "epoch": 0.133888,
      "grad_norm": 0.16990104992311894,
      "learning_rate": 9.950935318085781e-05,
      "loss": 0.0309,
      "step": 41840
    },
    {
      "epoch": 0.133952,
      "grad_norm": 0.07855564849265495,
      "learning_rate": 9.950888476871741e-05,
      "loss": 0.0312,
      "step": 41860
    },
    {
      "epoch": 0.134016,
      "grad_norm": 0.07613221369596639,
      "learning_rate": 9.950841613419463e-05,
      "loss": 0.0296,
      "step": 41880
    },
    {
      "epoch": 0.13408,
      "grad_norm": 0.07471296071565553,
      "learning_rate": 9.95079472772916e-05,
      "loss": 0.034,
      "step": 41900
    },
    {
      "epoch": 0.134144,
      "grad_norm": 0.1902086616829644,
      "learning_rate": 9.950747819801043e-05,
      "loss": 0.0325,
      "step": 41920
    },
    {
      "epoch": 0.134208,
      "grad_norm": 0.08673947918868105,
      "learning_rate": 9.950700889635323e-05,
      "loss": 0.032,
      "step": 41940
    },
    {
      "epoch": 0.134272,
      "grad_norm": 0.0768414924928411,
      "learning_rate": 9.95065393723221e-05,
      "loss": 0.0282,
      "step": 41960
    },
    {
      "epoch": 0.134336,
      "grad_norm": 0.12722566753794942,
      "learning_rate": 9.950606962591913e-05,
      "loss": 0.0308,
      "step": 41980
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.07969353225275928,
      "learning_rate": 9.950559965714648e-05,
      "loss": 0.033,
      "step": 42000
    },
    {
      "epoch": 0.134464,
      "grad_norm": 0.06512861153706287,
      "learning_rate": 9.950512946600621e-05,
      "loss": 0.0318,
      "step": 42020
    },
    {
      "epoch": 0.134528,
      "grad_norm": 0.08651996289082056,
      "learning_rate": 9.950465905250044e-05,
      "loss": 0.0316,
      "step": 42040
    },
    {
      "epoch": 0.134592,
      "grad_norm": 0.06852091455826752,
      "learning_rate": 9.950418841663131e-05,
      "loss": 0.0315,
      "step": 42060
    },
    {
      "epoch": 0.134656,
      "grad_norm": 0.07486769850043155,
      "learning_rate": 9.950371755840091e-05,
      "loss": 0.0326,
      "step": 42080
    },
    {
      "epoch": 0.13472,
      "grad_norm": 0.10014412546859712,
      "learning_rate": 9.950324647781137e-05,
      "loss": 0.0268,
      "step": 42100
    },
    {
      "epoch": 0.134784,
      "grad_norm": 0.07264300109446775,
      "learning_rate": 9.950277517486482e-05,
      "loss": 0.0302,
      "step": 42120
    },
    {
      "epoch": 0.134848,
      "grad_norm": 0.0937866211448371,
      "learning_rate": 9.950230364956332e-05,
      "loss": 0.0349,
      "step": 42140
    },
    {
      "epoch": 0.134912,
      "grad_norm": 0.13432973486935076,
      "learning_rate": 9.950183190190905e-05,
      "loss": 0.0311,
      "step": 42160
    },
    {
      "epoch": 0.134976,
      "grad_norm": 0.08107620678853775,
      "learning_rate": 9.950135993190409e-05,
      "loss": 0.0327,
      "step": 42180
    },
    {
      "epoch": 0.13504,
      "grad_norm": 0.06787385751745507,
      "learning_rate": 9.950088773955058e-05,
      "loss": 0.0295,
      "step": 42200
    },
    {
      "epoch": 0.135104,
      "grad_norm": 0.12238813827692771,
      "learning_rate": 9.950041532485063e-05,
      "loss": 0.0313,
      "step": 42220
    },
    {
      "epoch": 0.135168,
      "grad_norm": 0.20826547034533952,
      "learning_rate": 9.949994268780639e-05,
      "loss": 0.0315,
      "step": 42240
    },
    {
      "epoch": 0.135232,
      "grad_norm": 0.07914749245068702,
      "learning_rate": 9.949946982841992e-05,
      "loss": 0.0345,
      "step": 42260
    },
    {
      "epoch": 0.135296,
      "grad_norm": 0.1257478787765574,
      "learning_rate": 9.94989967466934e-05,
      "loss": 0.0362,
      "step": 42280
    },
    {
      "epoch": 0.13536,
      "grad_norm": 0.08219629694476246,
      "learning_rate": 9.949852344262895e-05,
      "loss": 0.0355,
      "step": 42300
    },
    {
      "epoch": 0.135424,
      "grad_norm": 0.13584094464604132,
      "learning_rate": 9.949804991622868e-05,
      "loss": 0.0314,
      "step": 42320
    },
    {
      "epoch": 0.135488,
      "grad_norm": 0.22936894439439323,
      "learning_rate": 9.949757616749471e-05,
      "loss": 0.0306,
      "step": 42340
    },
    {
      "epoch": 0.135552,
      "grad_norm": 0.12505019890260918,
      "learning_rate": 9.949710219642918e-05,
      "loss": 0.0305,
      "step": 42360
    },
    {
      "epoch": 0.135616,
      "grad_norm": 0.08010021115828088,
      "learning_rate": 9.949662800303423e-05,
      "loss": 0.0325,
      "step": 42380
    },
    {
      "epoch": 0.13568,
      "grad_norm": 0.07843595402995292,
      "learning_rate": 9.949615358731197e-05,
      "loss": 0.0373,
      "step": 42400
    },
    {
      "epoch": 0.135744,
      "grad_norm": 0.11402927426508497,
      "learning_rate": 9.949567894926455e-05,
      "loss": 0.0363,
      "step": 42420
    },
    {
      "epoch": 0.135808,
      "grad_norm": 0.2322388164179178,
      "learning_rate": 9.949520408889408e-05,
      "loss": 0.0353,
      "step": 42440
    },
    {
      "epoch": 0.135872,
      "grad_norm": 0.12328157280407359,
      "learning_rate": 9.949472900620271e-05,
      "loss": 0.0331,
      "step": 42460
    },
    {
      "epoch": 0.135936,
      "grad_norm": 0.07500274102638292,
      "learning_rate": 9.949425370119256e-05,
      "loss": 0.032,
      "step": 42480
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.09184218304185483,
      "learning_rate": 9.949377817386579e-05,
      "loss": 0.031,
      "step": 42500
    },
    {
      "epoch": 0.136064,
      "grad_norm": 0.12437866726968963,
      "learning_rate": 9.949330242422452e-05,
      "loss": 0.0295,
      "step": 42520
    },
    {
      "epoch": 0.136128,
      "grad_norm": 0.07051187846792681,
      "learning_rate": 9.949282645227087e-05,
      "loss": 0.0315,
      "step": 42540
    },
    {
      "epoch": 0.136192,
      "grad_norm": 0.07817752222580296,
      "learning_rate": 9.9492350258007e-05,
      "loss": 0.0315,
      "step": 42560
    },
    {
      "epoch": 0.136256,
      "grad_norm": 0.0769598069881319,
      "learning_rate": 9.949187384143503e-05,
      "loss": 0.0347,
      "step": 42580
    },
    {
      "epoch": 0.13632,
      "grad_norm": 0.07170667651901967,
      "learning_rate": 9.949139720255714e-05,
      "loss": 0.0329,
      "step": 42600
    },
    {
      "epoch": 0.136384,
      "grad_norm": 0.10794071680158461,
      "learning_rate": 9.949092034137541e-05,
      "loss": 0.0347,
      "step": 42620
    },
    {
      "epoch": 0.136448,
      "grad_norm": 0.07681502070751192,
      "learning_rate": 9.949044325789206e-05,
      "loss": 0.031,
      "step": 42640
    },
    {
      "epoch": 0.136512,
      "grad_norm": 0.09217239304777364,
      "learning_rate": 9.948996595210915e-05,
      "loss": 0.0312,
      "step": 42660
    },
    {
      "epoch": 0.136576,
      "grad_norm": 0.10853603947692773,
      "learning_rate": 9.948948842402888e-05,
      "loss": 0.0313,
      "step": 42680
    },
    {
      "epoch": 0.13664,
      "grad_norm": 0.08103549644473462,
      "learning_rate": 9.948901067365338e-05,
      "loss": 0.0316,
      "step": 42700
    },
    {
      "epoch": 0.136704,
      "grad_norm": 0.12297280074658411,
      "learning_rate": 9.948853270098477e-05,
      "loss": 0.0323,
      "step": 42720
    },
    {
      "epoch": 0.136768,
      "grad_norm": 0.061149836124419606,
      "learning_rate": 9.948805450602526e-05,
      "loss": 0.0303,
      "step": 42740
    },
    {
      "epoch": 0.136832,
      "grad_norm": 0.1085419150241325,
      "learning_rate": 9.948757608877692e-05,
      "loss": 0.031,
      "step": 42760
    },
    {
      "epoch": 0.136896,
      "grad_norm": 0.06263062224352771,
      "learning_rate": 9.948709744924196e-05,
      "loss": 0.0307,
      "step": 42780
    },
    {
      "epoch": 0.13696,
      "grad_norm": 0.10894210343509753,
      "learning_rate": 9.94866185874225e-05,
      "loss": 0.0284,
      "step": 42800
    },
    {
      "epoch": 0.137024,
      "grad_norm": 0.1591199729920336,
      "learning_rate": 9.948613950332071e-05,
      "loss": 0.0345,
      "step": 42820
    },
    {
      "epoch": 0.137088,
      "grad_norm": 0.07291582529499462,
      "learning_rate": 9.948566019693872e-05,
      "loss": 0.0288,
      "step": 42840
    },
    {
      "epoch": 0.137152,
      "grad_norm": 0.14259247956246893,
      "learning_rate": 9.948518066827868e-05,
      "loss": 0.0294,
      "step": 42860
    },
    {
      "epoch": 0.137216,
      "grad_norm": 0.08526659426247758,
      "learning_rate": 9.948470091734277e-05,
      "loss": 0.0312,
      "step": 42880
    },
    {
      "epoch": 0.13728,
      "grad_norm": 0.08398769815070868,
      "learning_rate": 9.948422094413315e-05,
      "loss": 0.0322,
      "step": 42900
    },
    {
      "epoch": 0.137344,
      "grad_norm": 0.1005253738831398,
      "learning_rate": 9.948374074865192e-05,
      "loss": 0.0321,
      "step": 42920
    },
    {
      "epoch": 0.137408,
      "grad_norm": 0.13419342365947656,
      "learning_rate": 9.94832603309013e-05,
      "loss": 0.0324,
      "step": 42940
    },
    {
      "epoch": 0.137472,
      "grad_norm": 0.44754006021674575,
      "learning_rate": 9.948277969088342e-05,
      "loss": 0.0335,
      "step": 42960
    },
    {
      "epoch": 0.137536,
      "grad_norm": 0.07416001988868091,
      "learning_rate": 9.948229882860044e-05,
      "loss": 0.0321,
      "step": 42980
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.09575406426181156,
      "learning_rate": 9.948181774405452e-05,
      "loss": 0.0328,
      "step": 43000
    },
    {
      "epoch": 0.137664,
      "grad_norm": 0.10080818572541332,
      "learning_rate": 9.948133643724782e-05,
      "loss": 0.0317,
      "step": 43020
    },
    {
      "epoch": 0.137728,
      "grad_norm": 0.085039641152275,
      "learning_rate": 9.948085490818251e-05,
      "loss": 0.0322,
      "step": 43040
    },
    {
      "epoch": 0.137792,
      "grad_norm": 0.07537975820334342,
      "learning_rate": 9.948037315686075e-05,
      "loss": 0.0306,
      "step": 43060
    },
    {
      "epoch": 0.137856,
      "grad_norm": 0.08469853162432425,
      "learning_rate": 9.947989118328471e-05,
      "loss": 0.0339,
      "step": 43080
    },
    {
      "epoch": 0.13792,
      "grad_norm": 0.13627252526213693,
      "learning_rate": 9.947940898745652e-05,
      "loss": 0.0287,
      "step": 43100
    },
    {
      "epoch": 0.137984,
      "grad_norm": 0.0935428958130107,
      "learning_rate": 9.947892656937838e-05,
      "loss": 0.0311,
      "step": 43120
    },
    {
      "epoch": 0.138048,
      "grad_norm": 0.16201928296848297,
      "learning_rate": 9.947844392905245e-05,
      "loss": 0.0304,
      "step": 43140
    },
    {
      "epoch": 0.138112,
      "grad_norm": 0.07634665705009923,
      "learning_rate": 9.947796106648092e-05,
      "loss": 0.031,
      "step": 43160
    },
    {
      "epoch": 0.138176,
      "grad_norm": 0.18404840923906227,
      "learning_rate": 9.947747798166591e-05,
      "loss": 0.0334,
      "step": 43180
    },
    {
      "epoch": 0.13824,
      "grad_norm": 0.06627281063116525,
      "learning_rate": 9.947699467460963e-05,
      "loss": 0.0324,
      "step": 43200
    },
    {
      "epoch": 0.138304,
      "grad_norm": 0.07097173157617676,
      "learning_rate": 9.947651114531422e-05,
      "loss": 0.0324,
      "step": 43220
    },
    {
      "epoch": 0.138368,
      "grad_norm": 0.07695453020839546,
      "learning_rate": 9.947602739378188e-05,
      "loss": 0.0347,
      "step": 43240
    },
    {
      "epoch": 0.138432,
      "grad_norm": 0.07271507658249661,
      "learning_rate": 9.947554342001478e-05,
      "loss": 0.0326,
      "step": 43260
    },
    {
      "epoch": 0.138496,
      "grad_norm": 0.0907294362769514,
      "learning_rate": 9.947505922401507e-05,
      "loss": 0.0317,
      "step": 43280
    },
    {
      "epoch": 0.13856,
      "grad_norm": 0.11702148868502561,
      "learning_rate": 9.947457480578495e-05,
      "loss": 0.0341,
      "step": 43300
    },
    {
      "epoch": 0.138624,
      "grad_norm": 0.07092002802625459,
      "learning_rate": 9.947409016532658e-05,
      "loss": 0.0343,
      "step": 43320
    },
    {
      "epoch": 0.138688,
      "grad_norm": 0.09559150188499406,
      "learning_rate": 9.947360530264214e-05,
      "loss": 0.0307,
      "step": 43340
    },
    {
      "epoch": 0.138752,
      "grad_norm": 0.07575799077733586,
      "learning_rate": 9.947312021773383e-05,
      "loss": 0.0333,
      "step": 43360
    },
    {
      "epoch": 0.138816,
      "grad_norm": 0.07991725391255566,
      "learning_rate": 9.947263491060379e-05,
      "loss": 0.0321,
      "step": 43380
    },
    {
      "epoch": 0.13888,
      "grad_norm": 0.08392834897280924,
      "learning_rate": 9.947214938125422e-05,
      "loss": 0.0293,
      "step": 43400
    },
    {
      "epoch": 0.138944,
      "grad_norm": 0.07143880189504376,
      "learning_rate": 9.947166362968732e-05,
      "loss": 0.031,
      "step": 43420
    },
    {
      "epoch": 0.139008,
      "grad_norm": 0.05710903095031855,
      "learning_rate": 9.947117765590523e-05,
      "loss": 0.0285,
      "step": 43440
    },
    {
      "epoch": 0.139072,
      "grad_norm": 0.11352949324055561,
      "learning_rate": 9.947069145991017e-05,
      "loss": 0.0311,
      "step": 43460
    },
    {
      "epoch": 0.139136,
      "grad_norm": 0.13588474411142884,
      "learning_rate": 9.94702050417043e-05,
      "loss": 0.0306,
      "step": 43480
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.1054201025936334,
      "learning_rate": 9.946971840128981e-05,
      "loss": 0.0321,
      "step": 43500
    },
    {
      "epoch": 0.139264,
      "grad_norm": 0.08933119637963963,
      "learning_rate": 9.94692315386689e-05,
      "loss": 0.0341,
      "step": 43520
    },
    {
      "epoch": 0.139328,
      "grad_norm": 0.09625817735827619,
      "learning_rate": 9.946874445384375e-05,
      "loss": 0.0332,
      "step": 43540
    },
    {
      "epoch": 0.139392,
      "grad_norm": 0.14484393338434143,
      "learning_rate": 9.946825714681654e-05,
      "loss": 0.0325,
      "step": 43560
    },
    {
      "epoch": 0.139456,
      "grad_norm": 0.0683339596166035,
      "learning_rate": 9.946776961758945e-05,
      "loss": 0.03,
      "step": 43580
    },
    {
      "epoch": 0.13952,
      "grad_norm": 0.10177336821474872,
      "learning_rate": 9.94672818661647e-05,
      "loss": 0.0306,
      "step": 43600
    },
    {
      "epoch": 0.139584,
      "grad_norm": 0.07553564513646266,
      "learning_rate": 9.946679389254448e-05,
      "loss": 0.0333,
      "step": 43620
    },
    {
      "epoch": 0.139648,
      "grad_norm": 0.06650640996577269,
      "learning_rate": 9.946630569673094e-05,
      "loss": 0.0302,
      "step": 43640
    },
    {
      "epoch": 0.139712,
      "grad_norm": 0.10896985518469338,
      "learning_rate": 9.94658172787263e-05,
      "loss": 0.0286,
      "step": 43660
    },
    {
      "epoch": 0.139776,
      "grad_norm": 0.07792751713105323,
      "learning_rate": 9.946532863853277e-05,
      "loss": 0.0304,
      "step": 43680
    },
    {
      "epoch": 0.13984,
      "grad_norm": 0.08708487014111582,
      "learning_rate": 9.94648397761525e-05,
      "loss": 0.0311,
      "step": 43700
    },
    {
      "epoch": 0.139904,
      "grad_norm": 0.14665370314964687,
      "learning_rate": 9.946435069158774e-05,
      "loss": 0.0284,
      "step": 43720
    },
    {
      "epoch": 0.139968,
      "grad_norm": 0.13126047953768288,
      "learning_rate": 9.946386138484065e-05,
      "loss": 0.0326,
      "step": 43740
    },
    {
      "epoch": 0.140032,
      "grad_norm": 0.1667786189845606,
      "learning_rate": 9.946337185591343e-05,
      "loss": 0.0319,
      "step": 43760
    },
    {
      "epoch": 0.140096,
      "grad_norm": 0.08203177439237458,
      "learning_rate": 9.94628821048083e-05,
      "loss": 0.0319,
      "step": 43780
    },
    {
      "epoch": 0.14016,
      "grad_norm": 0.0840635672034877,
      "learning_rate": 9.946239213152745e-05,
      "loss": 0.0343,
      "step": 43800
    },
    {
      "epoch": 0.140224,
      "grad_norm": 0.19184332980124338,
      "learning_rate": 9.946190193607307e-05,
      "loss": 0.0359,
      "step": 43820
    },
    {
      "epoch": 0.140288,
      "grad_norm": 0.08765050509586234,
      "learning_rate": 9.946141151844737e-05,
      "loss": 0.0325,
      "step": 43840
    },
    {
      "epoch": 0.140352,
      "grad_norm": 0.09556817931819744,
      "learning_rate": 9.946092087865255e-05,
      "loss": 0.0296,
      "step": 43860
    },
    {
      "epoch": 0.140416,
      "grad_norm": 0.08672951031920267,
      "learning_rate": 9.946043001669083e-05,
      "loss": 0.0324,
      "step": 43880
    },
    {
      "epoch": 0.14048,
      "grad_norm": 0.07298977539915834,
      "learning_rate": 9.945993893256439e-05,
      "loss": 0.0338,
      "step": 43900
    },
    {
      "epoch": 0.140544,
      "grad_norm": 0.17233156618349463,
      "learning_rate": 9.945944762627545e-05,
      "loss": 0.034,
      "step": 43920
    },
    {
      "epoch": 0.140608,
      "grad_norm": 0.06207802320170917,
      "learning_rate": 9.94589560978262e-05,
      "loss": 0.0327,
      "step": 43940
    },
    {
      "epoch": 0.140672,
      "grad_norm": 0.09764171518154835,
      "learning_rate": 9.945846434721889e-05,
      "loss": 0.031,
      "step": 43960
    },
    {
      "epoch": 0.140736,
      "grad_norm": 0.10636364453644002,
      "learning_rate": 9.945797237445567e-05,
      "loss": 0.0342,
      "step": 43980
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.06716676468685795,
      "learning_rate": 9.94574801795388e-05,
      "loss": 0.0356,
      "step": 44000
    },
    {
      "epoch": 0.140864,
      "grad_norm": 0.1122382114016688,
      "learning_rate": 9.945698776247048e-05,
      "loss": 0.034,
      "step": 44020
    },
    {
      "epoch": 0.140928,
      "grad_norm": 0.0839185343203512,
      "learning_rate": 9.94564951232529e-05,
      "loss": 0.0321,
      "step": 44040
    },
    {
      "epoch": 0.140992,
      "grad_norm": 0.06913776514673886,
      "learning_rate": 9.945600226188827e-05,
      "loss": 0.0299,
      "step": 44060
    },
    {
      "epoch": 0.141056,
      "grad_norm": 0.13219850310075404,
      "learning_rate": 9.945550917837885e-05,
      "loss": 0.0307,
      "step": 44080
    },
    {
      "epoch": 0.14112,
      "grad_norm": 0.11009348776955531,
      "learning_rate": 9.94550158727268e-05,
      "loss": 0.0329,
      "step": 44100
    },
    {
      "epoch": 0.141184,
      "grad_norm": 0.11465943285226894,
      "learning_rate": 9.945452234493437e-05,
      "loss": 0.0289,
      "step": 44120
    },
    {
      "epoch": 0.141248,
      "grad_norm": 0.08245215150787376,
      "learning_rate": 9.945402859500377e-05,
      "loss": 0.0292,
      "step": 44140
    },
    {
      "epoch": 0.141312,
      "grad_norm": 0.061509068599355635,
      "learning_rate": 9.94535346229372e-05,
      "loss": 0.0329,
      "step": 44160
    },
    {
      "epoch": 0.141376,
      "grad_norm": 0.05339866181914807,
      "learning_rate": 9.945304042873691e-05,
      "loss": 0.0308,
      "step": 44180
    },
    {
      "epoch": 0.14144,
      "grad_norm": 0.06868911322842283,
      "learning_rate": 9.94525460124051e-05,
      "loss": 0.0311,
      "step": 44200
    },
    {
      "epoch": 0.141504,
      "grad_norm": 0.0676701198001911,
      "learning_rate": 9.9452051373944e-05,
      "loss": 0.0325,
      "step": 44220
    },
    {
      "epoch": 0.141568,
      "grad_norm": 0.09804076495766727,
      "learning_rate": 9.945155651335583e-05,
      "loss": 0.0295,
      "step": 44240
    },
    {
      "epoch": 0.141632,
      "grad_norm": 0.11437173867529303,
      "learning_rate": 9.945106143064279e-05,
      "loss": 0.0335,
      "step": 44260
    },
    {
      "epoch": 0.141696,
      "grad_norm": 0.07728718845937241,
      "learning_rate": 9.945056612580713e-05,
      "loss": 0.0315,
      "step": 44280
    },
    {
      "epoch": 0.14176,
      "grad_norm": 0.08130251469449006,
      "learning_rate": 9.945007059885107e-05,
      "loss": 0.0334,
      "step": 44300
    },
    {
      "epoch": 0.141824,
      "grad_norm": 0.08075980284946264,
      "learning_rate": 9.944957484977683e-05,
      "loss": 0.031,
      "step": 44320
    },
    {
      "epoch": 0.141888,
      "grad_norm": 0.23518714080263184,
      "learning_rate": 9.944907887858665e-05,
      "loss": 0.0319,
      "step": 44340
    },
    {
      "epoch": 0.141952,
      "grad_norm": 0.11053678618225929,
      "learning_rate": 9.944858268528274e-05,
      "loss": 0.0365,
      "step": 44360
    },
    {
      "epoch": 0.142016,
      "grad_norm": 0.08609581400036871,
      "learning_rate": 9.944808626986734e-05,
      "loss": 0.032,
      "step": 44380
    },
    {
      "epoch": 0.14208,
      "grad_norm": 0.09896133451777779,
      "learning_rate": 9.944758963234266e-05,
      "loss": 0.0319,
      "step": 44400
    },
    {
      "epoch": 0.142144,
      "grad_norm": 0.11283720492191336,
      "learning_rate": 9.944709277271097e-05,
      "loss": 0.0344,
      "step": 44420
    },
    {
      "epoch": 0.142208,
      "grad_norm": 0.22978125442311853,
      "learning_rate": 9.944659569097448e-05,
      "loss": 0.032,
      "step": 44440
    },
    {
      "epoch": 0.142272,
      "grad_norm": 0.1315335767759104,
      "learning_rate": 9.944609838713542e-05,
      "loss": 0.0308,
      "step": 44460
    },
    {
      "epoch": 0.142336,
      "grad_norm": 0.09714272752372957,
      "learning_rate": 9.944560086119601e-05,
      "loss": 0.0363,
      "step": 44480
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.09227809766663257,
      "learning_rate": 9.94451031131585e-05,
      "loss": 0.0347,
      "step": 44500
    },
    {
      "epoch": 0.142464,
      "grad_norm": 0.10262969948075865,
      "learning_rate": 9.944460514302513e-05,
      "loss": 0.0298,
      "step": 44520
    },
    {
      "epoch": 0.142528,
      "grad_norm": 0.07339862831550231,
      "learning_rate": 9.944410695079814e-05,
      "loss": 0.0311,
      "step": 44540
    },
    {
      "epoch": 0.142592,
      "grad_norm": 0.09771678754754455,
      "learning_rate": 9.944360853647976e-05,
      "loss": 0.0303,
      "step": 44560
    },
    {
      "epoch": 0.142656,
      "grad_norm": 0.06852349464050257,
      "learning_rate": 9.944310990007223e-05,
      "loss": 0.0316,
      "step": 44580
    },
    {
      "epoch": 0.14272,
      "grad_norm": 0.13934347155132817,
      "learning_rate": 9.944261104157778e-05,
      "loss": 0.0296,
      "step": 44600
    },
    {
      "epoch": 0.142784,
      "grad_norm": 0.13306207936240774,
      "learning_rate": 9.944211196099866e-05,
      "loss": 0.03,
      "step": 44620
    },
    {
      "epoch": 0.142848,
      "grad_norm": 0.12148831245370686,
      "learning_rate": 9.944161265833713e-05,
      "loss": 0.0296,
      "step": 44640
    },
    {
      "epoch": 0.142912,
      "grad_norm": 0.09935488097025678,
      "learning_rate": 9.94411131335954e-05,
      "loss": 0.0305,
      "step": 44660
    },
    {
      "epoch": 0.142976,
      "grad_norm": 0.0839528953603813,
      "learning_rate": 9.944061338677572e-05,
      "loss": 0.0319,
      "step": 44680
    },
    {
      "epoch": 0.14304,
      "grad_norm": 0.07255629713976992,
      "learning_rate": 9.944011341788036e-05,
      "loss": 0.0332,
      "step": 44700
    },
    {
      "epoch": 0.143104,
      "grad_norm": 0.08208459227085675,
      "learning_rate": 9.943961322691156e-05,
      "loss": 0.0305,
      "step": 44720
    },
    {
      "epoch": 0.143168,
      "grad_norm": 0.1130568637514043,
      "learning_rate": 9.943911281387152e-05,
      "loss": 0.0381,
      "step": 44740
    },
    {
      "epoch": 0.143232,
      "grad_norm": 0.07918837464120848,
      "learning_rate": 9.943861217876255e-05,
      "loss": 0.0317,
      "step": 44760
    },
    {
      "epoch": 0.143296,
      "grad_norm": 0.07962213892261462,
      "learning_rate": 9.943811132158686e-05,
      "loss": 0.032,
      "step": 44780
    },
    {
      "epoch": 0.14336,
      "grad_norm": 0.07810614497076983,
      "learning_rate": 9.943761024234672e-05,
      "loss": 0.0308,
      "step": 44800
    },
    {
      "epoch": 0.143424,
      "grad_norm": 0.08074008935520487,
      "learning_rate": 9.943710894104437e-05,
      "loss": 0.0277,
      "step": 44820
    },
    {
      "epoch": 0.143488,
      "grad_norm": 0.0784583075106754,
      "learning_rate": 9.943660741768206e-05,
      "loss": 0.0287,
      "step": 44840
    },
    {
      "epoch": 0.143552,
      "grad_norm": 0.07116579090110624,
      "learning_rate": 9.943610567226205e-05,
      "loss": 0.0329,
      "step": 44860
    },
    {
      "epoch": 0.143616,
      "grad_norm": 0.06686010862961496,
      "learning_rate": 9.943560370478657e-05,
      "loss": 0.0317,
      "step": 44880
    },
    {
      "epoch": 0.14368,
      "grad_norm": 0.07582682979300236,
      "learning_rate": 9.943510151525792e-05,
      "loss": 0.0292,
      "step": 44900
    },
    {
      "epoch": 0.143744,
      "grad_norm": 0.06244356411598463,
      "learning_rate": 9.943459910367833e-05,
      "loss": 0.0328,
      "step": 44920
    },
    {
      "epoch": 0.143808,
      "grad_norm": 0.09932211287497399,
      "learning_rate": 9.943409647005004e-05,
      "loss": 0.0322,
      "step": 44940
    },
    {
      "epoch": 0.143872,
      "grad_norm": 0.13436156203484195,
      "learning_rate": 9.943359361437534e-05,
      "loss": 0.0355,
      "step": 44960
    },
    {
      "epoch": 0.143936,
      "grad_norm": 0.060035223037218664,
      "learning_rate": 9.943309053665648e-05,
      "loss": 0.0341,
      "step": 44980
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.0735895460859978,
      "learning_rate": 9.94325872368957e-05,
      "loss": 0.0303,
      "step": 45000
    },
    {
      "epoch": 0.144064,
      "grad_norm": 0.09283087910635777,
      "learning_rate": 9.943208371509529e-05,
      "loss": 0.0353,
      "step": 45020
    },
    {
      "epoch": 0.144128,
      "grad_norm": 0.06370576805589122,
      "learning_rate": 9.943157997125748e-05,
      "loss": 0.0329,
      "step": 45040
    },
    {
      "epoch": 0.144192,
      "grad_norm": 0.11249501379345124,
      "learning_rate": 9.943107600538457e-05,
      "loss": 0.0357,
      "step": 45060
    },
    {
      "epoch": 0.144256,
      "grad_norm": 0.1743569865292881,
      "learning_rate": 9.943057181747877e-05,
      "loss": 0.0334,
      "step": 45080
    },
    {
      "epoch": 0.14432,
      "grad_norm": 0.15340215685007777,
      "learning_rate": 9.94300674075424e-05,
      "loss": 0.0314,
      "step": 45100
    },
    {
      "epoch": 0.144384,
      "grad_norm": 0.07734797801592953,
      "learning_rate": 9.94295627755777e-05,
      "loss": 0.0361,
      "step": 45120
    },
    {
      "epoch": 0.144448,
      "grad_norm": 0.0944424417827727,
      "learning_rate": 9.942905792158695e-05,
      "loss": 0.0329,
      "step": 45140
    },
    {
      "epoch": 0.144512,
      "grad_norm": 0.18694625052907426,
      "learning_rate": 9.942855284557238e-05,
      "loss": 0.0329,
      "step": 45160
    },
    {
      "epoch": 0.144576,
      "grad_norm": 0.17912878062783963,
      "learning_rate": 9.942804754753631e-05,
      "loss": 0.0336,
      "step": 45180
    },
    {
      "epoch": 0.14464,
      "grad_norm": 0.0822804187749451,
      "learning_rate": 9.942754202748097e-05,
      "loss": 0.033,
      "step": 45200
    },
    {
      "epoch": 0.144704,
      "grad_norm": 0.07199907837023084,
      "learning_rate": 9.942703628540866e-05,
      "loss": 0.0341,
      "step": 45220
    },
    {
      "epoch": 0.144768,
      "grad_norm": 0.06595484442305903,
      "learning_rate": 9.942653032132163e-05,
      "loss": 0.0314,
      "step": 45240
    },
    {
      "epoch": 0.144832,
      "grad_norm": 0.21101409344193045,
      "learning_rate": 9.942602413522216e-05,
      "loss": 0.031,
      "step": 45260
    },
    {
      "epoch": 0.144896,
      "grad_norm": 0.27433541153479357,
      "learning_rate": 9.942551772711253e-05,
      "loss": 0.0296,
      "step": 45280
    },
    {
      "epoch": 0.14496,
      "grad_norm": 0.10164290483102832,
      "learning_rate": 9.9425011096995e-05,
      "loss": 0.0302,
      "step": 45300
    },
    {
      "epoch": 0.145024,
      "grad_norm": 0.07756871470530831,
      "learning_rate": 9.942450424487187e-05,
      "loss": 0.0321,
      "step": 45320
    },
    {
      "epoch": 0.145088,
      "grad_norm": 0.1129968037904023,
      "learning_rate": 9.942399717074539e-05,
      "loss": 0.0306,
      "step": 45340
    },
    {
      "epoch": 0.145152,
      "grad_norm": 0.09327859722297321,
      "learning_rate": 9.942348987461785e-05,
      "loss": 0.0305,
      "step": 45360
    },
    {
      "epoch": 0.145216,
      "grad_norm": 0.1590969937858857,
      "learning_rate": 9.942298235649152e-05,
      "loss": 0.0329,
      "step": 45380
    },
    {
      "epoch": 0.14528,
      "grad_norm": 0.06630503445706937,
      "learning_rate": 9.94224746163687e-05,
      "loss": 0.0305,
      "step": 45400
    },
    {
      "epoch": 0.145344,
      "grad_norm": 0.11045453900590403,
      "learning_rate": 9.942196665425165e-05,
      "loss": 0.0317,
      "step": 45420
    },
    {
      "epoch": 0.145408,
      "grad_norm": 0.07262598243246876,
      "learning_rate": 9.942145847014268e-05,
      "loss": 0.0345,
      "step": 45440
    },
    {
      "epoch": 0.145472,
      "grad_norm": 0.07834783262286689,
      "learning_rate": 9.942095006404404e-05,
      "loss": 0.0317,
      "step": 45460
    },
    {
      "epoch": 0.145536,
      "grad_norm": 0.07191157466035178,
      "learning_rate": 9.942044143595801e-05,
      "loss": 0.0346,
      "step": 45480
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.07668680647600666,
      "learning_rate": 9.941993258588691e-05,
      "loss": 0.0309,
      "step": 45500
    },
    {
      "epoch": 0.145664,
      "grad_norm": 0.07041920888807483,
      "learning_rate": 9.9419423513833e-05,
      "loss": 0.0287,
      "step": 45520
    },
    {
      "epoch": 0.145728,
      "grad_norm": 0.11835562972477168,
      "learning_rate": 9.941891421979857e-05,
      "loss": 0.0318,
      "step": 45540
    },
    {
      "epoch": 0.145792,
      "grad_norm": 0.0937626034968694,
      "learning_rate": 9.941840470378592e-05,
      "loss": 0.033,
      "step": 45560
    },
    {
      "epoch": 0.145856,
      "grad_norm": 0.09318282553620828,
      "learning_rate": 9.941789496579733e-05,
      "loss": 0.0315,
      "step": 45580
    },
    {
      "epoch": 0.14592,
      "grad_norm": 0.10281820061906448,
      "learning_rate": 9.941738500583506e-05,
      "loss": 0.0292,
      "step": 45600
    },
    {
      "epoch": 0.145984,
      "grad_norm": 0.1100995093191855,
      "learning_rate": 9.941687482390146e-05,
      "loss": 0.0315,
      "step": 45620
    },
    {
      "epoch": 0.146048,
      "grad_norm": 0.08801731855835009,
      "learning_rate": 9.941636441999877e-05,
      "loss": 0.0296,
      "step": 45640
    },
    {
      "epoch": 0.146112,
      "grad_norm": 0.07973052830645552,
      "learning_rate": 9.941585379412932e-05,
      "loss": 0.0273,
      "step": 45660
    },
    {
      "epoch": 0.146176,
      "grad_norm": 0.06405342410231209,
      "learning_rate": 9.941534294629538e-05,
      "loss": 0.0329,
      "step": 45680
    },
    {
      "epoch": 0.14624,
      "grad_norm": 0.07661828366254775,
      "learning_rate": 9.941483187649927e-05,
      "loss": 0.0302,
      "step": 45700
    },
    {
      "epoch": 0.146304,
      "grad_norm": 0.09846929536015242,
      "learning_rate": 9.941432058474325e-05,
      "loss": 0.0279,
      "step": 45720
    },
    {
      "epoch": 0.146368,
      "grad_norm": 0.06676787830470808,
      "learning_rate": 9.941380907102965e-05,
      "loss": 0.0287,
      "step": 45740
    },
    {
      "epoch": 0.146432,
      "grad_norm": 0.10850745215323246,
      "learning_rate": 9.941329733536071e-05,
      "loss": 0.0298,
      "step": 45760
    },
    {
      "epoch": 0.146496,
      "grad_norm": 0.06857623117633072,
      "learning_rate": 9.941278537773881e-05,
      "loss": 0.0276,
      "step": 45780
    },
    {
      "epoch": 0.14656,
      "grad_norm": 0.08976718895389513,
      "learning_rate": 9.94122731981662e-05,
      "loss": 0.0317,
      "step": 45800
    },
    {
      "epoch": 0.146624,
      "grad_norm": 0.08460687992055017,
      "learning_rate": 9.941176079664518e-05,
      "loss": 0.031,
      "step": 45820
    },
    {
      "epoch": 0.146688,
      "grad_norm": 0.073861298680393,
      "learning_rate": 9.941124817317807e-05,
      "loss": 0.0287,
      "step": 45840
    },
    {
      "epoch": 0.146752,
      "grad_norm": 0.07962980604798256,
      "learning_rate": 9.941073532776717e-05,
      "loss": 0.0345,
      "step": 45860
    },
    {
      "epoch": 0.146816,
      "grad_norm": 0.08888390369116214,
      "learning_rate": 9.941022226041477e-05,
      "loss": 0.0324,
      "step": 45880
    },
    {
      "epoch": 0.14688,
      "grad_norm": 0.06465314487516263,
      "learning_rate": 9.940970897112318e-05,
      "loss": 0.0302,
      "step": 45900
    },
    {
      "epoch": 0.146944,
      "grad_norm": 0.0852821757519658,
      "learning_rate": 9.940919545989473e-05,
      "loss": 0.031,
      "step": 45920
    },
    {
      "epoch": 0.147008,
      "grad_norm": 0.06472151014883815,
      "learning_rate": 9.940868172673167e-05,
      "loss": 0.0321,
      "step": 45940
    },
    {
      "epoch": 0.147072,
      "grad_norm": 0.07322408202590953,
      "learning_rate": 9.940816777163637e-05,
      "loss": 0.0307,
      "step": 45960
    },
    {
      "epoch": 0.147136,
      "grad_norm": 0.0763459418667312,
      "learning_rate": 9.940765359461111e-05,
      "loss": 0.0339,
      "step": 45980
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.0713914196685617,
      "learning_rate": 9.940713919565818e-05,
      "loss": 0.0345,
      "step": 46000
    },
    {
      "epoch": 0.147264,
      "grad_norm": 0.11324428818708661,
      "learning_rate": 9.940662457477993e-05,
      "loss": 0.0323,
      "step": 46020
    },
    {
      "epoch": 0.147328,
      "grad_norm": 0.06586571217892605,
      "learning_rate": 9.940610973197866e-05,
      "loss": 0.0301,
      "step": 46040
    },
    {
      "epoch": 0.147392,
      "grad_norm": 0.1456179123267802,
      "learning_rate": 9.940559466725665e-05,
      "loss": 0.0333,
      "step": 46060
    },
    {
      "epoch": 0.147456,
      "grad_norm": 0.07725844143023942,
      "learning_rate": 9.940507938061624e-05,
      "loss": 0.0328,
      "step": 46080
    },
    {
      "epoch": 0.14752,
      "grad_norm": 0.06554538602498296,
      "learning_rate": 9.940456387205976e-05,
      "loss": 0.0299,
      "step": 46100
    },
    {
      "epoch": 0.147584,
      "grad_norm": 0.15604864495179765,
      "learning_rate": 9.940404814158952e-05,
      "loss": 0.0318,
      "step": 46120
    },
    {
      "epoch": 0.147648,
      "grad_norm": 0.06390259851170609,
      "learning_rate": 9.94035321892078e-05,
      "loss": 0.0306,
      "step": 46140
    },
    {
      "epoch": 0.147712,
      "grad_norm": 0.06377724964397978,
      "learning_rate": 9.940301601491696e-05,
      "loss": 0.0281,
      "step": 46160
    },
    {
      "epoch": 0.147776,
      "grad_norm": 0.14040731774437945,
      "learning_rate": 9.940249961871929e-05,
      "loss": 0.0311,
      "step": 46180
    },
    {
      "epoch": 0.14784,
      "grad_norm": 0.13744763617337144,
      "learning_rate": 9.940198300061712e-05,
      "loss": 0.0316,
      "step": 46200
    },
    {
      "epoch": 0.147904,
      "grad_norm": 0.08924213792743513,
      "learning_rate": 9.940146616061279e-05,
      "loss": 0.034,
      "step": 46220
    },
    {
      "epoch": 0.147968,
      "grad_norm": 0.09632146089942842,
      "learning_rate": 9.940094909870859e-05,
      "loss": 0.0301,
      "step": 46240
    },
    {
      "epoch": 0.148032,
      "grad_norm": 0.07140229473390827,
      "learning_rate": 9.940043181490685e-05,
      "loss": 0.032,
      "step": 46260
    },
    {
      "epoch": 0.148096,
      "grad_norm": 0.10996114684599252,
      "learning_rate": 9.93999143092099e-05,
      "loss": 0.0294,
      "step": 46280
    },
    {
      "epoch": 0.14816,
      "grad_norm": 0.08984108632433775,
      "learning_rate": 9.939939658162007e-05,
      "loss": 0.0348,
      "step": 46300
    },
    {
      "epoch": 0.148224,
      "grad_norm": 0.07254968355836286,
      "learning_rate": 9.939887863213969e-05,
      "loss": 0.0356,
      "step": 46320
    },
    {
      "epoch": 0.148288,
      "grad_norm": 0.12003039044495054,
      "learning_rate": 9.939836046077104e-05,
      "loss": 0.0344,
      "step": 46340
    },
    {
      "epoch": 0.148352,
      "grad_norm": 0.06813999856464828,
      "learning_rate": 9.939784206751652e-05,
      "loss": 0.0327,
      "step": 46360
    },
    {
      "epoch": 0.148416,
      "grad_norm": 0.16690763985110113,
      "learning_rate": 9.93973234523784e-05,
      "loss": 0.0322,
      "step": 46380
    },
    {
      "epoch": 0.14848,
      "grad_norm": 0.09827324829997114,
      "learning_rate": 9.939680461535905e-05,
      "loss": 0.0312,
      "step": 46400
    },
    {
      "epoch": 0.148544,
      "grad_norm": 0.07838333271046842,
      "learning_rate": 9.939628555646077e-05,
      "loss": 0.0282,
      "step": 46420
    },
    {
      "epoch": 0.148608,
      "grad_norm": 0.09914416861598797,
      "learning_rate": 9.93957662756859e-05,
      "loss": 0.0363,
      "step": 46440
    },
    {
      "epoch": 0.148672,
      "grad_norm": 0.09648094210648592,
      "learning_rate": 9.939524677303677e-05,
      "loss": 0.0331,
      "step": 46460
    },
    {
      "epoch": 0.148736,
      "grad_norm": 0.06205894600673664,
      "learning_rate": 9.939472704851573e-05,
      "loss": 0.0274,
      "step": 46480
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.13086498230804006,
      "learning_rate": 9.939420710212511e-05,
      "loss": 0.0273,
      "step": 46500
    },
    {
      "epoch": 0.148864,
      "grad_norm": 0.0936157924584635,
      "learning_rate": 9.939368693386724e-05,
      "loss": 0.0289,
      "step": 46520
    },
    {
      "epoch": 0.148928,
      "grad_norm": 0.10357413821536994,
      "learning_rate": 9.939316654374444e-05,
      "loss": 0.032,
      "step": 46540
    },
    {
      "epoch": 0.148992,
      "grad_norm": 0.09739226154550425,
      "learning_rate": 9.939264593175908e-05,
      "loss": 0.0302,
      "step": 46560
    },
    {
      "epoch": 0.149056,
      "grad_norm": 0.10253538558746574,
      "learning_rate": 9.939212509791347e-05,
      "loss": 0.03,
      "step": 46580
    },
    {
      "epoch": 0.14912,
      "grad_norm": 0.08714046655221884,
      "learning_rate": 9.939160404220997e-05,
      "loss": 0.032,
      "step": 46600
    },
    {
      "epoch": 0.149184,
      "grad_norm": 0.07105167641551288,
      "learning_rate": 9.93910827646509e-05,
      "loss": 0.0313,
      "step": 46620
    },
    {
      "epoch": 0.149248,
      "grad_norm": 0.07769119862566892,
      "learning_rate": 9.939056126523861e-05,
      "loss": 0.0315,
      "step": 46640
    },
    {
      "epoch": 0.149312,
      "grad_norm": 0.07658669882878325,
      "learning_rate": 9.939003954397546e-05,
      "loss": 0.0332,
      "step": 46660
    },
    {
      "epoch": 0.149376,
      "grad_norm": 0.06952651886100032,
      "learning_rate": 9.938951760086377e-05,
      "loss": 0.03,
      "step": 46680
    },
    {
      "epoch": 0.14944,
      "grad_norm": 0.05657640155364597,
      "learning_rate": 9.93889954359059e-05,
      "loss": 0.0307,
      "step": 46700
    },
    {
      "epoch": 0.149504,
      "grad_norm": 0.060772649234232846,
      "learning_rate": 9.938847304910418e-05,
      "loss": 0.0313,
      "step": 46720
    },
    {
      "epoch": 0.149568,
      "grad_norm": 0.08657837054906613,
      "learning_rate": 9.938795044046097e-05,
      "loss": 0.0307,
      "step": 46740
    },
    {
      "epoch": 0.149632,
      "grad_norm": 0.08027933804587406,
      "learning_rate": 9.938742760997861e-05,
      "loss": 0.0305,
      "step": 46760
    },
    {
      "epoch": 0.149696,
      "grad_norm": 0.09409280808655238,
      "learning_rate": 9.938690455765945e-05,
      "loss": 0.0313,
      "step": 46780
    },
    {
      "epoch": 0.14976,
      "grad_norm": 0.08509766405976296,
      "learning_rate": 9.938638128350585e-05,
      "loss": 0.032,
      "step": 46800
    },
    {
      "epoch": 0.149824,
      "grad_norm": 0.05583496773047922,
      "learning_rate": 9.938585778752014e-05,
      "loss": 0.0312,
      "step": 46820
    },
    {
      "epoch": 0.149888,
      "grad_norm": 0.10010265872088056,
      "learning_rate": 9.938533406970469e-05,
      "loss": 0.0333,
      "step": 46840
    },
    {
      "epoch": 0.149952,
      "grad_norm": 0.08872981950016327,
      "learning_rate": 9.938481013006184e-05,
      "loss": 0.0303,
      "step": 46860
    },
    {
      "epoch": 0.150016,
      "grad_norm": 0.10262009964284717,
      "learning_rate": 9.938428596859395e-05,
      "loss": 0.0335,
      "step": 46880
    },
    {
      "epoch": 0.15008,
      "grad_norm": 0.06717229212581256,
      "learning_rate": 9.938376158530337e-05,
      "loss": 0.0294,
      "step": 46900
    },
    {
      "epoch": 0.150144,
      "grad_norm": 0.10930912100750657,
      "learning_rate": 9.938323698019246e-05,
      "loss": 0.0292,
      "step": 46920
    },
    {
      "epoch": 0.150208,
      "grad_norm": 0.12899339472913562,
      "learning_rate": 9.938271215326358e-05,
      "loss": 0.0316,
      "step": 46940
    },
    {
      "epoch": 0.150272,
      "grad_norm": 0.14791430349800785,
      "learning_rate": 9.938218710451907e-05,
      "loss": 0.0341,
      "step": 46960
    },
    {
      "epoch": 0.150336,
      "grad_norm": 0.12695112518559196,
      "learning_rate": 9.938166183396131e-05,
      "loss": 0.0299,
      "step": 46980
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.10449814218920127,
      "learning_rate": 9.938113634159265e-05,
      "loss": 0.0297,
      "step": 47000
    },
    {
      "epoch": 0.150464,
      "grad_norm": 0.06885648507316686,
      "learning_rate": 9.938061062741544e-05,
      "loss": 0.0315,
      "step": 47020
    },
    {
      "epoch": 0.150528,
      "grad_norm": 0.08223492148444912,
      "learning_rate": 9.938008469143205e-05,
      "loss": 0.0326,
      "step": 47040
    },
    {
      "epoch": 0.150592,
      "grad_norm": 0.14005598580387021,
      "learning_rate": 9.937955853364486e-05,
      "loss": 0.0328,
      "step": 47060
    },
    {
      "epoch": 0.150656,
      "grad_norm": 0.09102648426699513,
      "learning_rate": 9.93790321540562e-05,
      "loss": 0.0316,
      "step": 47080
    },
    {
      "epoch": 0.15072,
      "grad_norm": 0.1161245812908459,
      "learning_rate": 9.937850555266846e-05,
      "loss": 0.031,
      "step": 47100
    },
    {
      "epoch": 0.150784,
      "grad_norm": 0.09258502563134016,
      "learning_rate": 9.9377978729484e-05,
      "loss": 0.03,
      "step": 47120
    },
    {
      "epoch": 0.150848,
      "grad_norm": 0.09455246032115502,
      "learning_rate": 9.937745168450518e-05,
      "loss": 0.0297,
      "step": 47140
    },
    {
      "epoch": 0.150912,
      "grad_norm": 0.11034507521592121,
      "learning_rate": 9.937692441773437e-05,
      "loss": 0.0331,
      "step": 47160
    },
    {
      "epoch": 0.150976,
      "grad_norm": 0.1563965361057462,
      "learning_rate": 9.937639692917394e-05,
      "loss": 0.034,
      "step": 47180
    },
    {
      "epoch": 0.15104,
      "grad_norm": 0.11750626625630985,
      "learning_rate": 9.937586921882626e-05,
      "loss": 0.0296,
      "step": 47200
    },
    {
      "epoch": 0.151104,
      "grad_norm": 0.0991318193920632,
      "learning_rate": 9.93753412866937e-05,
      "loss": 0.0345,
      "step": 47220
    },
    {
      "epoch": 0.151168,
      "grad_norm": 0.10708570931373076,
      "learning_rate": 9.937481313277863e-05,
      "loss": 0.0313,
      "step": 47240
    },
    {
      "epoch": 0.151232,
      "grad_norm": 0.07659709455960267,
      "learning_rate": 9.937428475708342e-05,
      "loss": 0.0294,
      "step": 47260
    },
    {
      "epoch": 0.151296,
      "grad_norm": 0.09766081678448985,
      "learning_rate": 9.937375615961043e-05,
      "loss": 0.0326,
      "step": 47280
    },
    {
      "epoch": 0.15136,
      "grad_norm": 0.05865594002239727,
      "learning_rate": 9.937322734036207e-05,
      "loss": 0.0316,
      "step": 47300
    },
    {
      "epoch": 0.151424,
      "grad_norm": 0.11250546550197693,
      "learning_rate": 9.937269829934068e-05,
      "loss": 0.0313,
      "step": 47320
    },
    {
      "epoch": 0.151488,
      "grad_norm": 0.07881982644198857,
      "learning_rate": 9.937216903654867e-05,
      "loss": 0.0314,
      "step": 47340
    },
    {
      "epoch": 0.151552,
      "grad_norm": 0.06792830991567207,
      "learning_rate": 9.937163955198839e-05,
      "loss": 0.0336,
      "step": 47360
    },
    {
      "epoch": 0.151616,
      "grad_norm": 0.1046935176801294,
      "learning_rate": 9.937110984566222e-05,
      "loss": 0.0303,
      "step": 47380
    },
    {
      "epoch": 0.15168,
      "grad_norm": 0.09471817929841085,
      "learning_rate": 9.937057991757256e-05,
      "loss": 0.0294,
      "step": 47400
    },
    {
      "epoch": 0.151744,
      "grad_norm": 0.06519829639884701,
      "learning_rate": 9.937004976772177e-05,
      "loss": 0.0296,
      "step": 47420
    },
    {
      "epoch": 0.151808,
      "grad_norm": 0.0914108037579146,
      "learning_rate": 9.936951939611224e-05,
      "loss": 0.0333,
      "step": 47440
    },
    {
      "epoch": 0.151872,
      "grad_norm": 0.1095163164154996,
      "learning_rate": 9.936898880274635e-05,
      "loss": 0.0349,
      "step": 47460
    },
    {
      "epoch": 0.151936,
      "grad_norm": 0.0872318682174451,
      "learning_rate": 9.936845798762649e-05,
      "loss": 0.0314,
      "step": 47480
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.0894511986316892,
      "learning_rate": 9.936792695075502e-05,
      "loss": 0.0313,
      "step": 47500
    },
    {
      "epoch": 0.152064,
      "grad_norm": 0.11465131367242962,
      "learning_rate": 9.936739569213436e-05,
      "loss": 0.0298,
      "step": 47520
    },
    {
      "epoch": 0.152128,
      "grad_norm": 0.11415187623932345,
      "learning_rate": 9.936686421176687e-05,
      "loss": 0.0321,
      "step": 47540
    },
    {
      "epoch": 0.152192,
      "grad_norm": 0.05614353031457746,
      "learning_rate": 9.936633250965495e-05,
      "loss": 0.0314,
      "step": 47560
    },
    {
      "epoch": 0.152256,
      "grad_norm": 0.11187349813578808,
      "learning_rate": 9.936580058580099e-05,
      "loss": 0.0321,
      "step": 47580
    },
    {
      "epoch": 0.15232,
      "grad_norm": 0.095249704237084,
      "learning_rate": 9.936526844020737e-05,
      "loss": 0.0347,
      "step": 47600
    },
    {
      "epoch": 0.152384,
      "grad_norm": 0.06878696706060054,
      "learning_rate": 9.936473607287648e-05,
      "loss": 0.0321,
      "step": 47620
    },
    {
      "epoch": 0.152448,
      "grad_norm": 0.09657385405089218,
      "learning_rate": 9.936420348381073e-05,
      "loss": 0.0342,
      "step": 47640
    },
    {
      "epoch": 0.152512,
      "grad_norm": 0.06523165251001424,
      "learning_rate": 9.936367067301249e-05,
      "loss": 0.0334,
      "step": 47660
    },
    {
      "epoch": 0.152576,
      "grad_norm": 0.08361358394777578,
      "learning_rate": 9.936313764048418e-05,
      "loss": 0.0368,
      "step": 47680
    },
    {
      "epoch": 0.15264,
      "grad_norm": 0.11105453719160574,
      "learning_rate": 9.936260438622815e-05,
      "loss": 0.031,
      "step": 47700
    },
    {
      "epoch": 0.152704,
      "grad_norm": 0.049282486443328076,
      "learning_rate": 9.936207091024683e-05,
      "loss": 0.0305,
      "step": 47720
    },
    {
      "epoch": 0.152768,
      "grad_norm": 0.05392642900739235,
      "learning_rate": 9.93615372125426e-05,
      "loss": 0.0295,
      "step": 47740
    },
    {
      "epoch": 0.152832,
      "grad_norm": 0.08171266608289282,
      "learning_rate": 9.936100329311787e-05,
      "loss": 0.0294,
      "step": 47760
    },
    {
      "epoch": 0.152896,
      "grad_norm": 0.21723179197645665,
      "learning_rate": 9.936046915197504e-05,
      "loss": 0.0334,
      "step": 47780
    },
    {
      "epoch": 0.15296,
      "grad_norm": 0.06804340390934793,
      "learning_rate": 9.93599347891165e-05,
      "loss": 0.0336,
      "step": 47800
    },
    {
      "epoch": 0.153024,
      "grad_norm": 0.10602678492051296,
      "learning_rate": 9.935940020454464e-05,
      "loss": 0.0294,
      "step": 47820
    },
    {
      "epoch": 0.153088,
      "grad_norm": 0.09373669930158983,
      "learning_rate": 9.935886539826189e-05,
      "loss": 0.0316,
      "step": 47840
    },
    {
      "epoch": 0.153152,
      "grad_norm": 0.06574231525928272,
      "learning_rate": 9.935833037027063e-05,
      "loss": 0.0317,
      "step": 47860
    },
    {
      "epoch": 0.153216,
      "grad_norm": 0.05741591396011395,
      "learning_rate": 9.935779512057326e-05,
      "loss": 0.031,
      "step": 47880
    },
    {
      "epoch": 0.15328,
      "grad_norm": 0.08651174210177837,
      "learning_rate": 9.93572596491722e-05,
      "loss": 0.0319,
      "step": 47900
    },
    {
      "epoch": 0.153344,
      "grad_norm": 0.07670880617933137,
      "learning_rate": 9.935672395606986e-05,
      "loss": 0.029,
      "step": 47920
    },
    {
      "epoch": 0.153408,
      "grad_norm": 0.11826103380508518,
      "learning_rate": 9.935618804126862e-05,
      "loss": 0.0325,
      "step": 47940
    },
    {
      "epoch": 0.153472,
      "grad_norm": 0.0951924350658214,
      "learning_rate": 9.93556519047709e-05,
      "loss": 0.0317,
      "step": 47960
    },
    {
      "epoch": 0.153536,
      "grad_norm": 0.12285451581924553,
      "learning_rate": 9.935511554657913e-05,
      "loss": 0.03,
      "step": 47980
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.09295613763446567,
      "learning_rate": 9.935457896669568e-05,
      "loss": 0.0337,
      "step": 48000
    },
    {
      "epoch": 0.153664,
      "grad_norm": 0.07649830183179868,
      "learning_rate": 9.935404216512298e-05,
      "loss": 0.0329,
      "step": 48020
    },
    {
      "epoch": 0.153728,
      "grad_norm": 0.12308444877669553,
      "learning_rate": 9.935350514186345e-05,
      "loss": 0.0298,
      "step": 48040
    },
    {
      "epoch": 0.153792,
      "grad_norm": 0.073565302633695,
      "learning_rate": 9.935296789691948e-05,
      "loss": 0.0347,
      "step": 48060
    },
    {
      "epoch": 0.153856,
      "grad_norm": 0.16435234169562224,
      "learning_rate": 9.93524304302935e-05,
      "loss": 0.0318,
      "step": 48080
    },
    {
      "epoch": 0.15392,
      "grad_norm": 0.12342510180018815,
      "learning_rate": 9.935189274198792e-05,
      "loss": 0.0319,
      "step": 48100
    },
    {
      "epoch": 0.153984,
      "grad_norm": 0.15711880367162234,
      "learning_rate": 9.935135483200517e-05,
      "loss": 0.0317,
      "step": 48120
    },
    {
      "epoch": 0.154048,
      "grad_norm": 0.13183904430458246,
      "learning_rate": 9.935081670034765e-05,
      "loss": 0.0326,
      "step": 48140
    },
    {
      "epoch": 0.154112,
      "grad_norm": 0.1603813572220954,
      "learning_rate": 9.935027834701777e-05,
      "loss": 0.0298,
      "step": 48160
    },
    {
      "epoch": 0.154176,
      "grad_norm": 0.05849572884551675,
      "learning_rate": 9.934973977201796e-05,
      "loss": 0.0307,
      "step": 48180
    },
    {
      "epoch": 0.15424,
      "grad_norm": 0.07607255537902217,
      "learning_rate": 9.934920097535063e-05,
      "loss": 0.029,
      "step": 48200
    },
    {
      "epoch": 0.154304,
      "grad_norm": 0.10129880444059655,
      "learning_rate": 9.934866195701821e-05,
      "loss": 0.0319,
      "step": 48220
    },
    {
      "epoch": 0.154368,
      "grad_norm": 0.07338006479938176,
      "learning_rate": 9.934812271702312e-05,
      "loss": 0.0297,
      "step": 48240
    },
    {
      "epoch": 0.154432,
      "grad_norm": 0.07899350096244173,
      "learning_rate": 9.934758325536777e-05,
      "loss": 0.0279,
      "step": 48260
    },
    {
      "epoch": 0.154496,
      "grad_norm": 0.07471668688072794,
      "learning_rate": 9.93470435720546e-05,
      "loss": 0.0285,
      "step": 48280
    },
    {
      "epoch": 0.15456,
      "grad_norm": 0.0606879441265874,
      "learning_rate": 9.934650366708602e-05,
      "loss": 0.0315,
      "step": 48300
    },
    {
      "epoch": 0.154624,
      "grad_norm": 0.06056321723365228,
      "learning_rate": 9.934596354046448e-05,
      "loss": 0.0298,
      "step": 48320
    },
    {
      "epoch": 0.154688,
      "grad_norm": 0.061812749033990345,
      "learning_rate": 9.934542319219237e-05,
      "loss": 0.0311,
      "step": 48340
    },
    {
      "epoch": 0.154752,
      "grad_norm": 0.18511088830744588,
      "learning_rate": 9.934488262227213e-05,
      "loss": 0.0365,
      "step": 48360
    },
    {
      "epoch": 0.154816,
      "grad_norm": 0.12615828983360142,
      "learning_rate": 9.934434183070621e-05,
      "loss": 0.0337,
      "step": 48380
    },
    {
      "epoch": 0.15488,
      "grad_norm": 0.06314131120509267,
      "learning_rate": 9.9343800817497e-05,
      "loss": 0.0324,
      "step": 48400
    },
    {
      "epoch": 0.154944,
      "grad_norm": 0.11805073927804464,
      "learning_rate": 9.934325958264699e-05,
      "loss": 0.032,
      "step": 48420
    },
    {
      "epoch": 0.155008,
      "grad_norm": 0.13177410375184753,
      "learning_rate": 9.934271812615854e-05,
      "loss": 0.0293,
      "step": 48440
    },
    {
      "epoch": 0.155072,
      "grad_norm": 0.11968151949427579,
      "learning_rate": 9.934217644803415e-05,
      "loss": 0.0314,
      "step": 48460
    },
    {
      "epoch": 0.155136,
      "grad_norm": 0.10424935559330906,
      "learning_rate": 9.934163454827618e-05,
      "loss": 0.0344,
      "step": 48480
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.06268611257712212,
      "learning_rate": 9.934109242688712e-05,
      "loss": 0.0325,
      "step": 48500
    },
    {
      "epoch": 0.155264,
      "grad_norm": 0.10164583215207992,
      "learning_rate": 9.934055008386939e-05,
      "loss": 0.0309,
      "step": 48520
    },
    {
      "epoch": 0.155328,
      "grad_norm": 0.0466283264623726,
      "learning_rate": 9.93400075192254e-05,
      "loss": 0.029,
      "step": 48540
    },
    {
      "epoch": 0.155392,
      "grad_norm": 0.11685403697332548,
      "learning_rate": 9.933946473295765e-05,
      "loss": 0.0308,
      "step": 48560
    },
    {
      "epoch": 0.155456,
      "grad_norm": 0.07968094236867744,
      "learning_rate": 9.93389217250685e-05,
      "loss": 0.0288,
      "step": 48580
    },
    {
      "epoch": 0.15552,
      "grad_norm": 0.0871747731854775,
      "learning_rate": 9.933837849556047e-05,
      "loss": 0.0309,
      "step": 48600
    },
    {
      "epoch": 0.155584,
      "grad_norm": 0.08585406210884133,
      "learning_rate": 9.933783504443593e-05,
      "loss": 0.0296,
      "step": 48620
    },
    {
      "epoch": 0.155648,
      "grad_norm": 0.07902233622185316,
      "learning_rate": 9.933729137169736e-05,
      "loss": 0.0316,
      "step": 48640
    },
    {
      "epoch": 0.155712,
      "grad_norm": 0.05141512409029975,
      "learning_rate": 9.933674747734719e-05,
      "loss": 0.0292,
      "step": 48660
    },
    {
      "epoch": 0.155776,
      "grad_norm": 0.08580218788197641,
      "learning_rate": 9.933620336138787e-05,
      "loss": 0.0312,
      "step": 48680
    },
    {
      "epoch": 0.15584,
      "grad_norm": 0.1031184942870981,
      "learning_rate": 9.933565902382183e-05,
      "loss": 0.0337,
      "step": 48700
    },
    {
      "epoch": 0.155904,
      "grad_norm": 0.195970797921049,
      "learning_rate": 9.933511446465151e-05,
      "loss": 0.0337,
      "step": 48720
    },
    {
      "epoch": 0.155968,
      "grad_norm": 0.17182881711200834,
      "learning_rate": 9.93345696838794e-05,
      "loss": 0.0313,
      "step": 48740
    },
    {
      "epoch": 0.156032,
      "grad_norm": 0.11188222083980782,
      "learning_rate": 9.93340246815079e-05,
      "loss": 0.0306,
      "step": 48760
    },
    {
      "epoch": 0.156096,
      "grad_norm": 0.08352933439259387,
      "learning_rate": 9.933347945753946e-05,
      "loss": 0.0321,
      "step": 48780
    },
    {
      "epoch": 0.15616,
      "grad_norm": 0.07587366896792365,
      "learning_rate": 9.933293401197657e-05,
      "loss": 0.031,
      "step": 48800
    },
    {
      "epoch": 0.156224,
      "grad_norm": 0.10261290966573956,
      "learning_rate": 9.933238834482164e-05,
      "loss": 0.0318,
      "step": 48820
    },
    {
      "epoch": 0.156288,
      "grad_norm": 0.05857025332956055,
      "learning_rate": 9.933184245607712e-05,
      "loss": 0.0318,
      "step": 48840
    },
    {
      "epoch": 0.156352,
      "grad_norm": 0.08511855904508554,
      "learning_rate": 9.93312963457455e-05,
      "loss": 0.0307,
      "step": 48860
    },
    {
      "epoch": 0.156416,
      "grad_norm": 0.06230406833463281,
      "learning_rate": 9.933075001382921e-05,
      "loss": 0.032,
      "step": 48880
    },
    {
      "epoch": 0.15648,
      "grad_norm": 0.07172964512517768,
      "learning_rate": 9.933020346033068e-05,
      "loss": 0.0317,
      "step": 48900
    },
    {
      "epoch": 0.156544,
      "grad_norm": 0.04747272626907838,
      "learning_rate": 9.932965668525241e-05,
      "loss": 0.0324,
      "step": 48920
    },
    {
      "epoch": 0.156608,
      "grad_norm": 0.10074295129664218,
      "learning_rate": 9.932910968859684e-05,
      "loss": 0.033,
      "step": 48940
    },
    {
      "epoch": 0.156672,
      "grad_norm": 0.06433961268710074,
      "learning_rate": 9.932856247036641e-05,
      "loss": 0.0318,
      "step": 48960
    },
    {
      "epoch": 0.156736,
      "grad_norm": 0.05786985665701216,
      "learning_rate": 9.93280150305636e-05,
      "loss": 0.0318,
      "step": 48980
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.16628679493344883,
      "learning_rate": 9.932746736919083e-05,
      "loss": 0.0346,
      "step": 49000
    },
    {
      "epoch": 0.156864,
      "grad_norm": 0.08000269878384533,
      "learning_rate": 9.932691948625061e-05,
      "loss": 0.0312,
      "step": 49020
    },
    {
      "epoch": 0.156928,
      "grad_norm": 0.13121743849844697,
      "learning_rate": 9.932637138174537e-05,
      "loss": 0.0317,
      "step": 49040
    },
    {
      "epoch": 0.156992,
      "grad_norm": 0.12361098048767018,
      "learning_rate": 9.93258230556776e-05,
      "loss": 0.033,
      "step": 49060
    },
    {
      "epoch": 0.157056,
      "grad_norm": 0.10429858292176185,
      "learning_rate": 9.932527450804973e-05,
      "loss": 0.0337,
      "step": 49080
    },
    {
      "epoch": 0.15712,
      "grad_norm": 0.0647764292036461,
      "learning_rate": 9.932472573886424e-05,
      "loss": 0.0319,
      "step": 49100
    },
    {
      "epoch": 0.157184,
      "grad_norm": 0.09384016399478,
      "learning_rate": 9.93241767481236e-05,
      "loss": 0.0317,
      "step": 49120
    },
    {
      "epoch": 0.157248,
      "grad_norm": 0.12659843442396596,
      "learning_rate": 9.932362753583025e-05,
      "loss": 0.0327,
      "step": 49140
    },
    {
      "epoch": 0.157312,
      "grad_norm": 0.07756448049192011,
      "learning_rate": 9.93230781019867e-05,
      "loss": 0.0296,
      "step": 49160
    },
    {
      "epoch": 0.157376,
      "grad_norm": 0.12804142641185356,
      "learning_rate": 9.932252844659537e-05,
      "loss": 0.0273,
      "step": 49180
    },
    {
      "epoch": 0.15744,
      "grad_norm": 0.06399469639064538,
      "learning_rate": 9.932197856965877e-05,
      "loss": 0.0311,
      "step": 49200
    },
    {
      "epoch": 0.157504,
      "grad_norm": 0.07353854042600966,
      "learning_rate": 9.932142847117936e-05,
      "loss": 0.0318,
      "step": 49220
    },
    {
      "epoch": 0.157568,
      "grad_norm": 0.09335556916903189,
      "learning_rate": 9.932087815115958e-05,
      "loss": 0.0322,
      "step": 49240
    },
    {
      "epoch": 0.157632,
      "grad_norm": 0.07250359823535418,
      "learning_rate": 9.932032760960194e-05,
      "loss": 0.0295,
      "step": 49260
    },
    {
      "epoch": 0.157696,
      "grad_norm": 0.09539354157045841,
      "learning_rate": 9.931977684650889e-05,
      "loss": 0.0329,
      "step": 49280
    },
    {
      "epoch": 0.15776,
      "grad_norm": 0.12241863334999789,
      "learning_rate": 9.931922586188292e-05,
      "loss": 0.0332,
      "step": 49300
    },
    {
      "epoch": 0.157824,
      "grad_norm": 0.09544072927237139,
      "learning_rate": 9.931867465572651e-05,
      "loss": 0.0337,
      "step": 49320
    },
    {
      "epoch": 0.157888,
      "grad_norm": 0.17981690117267587,
      "learning_rate": 9.931812322804211e-05,
      "loss": 0.0313,
      "step": 49340
    },
    {
      "epoch": 0.157952,
      "grad_norm": 0.12717263082414357,
      "learning_rate": 9.931757157883221e-05,
      "loss": 0.0286,
      "step": 49360
    },
    {
      "epoch": 0.158016,
      "grad_norm": 0.08473942921715966,
      "learning_rate": 9.931701970809927e-05,
      "loss": 0.0267,
      "step": 49380
    },
    {
      "epoch": 0.15808,
      "grad_norm": 0.055487440764002215,
      "learning_rate": 9.931646761584581e-05,
      "loss": 0.0287,
      "step": 49400
    },
    {
      "epoch": 0.158144,
      "grad_norm": 0.08651242874729155,
      "learning_rate": 9.93159153020743e-05,
      "loss": 0.0345,
      "step": 49420
    },
    {
      "epoch": 0.158208,
      "grad_norm": 0.0763901865694479,
      "learning_rate": 9.931536276678717e-05,
      "loss": 0.0336,
      "step": 49440
    },
    {
      "epoch": 0.158272,
      "grad_norm": 0.0926115735063431,
      "learning_rate": 9.931481000998697e-05,
      "loss": 0.0343,
      "step": 49460
    },
    {
      "epoch": 0.158336,
      "grad_norm": 0.09649007467061342,
      "learning_rate": 9.931425703167614e-05,
      "loss": 0.0289,
      "step": 49480
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.055147182717572775,
      "learning_rate": 9.931370383185718e-05,
      "loss": 0.0276,
      "step": 49500
    },
    {
      "epoch": 0.158464,
      "grad_norm": 0.08564565453956721,
      "learning_rate": 9.931315041053256e-05,
      "loss": 0.0318,
      "step": 49520
    },
    {
      "epoch": 0.158528,
      "grad_norm": 0.07635713954087532,
      "learning_rate": 9.931259676770479e-05,
      "loss": 0.0323,
      "step": 49540
    },
    {
      "epoch": 0.158592,
      "grad_norm": 0.052007598933735785,
      "learning_rate": 9.931204290337634e-05,
      "loss": 0.0323,
      "step": 49560
    },
    {
      "epoch": 0.158656,
      "grad_norm": 0.07438361683379209,
      "learning_rate": 9.931148881754971e-05,
      "loss": 0.0332,
      "step": 49580
    },
    {
      "epoch": 0.15872,
      "grad_norm": 0.1556976763584939,
      "learning_rate": 9.931093451022735e-05,
      "loss": 0.0338,
      "step": 49600
    },
    {
      "epoch": 0.158784,
      "grad_norm": 0.07751104895192198,
      "learning_rate": 9.931037998141181e-05,
      "loss": 0.0283,
      "step": 49620
    },
    {
      "epoch": 0.158848,
      "grad_norm": 0.11637964142966958,
      "learning_rate": 9.930982523110554e-05,
      "loss": 0.0325,
      "step": 49640
    },
    {
      "epoch": 0.158912,
      "grad_norm": 0.11052488360844216,
      "learning_rate": 9.930927025931105e-05,
      "loss": 0.0321,
      "step": 49660
    },
    {
      "epoch": 0.158976,
      "grad_norm": 0.07835323101756353,
      "learning_rate": 9.930871506603081e-05,
      "loss": 0.0306,
      "step": 49680
    },
    {
      "epoch": 0.15904,
      "grad_norm": 0.0943194225294084,
      "learning_rate": 9.930815965126734e-05,
      "loss": 0.0353,
      "step": 49700
    },
    {
      "epoch": 0.159104,
      "grad_norm": 0.059596079934019,
      "learning_rate": 9.930760401502313e-05,
      "loss": 0.0334,
      "step": 49720
    },
    {
      "epoch": 0.159168,
      "grad_norm": 0.11983798600383945,
      "learning_rate": 9.930704815730066e-05,
      "loss": 0.0329,
      "step": 49740
    },
    {
      "epoch": 0.159232,
      "grad_norm": 0.08806423718862402,
      "learning_rate": 9.930649207810244e-05,
      "loss": 0.0347,
      "step": 49760
    },
    {
      "epoch": 0.159296,
      "grad_norm": 0.12227629251422667,
      "learning_rate": 9.930593577743097e-05,
      "loss": 0.0331,
      "step": 49780
    },
    {
      "epoch": 0.15936,
      "grad_norm": 0.08686716783636916,
      "learning_rate": 9.930537925528874e-05,
      "loss": 0.0305,
      "step": 49800
    },
    {
      "epoch": 0.159424,
      "grad_norm": 0.06346037990121205,
      "learning_rate": 9.930482251167826e-05,
      "loss": 0.0298,
      "step": 49820
    },
    {
      "epoch": 0.159488,
      "grad_norm": 0.08159099411169625,
      "learning_rate": 9.930426554660201e-05,
      "loss": 0.03,
      "step": 49840
    },
    {
      "epoch": 0.159552,
      "grad_norm": 0.09955861551417573,
      "learning_rate": 9.930370836006251e-05,
      "loss": 0.0271,
      "step": 49860
    },
    {
      "epoch": 0.159616,
      "grad_norm": 0.09261095927437955,
      "learning_rate": 9.930315095206226e-05,
      "loss": 0.0326,
      "step": 49880
    },
    {
      "epoch": 0.15968,
      "grad_norm": 0.07297339814073228,
      "learning_rate": 9.930259332260377e-05,
      "loss": 0.0309,
      "step": 49900
    },
    {
      "epoch": 0.159744,
      "grad_norm": 0.06924682230448155,
      "learning_rate": 9.930203547168953e-05,
      "loss": 0.0308,
      "step": 49920
    },
    {
      "epoch": 0.159808,
      "grad_norm": 0.07797906326662384,
      "learning_rate": 9.930147739932204e-05,
      "loss": 0.031,
      "step": 49940
    },
    {
      "epoch": 0.159872,
      "grad_norm": 0.09850170486500891,
      "learning_rate": 9.930091910550384e-05,
      "loss": 0.034,
      "step": 49960
    },
    {
      "epoch": 0.159936,
      "grad_norm": 0.12668685590072776,
      "learning_rate": 9.93003605902374e-05,
      "loss": 0.0304,
      "step": 49980
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.08995334510165826,
      "learning_rate": 9.929980185352526e-05,
      "loss": 0.0317,
      "step": 50000
    },
    {
      "epoch": 0.160064,
      "grad_norm": 0.10484565801052002,
      "learning_rate": 9.929924289536989e-05,
      "loss": 0.0289,
      "step": 50020
    },
    {
      "epoch": 0.160128,
      "grad_norm": 0.06870780139721683,
      "learning_rate": 9.929868371577385e-05,
      "loss": 0.0309,
      "step": 50040
    },
    {
      "epoch": 0.160192,
      "grad_norm": 0.07729315804348545,
      "learning_rate": 9.929812431473962e-05,
      "loss": 0.0315,
      "step": 50060
    },
    {
      "epoch": 0.160256,
      "grad_norm": 0.06636118050927628,
      "learning_rate": 9.929756469226975e-05,
      "loss": 0.0303,
      "step": 50080
    },
    {
      "epoch": 0.16032,
      "grad_norm": 0.06343752170211274,
      "learning_rate": 9.929700484836668e-05,
      "loss": 0.0286,
      "step": 50100
    },
    {
      "epoch": 0.160384,
      "grad_norm": 0.07586865005024584,
      "learning_rate": 9.929644478303299e-05,
      "loss": 0.0316,
      "step": 50120
    },
    {
      "epoch": 0.160448,
      "grad_norm": 0.07388963618816875,
      "learning_rate": 9.929588449627116e-05,
      "loss": 0.0304,
      "step": 50140
    },
    {
      "epoch": 0.160512,
      "grad_norm": 0.15512214275072297,
      "learning_rate": 9.929532398808375e-05,
      "loss": 0.0329,
      "step": 50160
    },
    {
      "epoch": 0.160576,
      "grad_norm": 0.10509976931514123,
      "learning_rate": 9.929476325847322e-05,
      "loss": 0.031,
      "step": 50180
    },
    {
      "epoch": 0.16064,
      "grad_norm": 0.10879812237408239,
      "learning_rate": 9.929420230744214e-05,
      "loss": 0.0309,
      "step": 50200
    },
    {
      "epoch": 0.160704,
      "grad_norm": 0.06640496434008838,
      "learning_rate": 9.9293641134993e-05,
      "loss": 0.0335,
      "step": 50220
    },
    {
      "epoch": 0.160768,
      "grad_norm": 0.0827563420078682,
      "learning_rate": 9.929307974112832e-05,
      "loss": 0.0323,
      "step": 50240
    },
    {
      "epoch": 0.160832,
      "grad_norm": 0.11127909388966875,
      "learning_rate": 9.929251812585062e-05,
      "loss": 0.029,
      "step": 50260
    },
    {
      "epoch": 0.160896,
      "grad_norm": 0.09713906597783596,
      "learning_rate": 9.929195628916246e-05,
      "loss": 0.0302,
      "step": 50280
    },
    {
      "epoch": 0.16096,
      "grad_norm": 0.0723694695822792,
      "learning_rate": 9.929139423106633e-05,
      "loss": 0.031,
      "step": 50300
    },
    {
      "epoch": 0.161024,
      "grad_norm": 0.0964101822993798,
      "learning_rate": 9.929083195156475e-05,
      "loss": 0.0312,
      "step": 50320
    },
    {
      "epoch": 0.161088,
      "grad_norm": 0.07051873461660252,
      "learning_rate": 9.929026945066025e-05,
      "loss": 0.0332,
      "step": 50340
    },
    {
      "epoch": 0.161152,
      "grad_norm": 0.09414106429200186,
      "learning_rate": 9.928970672835538e-05,
      "loss": 0.0313,
      "step": 50360
    },
    {
      "epoch": 0.161216,
      "grad_norm": 0.11772716243594701,
      "learning_rate": 9.928914378465263e-05,
      "loss": 0.0345,
      "step": 50380
    },
    {
      "epoch": 0.16128,
      "grad_norm": 0.07461705641114656,
      "learning_rate": 9.928858061955457e-05,
      "loss": 0.0306,
      "step": 50400
    },
    {
      "epoch": 0.161344,
      "grad_norm": 0.16689222510905194,
      "learning_rate": 9.92880172330637e-05,
      "loss": 0.03,
      "step": 50420
    },
    {
      "epoch": 0.161408,
      "grad_norm": 0.07913562416839212,
      "learning_rate": 9.928745362518256e-05,
      "loss": 0.0301,
      "step": 50440
    },
    {
      "epoch": 0.161472,
      "grad_norm": 0.050300774448710464,
      "learning_rate": 9.928688979591368e-05,
      "loss": 0.029,
      "step": 50460
    },
    {
      "epoch": 0.161536,
      "grad_norm": 0.08429781116475236,
      "learning_rate": 9.92863257452596e-05,
      "loss": 0.0276,
      "step": 50480
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.11099378024299517,
      "learning_rate": 9.928576147322284e-05,
      "loss": 0.031,
      "step": 50500
    },
    {
      "epoch": 0.161664,
      "grad_norm": 0.10813686447975093,
      "learning_rate": 9.928519697980594e-05,
      "loss": 0.031,
      "step": 50520
    },
    {
      "epoch": 0.161728,
      "grad_norm": 0.0685192254157951,
      "learning_rate": 9.928463226501143e-05,
      "loss": 0.0266,
      "step": 50540
    },
    {
      "epoch": 0.161792,
      "grad_norm": 0.06863719815742642,
      "learning_rate": 9.928406732884188e-05,
      "loss": 0.0342,
      "step": 50560
    },
    {
      "epoch": 0.161856,
      "grad_norm": 0.08230820340311004,
      "learning_rate": 9.928350217129977e-05,
      "loss": 0.0326,
      "step": 50580
    },
    {
      "epoch": 0.16192,
      "grad_norm": 0.06509154971910303,
      "learning_rate": 9.92829367923877e-05,
      "loss": 0.0312,
      "step": 50600
    },
    {
      "epoch": 0.161984,
      "grad_norm": 0.11518141006203565,
      "learning_rate": 9.928237119210815e-05,
      "loss": 0.0314,
      "step": 50620
    },
    {
      "epoch": 0.162048,
      "grad_norm": 0.09876785991501875,
      "learning_rate": 9.92818053704637e-05,
      "loss": 0.0324,
      "step": 50640
    },
    {
      "epoch": 0.162112,
      "grad_norm": 0.0892518642207428,
      "learning_rate": 9.92812393274569e-05,
      "loss": 0.0347,
      "step": 50660
    },
    {
      "epoch": 0.162176,
      "grad_norm": 0.07550052485582388,
      "learning_rate": 9.928067306309026e-05,
      "loss": 0.034,
      "step": 50680
    },
    {
      "epoch": 0.16224,
      "grad_norm": 0.06482135585403946,
      "learning_rate": 9.928010657736633e-05,
      "loss": 0.0366,
      "step": 50700
    },
    {
      "epoch": 0.162304,
      "grad_norm": 0.16458258672769438,
      "learning_rate": 9.927953987028767e-05,
      "loss": 0.0323,
      "step": 50720
    },
    {
      "epoch": 0.162368,
      "grad_norm": 0.10358684245956191,
      "learning_rate": 9.927897294185682e-05,
      "loss": 0.0317,
      "step": 50740
    },
    {
      "epoch": 0.162432,
      "grad_norm": 0.14390584348464086,
      "learning_rate": 9.927840579207633e-05,
      "loss": 0.0291,
      "step": 50760
    },
    {
      "epoch": 0.162496,
      "grad_norm": 0.06543715676469103,
      "learning_rate": 9.927783842094872e-05,
      "loss": 0.0295,
      "step": 50780
    },
    {
      "epoch": 0.16256,
      "grad_norm": 0.07231833572505786,
      "learning_rate": 9.927727082847658e-05,
      "loss": 0.0318,
      "step": 50800
    },
    {
      "epoch": 0.162624,
      "grad_norm": 0.09524849656835833,
      "learning_rate": 9.927670301466244e-05,
      "loss": 0.0306,
      "step": 50820
    },
    {
      "epoch": 0.162688,
      "grad_norm": 0.19935645305316482,
      "learning_rate": 9.927613497950883e-05,
      "loss": 0.0326,
      "step": 50840
    },
    {
      "epoch": 0.162752,
      "grad_norm": 0.0680535305092903,
      "learning_rate": 9.927556672301834e-05,
      "loss": 0.0312,
      "step": 50860
    },
    {
      "epoch": 0.162816,
      "grad_norm": 0.08080350899695349,
      "learning_rate": 9.927499824519348e-05,
      "loss": 0.0363,
      "step": 50880
    },
    {
      "epoch": 0.16288,
      "grad_norm": 0.14849199161636034,
      "learning_rate": 9.927442954603685e-05,
      "loss": 0.0393,
      "step": 50900
    },
    {
      "epoch": 0.162944,
      "grad_norm": 0.14972292155397732,
      "learning_rate": 9.927386062555099e-05,
      "loss": 0.0321,
      "step": 50920
    },
    {
      "epoch": 0.163008,
      "grad_norm": 0.10823737414139363,
      "learning_rate": 9.927329148373843e-05,
      "loss": 0.0292,
      "step": 50940
    },
    {
      "epoch": 0.163072,
      "grad_norm": 0.09126033619025652,
      "learning_rate": 9.927272212060175e-05,
      "loss": 0.0344,
      "step": 50960
    },
    {
      "epoch": 0.163136,
      "grad_norm": 0.07754175292339982,
      "learning_rate": 9.92721525361435e-05,
      "loss": 0.0334,
      "step": 50980
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.10516637252121326,
      "learning_rate": 9.927158273036625e-05,
      "loss": 0.0327,
      "step": 51000
    },
    {
      "epoch": 0.163264,
      "grad_norm": 0.13199644513495773,
      "learning_rate": 9.927101270327252e-05,
      "loss": 0.0335,
      "step": 51020
    },
    {
      "epoch": 0.163328,
      "grad_norm": 0.06694751698605156,
      "learning_rate": 9.927044245486492e-05,
      "loss": 0.032,
      "step": 51040
    },
    {
      "epoch": 0.163392,
      "grad_norm": 0.08706794643911839,
      "learning_rate": 9.9269871985146e-05,
      "loss": 0.0296,
      "step": 51060
    },
    {
      "epoch": 0.163456,
      "grad_norm": 0.06883197814459027,
      "learning_rate": 9.92693012941183e-05,
      "loss": 0.031,
      "step": 51080
    },
    {
      "epoch": 0.16352,
      "grad_norm": 0.14265238195938584,
      "learning_rate": 9.926873038178439e-05,
      "loss": 0.0312,
      "step": 51100
    },
    {
      "epoch": 0.163584,
      "grad_norm": 0.08199550221964322,
      "learning_rate": 9.926815924814687e-05,
      "loss": 0.032,
      "step": 51120
    },
    {
      "epoch": 0.163648,
      "grad_norm": 0.1286889855575657,
      "learning_rate": 9.926758789320825e-05,
      "loss": 0.0325,
      "step": 51140
    },
    {
      "epoch": 0.163712,
      "grad_norm": 0.17403492446015967,
      "learning_rate": 9.926701631697113e-05,
      "loss": 0.0319,
      "step": 51160
    },
    {
      "epoch": 0.163776,
      "grad_norm": 0.07470681568472168,
      "learning_rate": 9.926644451943807e-05,
      "loss": 0.0282,
      "step": 51180
    },
    {
      "epoch": 0.16384,
      "grad_norm": 0.09782699404728386,
      "learning_rate": 9.926587250061164e-05,
      "loss": 0.0283,
      "step": 51200
    },
    {
      "epoch": 0.163904,
      "grad_norm": 0.06487118520912383,
      "learning_rate": 9.926530026049441e-05,
      "loss": 0.029,
      "step": 51220
    },
    {
      "epoch": 0.163968,
      "grad_norm": 0.08146092177938395,
      "learning_rate": 9.926472779908896e-05,
      "loss": 0.0314,
      "step": 51240
    },
    {
      "epoch": 0.164032,
      "grad_norm": 0.10401449778480971,
      "learning_rate": 9.926415511639783e-05,
      "loss": 0.0321,
      "step": 51260
    },
    {
      "epoch": 0.164096,
      "grad_norm": 0.06450719894636027,
      "learning_rate": 9.926358221242362e-05,
      "loss": 0.0295,
      "step": 51280
    },
    {
      "epoch": 0.16416,
      "grad_norm": 0.07639253295228808,
      "learning_rate": 9.926300908716889e-05,
      "loss": 0.0326,
      "step": 51300
    },
    {
      "epoch": 0.164224,
      "grad_norm": 0.07906989813952332,
      "learning_rate": 9.926243574063623e-05,
      "loss": 0.033,
      "step": 51320
    },
    {
      "epoch": 0.164288,
      "grad_norm": 0.1218135693052076,
      "learning_rate": 9.92618621728282e-05,
      "loss": 0.0332,
      "step": 51340
    },
    {
      "epoch": 0.164352,
      "grad_norm": 0.0648113099023763,
      "learning_rate": 9.926128838374738e-05,
      "loss": 0.0295,
      "step": 51360
    },
    {
      "epoch": 0.164416,
      "grad_norm": 0.07123555000472492,
      "learning_rate": 9.926071437339634e-05,
      "loss": 0.0271,
      "step": 51380
    },
    {
      "epoch": 0.16448,
      "grad_norm": 0.0696346716827423,
      "learning_rate": 9.92601401417777e-05,
      "loss": 0.0325,
      "step": 51400
    },
    {
      "epoch": 0.164544,
      "grad_norm": 0.10624430299885847,
      "learning_rate": 9.925956568889397e-05,
      "loss": 0.0362,
      "step": 51420
    },
    {
      "epoch": 0.164608,
      "grad_norm": 0.11595614242976489,
      "learning_rate": 9.925899101474778e-05,
      "loss": 0.0302,
      "step": 51440
    },
    {
      "epoch": 0.164672,
      "grad_norm": 0.08169263192304588,
      "learning_rate": 9.92584161193417e-05,
      "loss": 0.0311,
      "step": 51460
    },
    {
      "epoch": 0.164736,
      "grad_norm": 0.10775947598176998,
      "learning_rate": 9.925784100267832e-05,
      "loss": 0.0322,
      "step": 51480
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.07657609166749417,
      "learning_rate": 9.92572656647602e-05,
      "loss": 0.0308,
      "step": 51500
    },
    {
      "epoch": 0.164864,
      "grad_norm": 0.09146354766575497,
      "learning_rate": 9.925669010558994e-05,
      "loss": 0.0332,
      "step": 51520
    },
    {
      "epoch": 0.164928,
      "grad_norm": 0.10038750166039168,
      "learning_rate": 9.925611432517013e-05,
      "loss": 0.0312,
      "step": 51540
    },
    {
      "epoch": 0.164992,
      "grad_norm": 0.13152276685572026,
      "learning_rate": 9.925553832350335e-05,
      "loss": 0.0336,
      "step": 51560
    },
    {
      "epoch": 0.165056,
      "grad_norm": 0.07257892834662695,
      "learning_rate": 9.925496210059217e-05,
      "loss": 0.034,
      "step": 51580
    },
    {
      "epoch": 0.16512,
      "grad_norm": 0.1368160087000327,
      "learning_rate": 9.925438565643922e-05,
      "loss": 0.0318,
      "step": 51600
    },
    {
      "epoch": 0.165184,
      "grad_norm": 0.10509608417678797,
      "learning_rate": 9.925380899104706e-05,
      "loss": 0.0317,
      "step": 51620
    },
    {
      "epoch": 0.165248,
      "grad_norm": 0.10170376891373777,
      "learning_rate": 9.925323210441827e-05,
      "loss": 0.0309,
      "step": 51640
    },
    {
      "epoch": 0.165312,
      "grad_norm": 0.06544655377744597,
      "learning_rate": 9.925265499655547e-05,
      "loss": 0.0334,
      "step": 51660
    },
    {
      "epoch": 0.165376,
      "grad_norm": 0.06503813536977048,
      "learning_rate": 9.925207766746123e-05,
      "loss": 0.032,
      "step": 51680
    },
    {
      "epoch": 0.16544,
      "grad_norm": 0.05718428299776666,
      "learning_rate": 9.925150011713815e-05,
      "loss": 0.0308,
      "step": 51700
    },
    {
      "epoch": 0.165504,
      "grad_norm": 0.08339893608014584,
      "learning_rate": 9.925092234558882e-05,
      "loss": 0.0307,
      "step": 51720
    },
    {
      "epoch": 0.165568,
      "grad_norm": 0.10773249539027138,
      "learning_rate": 9.925034435281586e-05,
      "loss": 0.032,
      "step": 51740
    },
    {
      "epoch": 0.165632,
      "grad_norm": 0.07801557840251831,
      "learning_rate": 9.924976613882183e-05,
      "loss": 0.0285,
      "step": 51760
    },
    {
      "epoch": 0.165696,
      "grad_norm": 0.05561458972447706,
      "learning_rate": 9.924918770360935e-05,
      "loss": 0.0293,
      "step": 51780
    },
    {
      "epoch": 0.16576,
      "grad_norm": 0.1022244361708253,
      "learning_rate": 9.924860904718101e-05,
      "loss": 0.0271,
      "step": 51800
    },
    {
      "epoch": 0.165824,
      "grad_norm": 0.07001538775612266,
      "learning_rate": 9.924803016953942e-05,
      "loss": 0.0294,
      "step": 51820
    },
    {
      "epoch": 0.165888,
      "grad_norm": 0.10252383668519809,
      "learning_rate": 9.924745107068716e-05,
      "loss": 0.0333,
      "step": 51840
    },
    {
      "epoch": 0.165952,
      "grad_norm": 0.10561463285844534,
      "learning_rate": 9.924687175062686e-05,
      "loss": 0.0376,
      "step": 51860
    },
    {
      "epoch": 0.166016,
      "grad_norm": 0.07482436166623027,
      "learning_rate": 9.924629220936108e-05,
      "loss": 0.0327,
      "step": 51880
    },
    {
      "epoch": 0.16608,
      "grad_norm": 0.06785578315135021,
      "learning_rate": 9.924571244689247e-05,
      "loss": 0.0278,
      "step": 51900
    },
    {
      "epoch": 0.166144,
      "grad_norm": 0.08702415576792027,
      "learning_rate": 9.92451324632236e-05,
      "loss": 0.0308,
      "step": 51920
    },
    {
      "epoch": 0.166208,
      "grad_norm": 0.06905621349735323,
      "learning_rate": 9.924455225835709e-05,
      "loss": 0.0346,
      "step": 51940
    },
    {
      "epoch": 0.166272,
      "grad_norm": 0.08197492519966695,
      "learning_rate": 9.924397183229556e-05,
      "loss": 0.0332,
      "step": 51960
    },
    {
      "epoch": 0.166336,
      "grad_norm": 0.21338512474612942,
      "learning_rate": 9.924339118504158e-05,
      "loss": 0.0321,
      "step": 51980
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.14102681187289734,
      "learning_rate": 9.92428103165978e-05,
      "loss": 0.0356,
      "step": 52000
    },
    {
      "epoch": 0.166464,
      "grad_norm": 0.10183137664835576,
      "learning_rate": 9.924222922696678e-05,
      "loss": 0.0331,
      "step": 52020
    },
    {
      "epoch": 0.166528,
      "grad_norm": 0.13725531938837807,
      "learning_rate": 9.924164791615119e-05,
      "loss": 0.0333,
      "step": 52040
    },
    {
      "epoch": 0.166592,
      "grad_norm": 0.08604272771775957,
      "learning_rate": 9.924106638415358e-05,
      "loss": 0.0297,
      "step": 52060
    },
    {
      "epoch": 0.166656,
      "grad_norm": 0.12455713972365082,
      "learning_rate": 9.92404846309766e-05,
      "loss": 0.0306,
      "step": 52080
    },
    {
      "epoch": 0.16672,
      "grad_norm": 0.10586638057793347,
      "learning_rate": 9.923990265662286e-05,
      "loss": 0.0299,
      "step": 52100
    },
    {
      "epoch": 0.166784,
      "grad_norm": 0.09354331096569239,
      "learning_rate": 9.923932046109496e-05,
      "loss": 0.0292,
      "step": 52120
    },
    {
      "epoch": 0.166848,
      "grad_norm": 0.0725808832422317,
      "learning_rate": 9.923873804439554e-05,
      "loss": 0.0279,
      "step": 52140
    },
    {
      "epoch": 0.166912,
      "grad_norm": 0.0930606813308102,
      "learning_rate": 9.923815540652719e-05,
      "loss": 0.0322,
      "step": 52160
    },
    {
      "epoch": 0.166976,
      "grad_norm": 0.07966735750716024,
      "learning_rate": 9.923757254749254e-05,
      "loss": 0.0336,
      "step": 52180
    },
    {
      "epoch": 0.16704,
      "grad_norm": 0.11952993988819609,
      "learning_rate": 9.92369894672942e-05,
      "loss": 0.0307,
      "step": 52200
    },
    {
      "epoch": 0.167104,
      "grad_norm": 0.08336947137503813,
      "learning_rate": 9.92364061659348e-05,
      "loss": 0.0336,
      "step": 52220
    },
    {
      "epoch": 0.167168,
      "grad_norm": 0.06809469975476605,
      "learning_rate": 9.923582264341695e-05,
      "loss": 0.0303,
      "step": 52240
    },
    {
      "epoch": 0.167232,
      "grad_norm": 0.07866981825638819,
      "learning_rate": 9.923523889974327e-05,
      "loss": 0.0309,
      "step": 52260
    },
    {
      "epoch": 0.167296,
      "grad_norm": 0.10143591042860282,
      "learning_rate": 9.923465493491639e-05,
      "loss": 0.0334,
      "step": 52280
    },
    {
      "epoch": 0.16736,
      "grad_norm": 0.09757361316801456,
      "learning_rate": 9.923407074893894e-05,
      "loss": 0.0293,
      "step": 52300
    },
    {
      "epoch": 0.167424,
      "grad_norm": 0.10434374813917567,
      "learning_rate": 9.923348634181353e-05,
      "loss": 0.0264,
      "step": 52320
    },
    {
      "epoch": 0.167488,
      "grad_norm": 0.06820094614970226,
      "learning_rate": 9.92329017135428e-05,
      "loss": 0.0313,
      "step": 52340
    },
    {
      "epoch": 0.167552,
      "grad_norm": 0.09077555361309897,
      "learning_rate": 9.923231686412935e-05,
      "loss": 0.0289,
      "step": 52360
    },
    {
      "epoch": 0.167616,
      "grad_norm": 0.055018866253847214,
      "learning_rate": 9.923173179357581e-05,
      "loss": 0.0298,
      "step": 52380
    },
    {
      "epoch": 0.16768,
      "grad_norm": 0.11484318921072584,
      "learning_rate": 9.923114650188484e-05,
      "loss": 0.0339,
      "step": 52400
    },
    {
      "epoch": 0.167744,
      "grad_norm": 0.08856312616907716,
      "learning_rate": 9.923056098905905e-05,
      "loss": 0.0313,
      "step": 52420
    },
    {
      "epoch": 0.167808,
      "grad_norm": 0.08663006417387209,
      "learning_rate": 9.922997525510106e-05,
      "loss": 0.0304,
      "step": 52440
    },
    {
      "epoch": 0.167872,
      "grad_norm": 0.1077835338482995,
      "learning_rate": 9.922938930001351e-05,
      "loss": 0.0336,
      "step": 52460
    },
    {
      "epoch": 0.167936,
      "grad_norm": 0.08136703202548481,
      "learning_rate": 9.922880312379904e-05,
      "loss": 0.0323,
      "step": 52480
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.058970828083442985,
      "learning_rate": 9.922821672646027e-05,
      "loss": 0.0314,
      "step": 52500
    },
    {
      "epoch": 0.168064,
      "grad_norm": 0.08772403564825054,
      "learning_rate": 9.922763010799985e-05,
      "loss": 0.0306,
      "step": 52520
    },
    {
      "epoch": 0.168128,
      "grad_norm": 0.07579732349258023,
      "learning_rate": 9.922704326842039e-05,
      "loss": 0.0322,
      "step": 52540
    },
    {
      "epoch": 0.168192,
      "grad_norm": 0.05756871733740165,
      "learning_rate": 9.922645620772455e-05,
      "loss": 0.0353,
      "step": 52560
    },
    {
      "epoch": 0.168256,
      "grad_norm": 0.08309827407855326,
      "learning_rate": 9.922586892591494e-05,
      "loss": 0.0303,
      "step": 52580
    },
    {
      "epoch": 0.16832,
      "grad_norm": 0.1815933671476109,
      "learning_rate": 9.922528142299423e-05,
      "loss": 0.0326,
      "step": 52600
    },
    {
      "epoch": 0.168384,
      "grad_norm": 0.06510824172518967,
      "learning_rate": 9.922469369896505e-05,
      "loss": 0.0308,
      "step": 52620
    },
    {
      "epoch": 0.168448,
      "grad_norm": 0.07414921551709572,
      "learning_rate": 9.922410575383002e-05,
      "loss": 0.0303,
      "step": 52640
    },
    {
      "epoch": 0.168512,
      "grad_norm": 0.07015495544418383,
      "learning_rate": 9.92235175875918e-05,
      "loss": 0.0322,
      "step": 52660
    },
    {
      "epoch": 0.168576,
      "grad_norm": 0.0687650193427961,
      "learning_rate": 9.922292920025302e-05,
      "loss": 0.0333,
      "step": 52680
    },
    {
      "epoch": 0.16864,
      "grad_norm": 0.09827637358485757,
      "learning_rate": 9.922234059181634e-05,
      "loss": 0.0304,
      "step": 52700
    },
    {
      "epoch": 0.168704,
      "grad_norm": 0.12755071227545084,
      "learning_rate": 9.922175176228439e-05,
      "loss": 0.032,
      "step": 52720
    },
    {
      "epoch": 0.168768,
      "grad_norm": 0.08182040432494203,
      "learning_rate": 9.922116271165982e-05,
      "loss": 0.0287,
      "step": 52740
    },
    {
      "epoch": 0.168832,
      "grad_norm": 0.06708263020012792,
      "learning_rate": 9.922057343994527e-05,
      "loss": 0.0298,
      "step": 52760
    },
    {
      "epoch": 0.168896,
      "grad_norm": 0.10054394998860977,
      "learning_rate": 9.92199839471434e-05,
      "loss": 0.0345,
      "step": 52780
    },
    {
      "epoch": 0.16896,
      "grad_norm": 0.10441608313800908,
      "learning_rate": 9.921939423325684e-05,
      "loss": 0.0326,
      "step": 52800
    },
    {
      "epoch": 0.169024,
      "grad_norm": 0.08138901035339302,
      "learning_rate": 9.921880429828823e-05,
      "loss": 0.0289,
      "step": 52820
    },
    {
      "epoch": 0.169088,
      "grad_norm": 0.0789155974650951,
      "learning_rate": 9.921821414224026e-05,
      "loss": 0.0309,
      "step": 52840
    },
    {
      "epoch": 0.169152,
      "grad_norm": 0.07992279146282948,
      "learning_rate": 9.921762376511556e-05,
      "loss": 0.0286,
      "step": 52860
    },
    {
      "epoch": 0.169216,
      "grad_norm": 0.1701725206408709,
      "learning_rate": 9.921703316691677e-05,
      "loss": 0.03,
      "step": 52880
    },
    {
      "epoch": 0.16928,
      "grad_norm": 0.06538783949958216,
      "learning_rate": 9.921644234764657e-05,
      "loss": 0.0314,
      "step": 52900
    },
    {
      "epoch": 0.169344,
      "grad_norm": 0.07255474742041096,
      "learning_rate": 9.921585130730757e-05,
      "loss": 0.0274,
      "step": 52920
    },
    {
      "epoch": 0.169408,
      "grad_norm": 0.06842028176915492,
      "learning_rate": 9.921526004590247e-05,
      "loss": 0.03,
      "step": 52940
    },
    {
      "epoch": 0.169472,
      "grad_norm": 0.06264157629722407,
      "learning_rate": 9.92146685634339e-05,
      "loss": 0.0296,
      "step": 52960
    },
    {
      "epoch": 0.169536,
      "grad_norm": 0.06578209545573395,
      "learning_rate": 9.921407685990454e-05,
      "loss": 0.0301,
      "step": 52980
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.06465399115817935,
      "learning_rate": 9.921348493531701e-05,
      "loss": 0.0337,
      "step": 53000
    },
    {
      "epoch": 0.169664,
      "grad_norm": 0.13783237396821904,
      "learning_rate": 9.9212892789674e-05,
      "loss": 0.0294,
      "step": 53020
    },
    {
      "epoch": 0.169728,
      "grad_norm": 0.08357696760383225,
      "learning_rate": 9.921230042297817e-05,
      "loss": 0.0301,
      "step": 53040
    },
    {
      "epoch": 0.169792,
      "grad_norm": 0.08087643276662872,
      "learning_rate": 9.921170783523217e-05,
      "loss": 0.0327,
      "step": 53060
    },
    {
      "epoch": 0.169856,
      "grad_norm": 0.09223140281830625,
      "learning_rate": 9.921111502643865e-05,
      "loss": 0.0296,
      "step": 53080
    },
    {
      "epoch": 0.16992,
      "grad_norm": 0.05906062928301391,
      "learning_rate": 9.92105219966003e-05,
      "loss": 0.0314,
      "step": 53100
    },
    {
      "epoch": 0.169984,
      "grad_norm": 0.12985854919588832,
      "learning_rate": 9.920992874571977e-05,
      "loss": 0.0325,
      "step": 53120
    },
    {
      "epoch": 0.170048,
      "grad_norm": 0.08750609966692707,
      "learning_rate": 9.920933527379972e-05,
      "loss": 0.0279,
      "step": 53140
    },
    {
      "epoch": 0.170112,
      "grad_norm": 0.07849605157123798,
      "learning_rate": 9.920874158084281e-05,
      "loss": 0.0326,
      "step": 53160
    },
    {
      "epoch": 0.170176,
      "grad_norm": 0.09121358165961127,
      "learning_rate": 9.920814766685173e-05,
      "loss": 0.0315,
      "step": 53180
    },
    {
      "epoch": 0.17024,
      "grad_norm": 0.10040733623485716,
      "learning_rate": 9.920755353182912e-05,
      "loss": 0.0315,
      "step": 53200
    },
    {
      "epoch": 0.170304,
      "grad_norm": 0.06949009751419008,
      "learning_rate": 9.920695917577768e-05,
      "loss": 0.0312,
      "step": 53220
    },
    {
      "epoch": 0.170368,
      "grad_norm": 0.05668613443243568,
      "learning_rate": 9.920636459870005e-05,
      "loss": 0.0286,
      "step": 53240
    },
    {
      "epoch": 0.170432,
      "grad_norm": 0.118834320576583,
      "learning_rate": 9.920576980059893e-05,
      "loss": 0.0321,
      "step": 53260
    },
    {
      "epoch": 0.170496,
      "grad_norm": 0.11491425204814783,
      "learning_rate": 9.920517478147697e-05,
      "loss": 0.0318,
      "step": 53280
    },
    {
      "epoch": 0.17056,
      "grad_norm": 0.10130748213778534,
      "learning_rate": 9.920457954133684e-05,
      "loss": 0.0297,
      "step": 53300
    },
    {
      "epoch": 0.170624,
      "grad_norm": 0.0788841689387144,
      "learning_rate": 9.920398408018121e-05,
      "loss": 0.0307,
      "step": 53320
    },
    {
      "epoch": 0.170688,
      "grad_norm": 0.0750577109503732,
      "learning_rate": 9.92033883980128e-05,
      "loss": 0.0292,
      "step": 53340
    },
    {
      "epoch": 0.170752,
      "grad_norm": 0.0798979323047073,
      "learning_rate": 9.920279249483423e-05,
      "loss": 0.0326,
      "step": 53360
    },
    {
      "epoch": 0.170816,
      "grad_norm": 0.11861375265083017,
      "learning_rate": 9.920219637064821e-05,
      "loss": 0.0347,
      "step": 53380
    },
    {
      "epoch": 0.17088,
      "grad_norm": 0.07042137370283622,
      "learning_rate": 9.92016000254574e-05,
      "loss": 0.0332,
      "step": 53400
    },
    {
      "epoch": 0.170944,
      "grad_norm": 0.06976735506517781,
      "learning_rate": 9.920100345926448e-05,
      "loss": 0.0305,
      "step": 53420
    },
    {
      "epoch": 0.171008,
      "grad_norm": 0.09884066168152919,
      "learning_rate": 9.920040667207213e-05,
      "loss": 0.0311,
      "step": 53440
    },
    {
      "epoch": 0.171072,
      "grad_norm": 0.08957776902647491,
      "learning_rate": 9.919980966388304e-05,
      "loss": 0.0307,
      "step": 53460
    },
    {
      "epoch": 0.171136,
      "grad_norm": 0.14311288846498768,
      "learning_rate": 9.91992124346999e-05,
      "loss": 0.035,
      "step": 53480
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.07460503999188918,
      "learning_rate": 9.919861498452538e-05,
      "loss": 0.0306,
      "step": 53500
    },
    {
      "epoch": 0.171264,
      "grad_norm": 0.06371043305198766,
      "learning_rate": 9.919801731336215e-05,
      "loss": 0.0308,
      "step": 53520
    },
    {
      "epoch": 0.171328,
      "grad_norm": 0.0604285323046146,
      "learning_rate": 9.919741942121291e-05,
      "loss": 0.0312,
      "step": 53540
    },
    {
      "epoch": 0.171392,
      "grad_norm": 0.15143559458314848,
      "learning_rate": 9.919682130808035e-05,
      "loss": 0.0368,
      "step": 53560
    },
    {
      "epoch": 0.171456,
      "grad_norm": 0.06755668370527207,
      "learning_rate": 9.919622297396715e-05,
      "loss": 0.0347,
      "step": 53580
    },
    {
      "epoch": 0.17152,
      "grad_norm": 0.09883448013475127,
      "learning_rate": 9.9195624418876e-05,
      "loss": 0.0348,
      "step": 53600
    },
    {
      "epoch": 0.171584,
      "grad_norm": 0.06019099759944975,
      "learning_rate": 9.919502564280959e-05,
      "loss": 0.0335,
      "step": 53620
    },
    {
      "epoch": 0.171648,
      "grad_norm": 0.06525881854863104,
      "learning_rate": 9.919442664577058e-05,
      "loss": 0.0312,
      "step": 53640
    },
    {
      "epoch": 0.171712,
      "grad_norm": 0.08938804091826309,
      "learning_rate": 9.919382742776171e-05,
      "loss": 0.0292,
      "step": 53660
    },
    {
      "epoch": 0.171776,
      "grad_norm": 0.06703141282332108,
      "learning_rate": 9.919322798878563e-05,
      "loss": 0.0296,
      "step": 53680
    },
    {
      "epoch": 0.17184,
      "grad_norm": 0.05385434367129899,
      "learning_rate": 9.919262832884506e-05,
      "loss": 0.0275,
      "step": 53700
    },
    {
      "epoch": 0.171904,
      "grad_norm": 0.07286080154617536,
      "learning_rate": 9.919202844794269e-05,
      "loss": 0.0325,
      "step": 53720
    },
    {
      "epoch": 0.171968,
      "grad_norm": 0.13276363650132328,
      "learning_rate": 9.91914283460812e-05,
      "loss": 0.0307,
      "step": 53740
    },
    {
      "epoch": 0.172032,
      "grad_norm": 0.08132489743893076,
      "learning_rate": 9.91908280232633e-05,
      "loss": 0.0324,
      "step": 53760
    },
    {
      "epoch": 0.172096,
      "grad_norm": 0.12442817663886427,
      "learning_rate": 9.919022747949167e-05,
      "loss": 0.0305,
      "step": 53780
    },
    {
      "epoch": 0.17216,
      "grad_norm": 0.08397710068764623,
      "learning_rate": 9.918962671476903e-05,
      "loss": 0.031,
      "step": 53800
    },
    {
      "epoch": 0.172224,
      "grad_norm": 0.11539759790231466,
      "learning_rate": 9.918902572909807e-05,
      "loss": 0.0339,
      "step": 53820
    },
    {
      "epoch": 0.172288,
      "grad_norm": 0.05674429708565355,
      "learning_rate": 9.918842452248147e-05,
      "loss": 0.033,
      "step": 53840
    },
    {
      "epoch": 0.172352,
      "grad_norm": 0.11328900164746662,
      "learning_rate": 9.918782309492196e-05,
      "loss": 0.0298,
      "step": 53860
    },
    {
      "epoch": 0.172416,
      "grad_norm": 0.09390005756066026,
      "learning_rate": 9.918722144642223e-05,
      "loss": 0.0315,
      "step": 53880
    },
    {
      "epoch": 0.17248,
      "grad_norm": 0.06626530414951148,
      "learning_rate": 9.918661957698497e-05,
      "loss": 0.0327,
      "step": 53900
    },
    {
      "epoch": 0.172544,
      "grad_norm": 0.1860125245592864,
      "learning_rate": 9.918601748661289e-05,
      "loss": 0.0335,
      "step": 53920
    },
    {
      "epoch": 0.172608,
      "grad_norm": 0.0771748055697441,
      "learning_rate": 9.91854151753087e-05,
      "loss": 0.031,
      "step": 53940
    },
    {
      "epoch": 0.172672,
      "grad_norm": 0.10082282265842987,
      "learning_rate": 9.918481264307512e-05,
      "loss": 0.0327,
      "step": 53960
    },
    {
      "epoch": 0.172736,
      "grad_norm": 0.11034141211176166,
      "learning_rate": 9.918420988991483e-05,
      "loss": 0.0328,
      "step": 53980
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.09128214605362321,
      "learning_rate": 9.918360691583056e-05,
      "loss": 0.0325,
      "step": 54000
    },
    {
      "epoch": 0.172864,
      "grad_norm": 0.09015722078925593,
      "learning_rate": 9.918300372082499e-05,
      "loss": 0.0297,
      "step": 54020
    },
    {
      "epoch": 0.172928,
      "grad_norm": 0.0710194023491567,
      "learning_rate": 9.918240030490084e-05,
      "loss": 0.0306,
      "step": 54040
    },
    {
      "epoch": 0.172992,
      "grad_norm": 0.12552794552149327,
      "learning_rate": 9.918179666806084e-05,
      "loss": 0.0332,
      "step": 54060
    },
    {
      "epoch": 0.173056,
      "grad_norm": 0.09017113151744216,
      "learning_rate": 9.918119281030766e-05,
      "loss": 0.0357,
      "step": 54080
    },
    {
      "epoch": 0.17312,
      "grad_norm": 0.10253985128926699,
      "learning_rate": 9.918058873164408e-05,
      "loss": 0.0327,
      "step": 54100
    },
    {
      "epoch": 0.173184,
      "grad_norm": 0.09813362396155446,
      "learning_rate": 9.917998443207275e-05,
      "loss": 0.0302,
      "step": 54120
    },
    {
      "epoch": 0.173248,
      "grad_norm": 0.08933503040913926,
      "learning_rate": 9.91793799115964e-05,
      "loss": 0.0276,
      "step": 54140
    },
    {
      "epoch": 0.173312,
      "grad_norm": 0.19420673151881498,
      "learning_rate": 9.917877517021777e-05,
      "loss": 0.03,
      "step": 54160
    },
    {
      "epoch": 0.173376,
      "grad_norm": 0.09490862421460453,
      "learning_rate": 9.917817020793956e-05,
      "loss": 0.0318,
      "step": 54180
    },
    {
      "epoch": 0.17344,
      "grad_norm": 0.05281978002721933,
      "learning_rate": 9.917756502476447e-05,
      "loss": 0.0338,
      "step": 54200
    },
    {
      "epoch": 0.173504,
      "grad_norm": 0.1346937942471137,
      "learning_rate": 9.917695962069526e-05,
      "loss": 0.0288,
      "step": 54220
    },
    {
      "epoch": 0.173568,
      "grad_norm": 0.10340093133273946,
      "learning_rate": 9.91763539957346e-05,
      "loss": 0.0302,
      "step": 54240
    },
    {
      "epoch": 0.173632,
      "grad_norm": 0.12945925439800732,
      "learning_rate": 9.917574814988524e-05,
      "loss": 0.0313,
      "step": 54260
    },
    {
      "epoch": 0.173696,
      "grad_norm": 0.07218867013486345,
      "learning_rate": 9.91751420831499e-05,
      "loss": 0.03,
      "step": 54280
    },
    {
      "epoch": 0.17376,
      "grad_norm": 0.09811110918316432,
      "learning_rate": 9.917453579553131e-05,
      "loss": 0.0314,
      "step": 54300
    },
    {
      "epoch": 0.173824,
      "grad_norm": 0.09266532423955416,
      "learning_rate": 9.917392928703215e-05,
      "loss": 0.0331,
      "step": 54320
    },
    {
      "epoch": 0.173888,
      "grad_norm": 0.08765086125126974,
      "learning_rate": 9.917332255765521e-05,
      "loss": 0.032,
      "step": 54340
    },
    {
      "epoch": 0.173952,
      "grad_norm": 0.12154923514913077,
      "learning_rate": 9.917271560740316e-05,
      "loss": 0.0319,
      "step": 54360
    },
    {
      "epoch": 0.174016,
      "grad_norm": 0.07059666902726938,
      "learning_rate": 9.917210843627876e-05,
      "loss": 0.0332,
      "step": 54380
    },
    {
      "epoch": 0.17408,
      "grad_norm": 0.09817166848630199,
      "learning_rate": 9.91715010442847e-05,
      "loss": 0.0319,
      "step": 54400
    },
    {
      "epoch": 0.174144,
      "grad_norm": 0.08566627308306625,
      "learning_rate": 9.917089343142376e-05,
      "loss": 0.0287,
      "step": 54420
    },
    {
      "epoch": 0.174208,
      "grad_norm": 0.05658908047202619,
      "learning_rate": 9.917028559769864e-05,
      "loss": 0.031,
      "step": 54440
    },
    {
      "epoch": 0.174272,
      "grad_norm": 0.17471714735438232,
      "learning_rate": 9.916967754311205e-05,
      "loss": 0.0303,
      "step": 54460
    },
    {
      "epoch": 0.174336,
      "grad_norm": 0.06514398790138742,
      "learning_rate": 9.916906926766676e-05,
      "loss": 0.0294,
      "step": 54480
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.0981508353853162,
      "learning_rate": 9.916846077136548e-05,
      "loss": 0.0314,
      "step": 54500
    },
    {
      "epoch": 0.174464,
      "grad_norm": 0.10673193529676554,
      "learning_rate": 9.916785205421095e-05,
      "loss": 0.0316,
      "step": 54520
    },
    {
      "epoch": 0.174528,
      "grad_norm": 0.08738474398218177,
      "learning_rate": 9.916724311620591e-05,
      "loss": 0.0287,
      "step": 54540
    },
    {
      "epoch": 0.174592,
      "grad_norm": 0.08618553136910817,
      "learning_rate": 9.916663395735308e-05,
      "loss": 0.0306,
      "step": 54560
    },
    {
      "epoch": 0.174656,
      "grad_norm": 0.12411175415004129,
      "learning_rate": 9.916602457765521e-05,
      "loss": 0.0267,
      "step": 54580
    },
    {
      "epoch": 0.17472,
      "grad_norm": 0.07384505602743656,
      "learning_rate": 9.916541497711504e-05,
      "loss": 0.0268,
      "step": 54600
    },
    {
      "epoch": 0.174784,
      "grad_norm": 0.07063389918742245,
      "learning_rate": 9.916480515573528e-05,
      "loss": 0.0312,
      "step": 54620
    },
    {
      "epoch": 0.174848,
      "grad_norm": 0.15071338236700155,
      "learning_rate": 9.916419511351871e-05,
      "loss": 0.032,
      "step": 54640
    },
    {
      "epoch": 0.174912,
      "grad_norm": 0.07087289349818059,
      "learning_rate": 9.916358485046804e-05,
      "loss": 0.0344,
      "step": 54660
    },
    {
      "epoch": 0.174976,
      "grad_norm": 0.07549898343791041,
      "learning_rate": 9.916297436658601e-05,
      "loss": 0.0352,
      "step": 54680
    },
    {
      "epoch": 0.17504,
      "grad_norm": 0.09875310474321589,
      "learning_rate": 9.916236366187539e-05,
      "loss": 0.032,
      "step": 54700
    },
    {
      "epoch": 0.175104,
      "grad_norm": 0.0821898938901705,
      "learning_rate": 9.91617527363389e-05,
      "loss": 0.0336,
      "step": 54720
    },
    {
      "epoch": 0.175168,
      "grad_norm": 0.07857242068524695,
      "learning_rate": 9.916114158997929e-05,
      "loss": 0.0299,
      "step": 54740
    },
    {
      "epoch": 0.175232,
      "grad_norm": 0.07516806115007266,
      "learning_rate": 9.91605302227993e-05,
      "loss": 0.0338,
      "step": 54760
    },
    {
      "epoch": 0.175296,
      "grad_norm": 0.059130966495835394,
      "learning_rate": 9.915991863480167e-05,
      "loss": 0.0327,
      "step": 54780
    },
    {
      "epoch": 0.17536,
      "grad_norm": 0.07625141557380999,
      "learning_rate": 9.915930682598917e-05,
      "loss": 0.0362,
      "step": 54800
    },
    {
      "epoch": 0.175424,
      "grad_norm": 0.09590426684034094,
      "learning_rate": 9.915869479636455e-05,
      "loss": 0.0337,
      "step": 54820
    },
    {
      "epoch": 0.175488,
      "grad_norm": 0.08848114486439423,
      "learning_rate": 9.915808254593053e-05,
      "loss": 0.0317,
      "step": 54840
    },
    {
      "epoch": 0.175552,
      "grad_norm": 0.06969391325088582,
      "learning_rate": 9.915747007468988e-05,
      "loss": 0.031,
      "step": 54860
    },
    {
      "epoch": 0.175616,
      "grad_norm": 0.07948527225656765,
      "learning_rate": 9.915685738264535e-05,
      "loss": 0.0303,
      "step": 54880
    },
    {
      "epoch": 0.17568,
      "grad_norm": 0.06635544703537367,
      "learning_rate": 9.915624446979968e-05,
      "loss": 0.0314,
      "step": 54900
    },
    {
      "epoch": 0.175744,
      "grad_norm": 0.09018055230969806,
      "learning_rate": 9.915563133615564e-05,
      "loss": 0.0317,
      "step": 54920
    },
    {
      "epoch": 0.175808,
      "grad_norm": 0.0908287043778242,
      "learning_rate": 9.915501798171596e-05,
      "loss": 0.0274,
      "step": 54940
    },
    {
      "epoch": 0.175872,
      "grad_norm": 0.09102187716540129,
      "learning_rate": 9.915440440648343e-05,
      "loss": 0.0299,
      "step": 54960
    },
    {
      "epoch": 0.175936,
      "grad_norm": 0.10687802315299476,
      "learning_rate": 9.915379061046078e-05,
      "loss": 0.0291,
      "step": 54980
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.06500928746817333,
      "learning_rate": 9.915317659365077e-05,
      "loss": 0.0304,
      "step": 55000
    },
    {
      "epoch": 0.176064,
      "grad_norm": 0.07576406356013711,
      "learning_rate": 9.915256235605616e-05,
      "loss": 0.0282,
      "step": 55020
    },
    {
      "epoch": 0.176128,
      "grad_norm": 0.06007409050935332,
      "learning_rate": 9.915194789767973e-05,
      "loss": 0.034,
      "step": 55040
    },
    {
      "epoch": 0.176192,
      "grad_norm": 0.07412818693153386,
      "learning_rate": 9.915133321852421e-05,
      "loss": 0.0322,
      "step": 55060
    },
    {
      "epoch": 0.176256,
      "grad_norm": 0.08356303685786468,
      "learning_rate": 9.915071831859238e-05,
      "loss": 0.0311,
      "step": 55080
    },
    {
      "epoch": 0.17632,
      "grad_norm": 0.07137296619871143,
      "learning_rate": 9.915010319788697e-05,
      "loss": 0.0312,
      "step": 55100
    },
    {
      "epoch": 0.176384,
      "grad_norm": 0.1060604576416164,
      "learning_rate": 9.914948785641078e-05,
      "loss": 0.029,
      "step": 55120
    },
    {
      "epoch": 0.176448,
      "grad_norm": 0.06578685231982229,
      "learning_rate": 9.914887229416657e-05,
      "loss": 0.0287,
      "step": 55140
    },
    {
      "epoch": 0.176512,
      "grad_norm": 0.07273049488463115,
      "learning_rate": 9.914825651115708e-05,
      "loss": 0.0317,
      "step": 55160
    },
    {
      "epoch": 0.176576,
      "grad_norm": 0.0642781572805071,
      "learning_rate": 9.91476405073851e-05,
      "loss": 0.0289,
      "step": 55180
    },
    {
      "epoch": 0.17664,
      "grad_norm": 0.07139156284996613,
      "learning_rate": 9.914702428285339e-05,
      "loss": 0.0325,
      "step": 55200
    },
    {
      "epoch": 0.176704,
      "grad_norm": 0.06074867582628363,
      "learning_rate": 9.914640783756472e-05,
      "loss": 0.0319,
      "step": 55220
    },
    {
      "epoch": 0.176768,
      "grad_norm": 0.07114683341543115,
      "learning_rate": 9.914579117152184e-05,
      "loss": 0.0294,
      "step": 55240
    },
    {
      "epoch": 0.176832,
      "grad_norm": 0.10528300027129514,
      "learning_rate": 9.914517428472755e-05,
      "loss": 0.0325,
      "step": 55260
    },
    {
      "epoch": 0.176896,
      "grad_norm": 0.06063191410766032,
      "learning_rate": 9.914455717718461e-05,
      "loss": 0.0293,
      "step": 55280
    },
    {
      "epoch": 0.17696,
      "grad_norm": 0.12330157857593224,
      "learning_rate": 9.914393984889577e-05,
      "loss": 0.0295,
      "step": 55300
    },
    {
      "epoch": 0.177024,
      "grad_norm": 0.07862610818068834,
      "learning_rate": 9.914332229986382e-05,
      "loss": 0.0329,
      "step": 55320
    },
    {
      "epoch": 0.177088,
      "grad_norm": 0.07294536494491552,
      "learning_rate": 9.914270453009155e-05,
      "loss": 0.028,
      "step": 55340
    },
    {
      "epoch": 0.177152,
      "grad_norm": 0.07598019375089324,
      "learning_rate": 9.914208653958173e-05,
      "loss": 0.03,
      "step": 55360
    },
    {
      "epoch": 0.177216,
      "grad_norm": 0.07623797873976122,
      "learning_rate": 9.914146832833711e-05,
      "loss": 0.0287,
      "step": 55380
    },
    {
      "epoch": 0.17728,
      "grad_norm": 0.054833091014180844,
      "learning_rate": 9.914084989636047e-05,
      "loss": 0.0322,
      "step": 55400
    },
    {
      "epoch": 0.177344,
      "grad_norm": 0.05279147084374848,
      "learning_rate": 9.914023124365464e-05,
      "loss": 0.0285,
      "step": 55420
    },
    {
      "epoch": 0.177408,
      "grad_norm": 0.05924931725606422,
      "learning_rate": 9.913961237022232e-05,
      "loss": 0.0298,
      "step": 55440
    },
    {
      "epoch": 0.177472,
      "grad_norm": 0.1023072094207989,
      "learning_rate": 9.913899327606635e-05,
      "loss": 0.0306,
      "step": 55460
    },
    {
      "epoch": 0.177536,
      "grad_norm": 0.12688561859100922,
      "learning_rate": 9.913837396118947e-05,
      "loss": 0.0303,
      "step": 55480
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.10453511488677909,
      "learning_rate": 9.913775442559452e-05,
      "loss": 0.0304,
      "step": 55500
    },
    {
      "epoch": 0.177664,
      "grad_norm": 0.1981834741506519,
      "learning_rate": 9.91371346692842e-05,
      "loss": 0.0314,
      "step": 55520
    },
    {
      "epoch": 0.177728,
      "grad_norm": 0.10989328040554035,
      "learning_rate": 9.913651469226138e-05,
      "loss": 0.0352,
      "step": 55540
    },
    {
      "epoch": 0.177792,
      "grad_norm": 0.1289524936130172,
      "learning_rate": 9.913589449452879e-05,
      "loss": 0.0335,
      "step": 55560
    },
    {
      "epoch": 0.177856,
      "grad_norm": 0.07248589788477582,
      "learning_rate": 9.913527407608921e-05,
      "loss": 0.0329,
      "step": 55580
    },
    {
      "epoch": 0.17792,
      "grad_norm": 0.05135868207397774,
      "learning_rate": 9.913465343694545e-05,
      "loss": 0.0293,
      "step": 55600
    },
    {
      "epoch": 0.177984,
      "grad_norm": 0.10482562660220372,
      "learning_rate": 9.91340325771003e-05,
      "loss": 0.0333,
      "step": 55620
    },
    {
      "epoch": 0.178048,
      "grad_norm": 0.08948631843297361,
      "learning_rate": 9.913341149655654e-05,
      "loss": 0.0288,
      "step": 55640
    },
    {
      "epoch": 0.178112,
      "grad_norm": 0.05271922212389456,
      "learning_rate": 9.913279019531699e-05,
      "loss": 0.0311,
      "step": 55660
    },
    {
      "epoch": 0.178176,
      "grad_norm": 0.06146062059818811,
      "learning_rate": 9.913216867338437e-05,
      "loss": 0.0289,
      "step": 55680
    },
    {
      "epoch": 0.17824,
      "grad_norm": 0.13385441041291413,
      "learning_rate": 9.913154693076154e-05,
      "loss": 0.03,
      "step": 55700
    },
    {
      "epoch": 0.178304,
      "grad_norm": 0.09013751884894944,
      "learning_rate": 9.913092496745126e-05,
      "loss": 0.0324,
      "step": 55720
    },
    {
      "epoch": 0.178368,
      "grad_norm": 0.07695687654990913,
      "learning_rate": 9.913030278345634e-05,
      "loss": 0.0316,
      "step": 55740
    },
    {
      "epoch": 0.178432,
      "grad_norm": 0.10432404450418784,
      "learning_rate": 9.912968037877954e-05,
      "loss": 0.029,
      "step": 55760
    },
    {
      "epoch": 0.178496,
      "grad_norm": 0.15972553269282552,
      "learning_rate": 9.912905775342371e-05,
      "loss": 0.0312,
      "step": 55780
    },
    {
      "epoch": 0.17856,
      "grad_norm": 0.07375013758832,
      "learning_rate": 9.912843490739161e-05,
      "loss": 0.0324,
      "step": 55800
    },
    {
      "epoch": 0.178624,
      "grad_norm": 0.07781443787466266,
      "learning_rate": 9.912781184068604e-05,
      "loss": 0.0272,
      "step": 55820
    },
    {
      "epoch": 0.178688,
      "grad_norm": 0.07564892050891706,
      "learning_rate": 9.912718855330981e-05,
      "loss": 0.0331,
      "step": 55840
    },
    {
      "epoch": 0.178752,
      "grad_norm": 0.10414462047560454,
      "learning_rate": 9.912656504526572e-05,
      "loss": 0.0366,
      "step": 55860
    },
    {
      "epoch": 0.178816,
      "grad_norm": 0.13701186428373793,
      "learning_rate": 9.912594131655655e-05,
      "loss": 0.0315,
      "step": 55880
    },
    {
      "epoch": 0.17888,
      "grad_norm": 0.0748067491132546,
      "learning_rate": 9.912531736718513e-05,
      "loss": 0.0272,
      "step": 55900
    },
    {
      "epoch": 0.178944,
      "grad_norm": 0.12545775741132228,
      "learning_rate": 9.912469319715423e-05,
      "loss": 0.0311,
      "step": 55920
    },
    {
      "epoch": 0.179008,
      "grad_norm": 0.061478823344628876,
      "learning_rate": 9.912406880646669e-05,
      "loss": 0.0305,
      "step": 55940
    },
    {
      "epoch": 0.179072,
      "grad_norm": 0.14728005651704806,
      "learning_rate": 9.91234441951253e-05,
      "loss": 0.0312,
      "step": 55960
    },
    {
      "epoch": 0.179136,
      "grad_norm": 0.07069137787231027,
      "learning_rate": 9.912281936313285e-05,
      "loss": 0.0314,
      "step": 55980
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.060715287830979604,
      "learning_rate": 9.912219431049217e-05,
      "loss": 0.0302,
      "step": 56000
    },
    {
      "epoch": 0.179264,
      "grad_norm": 0.12350719048450609,
      "learning_rate": 9.912156903720604e-05,
      "loss": 0.0301,
      "step": 56020
    },
    {
      "epoch": 0.179328,
      "grad_norm": 0.10273929707499123,
      "learning_rate": 9.91209435432773e-05,
      "loss": 0.0298,
      "step": 56040
    },
    {
      "epoch": 0.179392,
      "grad_norm": 0.09410861765919187,
      "learning_rate": 9.912031782870874e-05,
      "loss": 0.0307,
      "step": 56060
    },
    {
      "epoch": 0.179456,
      "grad_norm": 0.08169279470106103,
      "learning_rate": 9.911969189350318e-05,
      "loss": 0.0295,
      "step": 56080
    },
    {
      "epoch": 0.17952,
      "grad_norm": 0.05309547248520194,
      "learning_rate": 9.911906573766342e-05,
      "loss": 0.0297,
      "step": 56100
    },
    {
      "epoch": 0.179584,
      "grad_norm": 0.11849248391154033,
      "learning_rate": 9.91184393611923e-05,
      "loss": 0.0353,
      "step": 56120
    },
    {
      "epoch": 0.179648,
      "grad_norm": 0.07189183414839781,
      "learning_rate": 9.91178127640926e-05,
      "loss": 0.0324,
      "step": 56140
    },
    {
      "epoch": 0.179712,
      "grad_norm": 0.1699438769631181,
      "learning_rate": 9.911718594636714e-05,
      "loss": 0.0323,
      "step": 56160
    },
    {
      "epoch": 0.179776,
      "grad_norm": 0.07653701406980844,
      "learning_rate": 9.911655890801875e-05,
      "loss": 0.0272,
      "step": 56180
    },
    {
      "epoch": 0.17984,
      "grad_norm": 0.07536764145566109,
      "learning_rate": 9.911593164905024e-05,
      "loss": 0.0317,
      "step": 56200
    },
    {
      "epoch": 0.179904,
      "grad_norm": 0.11038785629926327,
      "learning_rate": 9.911530416946444e-05,
      "loss": 0.0303,
      "step": 56220
    },
    {
      "epoch": 0.179968,
      "grad_norm": 0.12312996283196055,
      "learning_rate": 9.911467646926414e-05,
      "loss": 0.0375,
      "step": 56240
    },
    {
      "epoch": 0.180032,
      "grad_norm": 0.0702584870158073,
      "learning_rate": 9.911404854845218e-05,
      "loss": 0.0311,
      "step": 56260
    },
    {
      "epoch": 0.180096,
      "grad_norm": 0.07530939726463182,
      "learning_rate": 9.911342040703138e-05,
      "loss": 0.0334,
      "step": 56280
    },
    {
      "epoch": 0.18016,
      "grad_norm": 0.07459130549840669,
      "learning_rate": 9.911279204500454e-05,
      "loss": 0.0307,
      "step": 56300
    },
    {
      "epoch": 0.180224,
      "grad_norm": 0.05065137758340631,
      "learning_rate": 9.911216346237452e-05,
      "loss": 0.0301,
      "step": 56320
    },
    {
      "epoch": 0.180288,
      "grad_norm": 0.14169477434264507,
      "learning_rate": 9.911153465914411e-05,
      "loss": 0.03,
      "step": 56340
    },
    {
      "epoch": 0.180352,
      "grad_norm": 0.0648182406956438,
      "learning_rate": 9.911090563531615e-05,
      "loss": 0.0294,
      "step": 56360
    },
    {
      "epoch": 0.180416,
      "grad_norm": 0.06690949858181038,
      "learning_rate": 9.911027639089348e-05,
      "loss": 0.0299,
      "step": 56380
    },
    {
      "epoch": 0.18048,
      "grad_norm": 0.06859594889185171,
      "learning_rate": 9.910964692587889e-05,
      "loss": 0.033,
      "step": 56400
    },
    {
      "epoch": 0.180544,
      "grad_norm": 0.08307587472699843,
      "learning_rate": 9.910901724027524e-05,
      "loss": 0.0302,
      "step": 56420
    },
    {
      "epoch": 0.180608,
      "grad_norm": 0.08209489852014086,
      "learning_rate": 9.910838733408534e-05,
      "loss": 0.0301,
      "step": 56440
    },
    {
      "epoch": 0.180672,
      "grad_norm": 0.058682850242809934,
      "learning_rate": 9.910775720731203e-05,
      "loss": 0.0323,
      "step": 56460
    },
    {
      "epoch": 0.180736,
      "grad_norm": 0.09752275319418642,
      "learning_rate": 9.910712685995814e-05,
      "loss": 0.0335,
      "step": 56480
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.08555267136679671,
      "learning_rate": 9.910649629202647e-05,
      "loss": 0.0304,
      "step": 56500
    },
    {
      "epoch": 0.180864,
      "grad_norm": 0.07368800937799537,
      "learning_rate": 9.910586550351991e-05,
      "loss": 0.0285,
      "step": 56520
    },
    {
      "epoch": 0.180928,
      "grad_norm": 0.07019543441877546,
      "learning_rate": 9.910523449444123e-05,
      "loss": 0.0349,
      "step": 56540
    },
    {
      "epoch": 0.180992,
      "grad_norm": 0.08171540310539172,
      "learning_rate": 9.910460326479332e-05,
      "loss": 0.0316,
      "step": 56560
    },
    {
      "epoch": 0.181056,
      "grad_norm": 0.05815060868856384,
      "learning_rate": 9.9103971814579e-05,
      "loss": 0.0313,
      "step": 56580
    },
    {
      "epoch": 0.18112,
      "grad_norm": 0.0737736967418381,
      "learning_rate": 9.910334014380107e-05,
      "loss": 0.0344,
      "step": 56600
    },
    {
      "epoch": 0.181184,
      "grad_norm": 0.09170896839940221,
      "learning_rate": 9.910270825246242e-05,
      "loss": 0.0278,
      "step": 56620
    },
    {
      "epoch": 0.181248,
      "grad_norm": 0.06760672076632138,
      "learning_rate": 9.910207614056584e-05,
      "loss": 0.0298,
      "step": 56640
    },
    {
      "epoch": 0.181312,
      "grad_norm": 0.08431859265369361,
      "learning_rate": 9.910144380811421e-05,
      "loss": 0.0313,
      "step": 56660
    },
    {
      "epoch": 0.181376,
      "grad_norm": 0.10711550949603708,
      "learning_rate": 9.910081125511035e-05,
      "loss": 0.031,
      "step": 56680
    },
    {
      "epoch": 0.18144,
      "grad_norm": 0.08293984111946934,
      "learning_rate": 9.910017848155711e-05,
      "loss": 0.0334,
      "step": 56700
    },
    {
      "epoch": 0.181504,
      "grad_norm": 0.083191835354564,
      "learning_rate": 9.909954548745732e-05,
      "loss": 0.0297,
      "step": 56720
    },
    {
      "epoch": 0.181568,
      "grad_norm": 0.07573444360745306,
      "learning_rate": 9.909891227281384e-05,
      "loss": 0.0301,
      "step": 56740
    },
    {
      "epoch": 0.181632,
      "grad_norm": 0.05596412601630615,
      "learning_rate": 9.90982788376295e-05,
      "loss": 0.0312,
      "step": 56760
    },
    {
      "epoch": 0.181696,
      "grad_norm": 0.08605031321703613,
      "learning_rate": 9.909764518190714e-05,
      "loss": 0.0323,
      "step": 56780
    },
    {
      "epoch": 0.18176,
      "grad_norm": 0.1015272472593763,
      "learning_rate": 9.909701130564963e-05,
      "loss": 0.0301,
      "step": 56800
    },
    {
      "epoch": 0.181824,
      "grad_norm": 0.10415556897657033,
      "learning_rate": 9.90963772088598e-05,
      "loss": 0.0321,
      "step": 56820
    },
    {
      "epoch": 0.181888,
      "grad_norm": 0.12408160262975111,
      "learning_rate": 9.909574289154049e-05,
      "loss": 0.0304,
      "step": 56840
    },
    {
      "epoch": 0.181952,
      "grad_norm": 0.09297772925523458,
      "learning_rate": 9.909510835369457e-05,
      "loss": 0.0295,
      "step": 56860
    },
    {
      "epoch": 0.182016,
      "grad_norm": 0.05305486209263366,
      "learning_rate": 9.909447359532489e-05,
      "loss": 0.0328,
      "step": 56880
    },
    {
      "epoch": 0.18208,
      "grad_norm": 0.10102566198341581,
      "learning_rate": 9.909383861643428e-05,
      "loss": 0.0314,
      "step": 56900
    },
    {
      "epoch": 0.182144,
      "grad_norm": 0.07893723495202629,
      "learning_rate": 9.909320341702561e-05,
      "loss": 0.0316,
      "step": 56920
    },
    {
      "epoch": 0.182208,
      "grad_norm": 0.05664638759214131,
      "learning_rate": 9.909256799710171e-05,
      "loss": 0.0321,
      "step": 56940
    },
    {
      "epoch": 0.182272,
      "grad_norm": 0.1125596071707452,
      "learning_rate": 9.909193235666547e-05,
      "loss": 0.033,
      "step": 56960
    },
    {
      "epoch": 0.182336,
      "grad_norm": 0.1737896772541999,
      "learning_rate": 9.909129649571973e-05,
      "loss": 0.0335,
      "step": 56980
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.09583169543818493,
      "learning_rate": 9.909066041426733e-05,
      "loss": 0.0302,
      "step": 57000
    },
    {
      "epoch": 0.182464,
      "grad_norm": 0.07532716741546423,
      "learning_rate": 9.909002411231115e-05,
      "loss": 0.0331,
      "step": 57020
    },
    {
      "epoch": 0.182528,
      "grad_norm": 0.08963896438603018,
      "learning_rate": 9.908938758985404e-05,
      "loss": 0.0293,
      "step": 57040
    },
    {
      "epoch": 0.182592,
      "grad_norm": 0.08439617570155365,
      "learning_rate": 9.908875084689884e-05,
      "loss": 0.0317,
      "step": 57060
    },
    {
      "epoch": 0.182656,
      "grad_norm": 0.0648892001702721,
      "learning_rate": 9.908811388344845e-05,
      "loss": 0.0354,
      "step": 57080
    },
    {
      "epoch": 0.18272,
      "grad_norm": 0.1278686454188513,
      "learning_rate": 9.908747669950568e-05,
      "loss": 0.0311,
      "step": 57100
    },
    {
      "epoch": 0.182784,
      "grad_norm": 0.06124289491049138,
      "learning_rate": 9.908683929507346e-05,
      "loss": 0.031,
      "step": 57120
    },
    {
      "epoch": 0.182848,
      "grad_norm": 0.05422858781977851,
      "learning_rate": 9.908620167015458e-05,
      "loss": 0.0306,
      "step": 57140
    },
    {
      "epoch": 0.182912,
      "grad_norm": 0.1723098831529928,
      "learning_rate": 9.908556382475195e-05,
      "loss": 0.0318,
      "step": 57160
    },
    {
      "epoch": 0.182976,
      "grad_norm": 0.08604328820402815,
      "learning_rate": 9.908492575886842e-05,
      "loss": 0.0306,
      "step": 57180
    },
    {
      "epoch": 0.18304,
      "grad_norm": 0.07506632504164326,
      "learning_rate": 9.908428747250686e-05,
      "loss": 0.032,
      "step": 57200
    },
    {
      "epoch": 0.183104,
      "grad_norm": 0.06073716602567336,
      "learning_rate": 9.908364896567013e-05,
      "loss": 0.0291,
      "step": 57220
    },
    {
      "epoch": 0.183168,
      "grad_norm": 0.06555171283517904,
      "learning_rate": 9.90830102383611e-05,
      "loss": 0.0305,
      "step": 57240
    },
    {
      "epoch": 0.183232,
      "grad_norm": 0.06347101171198498,
      "learning_rate": 9.908237129058267e-05,
      "loss": 0.0297,
      "step": 57260
    },
    {
      "epoch": 0.183296,
      "grad_norm": 0.11978616834427984,
      "learning_rate": 9.908173212233767e-05,
      "loss": 0.0331,
      "step": 57280
    },
    {
      "epoch": 0.18336,
      "grad_norm": 0.09550141819550205,
      "learning_rate": 9.908109273362897e-05,
      "loss": 0.0296,
      "step": 57300
    },
    {
      "epoch": 0.183424,
      "grad_norm": 0.06810663842852016,
      "learning_rate": 9.908045312445946e-05,
      "loss": 0.0304,
      "step": 57320
    },
    {
      "epoch": 0.183488,
      "grad_norm": 0.14501367504534543,
      "learning_rate": 9.907981329483202e-05,
      "loss": 0.0304,
      "step": 57340
    },
    {
      "epoch": 0.183552,
      "grad_norm": 0.0554265901895841,
      "learning_rate": 9.907917324474951e-05,
      "loss": 0.0297,
      "step": 57360
    },
    {
      "epoch": 0.183616,
      "grad_norm": 0.08710988017084123,
      "learning_rate": 9.90785329742148e-05,
      "loss": 0.0329,
      "step": 57380
    },
    {
      "epoch": 0.18368,
      "grad_norm": 0.05330987866371492,
      "learning_rate": 9.907789248323078e-05,
      "loss": 0.0312,
      "step": 57400
    },
    {
      "epoch": 0.183744,
      "grad_norm": 0.07772023653561798,
      "learning_rate": 9.907725177180032e-05,
      "loss": 0.0262,
      "step": 57420
    },
    {
      "epoch": 0.183808,
      "grad_norm": 0.09233791667003935,
      "learning_rate": 9.90766108399263e-05,
      "loss": 0.0315,
      "step": 57440
    },
    {
      "epoch": 0.183872,
      "grad_norm": 0.19729096416239655,
      "learning_rate": 9.907596968761159e-05,
      "loss": 0.0326,
      "step": 57460
    },
    {
      "epoch": 0.183936,
      "grad_norm": 0.06460342799204342,
      "learning_rate": 9.907532831485909e-05,
      "loss": 0.0338,
      "step": 57480
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.1342037208495233,
      "learning_rate": 9.907468672167165e-05,
      "loss": 0.0316,
      "step": 57500
    },
    {
      "epoch": 0.184064,
      "grad_norm": 0.16442538588831396,
      "learning_rate": 9.907404490805218e-05,
      "loss": 0.0325,
      "step": 57520
    },
    {
      "epoch": 0.184128,
      "grad_norm": 0.08156563622311923,
      "learning_rate": 9.907340287400354e-05,
      "loss": 0.0317,
      "step": 57540
    },
    {
      "epoch": 0.184192,
      "grad_norm": 0.08684543433942785,
      "learning_rate": 9.907276061952865e-05,
      "loss": 0.0337,
      "step": 57560
    },
    {
      "epoch": 0.184256,
      "grad_norm": 0.07410014110286034,
      "learning_rate": 9.907211814463037e-05,
      "loss": 0.0342,
      "step": 57580
    },
    {
      "epoch": 0.18432,
      "grad_norm": 0.05480608773783919,
      "learning_rate": 9.907147544931157e-05,
      "loss": 0.0345,
      "step": 57600
    },
    {
      "epoch": 0.184384,
      "grad_norm": 0.05906528458308589,
      "learning_rate": 9.907083253357516e-05,
      "loss": 0.0326,
      "step": 57620
    },
    {
      "epoch": 0.184448,
      "grad_norm": 0.08903951766926992,
      "learning_rate": 9.907018939742403e-05,
      "loss": 0.0323,
      "step": 57640
    },
    {
      "epoch": 0.184512,
      "grad_norm": 0.07081410785107872,
      "learning_rate": 9.906954604086106e-05,
      "loss": 0.0292,
      "step": 57660
    },
    {
      "epoch": 0.184576,
      "grad_norm": 0.07586256810217905,
      "learning_rate": 9.906890246388914e-05,
      "loss": 0.0292,
      "step": 57680
    },
    {
      "epoch": 0.18464,
      "grad_norm": 0.0744451499589352,
      "learning_rate": 9.906825866651116e-05,
      "loss": 0.0334,
      "step": 57700
    },
    {
      "epoch": 0.184704,
      "grad_norm": 0.12983934858093307,
      "learning_rate": 9.906761464873002e-05,
      "loss": 0.0325,
      "step": 57720
    },
    {
      "epoch": 0.184768,
      "grad_norm": 0.08830877520963591,
      "learning_rate": 9.906697041054859e-05,
      "loss": 0.031,
      "step": 57740
    },
    {
      "epoch": 0.184832,
      "grad_norm": 0.11877272113202703,
      "learning_rate": 9.906632595196979e-05,
      "loss": 0.0286,
      "step": 57760
    },
    {
      "epoch": 0.184896,
      "grad_norm": 0.04945080611780583,
      "learning_rate": 9.90656812729965e-05,
      "loss": 0.0331,
      "step": 57780
    },
    {
      "epoch": 0.18496,
      "grad_norm": 0.07139052051405267,
      "learning_rate": 9.906503637363162e-05,
      "loss": 0.0323,
      "step": 57800
    },
    {
      "epoch": 0.185024,
      "grad_norm": 0.06954108646148342,
      "learning_rate": 9.906439125387805e-05,
      "loss": 0.0307,
      "step": 57820
    },
    {
      "epoch": 0.185088,
      "grad_norm": 0.14346285593146796,
      "learning_rate": 9.90637459137387e-05,
      "loss": 0.0295,
      "step": 57840
    },
    {
      "epoch": 0.185152,
      "grad_norm": 0.11312972083641779,
      "learning_rate": 9.906310035321644e-05,
      "loss": 0.0298,
      "step": 57860
    },
    {
      "epoch": 0.185216,
      "grad_norm": 0.05271038304640455,
      "learning_rate": 9.906245457231418e-05,
      "loss": 0.031,
      "step": 57880
    },
    {
      "epoch": 0.18528,
      "grad_norm": 0.12532956372097634,
      "learning_rate": 9.906180857103483e-05,
      "loss": 0.0335,
      "step": 57900
    },
    {
      "epoch": 0.185344,
      "grad_norm": 0.12245001381854656,
      "learning_rate": 9.906116234938127e-05,
      "loss": 0.0327,
      "step": 57920
    },
    {
      "epoch": 0.185408,
      "grad_norm": 0.0937271583837394,
      "learning_rate": 9.906051590735644e-05,
      "loss": 0.0303,
      "step": 57940
    },
    {
      "epoch": 0.185472,
      "grad_norm": 0.14448225250330357,
      "learning_rate": 9.905986924496323e-05,
      "loss": 0.0289,
      "step": 57960
    },
    {
      "epoch": 0.185536,
      "grad_norm": 0.060081288924044005,
      "learning_rate": 9.905922236220451e-05,
      "loss": 0.0331,
      "step": 57980
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.07078324606397143,
      "learning_rate": 9.905857525908322e-05,
      "loss": 0.0358,
      "step": 58000
    },
    {
      "epoch": 0.185664,
      "grad_norm": 0.05982410503298079,
      "learning_rate": 9.905792793560227e-05,
      "loss": 0.0292,
      "step": 58020
    },
    {
      "epoch": 0.185728,
      "grad_norm": 0.07724324963379274,
      "learning_rate": 9.905728039176455e-05,
      "loss": 0.0305,
      "step": 58040
    },
    {
      "epoch": 0.185792,
      "grad_norm": 0.1685445141227329,
      "learning_rate": 9.905663262757296e-05,
      "loss": 0.0323,
      "step": 58060
    },
    {
      "epoch": 0.185856,
      "grad_norm": 0.06875668170257895,
      "learning_rate": 9.905598464303045e-05,
      "loss": 0.0337,
      "step": 58080
    },
    {
      "epoch": 0.18592,
      "grad_norm": 0.05158441186128389,
      "learning_rate": 9.905533643813989e-05,
      "loss": 0.03,
      "step": 58100
    },
    {
      "epoch": 0.185984,
      "grad_norm": 0.09123109076352655,
      "learning_rate": 9.905468801290421e-05,
      "loss": 0.0297,
      "step": 58120
    },
    {
      "epoch": 0.186048,
      "grad_norm": 0.08462838839491714,
      "learning_rate": 9.905403936732632e-05,
      "loss": 0.0313,
      "step": 58140
    },
    {
      "epoch": 0.186112,
      "grad_norm": 0.09346657234491286,
      "learning_rate": 9.905339050140914e-05,
      "loss": 0.0337,
      "step": 58160
    },
    {
      "epoch": 0.186176,
      "grad_norm": 0.0768935643514365,
      "learning_rate": 9.905274141515557e-05,
      "loss": 0.0339,
      "step": 58180
    },
    {
      "epoch": 0.18624,
      "grad_norm": 0.09331706088229727,
      "learning_rate": 9.905209210856853e-05,
      "loss": 0.0315,
      "step": 58200
    },
    {
      "epoch": 0.186304,
      "grad_norm": 0.07275419801303047,
      "learning_rate": 9.905144258165096e-05,
      "loss": 0.0328,
      "step": 58220
    },
    {
      "epoch": 0.186368,
      "grad_norm": 0.0757349027872123,
      "learning_rate": 9.905079283440573e-05,
      "loss": 0.029,
      "step": 58240
    },
    {
      "epoch": 0.186432,
      "grad_norm": 0.0669475304033215,
      "learning_rate": 9.90501428668358e-05,
      "loss": 0.0322,
      "step": 58260
    },
    {
      "epoch": 0.186496,
      "grad_norm": 0.08847028405017106,
      "learning_rate": 9.904949267894408e-05,
      "loss": 0.0283,
      "step": 58280
    },
    {
      "epoch": 0.18656,
      "grad_norm": 0.06909242038783779,
      "learning_rate": 9.904884227073348e-05,
      "loss": 0.0325,
      "step": 58300
    },
    {
      "epoch": 0.186624,
      "grad_norm": 0.19995549201112395,
      "learning_rate": 9.904819164220694e-05,
      "loss": 0.0321,
      "step": 58320
    },
    {
      "epoch": 0.186688,
      "grad_norm": 0.0665049616967318,
      "learning_rate": 9.904754079336734e-05,
      "loss": 0.0314,
      "step": 58340
    },
    {
      "epoch": 0.186752,
      "grad_norm": 0.10241153882803158,
      "learning_rate": 9.904688972421765e-05,
      "loss": 0.0338,
      "step": 58360
    },
    {
      "epoch": 0.186816,
      "grad_norm": 0.13692861313251287,
      "learning_rate": 9.904623843476079e-05,
      "loss": 0.03,
      "step": 58380
    },
    {
      "epoch": 0.18688,
      "grad_norm": 0.07898760181456554,
      "learning_rate": 9.904558692499966e-05,
      "loss": 0.034,
      "step": 58400
    },
    {
      "epoch": 0.186944,
      "grad_norm": 0.05055437891294893,
      "learning_rate": 9.904493519493719e-05,
      "loss": 0.0313,
      "step": 58420
    },
    {
      "epoch": 0.187008,
      "grad_norm": 0.07358526720126503,
      "learning_rate": 9.904428324457634e-05,
      "loss": 0.0289,
      "step": 58440
    },
    {
      "epoch": 0.187072,
      "grad_norm": 0.08088897128388826,
      "learning_rate": 9.904363107391999e-05,
      "loss": 0.0322,
      "step": 58460
    },
    {
      "epoch": 0.187136,
      "grad_norm": 0.08869791717377383,
      "learning_rate": 9.904297868297112e-05,
      "loss": 0.0307,
      "step": 58480
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.147415059764648,
      "learning_rate": 9.904232607173262e-05,
      "loss": 0.0308,
      "step": 58500
    },
    {
      "epoch": 0.187264,
      "grad_norm": 0.09008447669058428,
      "learning_rate": 9.904167324020743e-05,
      "loss": 0.0301,
      "step": 58520
    },
    {
      "epoch": 0.187328,
      "grad_norm": 0.06257975273729069,
      "learning_rate": 9.904102018839851e-05,
      "loss": 0.0285,
      "step": 58540
    },
    {
      "epoch": 0.187392,
      "grad_norm": 0.09236922774292053,
      "learning_rate": 9.904036691630875e-05,
      "loss": 0.0283,
      "step": 58560
    },
    {
      "epoch": 0.187456,
      "grad_norm": 0.05783479242944942,
      "learning_rate": 9.903971342394114e-05,
      "loss": 0.0327,
      "step": 58580
    },
    {
      "epoch": 0.18752,
      "grad_norm": 0.0642322331243713,
      "learning_rate": 9.903905971129854e-05,
      "loss": 0.0332,
      "step": 58600
    },
    {
      "epoch": 0.187584,
      "grad_norm": 0.054949868027486734,
      "learning_rate": 9.903840577838395e-05,
      "loss": 0.0289,
      "step": 58620
    },
    {
      "epoch": 0.187648,
      "grad_norm": 0.059549791903426685,
      "learning_rate": 9.903775162520029e-05,
      "loss": 0.0316,
      "step": 58640
    },
    {
      "epoch": 0.187712,
      "grad_norm": 0.09237456590644062,
      "learning_rate": 9.90370972517505e-05,
      "loss": 0.0333,
      "step": 58660
    },
    {
      "epoch": 0.187776,
      "grad_norm": 0.09398873717077447,
      "learning_rate": 9.903644265803748e-05,
      "loss": 0.0336,
      "step": 58680
    },
    {
      "epoch": 0.18784,
      "grad_norm": 0.1218349700234445,
      "learning_rate": 9.903578784406424e-05,
      "loss": 0.037,
      "step": 58700
    },
    {
      "epoch": 0.187904,
      "grad_norm": 0.09955248436369646,
      "learning_rate": 9.903513280983368e-05,
      "loss": 0.0295,
      "step": 58720
    },
    {
      "epoch": 0.187968,
      "grad_norm": 0.05870748690406761,
      "learning_rate": 9.903447755534873e-05,
      "loss": 0.0292,
      "step": 58740
    },
    {
      "epoch": 0.188032,
      "grad_norm": 0.11603883656493827,
      "learning_rate": 9.903382208061236e-05,
      "loss": 0.0317,
      "step": 58760
    },
    {
      "epoch": 0.188096,
      "grad_norm": 0.06554559506074953,
      "learning_rate": 9.90331663856275e-05,
      "loss": 0.0286,
      "step": 58780
    },
    {
      "epoch": 0.18816,
      "grad_norm": 0.07941833638504525,
      "learning_rate": 9.90325104703971e-05,
      "loss": 0.0317,
      "step": 58800
    },
    {
      "epoch": 0.188224,
      "grad_norm": 0.09202662340089272,
      "learning_rate": 9.90318543349241e-05,
      "loss": 0.031,
      "step": 58820
    },
    {
      "epoch": 0.188288,
      "grad_norm": 0.07856832407519056,
      "learning_rate": 9.903119797921147e-05,
      "loss": 0.0288,
      "step": 58840
    },
    {
      "epoch": 0.188352,
      "grad_norm": 0.07439075329634934,
      "learning_rate": 9.903054140326214e-05,
      "loss": 0.0307,
      "step": 58860
    },
    {
      "epoch": 0.188416,
      "grad_norm": 0.06984042006854699,
      "learning_rate": 9.902988460707904e-05,
      "loss": 0.0294,
      "step": 58880
    },
    {
      "epoch": 0.18848,
      "grad_norm": 0.09006171841011561,
      "learning_rate": 9.902922759066515e-05,
      "loss": 0.0304,
      "step": 58900
    },
    {
      "epoch": 0.188544,
      "grad_norm": 0.09392771606545723,
      "learning_rate": 9.902857035402342e-05,
      "loss": 0.0295,
      "step": 58920
    },
    {
      "epoch": 0.188608,
      "grad_norm": 0.08471208694136559,
      "learning_rate": 9.902791289715678e-05,
      "loss": 0.0292,
      "step": 58940
    },
    {
      "epoch": 0.188672,
      "grad_norm": 0.07998655826277877,
      "learning_rate": 9.902725522006821e-05,
      "loss": 0.0341,
      "step": 58960
    },
    {
      "epoch": 0.188736,
      "grad_norm": 0.06395319894806595,
      "learning_rate": 9.902659732276065e-05,
      "loss": 0.0303,
      "step": 58980
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.16468244870864002,
      "learning_rate": 9.902593920523706e-05,
      "loss": 0.0344,
      "step": 59000
    },
    {
      "epoch": 0.188864,
      "grad_norm": 0.08946765415230847,
      "learning_rate": 9.902528086750038e-05,
      "loss": 0.0313,
      "step": 59020
    },
    {
      "epoch": 0.188928,
      "grad_norm": 0.06601339592631864,
      "learning_rate": 9.90246223095536e-05,
      "loss": 0.0291,
      "step": 59040
    },
    {
      "epoch": 0.188992,
      "grad_norm": 0.07364500215047344,
      "learning_rate": 9.902396353139965e-05,
      "loss": 0.0297,
      "step": 59060
    },
    {
      "epoch": 0.189056,
      "grad_norm": 0.1484921011831819,
      "learning_rate": 9.902330453304147e-05,
      "loss": 0.0316,
      "step": 59080
    },
    {
      "epoch": 0.18912,
      "grad_norm": 0.12532553248299033,
      "learning_rate": 9.902264531448208e-05,
      "loss": 0.0284,
      "step": 59100
    },
    {
      "epoch": 0.189184,
      "grad_norm": 0.12709477430716265,
      "learning_rate": 9.90219858757244e-05,
      "loss": 0.0276,
      "step": 59120
    },
    {
      "epoch": 0.189248,
      "grad_norm": 0.09190557956496918,
      "learning_rate": 9.90213262167714e-05,
      "loss": 0.0337,
      "step": 59140
    },
    {
      "epoch": 0.189312,
      "grad_norm": 0.09516964950831684,
      "learning_rate": 9.902066633762604e-05,
      "loss": 0.034,
      "step": 59160
    },
    {
      "epoch": 0.189376,
      "grad_norm": 0.06866381880927556,
      "learning_rate": 9.902000623829128e-05,
      "loss": 0.0321,
      "step": 59180
    },
    {
      "epoch": 0.18944,
      "grad_norm": 0.08075498435596498,
      "learning_rate": 9.901934591877009e-05,
      "loss": 0.0311,
      "step": 59200
    },
    {
      "epoch": 0.189504,
      "grad_norm": 0.06443910038982426,
      "learning_rate": 9.901868537906545e-05,
      "loss": 0.0337,
      "step": 59220
    },
    {
      "epoch": 0.189568,
      "grad_norm": 0.0794929062573456,
      "learning_rate": 9.901802461918032e-05,
      "loss": 0.0303,
      "step": 59240
    },
    {
      "epoch": 0.189632,
      "grad_norm": 0.06745287089125945,
      "learning_rate": 9.901736363911764e-05,
      "loss": 0.0305,
      "step": 59260
    },
    {
      "epoch": 0.189696,
      "grad_norm": 0.08099701285275905,
      "learning_rate": 9.901670243888042e-05,
      "loss": 0.0311,
      "step": 59280
    },
    {
      "epoch": 0.18976,
      "grad_norm": 0.07965720398341562,
      "learning_rate": 9.901604101847162e-05,
      "loss": 0.0315,
      "step": 59300
    },
    {
      "epoch": 0.189824,
      "grad_norm": 0.07593724989335497,
      "learning_rate": 9.901537937789418e-05,
      "loss": 0.0319,
      "step": 59320
    },
    {
      "epoch": 0.189888,
      "grad_norm": 0.09317259336978356,
      "learning_rate": 9.901471751715112e-05,
      "loss": 0.0293,
      "step": 59340
    },
    {
      "epoch": 0.189952,
      "grad_norm": 0.05905459412519879,
      "learning_rate": 9.901405543624537e-05,
      "loss": 0.0281,
      "step": 59360
    },
    {
      "epoch": 0.190016,
      "grad_norm": 0.07968501745742275,
      "learning_rate": 9.901339313517992e-05,
      "loss": 0.0324,
      "step": 59380
    },
    {
      "epoch": 0.19008,
      "grad_norm": 0.12536871771083333,
      "learning_rate": 9.901273061395775e-05,
      "loss": 0.029,
      "step": 59400
    },
    {
      "epoch": 0.190144,
      "grad_norm": 0.2147906065747188,
      "learning_rate": 9.901206787258184e-05,
      "loss": 0.0305,
      "step": 59420
    },
    {
      "epoch": 0.190208,
      "grad_norm": 0.07182313068834152,
      "learning_rate": 9.901140491105516e-05,
      "loss": 0.0328,
      "step": 59440
    },
    {
      "epoch": 0.190272,
      "grad_norm": 0.10155443638246053,
      "learning_rate": 9.901074172938069e-05,
      "loss": 0.0308,
      "step": 59460
    },
    {
      "epoch": 0.190336,
      "grad_norm": 0.1082382477169541,
      "learning_rate": 9.90100783275614e-05,
      "loss": 0.033,
      "step": 59480
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.09647242298128025,
      "learning_rate": 9.900941470560025e-05,
      "loss": 0.0312,
      "step": 59500
    },
    {
      "epoch": 0.190464,
      "grad_norm": 0.07094178732139758,
      "learning_rate": 9.90087508635003e-05,
      "loss": 0.0286,
      "step": 59520
    },
    {
      "epoch": 0.190528,
      "grad_norm": 0.06474229007468127,
      "learning_rate": 9.900808680126443e-05,
      "loss": 0.0284,
      "step": 59540
    },
    {
      "epoch": 0.190592,
      "grad_norm": 0.10677293858882929,
      "learning_rate": 9.90074225188957e-05,
      "loss": 0.0307,
      "step": 59560
    },
    {
      "epoch": 0.190656,
      "grad_norm": 0.0537825338301271,
      "learning_rate": 9.900675801639705e-05,
      "loss": 0.0295,
      "step": 59580
    },
    {
      "epoch": 0.19072,
      "grad_norm": 0.09617338246068792,
      "learning_rate": 9.900609329377148e-05,
      "loss": 0.0298,
      "step": 59600
    },
    {
      "epoch": 0.190784,
      "grad_norm": 0.08111650882835705,
      "learning_rate": 9.900542835102199e-05,
      "loss": 0.0331,
      "step": 59620
    },
    {
      "epoch": 0.190848,
      "grad_norm": 0.08847259118147248,
      "learning_rate": 9.900476318815155e-05,
      "loss": 0.0338,
      "step": 59640
    },
    {
      "epoch": 0.190912,
      "grad_norm": 0.06817495673650092,
      "learning_rate": 9.900409780516313e-05,
      "loss": 0.0303,
      "step": 59660
    },
    {
      "epoch": 0.190976,
      "grad_norm": 0.12673790494706766,
      "learning_rate": 9.900343220205976e-05,
      "loss": 0.0328,
      "step": 59680
    },
    {
      "epoch": 0.19104,
      "grad_norm": 0.07623826472990251,
      "learning_rate": 9.90027663788444e-05,
      "loss": 0.0328,
      "step": 59700
    },
    {
      "epoch": 0.191104,
      "grad_norm": 0.10876096146862675,
      "learning_rate": 9.900210033552007e-05,
      "loss": 0.0339,
      "step": 59720
    },
    {
      "epoch": 0.191168,
      "grad_norm": 0.10399991179139303,
      "learning_rate": 9.900143407208971e-05,
      "loss": 0.0313,
      "step": 59740
    },
    {
      "epoch": 0.191232,
      "grad_norm": 0.11294972424734066,
      "learning_rate": 9.900076758855636e-05,
      "loss": 0.0297,
      "step": 59760
    },
    {
      "epoch": 0.191296,
      "grad_norm": 0.055402407188321415,
      "learning_rate": 9.9000100884923e-05,
      "loss": 0.0318,
      "step": 59780
    },
    {
      "epoch": 0.19136,
      "grad_norm": 0.05761837819705909,
      "learning_rate": 9.899943396119262e-05,
      "loss": 0.0269,
      "step": 59800
    },
    {
      "epoch": 0.191424,
      "grad_norm": 0.08164212915303873,
      "learning_rate": 9.89987668173682e-05,
      "loss": 0.0298,
      "step": 59820
    },
    {
      "epoch": 0.191488,
      "grad_norm": 0.2302338665536421,
      "learning_rate": 9.899809945345277e-05,
      "loss": 0.0325,
      "step": 59840
    },
    {
      "epoch": 0.191552,
      "grad_norm": 0.04968183583372562,
      "learning_rate": 9.899743186944932e-05,
      "loss": 0.0285,
      "step": 59860
    },
    {
      "epoch": 0.191616,
      "grad_norm": 0.17335388495069726,
      "learning_rate": 9.899676406536083e-05,
      "loss": 0.0333,
      "step": 59880
    },
    {
      "epoch": 0.19168,
      "grad_norm": 0.07784064472922508,
      "learning_rate": 9.899609604119031e-05,
      "loss": 0.0289,
      "step": 59900
    },
    {
      "epoch": 0.191744,
      "grad_norm": 0.09696709547793268,
      "learning_rate": 9.899542779694077e-05,
      "loss": 0.032,
      "step": 59920
    },
    {
      "epoch": 0.191808,
      "grad_norm": 0.06729906168771423,
      "learning_rate": 9.89947593326152e-05,
      "loss": 0.0293,
      "step": 59940
    },
    {
      "epoch": 0.191872,
      "grad_norm": 0.06021421677168573,
      "learning_rate": 9.89940906482166e-05,
      "loss": 0.0329,
      "step": 59960
    },
    {
      "epoch": 0.191936,
      "grad_norm": 0.04960356883500862,
      "learning_rate": 9.899342174374798e-05,
      "loss": 0.0302,
      "step": 59980
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.08190764611894477,
      "learning_rate": 9.899275261921234e-05,
      "loss": 0.0338,
      "step": 60000
    },
    {
      "epoch": 0.192064,
      "grad_norm": 0.07750651514111975,
      "learning_rate": 9.89920832746127e-05,
      "loss": 0.0296,
      "step": 60020
    },
    {
      "epoch": 0.192128,
      "grad_norm": 0.12068706405558143,
      "learning_rate": 9.899141370995205e-05,
      "loss": 0.0288,
      "step": 60040
    },
    {
      "epoch": 0.192192,
      "grad_norm": 0.06030187931123488,
      "learning_rate": 9.89907439252334e-05,
      "loss": 0.0303,
      "step": 60060
    },
    {
      "epoch": 0.192256,
      "grad_norm": 0.06329086053099804,
      "learning_rate": 9.899007392045977e-05,
      "loss": 0.0306,
      "step": 60080
    },
    {
      "epoch": 0.19232,
      "grad_norm": 0.09425024788592297,
      "learning_rate": 9.898940369563416e-05,
      "loss": 0.031,
      "step": 60100
    },
    {
      "epoch": 0.192384,
      "grad_norm": 0.12986101014598134,
      "learning_rate": 9.898873325075957e-05,
      "loss": 0.0319,
      "step": 60120
    },
    {
      "epoch": 0.192448,
      "grad_norm": 0.09390149694711658,
      "learning_rate": 9.898806258583904e-05,
      "loss": 0.0309,
      "step": 60140
    },
    {
      "epoch": 0.192512,
      "grad_norm": 0.08418573659121127,
      "learning_rate": 9.898739170087554e-05,
      "loss": 0.0297,
      "step": 60160
    },
    {
      "epoch": 0.192576,
      "grad_norm": 0.0704679585610366,
      "learning_rate": 9.898672059587213e-05,
      "loss": 0.0306,
      "step": 60180
    },
    {
      "epoch": 0.19264,
      "grad_norm": 0.08951064028171715,
      "learning_rate": 9.898604927083179e-05,
      "loss": 0.033,
      "step": 60200
    },
    {
      "epoch": 0.192704,
      "grad_norm": 0.13454959719514914,
      "learning_rate": 9.898537772575756e-05,
      "loss": 0.0322,
      "step": 60220
    },
    {
      "epoch": 0.192768,
      "grad_norm": 0.11047458939317589,
      "learning_rate": 9.898470596065244e-05,
      "loss": 0.0289,
      "step": 60240
    },
    {
      "epoch": 0.192832,
      "grad_norm": 0.12751289374018013,
      "learning_rate": 9.898403397551946e-05,
      "loss": 0.0313,
      "step": 60260
    },
    {
      "epoch": 0.192896,
      "grad_norm": 0.10434423526967476,
      "learning_rate": 9.898336177036163e-05,
      "loss": 0.0319,
      "step": 60280
    },
    {
      "epoch": 0.19296,
      "grad_norm": 0.07071227445770183,
      "learning_rate": 9.898268934518195e-05,
      "loss": 0.0301,
      "step": 60300
    },
    {
      "epoch": 0.193024,
      "grad_norm": 0.05139802388862973,
      "learning_rate": 9.898201669998349e-05,
      "loss": 0.0281,
      "step": 60320
    },
    {
      "epoch": 0.193088,
      "grad_norm": 0.07961721565166838,
      "learning_rate": 9.898134383476923e-05,
      "loss": 0.0331,
      "step": 60340
    },
    {
      "epoch": 0.193152,
      "grad_norm": 0.12446669206563656,
      "learning_rate": 9.89806707495422e-05,
      "loss": 0.0298,
      "step": 60360
    },
    {
      "epoch": 0.193216,
      "grad_norm": 0.06648989390945005,
      "learning_rate": 9.897999744430544e-05,
      "loss": 0.0296,
      "step": 60380
    },
    {
      "epoch": 0.19328,
      "grad_norm": 0.10789188351453063,
      "learning_rate": 9.897932391906194e-05,
      "loss": 0.0321,
      "step": 60400
    },
    {
      "epoch": 0.193344,
      "grad_norm": 0.06158966927071713,
      "learning_rate": 9.897865017381478e-05,
      "loss": 0.0315,
      "step": 60420
    },
    {
      "epoch": 0.193408,
      "grad_norm": 0.11237228045891828,
      "learning_rate": 9.897797620856693e-05,
      "loss": 0.0267,
      "step": 60440
    },
    {
      "epoch": 0.193472,
      "grad_norm": 0.06100002967528478,
      "learning_rate": 9.897730202332144e-05,
      "loss": 0.0291,
      "step": 60460
    },
    {
      "epoch": 0.193536,
      "grad_norm": 0.08474741080533928,
      "learning_rate": 9.897662761808135e-05,
      "loss": 0.0299,
      "step": 60480
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.096926981113508,
      "learning_rate": 9.897595299284968e-05,
      "loss": 0.0331,
      "step": 60500
    },
    {
      "epoch": 0.193664,
      "grad_norm": 0.07855185510675963,
      "learning_rate": 9.897527814762946e-05,
      "loss": 0.0333,
      "step": 60520
    },
    {
      "epoch": 0.193728,
      "grad_norm": 0.05561983370065681,
      "learning_rate": 9.89746030824237e-05,
      "loss": 0.0318,
      "step": 60540
    },
    {
      "epoch": 0.193792,
      "grad_norm": 0.0878095607355052,
      "learning_rate": 9.897392779723547e-05,
      "loss": 0.0337,
      "step": 60560
    },
    {
      "epoch": 0.193856,
      "grad_norm": 0.06959904863320115,
      "learning_rate": 9.897325229206777e-05,
      "loss": 0.034,
      "step": 60580
    },
    {
      "epoch": 0.19392,
      "grad_norm": 0.10122390124259824,
      "learning_rate": 9.897257656692367e-05,
      "loss": 0.0333,
      "step": 60600
    },
    {
      "epoch": 0.193984,
      "grad_norm": 0.07790775664594773,
      "learning_rate": 9.897190062180619e-05,
      "loss": 0.0342,
      "step": 60620
    },
    {
      "epoch": 0.194048,
      "grad_norm": 0.1409200674558783,
      "learning_rate": 9.897122445671833e-05,
      "loss": 0.0304,
      "step": 60640
    },
    {
      "epoch": 0.194112,
      "grad_norm": 0.07186219182819582,
      "learning_rate": 9.897054807166319e-05,
      "loss": 0.0271,
      "step": 60660
    },
    {
      "epoch": 0.194176,
      "grad_norm": 0.07730216261491468,
      "learning_rate": 9.896987146664376e-05,
      "loss": 0.0284,
      "step": 60680
    },
    {
      "epoch": 0.19424,
      "grad_norm": 0.07092746616956244,
      "learning_rate": 9.89691946416631e-05,
      "loss": 0.0308,
      "step": 60700
    },
    {
      "epoch": 0.194304,
      "grad_norm": 0.09672085613502611,
      "learning_rate": 9.896851759672425e-05,
      "loss": 0.0286,
      "step": 60720
    },
    {
      "epoch": 0.194368,
      "grad_norm": 0.0686086032560444,
      "learning_rate": 9.896784033183025e-05,
      "loss": 0.0318,
      "step": 60740
    },
    {
      "epoch": 0.194432,
      "grad_norm": 0.1126728836128364,
      "learning_rate": 9.896716284698412e-05,
      "loss": 0.0299,
      "step": 60760
    },
    {
      "epoch": 0.194496,
      "grad_norm": 0.16872112576819884,
      "learning_rate": 9.896648514218894e-05,
      "loss": 0.0333,
      "step": 60780
    },
    {
      "epoch": 0.19456,
      "grad_norm": 0.08001816011286227,
      "learning_rate": 9.896580721744772e-05,
      "loss": 0.0319,
      "step": 60800
    },
    {
      "epoch": 0.194624,
      "grad_norm": 0.11760484434579395,
      "learning_rate": 9.896512907276354e-05,
      "loss": 0.0327,
      "step": 60820
    },
    {
      "epoch": 0.194688,
      "grad_norm": 0.0802170357540477,
      "learning_rate": 9.896445070813943e-05,
      "loss": 0.0344,
      "step": 60840
    },
    {
      "epoch": 0.194752,
      "grad_norm": 0.0736701887386983,
      "learning_rate": 9.89637721235784e-05,
      "loss": 0.0291,
      "step": 60860
    },
    {
      "epoch": 0.194816,
      "grad_norm": 0.05677184268701295,
      "learning_rate": 9.896309331908356e-05,
      "loss": 0.0308,
      "step": 60880
    },
    {
      "epoch": 0.19488,
      "grad_norm": 0.11042946171951377,
      "learning_rate": 9.896241429465794e-05,
      "loss": 0.0321,
      "step": 60900
    },
    {
      "epoch": 0.194944,
      "grad_norm": 0.0678211761816004,
      "learning_rate": 9.896173505030458e-05,
      "loss": 0.0295,
      "step": 60920
    },
    {
      "epoch": 0.195008,
      "grad_norm": 0.10701547818281253,
      "learning_rate": 9.896105558602651e-05,
      "loss": 0.0318,
      "step": 60940
    },
    {
      "epoch": 0.195072,
      "grad_norm": 0.0640714627087837,
      "learning_rate": 9.896037590182682e-05,
      "loss": 0.0321,
      "step": 60960
    },
    {
      "epoch": 0.195136,
      "grad_norm": 0.062094725726349956,
      "learning_rate": 9.895969599770853e-05,
      "loss": 0.0291,
      "step": 60980
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.06687166013531315,
      "learning_rate": 9.895901587367473e-05,
      "loss": 0.032,
      "step": 61000
    },
    {
      "epoch": 0.195264,
      "grad_norm": 0.09537621545359926,
      "learning_rate": 9.895833552972847e-05,
      "loss": 0.0288,
      "step": 61020
    },
    {
      "epoch": 0.195328,
      "grad_norm": 0.06471981423394278,
      "learning_rate": 9.895765496587276e-05,
      "loss": 0.031,
      "step": 61040
    },
    {
      "epoch": 0.195392,
      "grad_norm": 0.0819355863369456,
      "learning_rate": 9.895697418211072e-05,
      "loss": 0.0294,
      "step": 61060
    },
    {
      "epoch": 0.195456,
      "grad_norm": 0.05866861005891022,
      "learning_rate": 9.895629317844535e-05,
      "loss": 0.0322,
      "step": 61080
    },
    {
      "epoch": 0.19552,
      "grad_norm": 0.10875114650799464,
      "learning_rate": 9.895561195487975e-05,
      "loss": 0.0321,
      "step": 61100
    },
    {
      "epoch": 0.195584,
      "grad_norm": 0.07623822675649831,
      "learning_rate": 9.895493051141697e-05,
      "loss": 0.0301,
      "step": 61120
    },
    {
      "epoch": 0.195648,
      "grad_norm": 0.09785094467827996,
      "learning_rate": 9.895424884806007e-05,
      "loss": 0.0286,
      "step": 61140
    },
    {
      "epoch": 0.195712,
      "grad_norm": 0.06931473689650194,
      "learning_rate": 9.895356696481208e-05,
      "loss": 0.0297,
      "step": 61160
    },
    {
      "epoch": 0.195776,
      "grad_norm": 0.05549493272907254,
      "learning_rate": 9.895288486167613e-05,
      "loss": 0.0283,
      "step": 61180
    },
    {
      "epoch": 0.19584,
      "grad_norm": 0.07784006463678438,
      "learning_rate": 9.895220253865522e-05,
      "loss": 0.0312,
      "step": 61200
    },
    {
      "epoch": 0.195904,
      "grad_norm": 0.12533703760342307,
      "learning_rate": 9.895151999575245e-05,
      "loss": 0.0346,
      "step": 61220
    },
    {
      "epoch": 0.195968,
      "grad_norm": 0.07205968559113399,
      "learning_rate": 9.895083723297088e-05,
      "loss": 0.0329,
      "step": 61240
    },
    {
      "epoch": 0.196032,
      "grad_norm": 0.06113169352554559,
      "learning_rate": 9.895015425031356e-05,
      "loss": 0.0293,
      "step": 61260
    },
    {
      "epoch": 0.196096,
      "grad_norm": 0.1303784904252652,
      "learning_rate": 9.894947104778359e-05,
      "loss": 0.032,
      "step": 61280
    },
    {
      "epoch": 0.19616,
      "grad_norm": 0.14684742797318978,
      "learning_rate": 9.8948787625384e-05,
      "loss": 0.0333,
      "step": 61300
    },
    {
      "epoch": 0.196224,
      "grad_norm": 0.07605924929327698,
      "learning_rate": 9.89481039831179e-05,
      "loss": 0.0319,
      "step": 61320
    },
    {
      "epoch": 0.196288,
      "grad_norm": 0.10448186062506538,
      "learning_rate": 9.894742012098832e-05,
      "loss": 0.0312,
      "step": 61340
    },
    {
      "epoch": 0.196352,
      "grad_norm": 0.0698382859985516,
      "learning_rate": 9.894673603899836e-05,
      "loss": 0.0312,
      "step": 61360
    },
    {
      "epoch": 0.196416,
      "grad_norm": 0.08206932477813039,
      "learning_rate": 9.894605173715107e-05,
      "loss": 0.0303,
      "step": 61380
    },
    {
      "epoch": 0.19648,
      "grad_norm": 0.07141172314713462,
      "learning_rate": 9.894536721544957e-05,
      "loss": 0.031,
      "step": 61400
    },
    {
      "epoch": 0.196544,
      "grad_norm": 0.06709066594101129,
      "learning_rate": 9.894468247389689e-05,
      "loss": 0.0305,
      "step": 61420
    },
    {
      "epoch": 0.196608,
      "grad_norm": 0.12169138506048809,
      "learning_rate": 9.894399751249611e-05,
      "loss": 0.0326,
      "step": 61440
    },
    {
      "epoch": 0.196672,
      "grad_norm": 0.09613688788499254,
      "learning_rate": 9.894331233125033e-05,
      "loss": 0.0302,
      "step": 61460
    },
    {
      "epoch": 0.196736,
      "grad_norm": 0.05278142388055059,
      "learning_rate": 9.89426269301626e-05,
      "loss": 0.0284,
      "step": 61480
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.13578121101185436,
      "learning_rate": 9.894194130923602e-05,
      "loss": 0.0309,
      "step": 61500
    },
    {
      "epoch": 0.196864,
      "grad_norm": 0.06637212701748277,
      "learning_rate": 9.894125546847366e-05,
      "loss": 0.0324,
      "step": 61520
    },
    {
      "epoch": 0.196928,
      "grad_norm": 0.05240225896770924,
      "learning_rate": 9.89405694078786e-05,
      "loss": 0.0298,
      "step": 61540
    },
    {
      "epoch": 0.196992,
      "grad_norm": 0.05487980617276184,
      "learning_rate": 9.893988312745392e-05,
      "loss": 0.0283,
      "step": 61560
    },
    {
      "epoch": 0.197056,
      "grad_norm": 0.09063662250011725,
      "learning_rate": 9.89391966272027e-05,
      "loss": 0.0318,
      "step": 61580
    },
    {
      "epoch": 0.19712,
      "grad_norm": 0.11604046588493298,
      "learning_rate": 9.893850990712806e-05,
      "loss": 0.0308,
      "step": 61600
    },
    {
      "epoch": 0.197184,
      "grad_norm": 0.07700860958460015,
      "learning_rate": 9.893782296723302e-05,
      "loss": 0.0305,
      "step": 61620
    },
    {
      "epoch": 0.197248,
      "grad_norm": 0.07933001334214801,
      "learning_rate": 9.893713580752072e-05,
      "loss": 0.0293,
      "step": 61640
    },
    {
      "epoch": 0.197312,
      "grad_norm": 0.09772465961427232,
      "learning_rate": 9.893644842799422e-05,
      "loss": 0.0293,
      "step": 61660
    },
    {
      "epoch": 0.197376,
      "grad_norm": 0.10204794159022518,
      "learning_rate": 9.893576082865661e-05,
      "loss": 0.0299,
      "step": 61680
    },
    {
      "epoch": 0.19744,
      "grad_norm": 0.05855340392624238,
      "learning_rate": 9.8935073009511e-05,
      "loss": 0.0316,
      "step": 61700
    },
    {
      "epoch": 0.197504,
      "grad_norm": 0.08714582062645373,
      "learning_rate": 9.893438497056045e-05,
      "loss": 0.0293,
      "step": 61720
    },
    {
      "epoch": 0.197568,
      "grad_norm": 0.08166689874857597,
      "learning_rate": 9.893369671180806e-05,
      "loss": 0.0292,
      "step": 61740
    },
    {
      "epoch": 0.197632,
      "grad_norm": 0.07942049446652197,
      "learning_rate": 9.893300823325693e-05,
      "loss": 0.0315,
      "step": 61760
    },
    {
      "epoch": 0.197696,
      "grad_norm": 0.05679037065786764,
      "learning_rate": 9.893231953491015e-05,
      "loss": 0.0302,
      "step": 61780
    },
    {
      "epoch": 0.19776,
      "grad_norm": 0.0973253556157589,
      "learning_rate": 9.89316306167708e-05,
      "loss": 0.0343,
      "step": 61800
    },
    {
      "epoch": 0.197824,
      "grad_norm": 0.051617282043366325,
      "learning_rate": 9.893094147884199e-05,
      "loss": 0.0327,
      "step": 61820
    },
    {
      "epoch": 0.197888,
      "grad_norm": 0.06490598622432976,
      "learning_rate": 9.893025212112681e-05,
      "loss": 0.0277,
      "step": 61840
    },
    {
      "epoch": 0.197952,
      "grad_norm": 0.06926496415549095,
      "learning_rate": 9.892956254362835e-05,
      "loss": 0.0286,
      "step": 61860
    },
    {
      "epoch": 0.198016,
      "grad_norm": 0.06583024638132584,
      "learning_rate": 9.892887274634973e-05,
      "loss": 0.0309,
      "step": 61880
    },
    {
      "epoch": 0.19808,
      "grad_norm": 0.11182811176977141,
      "learning_rate": 9.892818272929403e-05,
      "loss": 0.0271,
      "step": 61900
    },
    {
      "epoch": 0.198144,
      "grad_norm": 0.05014027710008368,
      "learning_rate": 9.892749249246434e-05,
      "loss": 0.0298,
      "step": 61920
    },
    {
      "epoch": 0.198208,
      "grad_norm": 0.06955886565878724,
      "learning_rate": 9.892680203586377e-05,
      "loss": 0.0286,
      "step": 61940
    },
    {
      "epoch": 0.198272,
      "grad_norm": 0.10697841313446631,
      "learning_rate": 9.892611135949543e-05,
      "loss": 0.0302,
      "step": 61960
    },
    {
      "epoch": 0.198336,
      "grad_norm": 0.06625891120506502,
      "learning_rate": 9.892542046336243e-05,
      "loss": 0.0305,
      "step": 61980
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.15507989222184676,
      "learning_rate": 9.892472934746784e-05,
      "loss": 0.0326,
      "step": 62000
    },
    {
      "epoch": 0.198464,
      "grad_norm": 0.18375831456167252,
      "learning_rate": 9.89240380118148e-05,
      "loss": 0.0317,
      "step": 62020
    },
    {
      "epoch": 0.198528,
      "grad_norm": 0.07149617138962547,
      "learning_rate": 9.892334645640638e-05,
      "loss": 0.0351,
      "step": 62040
    },
    {
      "epoch": 0.198592,
      "grad_norm": 0.04779945142917935,
      "learning_rate": 9.892265468124572e-05,
      "loss": 0.0308,
      "step": 62060
    },
    {
      "epoch": 0.198656,
      "grad_norm": 0.10284807613957302,
      "learning_rate": 9.892196268633592e-05,
      "loss": 0.0317,
      "step": 62080
    },
    {
      "epoch": 0.19872,
      "grad_norm": 0.06000234518312874,
      "learning_rate": 9.892127047168004e-05,
      "loss": 0.0344,
      "step": 62100
    },
    {
      "epoch": 0.198784,
      "grad_norm": 0.06429949449582269,
      "learning_rate": 9.892057803728127e-05,
      "loss": 0.0302,
      "step": 62120
    },
    {
      "epoch": 0.198848,
      "grad_norm": 0.10842053577962579,
      "learning_rate": 9.891988538314268e-05,
      "loss": 0.0321,
      "step": 62140
    },
    {
      "epoch": 0.198912,
      "grad_norm": 0.13938717345038126,
      "learning_rate": 9.891919250926735e-05,
      "loss": 0.0322,
      "step": 62160
    },
    {
      "epoch": 0.198976,
      "grad_norm": 0.057713137488330776,
      "learning_rate": 9.891849941565845e-05,
      "loss": 0.0349,
      "step": 62180
    },
    {
      "epoch": 0.19904,
      "grad_norm": 0.0768692173925232,
      "learning_rate": 9.891780610231907e-05,
      "loss": 0.0317,
      "step": 62200
    },
    {
      "epoch": 0.199104,
      "grad_norm": 0.09271261722337276,
      "learning_rate": 9.891711256925232e-05,
      "loss": 0.0285,
      "step": 62220
    },
    {
      "epoch": 0.199168,
      "grad_norm": 0.0898927603500762,
      "learning_rate": 9.89164188164613e-05,
      "loss": 0.0315,
      "step": 62240
    },
    {
      "epoch": 0.199232,
      "grad_norm": 0.07646915821152574,
      "learning_rate": 9.891572484394916e-05,
      "loss": 0.0327,
      "step": 62260
    },
    {
      "epoch": 0.199296,
      "grad_norm": 0.07865861512866454,
      "learning_rate": 9.8915030651719e-05,
      "loss": 0.0302,
      "step": 62280
    },
    {
      "epoch": 0.19936,
      "grad_norm": 0.08436364241977502,
      "learning_rate": 9.891433623977391e-05,
      "loss": 0.0318,
      "step": 62300
    },
    {
      "epoch": 0.199424,
      "grad_norm": 0.062311075034575523,
      "learning_rate": 9.891364160811705e-05,
      "loss": 0.0326,
      "step": 62320
    },
    {
      "epoch": 0.199488,
      "grad_norm": 0.08078036865067863,
      "learning_rate": 9.891294675675153e-05,
      "loss": 0.0298,
      "step": 62340
    },
    {
      "epoch": 0.199552,
      "grad_norm": 0.11242842084438706,
      "learning_rate": 9.891225168568048e-05,
      "loss": 0.0345,
      "step": 62360
    },
    {
      "epoch": 0.199616,
      "grad_norm": 0.0863466846534019,
      "learning_rate": 9.8911556394907e-05,
      "loss": 0.0285,
      "step": 62380
    },
    {
      "epoch": 0.19968,
      "grad_norm": 0.05808027699246877,
      "learning_rate": 9.891086088443423e-05,
      "loss": 0.0264,
      "step": 62400
    },
    {
      "epoch": 0.199744,
      "grad_norm": 0.07995310188949552,
      "learning_rate": 9.891016515426528e-05,
      "loss": 0.0301,
      "step": 62420
    },
    {
      "epoch": 0.199808,
      "grad_norm": 0.08107171739928222,
      "learning_rate": 9.890946920440329e-05,
      "loss": 0.0323,
      "step": 62440
    },
    {
      "epoch": 0.199872,
      "grad_norm": 0.06297589335834405,
      "learning_rate": 9.890877303485138e-05,
      "loss": 0.0317,
      "step": 62460
    },
    {
      "epoch": 0.199936,
      "grad_norm": 0.07762944076852882,
      "learning_rate": 9.890807664561266e-05,
      "loss": 0.0288,
      "step": 62480
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12186999436172585,
      "learning_rate": 9.890738003669029e-05,
      "loss": 0.0327,
      "step": 62500
    },
    {
      "epoch": 0.200064,
      "grad_norm": 0.06563098417455279,
      "learning_rate": 9.890668320808739e-05,
      "loss": 0.033,
      "step": 62520
    },
    {
      "epoch": 0.200128,
      "grad_norm": 0.05871107683333555,
      "learning_rate": 9.890598615980706e-05,
      "loss": 0.0283,
      "step": 62540
    },
    {
      "epoch": 0.200192,
      "grad_norm": 0.08004769290431618,
      "learning_rate": 9.890528889185246e-05,
      "loss": 0.0303,
      "step": 62560
    },
    {
      "epoch": 0.200256,
      "grad_norm": 0.07938834792632665,
      "learning_rate": 9.890459140422673e-05,
      "loss": 0.0278,
      "step": 62580
    },
    {
      "epoch": 0.20032,
      "grad_norm": 0.08603775407234336,
      "learning_rate": 9.890389369693296e-05,
      "loss": 0.0308,
      "step": 62600
    },
    {
      "epoch": 0.200384,
      "grad_norm": 0.11055551034732886,
      "learning_rate": 9.890319576997433e-05,
      "loss": 0.0303,
      "step": 62620
    },
    {
      "epoch": 0.200448,
      "grad_norm": 0.06123784485716809,
      "learning_rate": 9.890249762335395e-05,
      "loss": 0.0325,
      "step": 62640
    },
    {
      "epoch": 0.200512,
      "grad_norm": 0.07983469946844252,
      "learning_rate": 9.890179925707497e-05,
      "loss": 0.0297,
      "step": 62660
    },
    {
      "epoch": 0.200576,
      "grad_norm": 0.05206335144078582,
      "learning_rate": 9.890110067114054e-05,
      "loss": 0.0307,
      "step": 62680
    },
    {
      "epoch": 0.20064,
      "grad_norm": 0.09512223442399825,
      "learning_rate": 9.890040186555375e-05,
      "loss": 0.0291,
      "step": 62700
    },
    {
      "epoch": 0.200704,
      "grad_norm": 0.06451238270080743,
      "learning_rate": 9.889970284031778e-05,
      "loss": 0.0281,
      "step": 62720
    },
    {
      "epoch": 0.200768,
      "grad_norm": 0.08550344291490274,
      "learning_rate": 9.889900359543575e-05,
      "loss": 0.0307,
      "step": 62740
    },
    {
      "epoch": 0.200832,
      "grad_norm": 0.07270337059535208,
      "learning_rate": 9.889830413091082e-05,
      "loss": 0.0338,
      "step": 62760
    },
    {
      "epoch": 0.200896,
      "grad_norm": 0.09512729992735945,
      "learning_rate": 9.88976044467461e-05,
      "loss": 0.034,
      "step": 62780
    },
    {
      "epoch": 0.20096,
      "grad_norm": 0.06615045591555849,
      "learning_rate": 9.889690454294476e-05,
      "loss": 0.0292,
      "step": 62800
    },
    {
      "epoch": 0.201024,
      "grad_norm": 0.08910879008877794,
      "learning_rate": 9.889620441950995e-05,
      "loss": 0.0305,
      "step": 62820
    },
    {
      "epoch": 0.201088,
      "grad_norm": 0.0605152520287331,
      "learning_rate": 9.889550407644478e-05,
      "loss": 0.0348,
      "step": 62840
    },
    {
      "epoch": 0.201152,
      "grad_norm": 0.07728539640240824,
      "learning_rate": 9.889480351375242e-05,
      "loss": 0.0334,
      "step": 62860
    },
    {
      "epoch": 0.201216,
      "grad_norm": 0.06152172644097212,
      "learning_rate": 9.889410273143602e-05,
      "loss": 0.0317,
      "step": 62880
    },
    {
      "epoch": 0.20128,
      "grad_norm": 0.05386747881846268,
      "learning_rate": 9.889340172949872e-05,
      "loss": 0.031,
      "step": 62900
    },
    {
      "epoch": 0.201344,
      "grad_norm": 0.07742339573750492,
      "learning_rate": 9.889270050794369e-05,
      "loss": 0.0302,
      "step": 62920
    },
    {
      "epoch": 0.201408,
      "grad_norm": 0.11064297781592901,
      "learning_rate": 9.889199906677402e-05,
      "loss": 0.033,
      "step": 62940
    },
    {
      "epoch": 0.201472,
      "grad_norm": 0.059745369438746164,
      "learning_rate": 9.889129740599293e-05,
      "loss": 0.0286,
      "step": 62960
    },
    {
      "epoch": 0.201536,
      "grad_norm": 0.06454175695880615,
      "learning_rate": 9.889059552560353e-05,
      "loss": 0.0311,
      "step": 62980
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.056593599562569506,
      "learning_rate": 9.888989342560899e-05,
      "loss": 0.0307,
      "step": 63000
    },
    {
      "epoch": 0.201664,
      "grad_norm": 0.06417742242848436,
      "learning_rate": 9.888919110601245e-05,
      "loss": 0.0307,
      "step": 63020
    },
    {
      "epoch": 0.201728,
      "grad_norm": 0.1268828004041676,
      "learning_rate": 9.88884885668171e-05,
      "loss": 0.0271,
      "step": 63040
    },
    {
      "epoch": 0.201792,
      "grad_norm": 0.11075245721018577,
      "learning_rate": 9.888778580802603e-05,
      "loss": 0.0276,
      "step": 63060
    },
    {
      "epoch": 0.201856,
      "grad_norm": 0.12940877064919387,
      "learning_rate": 9.888708282964245e-05,
      "loss": 0.0326,
      "step": 63080
    },
    {
      "epoch": 0.20192,
      "grad_norm": 0.051846573628494465,
      "learning_rate": 9.888637963166951e-05,
      "loss": 0.0311,
      "step": 63100
    },
    {
      "epoch": 0.201984,
      "grad_norm": 0.0967980313640854,
      "learning_rate": 9.888567621411037e-05,
      "loss": 0.0305,
      "step": 63120
    },
    {
      "epoch": 0.202048,
      "grad_norm": 0.14683090184630224,
      "learning_rate": 9.888497257696816e-05,
      "loss": 0.0322,
      "step": 63140
    },
    {
      "epoch": 0.202112,
      "grad_norm": 0.05832873128240348,
      "learning_rate": 9.888426872024607e-05,
      "loss": 0.0315,
      "step": 63160
    },
    {
      "epoch": 0.202176,
      "grad_norm": 0.07444137981373461,
      "learning_rate": 9.888356464394726e-05,
      "loss": 0.0317,
      "step": 63180
    },
    {
      "epoch": 0.20224,
      "grad_norm": 0.060514928654942284,
      "learning_rate": 9.888286034807488e-05,
      "loss": 0.0301,
      "step": 63200
    },
    {
      "epoch": 0.202304,
      "grad_norm": 0.0838569680536182,
      "learning_rate": 9.888215583263211e-05,
      "loss": 0.0281,
      "step": 63220
    },
    {
      "epoch": 0.202368,
      "grad_norm": 0.08829041062327733,
      "learning_rate": 9.88814510976221e-05,
      "loss": 0.0308,
      "step": 63240
    },
    {
      "epoch": 0.202432,
      "grad_norm": 0.06215733658389588,
      "learning_rate": 9.888074614304801e-05,
      "loss": 0.0294,
      "step": 63260
    },
    {
      "epoch": 0.202496,
      "grad_norm": 0.06359654917293786,
      "learning_rate": 9.888004096891301e-05,
      "loss": 0.0341,
      "step": 63280
    },
    {
      "epoch": 0.20256,
      "grad_norm": 0.17896120220466766,
      "learning_rate": 9.88793355752203e-05,
      "loss": 0.0311,
      "step": 63300
    },
    {
      "epoch": 0.202624,
      "grad_norm": 0.05048565255195389,
      "learning_rate": 9.887862996197299e-05,
      "loss": 0.0318,
      "step": 63320
    },
    {
      "epoch": 0.202688,
      "grad_norm": 0.0646998510329791,
      "learning_rate": 9.887792412917429e-05,
      "loss": 0.0302,
      "step": 63340
    },
    {
      "epoch": 0.202752,
      "grad_norm": 0.0562610591555951,
      "learning_rate": 9.887721807682737e-05,
      "loss": 0.0307,
      "step": 63360
    },
    {
      "epoch": 0.202816,
      "grad_norm": 0.1477430376627839,
      "learning_rate": 9.887651180493541e-05,
      "loss": 0.0305,
      "step": 63380
    },
    {
      "epoch": 0.20288,
      "grad_norm": 0.0674345676720661,
      "learning_rate": 9.887580531350153e-05,
      "loss": 0.0317,
      "step": 63400
    },
    {
      "epoch": 0.202944,
      "grad_norm": 0.07734606496544501,
      "learning_rate": 9.887509860252896e-05,
      "loss": 0.033,
      "step": 63420
    },
    {
      "epoch": 0.203008,
      "grad_norm": 0.12056069746244899,
      "learning_rate": 9.887439167202085e-05,
      "loss": 0.0342,
      "step": 63440
    },
    {
      "epoch": 0.203072,
      "grad_norm": 0.119200794918838,
      "learning_rate": 9.887368452198039e-05,
      "loss": 0.032,
      "step": 63460
    },
    {
      "epoch": 0.203136,
      "grad_norm": 0.10154048541431089,
      "learning_rate": 9.887297715241071e-05,
      "loss": 0.0302,
      "step": 63480
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.0672682043952556,
      "learning_rate": 9.887226956331505e-05,
      "loss": 0.0317,
      "step": 63500
    },
    {
      "epoch": 0.203264,
      "grad_norm": 0.06015799237233984,
      "learning_rate": 9.887156175469656e-05,
      "loss": 0.0297,
      "step": 63520
    },
    {
      "epoch": 0.203328,
      "grad_norm": 0.08212798306311808,
      "learning_rate": 9.887085372655842e-05,
      "loss": 0.029,
      "step": 63540
    },
    {
      "epoch": 0.203392,
      "grad_norm": 0.08341155068462985,
      "learning_rate": 9.88701454789038e-05,
      "loss": 0.0276,
      "step": 63560
    },
    {
      "epoch": 0.203456,
      "grad_norm": 0.10931404313253278,
      "learning_rate": 9.88694370117359e-05,
      "loss": 0.0332,
      "step": 63580
    },
    {
      "epoch": 0.20352,
      "grad_norm": 0.11037579197073154,
      "learning_rate": 9.886872832505789e-05,
      "loss": 0.0348,
      "step": 63600
    },
    {
      "epoch": 0.203584,
      "grad_norm": 0.06616123590128432,
      "learning_rate": 9.886801941887297e-05,
      "loss": 0.0324,
      "step": 63620
    },
    {
      "epoch": 0.203648,
      "grad_norm": 0.0657499508743157,
      "learning_rate": 9.88673102931843e-05,
      "loss": 0.0297,
      "step": 63640
    },
    {
      "epoch": 0.203712,
      "grad_norm": 0.1231905127093973,
      "learning_rate": 9.886660094799507e-05,
      "loss": 0.0304,
      "step": 63660
    },
    {
      "epoch": 0.203776,
      "grad_norm": 0.08221796481018362,
      "learning_rate": 9.886589138330848e-05,
      "loss": 0.0309,
      "step": 63680
    },
    {
      "epoch": 0.20384,
      "grad_norm": 0.09298171826584051,
      "learning_rate": 9.886518159912773e-05,
      "loss": 0.0348,
      "step": 63700
    },
    {
      "epoch": 0.203904,
      "grad_norm": 0.0687283839880023,
      "learning_rate": 9.886447159545596e-05,
      "loss": 0.0305,
      "step": 63720
    },
    {
      "epoch": 0.203968,
      "grad_norm": 0.06302537301108221,
      "learning_rate": 9.886376137229638e-05,
      "loss": 0.0305,
      "step": 63740
    },
    {
      "epoch": 0.204032,
      "grad_norm": 0.09716567822536326,
      "learning_rate": 9.886305092965221e-05,
      "loss": 0.0257,
      "step": 63760
    },
    {
      "epoch": 0.204096,
      "grad_norm": 0.10773349544042748,
      "learning_rate": 9.886234026752661e-05,
      "loss": 0.0285,
      "step": 63780
    },
    {
      "epoch": 0.20416,
      "grad_norm": 0.07901067280872685,
      "learning_rate": 9.886162938592279e-05,
      "loss": 0.032,
      "step": 63800
    },
    {
      "epoch": 0.204224,
      "grad_norm": 0.07664776168887391,
      "learning_rate": 9.886091828484392e-05,
      "loss": 0.0299,
      "step": 63820
    },
    {
      "epoch": 0.204288,
      "grad_norm": 0.05456249934455802,
      "learning_rate": 9.886020696429322e-05,
      "loss": 0.03,
      "step": 63840
    },
    {
      "epoch": 0.204352,
      "grad_norm": 0.06837568986442204,
      "learning_rate": 9.885949542427387e-05,
      "loss": 0.0301,
      "step": 63860
    },
    {
      "epoch": 0.204416,
      "grad_norm": 0.061365967702563716,
      "learning_rate": 9.885878366478906e-05,
      "loss": 0.0308,
      "step": 63880
    },
    {
      "epoch": 0.20448,
      "grad_norm": 0.09146446078901226,
      "learning_rate": 9.885807168584202e-05,
      "loss": 0.0334,
      "step": 63900
    },
    {
      "epoch": 0.204544,
      "grad_norm": 0.10042686227990938,
      "learning_rate": 9.885735948743589e-05,
      "loss": 0.0309,
      "step": 63920
    },
    {
      "epoch": 0.204608,
      "grad_norm": 0.06603926766223514,
      "learning_rate": 9.885664706957394e-05,
      "loss": 0.0308,
      "step": 63940
    },
    {
      "epoch": 0.204672,
      "grad_norm": 0.06374318497870726,
      "learning_rate": 9.885593443225931e-05,
      "loss": 0.0321,
      "step": 63960
    },
    {
      "epoch": 0.204736,
      "grad_norm": 0.07408396367228946,
      "learning_rate": 9.885522157549523e-05,
      "loss": 0.0292,
      "step": 63980
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.06248315119423602,
      "learning_rate": 9.885450849928489e-05,
      "loss": 0.0287,
      "step": 64000
    },
    {
      "epoch": 0.204864,
      "grad_norm": 0.11217650994761383,
      "learning_rate": 9.885379520363151e-05,
      "loss": 0.0309,
      "step": 64020
    },
    {
      "epoch": 0.204928,
      "grad_norm": 0.07386765104562358,
      "learning_rate": 9.885308168853827e-05,
      "loss": 0.0349,
      "step": 64040
    },
    {
      "epoch": 0.204992,
      "grad_norm": 0.11135194803739466,
      "learning_rate": 9.88523679540084e-05,
      "loss": 0.0309,
      "step": 64060
    },
    {
      "epoch": 0.205056,
      "grad_norm": 0.058430369177536384,
      "learning_rate": 9.885165400004508e-05,
      "loss": 0.0281,
      "step": 64080
    },
    {
      "epoch": 0.20512,
      "grad_norm": 0.08220734841135377,
      "learning_rate": 9.885093982665155e-05,
      "loss": 0.0303,
      "step": 64100
    },
    {
      "epoch": 0.205184,
      "grad_norm": 0.060990656579194336,
      "learning_rate": 9.885022543383099e-05,
      "loss": 0.0312,
      "step": 64120
    },
    {
      "epoch": 0.205248,
      "grad_norm": 0.09034580299613967,
      "learning_rate": 9.884951082158662e-05,
      "loss": 0.03,
      "step": 64140
    },
    {
      "epoch": 0.205312,
      "grad_norm": 0.07721098555870005,
      "learning_rate": 9.884879598992165e-05,
      "loss": 0.03,
      "step": 64160
    },
    {
      "epoch": 0.205376,
      "grad_norm": 0.05245287110735163,
      "learning_rate": 9.884808093883929e-05,
      "loss": 0.0293,
      "step": 64180
    },
    {
      "epoch": 0.20544,
      "grad_norm": 0.05473640872983397,
      "learning_rate": 9.884736566834274e-05,
      "loss": 0.0306,
      "step": 64200
    },
    {
      "epoch": 0.205504,
      "grad_norm": 0.09700912482389562,
      "learning_rate": 9.884665017843522e-05,
      "loss": 0.0317,
      "step": 64220
    },
    {
      "epoch": 0.205568,
      "grad_norm": 0.08198653204921219,
      "learning_rate": 9.884593446911996e-05,
      "loss": 0.0297,
      "step": 64240
    },
    {
      "epoch": 0.205632,
      "grad_norm": 0.12875403382407916,
      "learning_rate": 9.884521854040017e-05,
      "loss": 0.0312,
      "step": 64260
    },
    {
      "epoch": 0.205696,
      "grad_norm": 0.0625957501679003,
      "learning_rate": 9.884450239227903e-05,
      "loss": 0.027,
      "step": 64280
    },
    {
      "epoch": 0.20576,
      "grad_norm": 0.0748896994819878,
      "learning_rate": 9.88437860247598e-05,
      "loss": 0.0304,
      "step": 64300
    },
    {
      "epoch": 0.205824,
      "grad_norm": 0.07691370159412471,
      "learning_rate": 9.884306943784568e-05,
      "loss": 0.0287,
      "step": 64320
    },
    {
      "epoch": 0.205888,
      "grad_norm": 0.09988206869665896,
      "learning_rate": 9.88423526315399e-05,
      "loss": 0.0313,
      "step": 64340
    },
    {
      "epoch": 0.205952,
      "grad_norm": 0.06096291857040583,
      "learning_rate": 9.884163560584565e-05,
      "loss": 0.03,
      "step": 64360
    },
    {
      "epoch": 0.206016,
      "grad_norm": 0.05882499625324927,
      "learning_rate": 9.884091836076619e-05,
      "loss": 0.0283,
      "step": 64380
    },
    {
      "epoch": 0.20608,
      "grad_norm": 0.07311449352289706,
      "learning_rate": 9.884020089630473e-05,
      "loss": 0.0262,
      "step": 64400
    },
    {
      "epoch": 0.206144,
      "grad_norm": 0.062244495478648035,
      "learning_rate": 9.883948321246446e-05,
      "loss": 0.0294,
      "step": 64420
    },
    {
      "epoch": 0.206208,
      "grad_norm": 0.10751973944075745,
      "learning_rate": 9.883876530924865e-05,
      "loss": 0.0296,
      "step": 64440
    },
    {
      "epoch": 0.206272,
      "grad_norm": 0.08757285110306214,
      "learning_rate": 9.88380471866605e-05,
      "loss": 0.0303,
      "step": 64460
    },
    {
      "epoch": 0.206336,
      "grad_norm": 0.11072280387193506,
      "learning_rate": 9.883732884470322e-05,
      "loss": 0.0294,
      "step": 64480
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.07452427659408904,
      "learning_rate": 9.883661028338008e-05,
      "loss": 0.031,
      "step": 64500
    },
    {
      "epoch": 0.206464,
      "grad_norm": 0.10289466290419874,
      "learning_rate": 9.883589150269428e-05,
      "loss": 0.0324,
      "step": 64520
    },
    {
      "epoch": 0.206528,
      "grad_norm": 0.09347073594765434,
      "learning_rate": 9.883517250264904e-05,
      "loss": 0.0324,
      "step": 64540
    },
    {
      "epoch": 0.206592,
      "grad_norm": 0.06950875889445961,
      "learning_rate": 9.883445328324762e-05,
      "loss": 0.0315,
      "step": 64560
    },
    {
      "epoch": 0.206656,
      "grad_norm": 0.16004413109609228,
      "learning_rate": 9.883373384449321e-05,
      "loss": 0.0318,
      "step": 64580
    },
    {
      "epoch": 0.20672,
      "grad_norm": 0.15477221883523498,
      "learning_rate": 9.883301418638908e-05,
      "loss": 0.0296,
      "step": 64600
    },
    {
      "epoch": 0.206784,
      "grad_norm": 0.08781466540967116,
      "learning_rate": 9.883229430893846e-05,
      "loss": 0.028,
      "step": 64620
    },
    {
      "epoch": 0.206848,
      "grad_norm": 0.09294512414526,
      "learning_rate": 9.883157421214455e-05,
      "loss": 0.0313,
      "step": 64640
    },
    {
      "epoch": 0.206912,
      "grad_norm": 0.08566778758251467,
      "learning_rate": 9.883085389601061e-05,
      "loss": 0.0329,
      "step": 64660
    },
    {
      "epoch": 0.206976,
      "grad_norm": 0.08230644110344161,
      "learning_rate": 9.883013336053987e-05,
      "loss": 0.0309,
      "step": 64680
    },
    {
      "epoch": 0.20704,
      "grad_norm": 0.0690084071551508,
      "learning_rate": 9.882941260573557e-05,
      "loss": 0.0307,
      "step": 64700
    },
    {
      "epoch": 0.207104,
      "grad_norm": 0.09759997168483174,
      "learning_rate": 9.882869163160093e-05,
      "loss": 0.0284,
      "step": 64720
    },
    {
      "epoch": 0.207168,
      "grad_norm": 0.07242837389111798,
      "learning_rate": 9.882797043813922e-05,
      "loss": 0.0285,
      "step": 64740
    },
    {
      "epoch": 0.207232,
      "grad_norm": 0.07482801742379408,
      "learning_rate": 9.882724902535365e-05,
      "loss": 0.0337,
      "step": 64760
    },
    {
      "epoch": 0.207296,
      "grad_norm": 0.07163112894765901,
      "learning_rate": 9.882652739324749e-05,
      "loss": 0.0325,
      "step": 64780
    },
    {
      "epoch": 0.20736,
      "grad_norm": 0.06799728310017482,
      "learning_rate": 9.882580554182395e-05,
      "loss": 0.0295,
      "step": 64800
    },
    {
      "epoch": 0.207424,
      "grad_norm": 0.05140417337600272,
      "learning_rate": 9.882508347108629e-05,
      "loss": 0.0313,
      "step": 64820
    },
    {
      "epoch": 0.207488,
      "grad_norm": 0.0844284109742039,
      "learning_rate": 9.882436118103776e-05,
      "loss": 0.0325,
      "step": 64840
    },
    {
      "epoch": 0.207552,
      "grad_norm": 0.1082347599460806,
      "learning_rate": 9.882363867168157e-05,
      "loss": 0.0286,
      "step": 64860
    },
    {
      "epoch": 0.207616,
      "grad_norm": 0.1321313726237459,
      "learning_rate": 9.8822915943021e-05,
      "loss": 0.0294,
      "step": 64880
    },
    {
      "epoch": 0.20768,
      "grad_norm": 0.053184893732247385,
      "learning_rate": 9.882219299505928e-05,
      "loss": 0.0312,
      "step": 64900
    },
    {
      "epoch": 0.207744,
      "grad_norm": 0.07928081127986399,
      "learning_rate": 9.882146982779968e-05,
      "loss": 0.0285,
      "step": 64920
    },
    {
      "epoch": 0.207808,
      "grad_norm": 0.07231535765809001,
      "learning_rate": 9.882074644124542e-05,
      "loss": 0.0317,
      "step": 64940
    },
    {
      "epoch": 0.207872,
      "grad_norm": 0.06334499974691624,
      "learning_rate": 9.882002283539976e-05,
      "loss": 0.0282,
      "step": 64960
    },
    {
      "epoch": 0.207936,
      "grad_norm": 0.07207185842086515,
      "learning_rate": 9.881929901026596e-05,
      "loss": 0.0307,
      "step": 64980
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.1721508134809888,
      "learning_rate": 9.881857496584726e-05,
      "loss": 0.0289,
      "step": 65000
    },
    {
      "epoch": 0.208064,
      "grad_norm": 0.08803090965037179,
      "learning_rate": 9.88178507021469e-05,
      "loss": 0.0278,
      "step": 65020
    },
    {
      "epoch": 0.208128,
      "grad_norm": 0.06328641056238643,
      "learning_rate": 9.881712621916816e-05,
      "loss": 0.0319,
      "step": 65040
    },
    {
      "epoch": 0.208192,
      "grad_norm": 0.06464172430577718,
      "learning_rate": 9.881640151691426e-05,
      "loss": 0.0291,
      "step": 65060
    },
    {
      "epoch": 0.208256,
      "grad_norm": 0.0811637248113288,
      "learning_rate": 9.88156765953885e-05,
      "loss": 0.0305,
      "step": 65080
    },
    {
      "epoch": 0.20832,
      "grad_norm": 0.10973631260988599,
      "learning_rate": 9.881495145459411e-05,
      "loss": 0.0287,
      "step": 65100
    },
    {
      "epoch": 0.208384,
      "grad_norm": 0.08359290176455803,
      "learning_rate": 9.881422609453436e-05,
      "loss": 0.0293,
      "step": 65120
    },
    {
      "epoch": 0.208448,
      "grad_norm": 0.0646451899461119,
      "learning_rate": 9.881350051521249e-05,
      "loss": 0.0309,
      "step": 65140
    },
    {
      "epoch": 0.208512,
      "grad_norm": 0.057568645461188096,
      "learning_rate": 9.881277471663176e-05,
      "loss": 0.0311,
      "step": 65160
    },
    {
      "epoch": 0.208576,
      "grad_norm": 0.06858471435822595,
      "learning_rate": 9.881204869879545e-05,
      "loss": 0.0284,
      "step": 65180
    },
    {
      "epoch": 0.20864,
      "grad_norm": 0.13768895249512972,
      "learning_rate": 9.881132246170679e-05,
      "loss": 0.0312,
      "step": 65200
    },
    {
      "epoch": 0.208704,
      "grad_norm": 0.06067100071369753,
      "learning_rate": 9.881059600536908e-05,
      "loss": 0.0281,
      "step": 65220
    },
    {
      "epoch": 0.208768,
      "grad_norm": 0.16741521431349984,
      "learning_rate": 9.880986932978555e-05,
      "loss": 0.0324,
      "step": 65240
    },
    {
      "epoch": 0.208832,
      "grad_norm": 0.05726575772112028,
      "learning_rate": 9.880914243495949e-05,
      "loss": 0.0289,
      "step": 65260
    },
    {
      "epoch": 0.208896,
      "grad_norm": 0.10027081508957099,
      "learning_rate": 9.880841532089415e-05,
      "loss": 0.0301,
      "step": 65280
    },
    {
      "epoch": 0.20896,
      "grad_norm": 0.08863928465734576,
      "learning_rate": 9.880768798759279e-05,
      "loss": 0.0322,
      "step": 65300
    },
    {
      "epoch": 0.209024,
      "grad_norm": 0.05958664703588193,
      "learning_rate": 9.88069604350587e-05,
      "loss": 0.0328,
      "step": 65320
    },
    {
      "epoch": 0.209088,
      "grad_norm": 0.10350068693876718,
      "learning_rate": 9.880623266329513e-05,
      "loss": 0.0307,
      "step": 65340
    },
    {
      "epoch": 0.209152,
      "grad_norm": 0.0562583856087072,
      "learning_rate": 9.880550467230534e-05,
      "loss": 0.0284,
      "step": 65360
    },
    {
      "epoch": 0.209216,
      "grad_norm": 0.05908125080337446,
      "learning_rate": 9.880477646209263e-05,
      "loss": 0.0306,
      "step": 65380
    },
    {
      "epoch": 0.20928,
      "grad_norm": 0.06332803717872607,
      "learning_rate": 9.880404803266026e-05,
      "loss": 0.0308,
      "step": 65400
    },
    {
      "epoch": 0.209344,
      "grad_norm": 0.06042723871723859,
      "learning_rate": 9.880331938401148e-05,
      "loss": 0.0316,
      "step": 65420
    },
    {
      "epoch": 0.209408,
      "grad_norm": 0.06602475321586529,
      "learning_rate": 9.880259051614958e-05,
      "loss": 0.0267,
      "step": 65440
    },
    {
      "epoch": 0.209472,
      "grad_norm": 0.13518117720918105,
      "learning_rate": 9.880186142907784e-05,
      "loss": 0.0323,
      "step": 65460
    },
    {
      "epoch": 0.209536,
      "grad_norm": 0.12275732473190211,
      "learning_rate": 9.880113212279951e-05,
      "loss": 0.0294,
      "step": 65480
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.12786605206225263,
      "learning_rate": 9.88004025973179e-05,
      "loss": 0.0317,
      "step": 65500
    },
    {
      "epoch": 0.209664,
      "grad_norm": 0.09416366518834257,
      "learning_rate": 9.879967285263627e-05,
      "loss": 0.0295,
      "step": 65520
    },
    {
      "epoch": 0.209728,
      "grad_norm": 0.06578730232202905,
      "learning_rate": 9.87989428887579e-05,
      "loss": 0.031,
      "step": 65540
    },
    {
      "epoch": 0.209792,
      "grad_norm": 0.09013511319645717,
      "learning_rate": 9.879821270568606e-05,
      "loss": 0.0305,
      "step": 65560
    },
    {
      "epoch": 0.209856,
      "grad_norm": 0.07944115797382639,
      "learning_rate": 9.879748230342403e-05,
      "loss": 0.0284,
      "step": 65580
    },
    {
      "epoch": 0.20992,
      "grad_norm": 0.08855734107984915,
      "learning_rate": 9.879675168197511e-05,
      "loss": 0.0301,
      "step": 65600
    },
    {
      "epoch": 0.209984,
      "grad_norm": 0.12427098183292717,
      "learning_rate": 9.879602084134256e-05,
      "loss": 0.0313,
      "step": 65620
    },
    {
      "epoch": 0.210048,
      "grad_norm": 0.05430222823579225,
      "learning_rate": 9.879528978152968e-05,
      "loss": 0.0289,
      "step": 65640
    },
    {
      "epoch": 0.210112,
      "grad_norm": 0.06137296351349123,
      "learning_rate": 9.879455850253975e-05,
      "loss": 0.028,
      "step": 65660
    },
    {
      "epoch": 0.210176,
      "grad_norm": 0.09179284624749623,
      "learning_rate": 9.879382700437605e-05,
      "loss": 0.0296,
      "step": 65680
    },
    {
      "epoch": 0.21024,
      "grad_norm": 0.06480670108087928,
      "learning_rate": 9.879309528704186e-05,
      "loss": 0.0296,
      "step": 65700
    },
    {
      "epoch": 0.210304,
      "grad_norm": 0.058823207860685435,
      "learning_rate": 9.879236335054048e-05,
      "loss": 0.0277,
      "step": 65720
    },
    {
      "epoch": 0.210368,
      "grad_norm": 0.07097876662328613,
      "learning_rate": 9.879163119487517e-05,
      "loss": 0.0322,
      "step": 65740
    },
    {
      "epoch": 0.210432,
      "grad_norm": 0.05602535705272238,
      "learning_rate": 9.879089882004927e-05,
      "loss": 0.0265,
      "step": 65760
    },
    {
      "epoch": 0.210496,
      "grad_norm": 0.16553919162885017,
      "learning_rate": 9.879016622606601e-05,
      "loss": 0.031,
      "step": 65780
    },
    {
      "epoch": 0.21056,
      "grad_norm": 0.05712313358852256,
      "learning_rate": 9.878943341292872e-05,
      "loss": 0.0331,
      "step": 65800
    },
    {
      "epoch": 0.210624,
      "grad_norm": 0.06393461887123342,
      "learning_rate": 9.87887003806407e-05,
      "loss": 0.0319,
      "step": 65820
    },
    {
      "epoch": 0.210688,
      "grad_norm": 0.06304808254808351,
      "learning_rate": 9.87879671292052e-05,
      "loss": 0.0295,
      "step": 65840
    },
    {
      "epoch": 0.210752,
      "grad_norm": 0.11059108773570893,
      "learning_rate": 9.878723365862554e-05,
      "loss": 0.032,
      "step": 65860
    },
    {
      "epoch": 0.210816,
      "grad_norm": 0.10744175638042021,
      "learning_rate": 9.878649996890503e-05,
      "loss": 0.0321,
      "step": 65880
    },
    {
      "epoch": 0.21088,
      "grad_norm": 0.09046224499552181,
      "learning_rate": 9.878576606004694e-05,
      "loss": 0.0339,
      "step": 65900
    },
    {
      "epoch": 0.210944,
      "grad_norm": 0.07676937107170896,
      "learning_rate": 9.878503193205457e-05,
      "loss": 0.0331,
      "step": 65920
    },
    {
      "epoch": 0.211008,
      "grad_norm": 0.07090799273134167,
      "learning_rate": 9.878429758493122e-05,
      "loss": 0.0309,
      "step": 65940
    },
    {
      "epoch": 0.211072,
      "grad_norm": 0.04585085214838297,
      "learning_rate": 9.878356301868019e-05,
      "loss": 0.0279,
      "step": 65960
    },
    {
      "epoch": 0.211136,
      "grad_norm": 0.07262035826014616,
      "learning_rate": 9.878282823330478e-05,
      "loss": 0.0309,
      "step": 65980
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.07444829110114114,
      "learning_rate": 9.87820932288083e-05,
      "loss": 0.0294,
      "step": 66000
    },
    {
      "epoch": 0.211264,
      "grad_norm": 0.08314658382986373,
      "learning_rate": 9.878135800519404e-05,
      "loss": 0.03,
      "step": 66020
    },
    {
      "epoch": 0.211328,
      "grad_norm": 0.10260505758260019,
      "learning_rate": 9.87806225624653e-05,
      "loss": 0.0298,
      "step": 66040
    },
    {
      "epoch": 0.211392,
      "grad_norm": 0.11234865583599674,
      "learning_rate": 9.877988690062538e-05,
      "loss": 0.0303,
      "step": 66060
    },
    {
      "epoch": 0.211456,
      "grad_norm": 0.061335710646279885,
      "learning_rate": 9.877915101967761e-05,
      "loss": 0.0326,
      "step": 66080
    },
    {
      "epoch": 0.21152,
      "grad_norm": 0.07086046107088644,
      "learning_rate": 9.877841491962526e-05,
      "loss": 0.0255,
      "step": 66100
    },
    {
      "epoch": 0.211584,
      "grad_norm": 0.06304385096320285,
      "learning_rate": 9.877767860047167e-05,
      "loss": 0.028,
      "step": 66120
    },
    {
      "epoch": 0.211648,
      "grad_norm": 0.09172148196521665,
      "learning_rate": 9.877694206222011e-05,
      "loss": 0.0319,
      "step": 66140
    },
    {
      "epoch": 0.211712,
      "grad_norm": 0.11293899674061732,
      "learning_rate": 9.877620530487392e-05,
      "loss": 0.0306,
      "step": 66160
    },
    {
      "epoch": 0.211776,
      "grad_norm": 0.18020814284526251,
      "learning_rate": 9.87754683284364e-05,
      "loss": 0.0316,
      "step": 66180
    },
    {
      "epoch": 0.21184,
      "grad_norm": 0.05393480204452683,
      "learning_rate": 9.877473113291087e-05,
      "loss": 0.0317,
      "step": 66200
    },
    {
      "epoch": 0.211904,
      "grad_norm": 0.0962395034930969,
      "learning_rate": 9.877399371830062e-05,
      "loss": 0.0313,
      "step": 66220
    },
    {
      "epoch": 0.211968,
      "grad_norm": 0.06600540584477375,
      "learning_rate": 9.877325608460897e-05,
      "loss": 0.0301,
      "step": 66240
    },
    {
      "epoch": 0.212032,
      "grad_norm": 0.06950117837027779,
      "learning_rate": 9.877251823183925e-05,
      "loss": 0.0302,
      "step": 66260
    },
    {
      "epoch": 0.212096,
      "grad_norm": 0.08509827406158259,
      "learning_rate": 9.877178015999475e-05,
      "loss": 0.0298,
      "step": 66280
    },
    {
      "epoch": 0.21216,
      "grad_norm": 0.13662299728142893,
      "learning_rate": 9.87710418690788e-05,
      "loss": 0.0322,
      "step": 66300
    },
    {
      "epoch": 0.212224,
      "grad_norm": 0.07606081170277909,
      "learning_rate": 9.87703033590947e-05,
      "loss": 0.0307,
      "step": 66320
    },
    {
      "epoch": 0.212288,
      "grad_norm": 0.10297451755167362,
      "learning_rate": 9.876956463004579e-05,
      "loss": 0.0284,
      "step": 66340
    },
    {
      "epoch": 0.212352,
      "grad_norm": 0.07189507979759573,
      "learning_rate": 9.876882568193537e-05,
      "loss": 0.0312,
      "step": 66360
    },
    {
      "epoch": 0.212416,
      "grad_norm": 0.07516223002121793,
      "learning_rate": 9.876808651476677e-05,
      "loss": 0.0307,
      "step": 66380
    },
    {
      "epoch": 0.21248,
      "grad_norm": 0.0726003966033181,
      "learning_rate": 9.87673471285433e-05,
      "loss": 0.0347,
      "step": 66400
    },
    {
      "epoch": 0.212544,
      "grad_norm": 0.07778501977207862,
      "learning_rate": 9.87666075232683e-05,
      "loss": 0.031,
      "step": 66420
    },
    {
      "epoch": 0.212608,
      "grad_norm": 0.08637884442577837,
      "learning_rate": 9.876586769894508e-05,
      "loss": 0.0299,
      "step": 66440
    },
    {
      "epoch": 0.212672,
      "grad_norm": 0.08674391123902865,
      "learning_rate": 9.876512765557695e-05,
      "loss": 0.0303,
      "step": 66460
    },
    {
      "epoch": 0.212736,
      "grad_norm": 0.07016449148306768,
      "learning_rate": 9.876438739316727e-05,
      "loss": 0.0286,
      "step": 66480
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.07010860547956146,
      "learning_rate": 9.876364691171932e-05,
      "loss": 0.0295,
      "step": 66500
    },
    {
      "epoch": 0.212864,
      "grad_norm": 0.08670551723411213,
      "learning_rate": 9.876290621123645e-05,
      "loss": 0.0357,
      "step": 66520
    },
    {
      "epoch": 0.212928,
      "grad_norm": 0.07801653715471453,
      "learning_rate": 9.8762165291722e-05,
      "loss": 0.032,
      "step": 66540
    },
    {
      "epoch": 0.212992,
      "grad_norm": 0.05904062857960497,
      "learning_rate": 9.876142415317928e-05,
      "loss": 0.031,
      "step": 66560
    },
    {
      "epoch": 0.213056,
      "grad_norm": 0.07548206637336446,
      "learning_rate": 9.876068279561162e-05,
      "loss": 0.0317,
      "step": 66580
    },
    {
      "epoch": 0.21312,
      "grad_norm": 0.06260345583574385,
      "learning_rate": 9.875994121902234e-05,
      "loss": 0.0301,
      "step": 66600
    },
    {
      "epoch": 0.213184,
      "grad_norm": 0.07490355158714451,
      "learning_rate": 9.87591994234148e-05,
      "loss": 0.029,
      "step": 66620
    },
    {
      "epoch": 0.213248,
      "grad_norm": 0.0672918655386593,
      "learning_rate": 9.87584574087923e-05,
      "loss": 0.0288,
      "step": 66640
    },
    {
      "epoch": 0.213312,
      "grad_norm": 0.13492948460939544,
      "learning_rate": 9.87577151751582e-05,
      "loss": 0.0298,
      "step": 66660
    },
    {
      "epoch": 0.213376,
      "grad_norm": 0.06387780273175377,
      "learning_rate": 9.875697272251583e-05,
      "loss": 0.0306,
      "step": 66680
    },
    {
      "epoch": 0.21344,
      "grad_norm": 0.059812147910202916,
      "learning_rate": 9.87562300508685e-05,
      "loss": 0.0314,
      "step": 66700
    },
    {
      "epoch": 0.213504,
      "grad_norm": 0.07660155427685679,
      "learning_rate": 9.875548716021958e-05,
      "loss": 0.0294,
      "step": 66720
    },
    {
      "epoch": 0.213568,
      "grad_norm": 0.12606306519578506,
      "learning_rate": 9.875474405057237e-05,
      "loss": 0.0316,
      "step": 66740
    },
    {
      "epoch": 0.213632,
      "grad_norm": 0.06725353532980463,
      "learning_rate": 9.875400072193024e-05,
      "loss": 0.0323,
      "step": 66760
    },
    {
      "epoch": 0.213696,
      "grad_norm": 0.06727550112647027,
      "learning_rate": 9.875325717429652e-05,
      "loss": 0.0354,
      "step": 66780
    },
    {
      "epoch": 0.21376,
      "grad_norm": 0.07780889077323642,
      "learning_rate": 9.875251340767453e-05,
      "loss": 0.0325,
      "step": 66800
    },
    {
      "epoch": 0.213824,
      "grad_norm": 0.10243582524410631,
      "learning_rate": 9.875176942206765e-05,
      "loss": 0.0287,
      "step": 66820
    },
    {
      "epoch": 0.213888,
      "grad_norm": 0.05662151695491244,
      "learning_rate": 9.875102521747919e-05,
      "loss": 0.0319,
      "step": 66840
    },
    {
      "epoch": 0.213952,
      "grad_norm": 0.08143249440846456,
      "learning_rate": 9.87502807939125e-05,
      "loss": 0.0283,
      "step": 66860
    },
    {
      "epoch": 0.214016,
      "grad_norm": 0.07906029748393649,
      "learning_rate": 9.874953615137093e-05,
      "loss": 0.0325,
      "step": 66880
    },
    {
      "epoch": 0.21408,
      "grad_norm": 0.05623292283782337,
      "learning_rate": 9.874879128985781e-05,
      "loss": 0.0281,
      "step": 66900
    },
    {
      "epoch": 0.214144,
      "grad_norm": 0.03984736499432461,
      "learning_rate": 9.87480462093765e-05,
      "loss": 0.0265,
      "step": 66920
    },
    {
      "epoch": 0.214208,
      "grad_norm": 0.08704841714914519,
      "learning_rate": 9.874730090993035e-05,
      "loss": 0.0285,
      "step": 66940
    },
    {
      "epoch": 0.214272,
      "grad_norm": 0.12582909455596808,
      "learning_rate": 9.87465553915227e-05,
      "loss": 0.0347,
      "step": 66960
    },
    {
      "epoch": 0.214336,
      "grad_norm": 0.09271212086836707,
      "learning_rate": 9.87458096541569e-05,
      "loss": 0.0321,
      "step": 66980
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.06118585193056204,
      "learning_rate": 9.874506369783629e-05,
      "loss": 0.0291,
      "step": 67000
    },
    {
      "epoch": 0.214464,
      "grad_norm": 0.07639850503541895,
      "learning_rate": 9.874431752256423e-05,
      "loss": 0.0316,
      "step": 67020
    },
    {
      "epoch": 0.214528,
      "grad_norm": 0.11287480466422598,
      "learning_rate": 9.87435711283441e-05,
      "loss": 0.033,
      "step": 67040
    },
    {
      "epoch": 0.214592,
      "grad_norm": 0.12840883531753997,
      "learning_rate": 9.874282451517918e-05,
      "loss": 0.0323,
      "step": 67060
    },
    {
      "epoch": 0.214656,
      "grad_norm": 0.05725246818422788,
      "learning_rate": 9.874207768307289e-05,
      "loss": 0.0325,
      "step": 67080
    },
    {
      "epoch": 0.21472,
      "grad_norm": 0.15343184432184542,
      "learning_rate": 9.874133063202857e-05,
      "loss": 0.0273,
      "step": 67100
    },
    {
      "epoch": 0.214784,
      "grad_norm": 0.07523781487558626,
      "learning_rate": 9.874058336204955e-05,
      "loss": 0.0283,
      "step": 67120
    },
    {
      "epoch": 0.214848,
      "grad_norm": 0.07845050406310958,
      "learning_rate": 9.873983587313922e-05,
      "loss": 0.0315,
      "step": 67140
    },
    {
      "epoch": 0.214912,
      "grad_norm": 0.10556248499595557,
      "learning_rate": 9.873908816530091e-05,
      "loss": 0.0314,
      "step": 67160
    },
    {
      "epoch": 0.214976,
      "grad_norm": 0.07458678252752649,
      "learning_rate": 9.8738340238538e-05,
      "loss": 0.0329,
      "step": 67180
    },
    {
      "epoch": 0.21504,
      "grad_norm": 0.13480286254807902,
      "learning_rate": 9.873759209285383e-05,
      "loss": 0.0333,
      "step": 67200
    },
    {
      "epoch": 0.215104,
      "grad_norm": 0.12941368012492618,
      "learning_rate": 9.873684372825179e-05,
      "loss": 0.0303,
      "step": 67220
    },
    {
      "epoch": 0.215168,
      "grad_norm": 0.11877303412620768,
      "learning_rate": 9.873609514473521e-05,
      "loss": 0.0302,
      "step": 67240
    },
    {
      "epoch": 0.215232,
      "grad_norm": 0.08249525680924728,
      "learning_rate": 9.873534634230745e-05,
      "loss": 0.0324,
      "step": 67260
    },
    {
      "epoch": 0.215296,
      "grad_norm": 0.04885210667912073,
      "learning_rate": 9.87345973209719e-05,
      "loss": 0.0304,
      "step": 67280
    },
    {
      "epoch": 0.21536,
      "grad_norm": 0.08077339514755692,
      "learning_rate": 9.873384808073192e-05,
      "loss": 0.027,
      "step": 67300
    },
    {
      "epoch": 0.215424,
      "grad_norm": 0.08209176980644767,
      "learning_rate": 9.873309862159085e-05,
      "loss": 0.0287,
      "step": 67320
    },
    {
      "epoch": 0.215488,
      "grad_norm": 0.08186694964857857,
      "learning_rate": 9.87323489435521e-05,
      "loss": 0.0308,
      "step": 67340
    },
    {
      "epoch": 0.215552,
      "grad_norm": 0.04048221358208875,
      "learning_rate": 9.873159904661899e-05,
      "loss": 0.0286,
      "step": 67360
    },
    {
      "epoch": 0.215616,
      "grad_norm": 0.1327438894455643,
      "learning_rate": 9.873084893079492e-05,
      "loss": 0.0285,
      "step": 67380
    },
    {
      "epoch": 0.21568,
      "grad_norm": 0.0867618842218541,
      "learning_rate": 9.873009859608324e-05,
      "loss": 0.0275,
      "step": 67400
    },
    {
      "epoch": 0.215744,
      "grad_norm": 0.06559333893994203,
      "learning_rate": 9.872934804248735e-05,
      "loss": 0.0314,
      "step": 67420
    },
    {
      "epoch": 0.215808,
      "grad_norm": 0.11646669475001971,
      "learning_rate": 9.872859727001058e-05,
      "loss": 0.0292,
      "step": 67440
    },
    {
      "epoch": 0.215872,
      "grad_norm": 0.07849231516675449,
      "learning_rate": 9.872784627865632e-05,
      "loss": 0.0273,
      "step": 67460
    },
    {
      "epoch": 0.215936,
      "grad_norm": 0.13965998539438756,
      "learning_rate": 9.872709506842796e-05,
      "loss": 0.0292,
      "step": 67480
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.08488628668875155,
      "learning_rate": 9.872634363932887e-05,
      "loss": 0.0268,
      "step": 67500
    },
    {
      "epoch": 0.216064,
      "grad_norm": 0.07377945229537208,
      "learning_rate": 9.87255919913624e-05,
      "loss": 0.0297,
      "step": 67520
    },
    {
      "epoch": 0.216128,
      "grad_norm": 0.09933591969212001,
      "learning_rate": 9.872484012453194e-05,
      "loss": 0.029,
      "step": 67540
    },
    {
      "epoch": 0.216192,
      "grad_norm": 0.04267748442442709,
      "learning_rate": 9.872408803884088e-05,
      "loss": 0.0332,
      "step": 67560
    },
    {
      "epoch": 0.216256,
      "grad_norm": 0.07684293202764399,
      "learning_rate": 9.872333573429258e-05,
      "loss": 0.0264,
      "step": 67580
    },
    {
      "epoch": 0.21632,
      "grad_norm": 0.05810291490448085,
      "learning_rate": 9.872258321089042e-05,
      "loss": 0.0275,
      "step": 67600
    },
    {
      "epoch": 0.216384,
      "grad_norm": 0.065205498864142,
      "learning_rate": 9.872183046863779e-05,
      "loss": 0.0303,
      "step": 67620
    },
    {
      "epoch": 0.216448,
      "grad_norm": 0.08960050712340008,
      "learning_rate": 9.872107750753809e-05,
      "loss": 0.0305,
      "step": 67640
    },
    {
      "epoch": 0.216512,
      "grad_norm": 0.08923840358438835,
      "learning_rate": 9.872032432759466e-05,
      "loss": 0.0325,
      "step": 67660
    },
    {
      "epoch": 0.216576,
      "grad_norm": 0.06798349729989919,
      "learning_rate": 9.87195709288109e-05,
      "loss": 0.0302,
      "step": 67680
    },
    {
      "epoch": 0.21664,
      "grad_norm": 0.11214714616809551,
      "learning_rate": 9.871881731119022e-05,
      "loss": 0.0287,
      "step": 67700
    },
    {
      "epoch": 0.216704,
      "grad_norm": 0.1088425137283061,
      "learning_rate": 9.871806347473595e-05,
      "loss": 0.0317,
      "step": 67720
    },
    {
      "epoch": 0.216768,
      "grad_norm": 0.07056837820921764,
      "learning_rate": 9.871730941945154e-05,
      "loss": 0.0347,
      "step": 67740
    },
    {
      "epoch": 0.216832,
      "grad_norm": 0.06801061767057032,
      "learning_rate": 9.871655514534032e-05,
      "loss": 0.0329,
      "step": 67760
    },
    {
      "epoch": 0.216896,
      "grad_norm": 0.13493563047956883,
      "learning_rate": 9.871580065240572e-05,
      "loss": 0.0309,
      "step": 67780
    },
    {
      "epoch": 0.21696,
      "grad_norm": 0.09181917470371516,
      "learning_rate": 9.871504594065111e-05,
      "loss": 0.0322,
      "step": 67800
    },
    {
      "epoch": 0.217024,
      "grad_norm": 0.07273869132462686,
      "learning_rate": 9.871429101007987e-05,
      "loss": 0.0343,
      "step": 67820
    },
    {
      "epoch": 0.217088,
      "grad_norm": 0.12655370201647823,
      "learning_rate": 9.871353586069542e-05,
      "loss": 0.034,
      "step": 67840
    },
    {
      "epoch": 0.217152,
      "grad_norm": 0.07248954400355188,
      "learning_rate": 9.871278049250113e-05,
      "loss": 0.0331,
      "step": 67860
    },
    {
      "epoch": 0.217216,
      "grad_norm": 0.07201980162607466,
      "learning_rate": 9.87120249055004e-05,
      "loss": 0.0305,
      "step": 67880
    },
    {
      "epoch": 0.21728,
      "grad_norm": 0.06672467850491343,
      "learning_rate": 9.871126909969661e-05,
      "loss": 0.0309,
      "step": 67900
    },
    {
      "epoch": 0.217344,
      "grad_norm": 0.08097269494293267,
      "learning_rate": 9.871051307509318e-05,
      "loss": 0.0296,
      "step": 67920
    },
    {
      "epoch": 0.217408,
      "grad_norm": 0.08149620038151364,
      "learning_rate": 9.87097568316935e-05,
      "loss": 0.0317,
      "step": 67940
    },
    {
      "epoch": 0.217472,
      "grad_norm": 0.14182599450038555,
      "learning_rate": 9.870900036950095e-05,
      "loss": 0.0326,
      "step": 67960
    },
    {
      "epoch": 0.217536,
      "grad_norm": 0.06905243954447576,
      "learning_rate": 9.870824368851893e-05,
      "loss": 0.0294,
      "step": 67980
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.051379342542332875,
      "learning_rate": 9.870748678875086e-05,
      "loss": 0.0279,
      "step": 68000
    },
    {
      "epoch": 0.217664,
      "grad_norm": 0.11714916526157418,
      "learning_rate": 9.870672967020012e-05,
      "loss": 0.029,
      "step": 68020
    },
    {
      "epoch": 0.217728,
      "grad_norm": 0.05876549963826233,
      "learning_rate": 9.870597233287011e-05,
      "loss": 0.0296,
      "step": 68040
    },
    {
      "epoch": 0.217792,
      "grad_norm": 0.1054752551697724,
      "learning_rate": 9.870521477676426e-05,
      "loss": 0.0317,
      "step": 68060
    },
    {
      "epoch": 0.217856,
      "grad_norm": 0.062091893914243135,
      "learning_rate": 9.870445700188593e-05,
      "loss": 0.0319,
      "step": 68080
    },
    {
      "epoch": 0.21792,
      "grad_norm": 0.059789747971987495,
      "learning_rate": 9.870369900823856e-05,
      "loss": 0.0293,
      "step": 68100
    },
    {
      "epoch": 0.217984,
      "grad_norm": 0.04791912422638542,
      "learning_rate": 9.870294079582554e-05,
      "loss": 0.0303,
      "step": 68120
    },
    {
      "epoch": 0.218048,
      "grad_norm": 0.09599862325507434,
      "learning_rate": 9.870218236465027e-05,
      "loss": 0.0345,
      "step": 68140
    },
    {
      "epoch": 0.218112,
      "grad_norm": 0.08339019857539463,
      "learning_rate": 9.870142371471616e-05,
      "loss": 0.0312,
      "step": 68160
    },
    {
      "epoch": 0.218176,
      "grad_norm": 0.0761389638286953,
      "learning_rate": 9.870066484602662e-05,
      "loss": 0.0326,
      "step": 68180
    },
    {
      "epoch": 0.21824,
      "grad_norm": 0.11389618608868135,
      "learning_rate": 9.869990575858508e-05,
      "loss": 0.0296,
      "step": 68200
    },
    {
      "epoch": 0.218304,
      "grad_norm": 0.15392625212120667,
      "learning_rate": 9.869914645239491e-05,
      "loss": 0.0311,
      "step": 68220
    },
    {
      "epoch": 0.218368,
      "grad_norm": 0.10050012147292824,
      "learning_rate": 9.869838692745954e-05,
      "loss": 0.0349,
      "step": 68240
    },
    {
      "epoch": 0.218432,
      "grad_norm": 0.06612473573334282,
      "learning_rate": 9.869762718378237e-05,
      "loss": 0.0281,
      "step": 68260
    },
    {
      "epoch": 0.218496,
      "grad_norm": 0.04140456027936097,
      "learning_rate": 9.869686722136684e-05,
      "loss": 0.0309,
      "step": 68280
    },
    {
      "epoch": 0.21856,
      "grad_norm": 0.09175069374322363,
      "learning_rate": 9.869610704021635e-05,
      "loss": 0.0332,
      "step": 68300
    },
    {
      "epoch": 0.218624,
      "grad_norm": 0.14221275023779972,
      "learning_rate": 9.86953466403343e-05,
      "loss": 0.0338,
      "step": 68320
    },
    {
      "epoch": 0.218688,
      "grad_norm": 0.06957420834007481,
      "learning_rate": 9.869458602172412e-05,
      "loss": 0.0324,
      "step": 68340
    },
    {
      "epoch": 0.218752,
      "grad_norm": 0.09575596165704836,
      "learning_rate": 9.869382518438923e-05,
      "loss": 0.0301,
      "step": 68360
    },
    {
      "epoch": 0.218816,
      "grad_norm": 0.06792052766037862,
      "learning_rate": 9.869306412833304e-05,
      "loss": 0.032,
      "step": 68380
    },
    {
      "epoch": 0.21888,
      "grad_norm": 0.11393765134938433,
      "learning_rate": 9.869230285355897e-05,
      "loss": 0.0318,
      "step": 68400
    },
    {
      "epoch": 0.218944,
      "grad_norm": 0.09251537765404758,
      "learning_rate": 9.869154136007044e-05,
      "loss": 0.0329,
      "step": 68420
    },
    {
      "epoch": 0.219008,
      "grad_norm": 0.057662051956436707,
      "learning_rate": 9.869077964787086e-05,
      "loss": 0.0322,
      "step": 68440
    },
    {
      "epoch": 0.219072,
      "grad_norm": 0.09898662378028712,
      "learning_rate": 9.869001771696367e-05,
      "loss": 0.0316,
      "step": 68460
    },
    {
      "epoch": 0.219136,
      "grad_norm": 0.05781578600547082,
      "learning_rate": 9.868925556735228e-05,
      "loss": 0.0324,
      "step": 68480
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.07605016040599795,
      "learning_rate": 9.868849319904012e-05,
      "loss": 0.0305,
      "step": 68500
    },
    {
      "epoch": 0.219264,
      "grad_norm": 0.08378701150905193,
      "learning_rate": 9.86877306120306e-05,
      "loss": 0.0317,
      "step": 68520
    },
    {
      "epoch": 0.219328,
      "grad_norm": 0.1001351306044324,
      "learning_rate": 9.868696780632717e-05,
      "loss": 0.0299,
      "step": 68540
    },
    {
      "epoch": 0.219392,
      "grad_norm": 0.05959221521103893,
      "learning_rate": 9.868620478193324e-05,
      "loss": 0.0322,
      "step": 68560
    },
    {
      "epoch": 0.219456,
      "grad_norm": 0.09052356298479967,
      "learning_rate": 9.868544153885224e-05,
      "loss": 0.0311,
      "step": 68580
    },
    {
      "epoch": 0.21952,
      "grad_norm": 0.12104670831758771,
      "learning_rate": 9.86846780770876e-05,
      "loss": 0.0319,
      "step": 68600
    },
    {
      "epoch": 0.219584,
      "grad_norm": 0.12493117494130951,
      "learning_rate": 9.868391439664274e-05,
      "loss": 0.0282,
      "step": 68620
    },
    {
      "epoch": 0.219648,
      "grad_norm": 0.057792980021449156,
      "learning_rate": 9.86831504975211e-05,
      "loss": 0.0303,
      "step": 68640
    },
    {
      "epoch": 0.219712,
      "grad_norm": 0.08721662730812321,
      "learning_rate": 9.868238637972612e-05,
      "loss": 0.0289,
      "step": 68660
    },
    {
      "epoch": 0.219776,
      "grad_norm": 0.07111036225678337,
      "learning_rate": 9.868162204326122e-05,
      "loss": 0.0323,
      "step": 68680
    },
    {
      "epoch": 0.21984,
      "grad_norm": 0.061945063042386415,
      "learning_rate": 9.868085748812983e-05,
      "loss": 0.0277,
      "step": 68700
    },
    {
      "epoch": 0.219904,
      "grad_norm": 0.06238321433134148,
      "learning_rate": 9.868009271433538e-05,
      "loss": 0.031,
      "step": 68720
    },
    {
      "epoch": 0.219968,
      "grad_norm": 0.10073922845660825,
      "learning_rate": 9.867932772188132e-05,
      "loss": 0.0293,
      "step": 68740
    },
    {
      "epoch": 0.220032,
      "grad_norm": 0.07992004236441834,
      "learning_rate": 9.86785625107711e-05,
      "loss": 0.0293,
      "step": 68760
    },
    {
      "epoch": 0.220096,
      "grad_norm": 0.09691541437464792,
      "learning_rate": 9.867779708100812e-05,
      "loss": 0.0316,
      "step": 68780
    },
    {
      "epoch": 0.22016,
      "grad_norm": 0.10342710995607346,
      "learning_rate": 9.867703143259583e-05,
      "loss": 0.0277,
      "step": 68800
    },
    {
      "epoch": 0.220224,
      "grad_norm": 0.053308622387769435,
      "learning_rate": 9.867626556553769e-05,
      "loss": 0.0322,
      "step": 68820
    },
    {
      "epoch": 0.220288,
      "grad_norm": 0.1079514400244129,
      "learning_rate": 9.867549947983712e-05,
      "loss": 0.0289,
      "step": 68840
    },
    {
      "epoch": 0.220352,
      "grad_norm": 0.06950479003268839,
      "learning_rate": 9.867473317549755e-05,
      "loss": 0.0283,
      "step": 68860
    },
    {
      "epoch": 0.220416,
      "grad_norm": 0.11259269088913085,
      "learning_rate": 9.867396665252245e-05,
      "loss": 0.0311,
      "step": 68880
    },
    {
      "epoch": 0.22048,
      "grad_norm": 0.08215620720888792,
      "learning_rate": 9.867319991091526e-05,
      "loss": 0.0305,
      "step": 68900
    },
    {
      "epoch": 0.220544,
      "grad_norm": 0.05771123855221282,
      "learning_rate": 9.867243295067941e-05,
      "loss": 0.0274,
      "step": 68920
    },
    {
      "epoch": 0.220608,
      "grad_norm": 0.06628732950144485,
      "learning_rate": 9.867166577181835e-05,
      "loss": 0.0289,
      "step": 68940
    },
    {
      "epoch": 0.220672,
      "grad_norm": 0.07917533160137588,
      "learning_rate": 9.867089837433552e-05,
      "loss": 0.0339,
      "step": 68960
    },
    {
      "epoch": 0.220736,
      "grad_norm": 0.11606543283484985,
      "learning_rate": 9.867013075823437e-05,
      "loss": 0.0306,
      "step": 68980
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.08363859604261542,
      "learning_rate": 9.866936292351836e-05,
      "loss": 0.0306,
      "step": 69000
    },
    {
      "epoch": 0.220864,
      "grad_norm": 0.07062203276195746,
      "learning_rate": 9.866859487019093e-05,
      "loss": 0.0283,
      "step": 69020
    },
    {
      "epoch": 0.220928,
      "grad_norm": 0.07071115083141023,
      "learning_rate": 9.866782659825554e-05,
      "loss": 0.03,
      "step": 69040
    },
    {
      "epoch": 0.220992,
      "grad_norm": 0.09655140672597251,
      "learning_rate": 9.866705810771562e-05,
      "loss": 0.0305,
      "step": 69060
    },
    {
      "epoch": 0.221056,
      "grad_norm": 0.05046077946477986,
      "learning_rate": 9.866628939857462e-05,
      "loss": 0.0313,
      "step": 69080
    },
    {
      "epoch": 0.22112,
      "grad_norm": 0.060558568359093075,
      "learning_rate": 9.866552047083602e-05,
      "loss": 0.0292,
      "step": 69100
    },
    {
      "epoch": 0.221184,
      "grad_norm": 0.08303770828837509,
      "learning_rate": 9.866475132450325e-05,
      "loss": 0.0311,
      "step": 69120
    },
    {
      "epoch": 0.221248,
      "grad_norm": 0.1119541878616985,
      "learning_rate": 9.866398195957978e-05,
      "loss": 0.0317,
      "step": 69140
    },
    {
      "epoch": 0.221312,
      "grad_norm": 0.07490898762209262,
      "learning_rate": 9.866321237606907e-05,
      "loss": 0.0281,
      "step": 69160
    },
    {
      "epoch": 0.221376,
      "grad_norm": 0.05855941665835596,
      "learning_rate": 9.866244257397455e-05,
      "loss": 0.0293,
      "step": 69180
    },
    {
      "epoch": 0.22144,
      "grad_norm": 0.0978977459350901,
      "learning_rate": 9.866167255329971e-05,
      "loss": 0.0286,
      "step": 69200
    },
    {
      "epoch": 0.221504,
      "grad_norm": 0.06373255795105619,
      "learning_rate": 9.866090231404799e-05,
      "loss": 0.029,
      "step": 69220
    },
    {
      "epoch": 0.221568,
      "grad_norm": 0.05294443695661544,
      "learning_rate": 9.866013185622285e-05,
      "loss": 0.0353,
      "step": 69240
    },
    {
      "epoch": 0.221632,
      "grad_norm": 0.11510963286014482,
      "learning_rate": 9.865936117982775e-05,
      "loss": 0.0298,
      "step": 69260
    },
    {
      "epoch": 0.221696,
      "grad_norm": 0.08900469947997638,
      "learning_rate": 9.865859028486616e-05,
      "loss": 0.0299,
      "step": 69280
    },
    {
      "epoch": 0.22176,
      "grad_norm": 0.0943613027735701,
      "learning_rate": 9.865781917134153e-05,
      "loss": 0.0297,
      "step": 69300
    },
    {
      "epoch": 0.221824,
      "grad_norm": 0.05981912376357919,
      "learning_rate": 9.865704783925735e-05,
      "loss": 0.0324,
      "step": 69320
    },
    {
      "epoch": 0.221888,
      "grad_norm": 0.05941475582224709,
      "learning_rate": 9.865627628861704e-05,
      "loss": 0.027,
      "step": 69340
    },
    {
      "epoch": 0.221952,
      "grad_norm": 0.058893571788512,
      "learning_rate": 9.865550451942412e-05,
      "loss": 0.0292,
      "step": 69360
    },
    {
      "epoch": 0.222016,
      "grad_norm": 0.08455912033762589,
      "learning_rate": 9.865473253168201e-05,
      "loss": 0.0296,
      "step": 69380
    },
    {
      "epoch": 0.22208,
      "grad_norm": 0.08585004571001624,
      "learning_rate": 9.86539603253942e-05,
      "loss": 0.0314,
      "step": 69400
    },
    {
      "epoch": 0.222144,
      "grad_norm": 0.08374023805836503,
      "learning_rate": 9.865318790056416e-05,
      "loss": 0.0308,
      "step": 69420
    },
    {
      "epoch": 0.222208,
      "grad_norm": 0.05686443997755606,
      "learning_rate": 9.865241525719535e-05,
      "loss": 0.0322,
      "step": 69440
    },
    {
      "epoch": 0.222272,
      "grad_norm": 0.09342012286271038,
      "learning_rate": 9.865164239529126e-05,
      "loss": 0.0317,
      "step": 69460
    },
    {
      "epoch": 0.222336,
      "grad_norm": 0.08434589662213086,
      "learning_rate": 9.865086931485532e-05,
      "loss": 0.0295,
      "step": 69480
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.09588798702581318,
      "learning_rate": 9.865009601589105e-05,
      "loss": 0.0295,
      "step": 69500
    },
    {
      "epoch": 0.222464,
      "grad_norm": 0.1593998903373086,
      "learning_rate": 9.864932249840188e-05,
      "loss": 0.0317,
      "step": 69520
    },
    {
      "epoch": 0.222528,
      "grad_norm": 0.06020603953728634,
      "learning_rate": 9.864854876239133e-05,
      "loss": 0.0303,
      "step": 69540
    },
    {
      "epoch": 0.222592,
      "grad_norm": 0.08129111370164327,
      "learning_rate": 9.864777480786285e-05,
      "loss": 0.0331,
      "step": 69560
    },
    {
      "epoch": 0.222656,
      "grad_norm": 0.13440618136206764,
      "learning_rate": 9.864700063481991e-05,
      "loss": 0.0308,
      "step": 69580
    },
    {
      "epoch": 0.22272,
      "grad_norm": 0.11914988104000453,
      "learning_rate": 9.8646226243266e-05,
      "loss": 0.0298,
      "step": 69600
    },
    {
      "epoch": 0.222784,
      "grad_norm": 0.06866231156710112,
      "learning_rate": 9.86454516332046e-05,
      "loss": 0.031,
      "step": 69620
    },
    {
      "epoch": 0.222848,
      "grad_norm": 0.08603332176271056,
      "learning_rate": 9.864467680463917e-05,
      "loss": 0.0277,
      "step": 69640
    },
    {
      "epoch": 0.222912,
      "grad_norm": 0.06213886669787686,
      "learning_rate": 9.86439017575732e-05,
      "loss": 0.0286,
      "step": 69660
    },
    {
      "epoch": 0.222976,
      "grad_norm": 0.13247532075528468,
      "learning_rate": 9.86431264920102e-05,
      "loss": 0.031,
      "step": 69680
    },
    {
      "epoch": 0.22304,
      "grad_norm": 0.09652823205146623,
      "learning_rate": 9.864235100795361e-05,
      "loss": 0.0272,
      "step": 69700
    },
    {
      "epoch": 0.223104,
      "grad_norm": 0.07384354115863988,
      "learning_rate": 9.864157530540694e-05,
      "loss": 0.0314,
      "step": 69720
    },
    {
      "epoch": 0.223168,
      "grad_norm": 0.05372201896788973,
      "learning_rate": 9.864079938437367e-05,
      "loss": 0.029,
      "step": 69740
    },
    {
      "epoch": 0.223232,
      "grad_norm": 0.0659595111517275,
      "learning_rate": 9.864002324485726e-05,
      "loss": 0.0302,
      "step": 69760
    },
    {
      "epoch": 0.223296,
      "grad_norm": 0.10875957829049508,
      "learning_rate": 9.863924688686123e-05,
      "loss": 0.0331,
      "step": 69780
    },
    {
      "epoch": 0.22336,
      "grad_norm": 0.0681331014402996,
      "learning_rate": 9.863847031038906e-05,
      "loss": 0.0304,
      "step": 69800
    },
    {
      "epoch": 0.223424,
      "grad_norm": 0.08115272395146839,
      "learning_rate": 9.863769351544423e-05,
      "loss": 0.032,
      "step": 69820
    },
    {
      "epoch": 0.223488,
      "grad_norm": 0.08545763166007583,
      "learning_rate": 9.863691650203023e-05,
      "loss": 0.0309,
      "step": 69840
    },
    {
      "epoch": 0.223552,
      "grad_norm": 0.04510506112034373,
      "learning_rate": 9.863613927015054e-05,
      "loss": 0.0299,
      "step": 69860
    },
    {
      "epoch": 0.223616,
      "grad_norm": 0.15148366943931146,
      "learning_rate": 9.863536181980869e-05,
      "loss": 0.0319,
      "step": 69880
    },
    {
      "epoch": 0.22368,
      "grad_norm": 0.08736265223527875,
      "learning_rate": 9.863458415100813e-05,
      "loss": 0.032,
      "step": 69900
    },
    {
      "epoch": 0.223744,
      "grad_norm": 0.0995569055451456,
      "learning_rate": 9.863380626375237e-05,
      "loss": 0.028,
      "step": 69920
    },
    {
      "epoch": 0.223808,
      "grad_norm": 0.0745219615332586,
      "learning_rate": 9.86330281580449e-05,
      "loss": 0.0282,
      "step": 69940
    },
    {
      "epoch": 0.223872,
      "grad_norm": 0.05943074838776341,
      "learning_rate": 9.86322498338892e-05,
      "loss": 0.0323,
      "step": 69960
    },
    {
      "epoch": 0.223936,
      "grad_norm": 0.0648720037921864,
      "learning_rate": 9.86314712912888e-05,
      "loss": 0.0341,
      "step": 69980
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.06541090701503417,
      "learning_rate": 9.863069253024719e-05,
      "loss": 0.0269,
      "step": 70000
    },
    {
      "epoch": 0.224064,
      "grad_norm": 0.06886532306066297,
      "learning_rate": 9.862991355076784e-05,
      "loss": 0.0275,
      "step": 70020
    },
    {
      "epoch": 0.224128,
      "grad_norm": 0.051552526477362436,
      "learning_rate": 9.862913435285428e-05,
      "loss": 0.0305,
      "step": 70040
    },
    {
      "epoch": 0.224192,
      "grad_norm": 0.05431933336465912,
      "learning_rate": 9.862835493651e-05,
      "loss": 0.0296,
      "step": 70060
    },
    {
      "epoch": 0.224256,
      "grad_norm": 0.06423449453176712,
      "learning_rate": 9.862757530173847e-05,
      "loss": 0.0275,
      "step": 70080
    },
    {
      "epoch": 0.22432,
      "grad_norm": 0.055022307984107864,
      "learning_rate": 9.862679544854326e-05,
      "loss": 0.0293,
      "step": 70100
    },
    {
      "epoch": 0.224384,
      "grad_norm": 0.06627376218236176,
      "learning_rate": 9.86260153769278e-05,
      "loss": 0.0296,
      "step": 70120
    },
    {
      "epoch": 0.224448,
      "grad_norm": 0.04935847000620073,
      "learning_rate": 9.862523508689565e-05,
      "loss": 0.0301,
      "step": 70140
    },
    {
      "epoch": 0.224512,
      "grad_norm": 0.05689089048743246,
      "learning_rate": 9.862445457845029e-05,
      "loss": 0.0289,
      "step": 70160
    },
    {
      "epoch": 0.224576,
      "grad_norm": 0.06719833616918527,
      "learning_rate": 9.86236738515952e-05,
      "loss": 0.0305,
      "step": 70180
    },
    {
      "epoch": 0.22464,
      "grad_norm": 0.07241004830050171,
      "learning_rate": 9.862289290633395e-05,
      "loss": 0.0344,
      "step": 70200
    },
    {
      "epoch": 0.224704,
      "grad_norm": 0.0564231795951191,
      "learning_rate": 9.862211174267e-05,
      "loss": 0.0317,
      "step": 70220
    },
    {
      "epoch": 0.224768,
      "grad_norm": 0.07766551135367324,
      "learning_rate": 9.862133036060686e-05,
      "loss": 0.033,
      "step": 70240
    },
    {
      "epoch": 0.224832,
      "grad_norm": 0.06802968188954439,
      "learning_rate": 9.862054876014807e-05,
      "loss": 0.0329,
      "step": 70260
    },
    {
      "epoch": 0.224896,
      "grad_norm": 0.11848079958814707,
      "learning_rate": 9.86197669412971e-05,
      "loss": 0.0292,
      "step": 70280
    },
    {
      "epoch": 0.22496,
      "grad_norm": 0.07979101928775165,
      "learning_rate": 9.86189849040575e-05,
      "loss": 0.0294,
      "step": 70300
    },
    {
      "epoch": 0.225024,
      "grad_norm": 0.06788643323059138,
      "learning_rate": 9.861820264843278e-05,
      "loss": 0.0287,
      "step": 70320
    },
    {
      "epoch": 0.225088,
      "grad_norm": 0.11808172951143883,
      "learning_rate": 9.861742017442642e-05,
      "loss": 0.0294,
      "step": 70340
    },
    {
      "epoch": 0.225152,
      "grad_norm": 0.09142622314927878,
      "learning_rate": 9.861663748204195e-05,
      "loss": 0.0331,
      "step": 70360
    },
    {
      "epoch": 0.225216,
      "grad_norm": 0.07583686174845784,
      "learning_rate": 9.861585457128291e-05,
      "loss": 0.0308,
      "step": 70380
    },
    {
      "epoch": 0.22528,
      "grad_norm": 0.13242172687521286,
      "learning_rate": 9.861507144215279e-05,
      "loss": 0.0316,
      "step": 70400
    },
    {
      "epoch": 0.225344,
      "grad_norm": 0.09477221800311485,
      "learning_rate": 9.86142880946551e-05,
      "loss": 0.03,
      "step": 70420
    },
    {
      "epoch": 0.225408,
      "grad_norm": 0.06637270182019295,
      "learning_rate": 9.861350452879339e-05,
      "loss": 0.0276,
      "step": 70440
    },
    {
      "epoch": 0.225472,
      "grad_norm": 0.09414619956863823,
      "learning_rate": 9.861272074457115e-05,
      "loss": 0.0271,
      "step": 70460
    },
    {
      "epoch": 0.225536,
      "grad_norm": 0.0582309482239349,
      "learning_rate": 9.861193674199191e-05,
      "loss": 0.0316,
      "step": 70480
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.0757224232444805,
      "learning_rate": 9.861115252105921e-05,
      "loss": 0.0335,
      "step": 70500
    },
    {
      "epoch": 0.225664,
      "grad_norm": 0.09264569733967844,
      "learning_rate": 9.861036808177654e-05,
      "loss": 0.0301,
      "step": 70520
    },
    {
      "epoch": 0.225728,
      "grad_norm": 0.06370993187085014,
      "learning_rate": 9.860958342414747e-05,
      "loss": 0.0292,
      "step": 70540
    },
    {
      "epoch": 0.225792,
      "grad_norm": 0.04199171767832429,
      "learning_rate": 9.860879854817549e-05,
      "loss": 0.0298,
      "step": 70560
    },
    {
      "epoch": 0.225856,
      "grad_norm": 0.06694918047491029,
      "learning_rate": 9.86080134538641e-05,
      "loss": 0.0316,
      "step": 70580
    },
    {
      "epoch": 0.22592,
      "grad_norm": 0.10237383746198378,
      "learning_rate": 9.860722814121688e-05,
      "loss": 0.033,
      "step": 70600
    },
    {
      "epoch": 0.225984,
      "grad_norm": 0.10330753876007515,
      "learning_rate": 9.860644261023733e-05,
      "loss": 0.027,
      "step": 70620
    },
    {
      "epoch": 0.226048,
      "grad_norm": 0.051433865369725884,
      "learning_rate": 9.8605656860929e-05,
      "loss": 0.03,
      "step": 70640
    },
    {
      "epoch": 0.226112,
      "grad_norm": 0.11426363385974622,
      "learning_rate": 9.860487089329538e-05,
      "loss": 0.0337,
      "step": 70660
    },
    {
      "epoch": 0.226176,
      "grad_norm": 0.1274024731509269,
      "learning_rate": 9.860408470734004e-05,
      "loss": 0.0293,
      "step": 70680
    },
    {
      "epoch": 0.22624,
      "grad_norm": 0.0709922635448835,
      "learning_rate": 9.860329830306648e-05,
      "loss": 0.0302,
      "step": 70700
    },
    {
      "epoch": 0.226304,
      "grad_norm": 0.11089704072971417,
      "learning_rate": 9.860251168047825e-05,
      "loss": 0.0316,
      "step": 70720
    },
    {
      "epoch": 0.226368,
      "grad_norm": 0.05630543056212624,
      "learning_rate": 9.860172483957889e-05,
      "loss": 0.0334,
      "step": 70740
    },
    {
      "epoch": 0.226432,
      "grad_norm": 0.12199056615744541,
      "learning_rate": 9.860093778037191e-05,
      "loss": 0.0323,
      "step": 70760
    },
    {
      "epoch": 0.226496,
      "grad_norm": 0.05680338126731628,
      "learning_rate": 9.860015050286088e-05,
      "loss": 0.03,
      "step": 70780
    },
    {
      "epoch": 0.22656,
      "grad_norm": 0.06036359703963939,
      "learning_rate": 9.85993630070493e-05,
      "loss": 0.0303,
      "step": 70800
    },
    {
      "epoch": 0.226624,
      "grad_norm": 0.0681112874786638,
      "learning_rate": 9.859857529294072e-05,
      "loss": 0.031,
      "step": 70820
    },
    {
      "epoch": 0.226688,
      "grad_norm": 0.057277540092733795,
      "learning_rate": 9.85977873605387e-05,
      "loss": 0.0286,
      "step": 70840
    },
    {
      "epoch": 0.226752,
      "grad_norm": 0.0604675958336251,
      "learning_rate": 9.859699920984676e-05,
      "loss": 0.0317,
      "step": 70860
    },
    {
      "epoch": 0.226816,
      "grad_norm": 0.07250683647354315,
      "learning_rate": 9.859621084086842e-05,
      "loss": 0.0319,
      "step": 70880
    },
    {
      "epoch": 0.22688,
      "grad_norm": 0.044788326843599846,
      "learning_rate": 9.859542225360726e-05,
      "loss": 0.0292,
      "step": 70900
    },
    {
      "epoch": 0.226944,
      "grad_norm": 0.11287796680973239,
      "learning_rate": 9.859463344806678e-05,
      "loss": 0.031,
      "step": 70920
    },
    {
      "epoch": 0.227008,
      "grad_norm": 0.07257527907318567,
      "learning_rate": 9.859384442425057e-05,
      "loss": 0.0307,
      "step": 70940
    },
    {
      "epoch": 0.227072,
      "grad_norm": 0.054857796379834636,
      "learning_rate": 9.859305518216215e-05,
      "loss": 0.0328,
      "step": 70960
    },
    {
      "epoch": 0.227136,
      "grad_norm": 0.054961980582535576,
      "learning_rate": 9.859226572180507e-05,
      "loss": 0.0344,
      "step": 70980
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.05044270101863525,
      "learning_rate": 9.859147604318287e-05,
      "loss": 0.029,
      "step": 71000
    },
    {
      "epoch": 0.227264,
      "grad_norm": 0.10841430005961779,
      "learning_rate": 9.859068614629907e-05,
      "loss": 0.0319,
      "step": 71020
    },
    {
      "epoch": 0.227328,
      "grad_norm": 0.08221273153549728,
      "learning_rate": 9.858989603115729e-05,
      "loss": 0.0288,
      "step": 71040
    },
    {
      "epoch": 0.227392,
      "grad_norm": 0.09097897179277246,
      "learning_rate": 9.858910569776101e-05,
      "loss": 0.0335,
      "step": 71060
    },
    {
      "epoch": 0.227456,
      "grad_norm": 0.055297123314702185,
      "learning_rate": 9.858831514611382e-05,
      "loss": 0.0282,
      "step": 71080
    },
    {
      "epoch": 0.22752,
      "grad_norm": 0.07608198757606531,
      "learning_rate": 9.858752437621925e-05,
      "loss": 0.0307,
      "step": 71100
    },
    {
      "epoch": 0.227584,
      "grad_norm": 0.0599109050514312,
      "learning_rate": 9.858673338808086e-05,
      "loss": 0.0312,
      "step": 71120
    },
    {
      "epoch": 0.227648,
      "grad_norm": 0.03942068634870746,
      "learning_rate": 9.858594218170221e-05,
      "loss": 0.0252,
      "step": 71140
    },
    {
      "epoch": 0.227712,
      "grad_norm": 0.05416762234939015,
      "learning_rate": 9.858515075708685e-05,
      "loss": 0.0282,
      "step": 71160
    },
    {
      "epoch": 0.227776,
      "grad_norm": 0.12121948936915276,
      "learning_rate": 9.858435911423831e-05,
      "loss": 0.0309,
      "step": 71180
    },
    {
      "epoch": 0.22784,
      "grad_norm": 0.041868368960762514,
      "learning_rate": 9.858356725316019e-05,
      "loss": 0.0299,
      "step": 71200
    },
    {
      "epoch": 0.227904,
      "grad_norm": 0.058200155555062395,
      "learning_rate": 9.858277517385601e-05,
      "loss": 0.0307,
      "step": 71220
    },
    {
      "epoch": 0.227968,
      "grad_norm": 0.06608379822285913,
      "learning_rate": 9.858198287632935e-05,
      "loss": 0.0307,
      "step": 71240
    },
    {
      "epoch": 0.228032,
      "grad_norm": 0.05708604779548623,
      "learning_rate": 9.858119036058377e-05,
      "loss": 0.0345,
      "step": 71260
    },
    {
      "epoch": 0.228096,
      "grad_norm": 0.08899591988316054,
      "learning_rate": 9.85803976266228e-05,
      "loss": 0.0348,
      "step": 71280
    },
    {
      "epoch": 0.22816,
      "grad_norm": 0.08169544353497313,
      "learning_rate": 9.857960467445003e-05,
      "loss": 0.0321,
      "step": 71300
    },
    {
      "epoch": 0.228224,
      "grad_norm": 0.1348740975243117,
      "learning_rate": 9.857881150406901e-05,
      "loss": 0.029,
      "step": 71320
    },
    {
      "epoch": 0.228288,
      "grad_norm": 0.06257130258345407,
      "learning_rate": 9.857801811548332e-05,
      "loss": 0.0306,
      "step": 71340
    },
    {
      "epoch": 0.228352,
      "grad_norm": 0.08424239104082941,
      "learning_rate": 9.857722450869648e-05,
      "loss": 0.0263,
      "step": 71360
    },
    {
      "epoch": 0.228416,
      "grad_norm": 0.0699461452147675,
      "learning_rate": 9.857643068371212e-05,
      "loss": 0.0336,
      "step": 71380
    },
    {
      "epoch": 0.22848,
      "grad_norm": 0.07777112326677162,
      "learning_rate": 9.857563664053376e-05,
      "loss": 0.0332,
      "step": 71400
    },
    {
      "epoch": 0.228544,
      "grad_norm": 0.08098745005590956,
      "learning_rate": 9.857484237916497e-05,
      "loss": 0.0284,
      "step": 71420
    },
    {
      "epoch": 0.228608,
      "grad_norm": 0.07398796965985235,
      "learning_rate": 9.857404789960931e-05,
      "loss": 0.0315,
      "step": 71440
    },
    {
      "epoch": 0.228672,
      "grad_norm": 0.07373104298183948,
      "learning_rate": 9.857325320187038e-05,
      "loss": 0.0299,
      "step": 71460
    },
    {
      "epoch": 0.228736,
      "grad_norm": 0.12303508748213184,
      "learning_rate": 9.857245828595173e-05,
      "loss": 0.0327,
      "step": 71480
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.057822655736534175,
      "learning_rate": 9.857166315185693e-05,
      "loss": 0.0337,
      "step": 71500
    },
    {
      "epoch": 0.228864,
      "grad_norm": 0.05462273842366747,
      "learning_rate": 9.857086779958957e-05,
      "loss": 0.033,
      "step": 71520
    },
    {
      "epoch": 0.228928,
      "grad_norm": 0.05720386944429372,
      "learning_rate": 9.857007222915319e-05,
      "loss": 0.0306,
      "step": 71540
    },
    {
      "epoch": 0.228992,
      "grad_norm": 0.07307075942986503,
      "learning_rate": 9.856927644055138e-05,
      "loss": 0.0276,
      "step": 71560
    },
    {
      "epoch": 0.229056,
      "grad_norm": 0.06341500489193089,
      "learning_rate": 9.856848043378772e-05,
      "loss": 0.0278,
      "step": 71580
    },
    {
      "epoch": 0.22912,
      "grad_norm": 0.06210893774492558,
      "learning_rate": 9.856768420886577e-05,
      "loss": 0.0302,
      "step": 71600
    },
    {
      "epoch": 0.229184,
      "grad_norm": 0.10237382693517903,
      "learning_rate": 9.856688776578914e-05,
      "loss": 0.0297,
      "step": 71620
    },
    {
      "epoch": 0.229248,
      "grad_norm": 0.05943778262486167,
      "learning_rate": 9.856609110456136e-05,
      "loss": 0.0313,
      "step": 71640
    },
    {
      "epoch": 0.229312,
      "grad_norm": 0.06271999406604178,
      "learning_rate": 9.856529422518606e-05,
      "loss": 0.0325,
      "step": 71660
    },
    {
      "epoch": 0.229376,
      "grad_norm": 0.06706829684427264,
      "learning_rate": 9.856449712766678e-05,
      "loss": 0.0277,
      "step": 71680
    },
    {
      "epoch": 0.22944,
      "grad_norm": 0.06314365798703563,
      "learning_rate": 9.85636998120071e-05,
      "loss": 0.0296,
      "step": 71700
    },
    {
      "epoch": 0.229504,
      "grad_norm": 0.052483717606852866,
      "learning_rate": 9.856290227821064e-05,
      "loss": 0.0293,
      "step": 71720
    },
    {
      "epoch": 0.229568,
      "grad_norm": 0.08172471901602323,
      "learning_rate": 9.856210452628092e-05,
      "loss": 0.0282,
      "step": 71740
    },
    {
      "epoch": 0.229632,
      "grad_norm": 0.11113952485063047,
      "learning_rate": 9.85613065562216e-05,
      "loss": 0.0327,
      "step": 71760
    },
    {
      "epoch": 0.229696,
      "grad_norm": 0.06440926505141023,
      "learning_rate": 9.85605083680362e-05,
      "loss": 0.0297,
      "step": 71780
    },
    {
      "epoch": 0.22976,
      "grad_norm": 0.05531329358997412,
      "learning_rate": 9.855970996172833e-05,
      "loss": 0.0308,
      "step": 71800
    },
    {
      "epoch": 0.229824,
      "grad_norm": 0.06196579071209111,
      "learning_rate": 9.855891133730158e-05,
      "loss": 0.0334,
      "step": 71820
    },
    {
      "epoch": 0.229888,
      "grad_norm": 0.10302780948203324,
      "learning_rate": 9.855811249475952e-05,
      "loss": 0.0308,
      "step": 71840
    },
    {
      "epoch": 0.229952,
      "grad_norm": 0.11494051287857439,
      "learning_rate": 9.855731343410576e-05,
      "loss": 0.0278,
      "step": 71860
    },
    {
      "epoch": 0.230016,
      "grad_norm": 0.05434459077806702,
      "learning_rate": 9.855651415534391e-05,
      "loss": 0.0299,
      "step": 71880
    },
    {
      "epoch": 0.23008,
      "grad_norm": 0.07056731526516997,
      "learning_rate": 9.855571465847749e-05,
      "loss": 0.0277,
      "step": 71900
    },
    {
      "epoch": 0.230144,
      "grad_norm": 0.0903388774666306,
      "learning_rate": 9.855491494351015e-05,
      "loss": 0.0293,
      "step": 71920
    },
    {
      "epoch": 0.230208,
      "grad_norm": 0.04642249806281933,
      "learning_rate": 9.855411501044545e-05,
      "loss": 0.0267,
      "step": 71940
    },
    {
      "epoch": 0.230272,
      "grad_norm": 0.08195177250898336,
      "learning_rate": 9.8553314859287e-05,
      "loss": 0.0305,
      "step": 71960
    },
    {
      "epoch": 0.230336,
      "grad_norm": 0.045829004867807194,
      "learning_rate": 9.855251449003842e-05,
      "loss": 0.031,
      "step": 71980
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.1869064642574679,
      "learning_rate": 9.855171390270324e-05,
      "loss": 0.0309,
      "step": 72000
    },
    {
      "epoch": 0.230464,
      "grad_norm": 0.0764603708826692,
      "learning_rate": 9.85509130972851e-05,
      "loss": 0.0311,
      "step": 72020
    },
    {
      "epoch": 0.230528,
      "grad_norm": 0.15592349234233618,
      "learning_rate": 9.85501120737876e-05,
      "loss": 0.0314,
      "step": 72040
    },
    {
      "epoch": 0.230592,
      "grad_norm": 0.10552664150240071,
      "learning_rate": 9.854931083221433e-05,
      "loss": 0.0318,
      "step": 72060
    },
    {
      "epoch": 0.230656,
      "grad_norm": 0.07495180337756942,
      "learning_rate": 9.854850937256887e-05,
      "loss": 0.0319,
      "step": 72080
    },
    {
      "epoch": 0.23072,
      "grad_norm": 0.05206205638687262,
      "learning_rate": 9.854770769485484e-05,
      "loss": 0.0303,
      "step": 72100
    },
    {
      "epoch": 0.230784,
      "grad_norm": 0.0861631549347789,
      "learning_rate": 9.854690579907584e-05,
      "loss": 0.0298,
      "step": 72120
    },
    {
      "epoch": 0.230848,
      "grad_norm": 0.09837617101043866,
      "learning_rate": 9.854610368523547e-05,
      "loss": 0.0284,
      "step": 72140
    },
    {
      "epoch": 0.230912,
      "grad_norm": 0.13567813095528705,
      "learning_rate": 9.854530135333733e-05,
      "loss": 0.0308,
      "step": 72160
    },
    {
      "epoch": 0.230976,
      "grad_norm": 0.11513132331976397,
      "learning_rate": 9.854449880338503e-05,
      "loss": 0.0315,
      "step": 72180
    },
    {
      "epoch": 0.23104,
      "grad_norm": 0.16515107381220356,
      "learning_rate": 9.854369603538216e-05,
      "loss": 0.0355,
      "step": 72200
    },
    {
      "epoch": 0.231104,
      "grad_norm": 0.05606183173010271,
      "learning_rate": 9.854289304933234e-05,
      "loss": 0.0293,
      "step": 72220
    },
    {
      "epoch": 0.231168,
      "grad_norm": 0.0849731232024897,
      "learning_rate": 9.854208984523918e-05,
      "loss": 0.0301,
      "step": 72240
    },
    {
      "epoch": 0.231232,
      "grad_norm": 0.06643895312220752,
      "learning_rate": 9.854128642310627e-05,
      "loss": 0.0303,
      "step": 72260
    },
    {
      "epoch": 0.231296,
      "grad_norm": 0.058753004920061226,
      "learning_rate": 9.854048278293723e-05,
      "loss": 0.0294,
      "step": 72280
    },
    {
      "epoch": 0.23136,
      "grad_norm": 0.24123233547069345,
      "learning_rate": 9.853967892473569e-05,
      "loss": 0.0291,
      "step": 72300
    },
    {
      "epoch": 0.231424,
      "grad_norm": 0.04594092651383566,
      "learning_rate": 9.853887484850523e-05,
      "loss": 0.0288,
      "step": 72320
    },
    {
      "epoch": 0.231488,
      "grad_norm": 0.1347517942808203,
      "learning_rate": 9.853807055424947e-05,
      "loss": 0.0308,
      "step": 72340
    },
    {
      "epoch": 0.231552,
      "grad_norm": 0.09659551760733022,
      "learning_rate": 9.853726604197202e-05,
      "loss": 0.0285,
      "step": 72360
    },
    {
      "epoch": 0.231616,
      "grad_norm": 0.05950393429453599,
      "learning_rate": 9.85364613116765e-05,
      "loss": 0.0291,
      "step": 72380
    },
    {
      "epoch": 0.23168,
      "grad_norm": 0.07527490142209554,
      "learning_rate": 9.853565636336652e-05,
      "loss": 0.0313,
      "step": 72400
    },
    {
      "epoch": 0.231744,
      "grad_norm": 0.08145133182154145,
      "learning_rate": 9.853485119704571e-05,
      "loss": 0.0302,
      "step": 72420
    },
    {
      "epoch": 0.231808,
      "grad_norm": 0.05019215430570018,
      "learning_rate": 9.853404581271766e-05,
      "loss": 0.0287,
      "step": 72440
    },
    {
      "epoch": 0.231872,
      "grad_norm": 0.060856781847081196,
      "learning_rate": 9.853324021038602e-05,
      "loss": 0.0318,
      "step": 72460
    },
    {
      "epoch": 0.231936,
      "grad_norm": 0.05248657855799008,
      "learning_rate": 9.853243439005437e-05,
      "loss": 0.029,
      "step": 72480
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.08487587807572816,
      "learning_rate": 9.853162835172637e-05,
      "loss": 0.0312,
      "step": 72500
    },
    {
      "epoch": 0.232064,
      "grad_norm": 0.06194473556295857,
      "learning_rate": 9.853082209540562e-05,
      "loss": 0.0273,
      "step": 72520
    },
    {
      "epoch": 0.232128,
      "grad_norm": 0.058843435829742614,
      "learning_rate": 9.853001562109573e-05,
      "loss": 0.0322,
      "step": 72540
    },
    {
      "epoch": 0.232192,
      "grad_norm": 0.13416378690502218,
      "learning_rate": 9.852920892880036e-05,
      "loss": 0.0318,
      "step": 72560
    },
    {
      "epoch": 0.232256,
      "grad_norm": 0.056075980759534405,
      "learning_rate": 9.852840201852307e-05,
      "loss": 0.0323,
      "step": 72580
    },
    {
      "epoch": 0.23232,
      "grad_norm": 0.08170905644250934,
      "learning_rate": 9.852759489026755e-05,
      "loss": 0.0316,
      "step": 72600
    },
    {
      "epoch": 0.232384,
      "grad_norm": 0.08291162617534513,
      "learning_rate": 9.852678754403741e-05,
      "loss": 0.0299,
      "step": 72620
    },
    {
      "epoch": 0.232448,
      "grad_norm": 0.07373489452897254,
      "learning_rate": 9.852597997983625e-05,
      "loss": 0.0277,
      "step": 72640
    },
    {
      "epoch": 0.232512,
      "grad_norm": 0.06618492591109143,
      "learning_rate": 9.85251721976677e-05,
      "loss": 0.0321,
      "step": 72660
    },
    {
      "epoch": 0.232576,
      "grad_norm": 0.11748038921821068,
      "learning_rate": 9.852436419753542e-05,
      "loss": 0.0331,
      "step": 72680
    },
    {
      "epoch": 0.23264,
      "grad_norm": 0.1160299393632872,
      "learning_rate": 9.852355597944303e-05,
      "loss": 0.0311,
      "step": 72700
    },
    {
      "epoch": 0.232704,
      "grad_norm": 0.05902344545507101,
      "learning_rate": 9.852274754339412e-05,
      "loss": 0.0298,
      "step": 72720
    },
    {
      "epoch": 0.232768,
      "grad_norm": 0.05753557154074273,
      "learning_rate": 9.852193888939238e-05,
      "loss": 0.0302,
      "step": 72740
    },
    {
      "epoch": 0.232832,
      "grad_norm": 0.056919126024623456,
      "learning_rate": 9.85211300174414e-05,
      "loss": 0.034,
      "step": 72760
    },
    {
      "epoch": 0.232896,
      "grad_norm": 0.050485798781149886,
      "learning_rate": 9.852032092754483e-05,
      "loss": 0.0328,
      "step": 72780
    },
    {
      "epoch": 0.23296,
      "grad_norm": 0.06724347152252266,
      "learning_rate": 9.85195116197063e-05,
      "loss": 0.0313,
      "step": 72800
    },
    {
      "epoch": 0.233024,
      "grad_norm": 0.0749119493276647,
      "learning_rate": 9.851870209392944e-05,
      "loss": 0.0285,
      "step": 72820
    },
    {
      "epoch": 0.233088,
      "grad_norm": 0.0747565212144267,
      "learning_rate": 9.851789235021791e-05,
      "loss": 0.033,
      "step": 72840
    },
    {
      "epoch": 0.233152,
      "grad_norm": 0.14922068837177918,
      "learning_rate": 9.851708238857534e-05,
      "loss": 0.0269,
      "step": 72860
    },
    {
      "epoch": 0.233216,
      "grad_norm": 0.130045536240356,
      "learning_rate": 9.851627220900533e-05,
      "loss": 0.031,
      "step": 72880
    },
    {
      "epoch": 0.23328,
      "grad_norm": 0.08096347998963688,
      "learning_rate": 9.851546181151157e-05,
      "loss": 0.0278,
      "step": 72900
    },
    {
      "epoch": 0.233344,
      "grad_norm": 0.13871661455987636,
      "learning_rate": 9.851465119609767e-05,
      "loss": 0.0308,
      "step": 72920
    },
    {
      "epoch": 0.233408,
      "grad_norm": 0.06201813537612768,
      "learning_rate": 9.851384036276726e-05,
      "loss": 0.0304,
      "step": 72940
    },
    {
      "epoch": 0.233472,
      "grad_norm": 0.08931282117946661,
      "learning_rate": 9.851302931152402e-05,
      "loss": 0.0313,
      "step": 72960
    },
    {
      "epoch": 0.233536,
      "grad_norm": 0.09496835265923786,
      "learning_rate": 9.851221804237157e-05,
      "loss": 0.0264,
      "step": 72980
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.056307204672306474,
      "learning_rate": 9.851140655531356e-05,
      "loss": 0.0301,
      "step": 73000
    },
    {
      "epoch": 0.233664,
      "grad_norm": 0.06429057948898363,
      "learning_rate": 9.851059485035363e-05,
      "loss": 0.0319,
      "step": 73020
    },
    {
      "epoch": 0.233728,
      "grad_norm": 0.08041716825232202,
      "learning_rate": 9.850978292749545e-05,
      "loss": 0.0307,
      "step": 73040
    },
    {
      "epoch": 0.233792,
      "grad_norm": 0.06610063827515962,
      "learning_rate": 9.850897078674262e-05,
      "loss": 0.03,
      "step": 73060
    },
    {
      "epoch": 0.233856,
      "grad_norm": 0.06478378448968702,
      "learning_rate": 9.850815842809882e-05,
      "loss": 0.0318,
      "step": 73080
    },
    {
      "epoch": 0.23392,
      "grad_norm": 0.08875153509941616,
      "learning_rate": 9.850734585156769e-05,
      "loss": 0.0323,
      "step": 73100
    },
    {
      "epoch": 0.233984,
      "grad_norm": 0.1461013541162037,
      "learning_rate": 9.85065330571529e-05,
      "loss": 0.0327,
      "step": 73120
    },
    {
      "epoch": 0.234048,
      "grad_norm": 0.12015203748012013,
      "learning_rate": 9.850572004485807e-05,
      "loss": 0.0334,
      "step": 73140
    },
    {
      "epoch": 0.234112,
      "grad_norm": 0.07319280325016944,
      "learning_rate": 9.850490681468688e-05,
      "loss": 0.0301,
      "step": 73160
    },
    {
      "epoch": 0.234176,
      "grad_norm": 0.08537072315072389,
      "learning_rate": 9.850409336664295e-05,
      "loss": 0.0324,
      "step": 73180
    },
    {
      "epoch": 0.23424,
      "grad_norm": 0.06933867739439176,
      "learning_rate": 9.850327970072995e-05,
      "loss": 0.0292,
      "step": 73200
    },
    {
      "epoch": 0.234304,
      "grad_norm": 0.10618527187894503,
      "learning_rate": 9.850246581695155e-05,
      "loss": 0.0299,
      "step": 73220
    },
    {
      "epoch": 0.234368,
      "grad_norm": 0.0592141978464065,
      "learning_rate": 9.850165171531138e-05,
      "loss": 0.0316,
      "step": 73240
    },
    {
      "epoch": 0.234432,
      "grad_norm": 0.11331446876855693,
      "learning_rate": 9.850083739581313e-05,
      "loss": 0.0282,
      "step": 73260
    },
    {
      "epoch": 0.234496,
      "grad_norm": 0.07214465406807367,
      "learning_rate": 9.850002285846041e-05,
      "loss": 0.0307,
      "step": 73280
    },
    {
      "epoch": 0.23456,
      "grad_norm": 0.09214934523273946,
      "learning_rate": 9.849920810325692e-05,
      "loss": 0.0323,
      "step": 73300
    },
    {
      "epoch": 0.234624,
      "grad_norm": 0.06662451040451721,
      "learning_rate": 9.849839313020632e-05,
      "loss": 0.0321,
      "step": 73320
    },
    {
      "epoch": 0.234688,
      "grad_norm": 0.05681010824671877,
      "learning_rate": 9.849757793931224e-05,
      "loss": 0.0305,
      "step": 73340
    },
    {
      "epoch": 0.234752,
      "grad_norm": 0.08932626849913457,
      "learning_rate": 9.849676253057835e-05,
      "loss": 0.0307,
      "step": 73360
    },
    {
      "epoch": 0.234816,
      "grad_norm": 0.053972331227776525,
      "learning_rate": 9.849594690400834e-05,
      "loss": 0.0272,
      "step": 73380
    },
    {
      "epoch": 0.23488,
      "grad_norm": 0.06872158527024105,
      "learning_rate": 9.849513105960586e-05,
      "loss": 0.0298,
      "step": 73400
    },
    {
      "epoch": 0.234944,
      "grad_norm": 0.05752597820959559,
      "learning_rate": 9.849431499737455e-05,
      "loss": 0.029,
      "step": 73420
    },
    {
      "epoch": 0.235008,
      "grad_norm": 0.07124086533570095,
      "learning_rate": 9.84934987173181e-05,
      "loss": 0.0298,
      "step": 73440
    },
    {
      "epoch": 0.235072,
      "grad_norm": 0.0559715033058606,
      "learning_rate": 9.849268221944017e-05,
      "loss": 0.0291,
      "step": 73460
    },
    {
      "epoch": 0.235136,
      "grad_norm": 0.08191126959248517,
      "learning_rate": 9.849186550374443e-05,
      "loss": 0.0278,
      "step": 73480
    },
    {
      "epoch": 0.2352,
      "grad_norm": 0.08273739800958059,
      "learning_rate": 9.849104857023455e-05,
      "loss": 0.0297,
      "step": 73500
    },
    {
      "epoch": 0.235264,
      "grad_norm": 0.07598945937019032,
      "learning_rate": 9.84902314189142e-05,
      "loss": 0.0301,
      "step": 73520
    },
    {
      "epoch": 0.235328,
      "grad_norm": 0.11996537515976421,
      "learning_rate": 9.848941404978704e-05,
      "loss": 0.0289,
      "step": 73540
    },
    {
      "epoch": 0.235392,
      "grad_norm": 0.06735558748171384,
      "learning_rate": 9.848859646285674e-05,
      "loss": 0.0314,
      "step": 73560
    },
    {
      "epoch": 0.235456,
      "grad_norm": 0.1376354388182584,
      "learning_rate": 9.8487778658127e-05,
      "loss": 0.0341,
      "step": 73580
    },
    {
      "epoch": 0.23552,
      "grad_norm": 0.08248441431155565,
      "learning_rate": 9.848696063560145e-05,
      "loss": 0.0335,
      "step": 73600
    },
    {
      "epoch": 0.235584,
      "grad_norm": 0.17015547019203925,
      "learning_rate": 9.848614239528382e-05,
      "loss": 0.0308,
      "step": 73620
    },
    {
      "epoch": 0.235648,
      "grad_norm": 0.08528335001360855,
      "learning_rate": 9.848532393717773e-05,
      "loss": 0.0299,
      "step": 73640
    },
    {
      "epoch": 0.235712,
      "grad_norm": 0.11351969947048708,
      "learning_rate": 9.848450526128687e-05,
      "loss": 0.0362,
      "step": 73660
    },
    {
      "epoch": 0.235776,
      "grad_norm": 0.17909695871508194,
      "learning_rate": 9.848368636761496e-05,
      "loss": 0.0305,
      "step": 73680
    },
    {
      "epoch": 0.23584,
      "grad_norm": 0.060247263401596564,
      "learning_rate": 9.848286725616563e-05,
      "loss": 0.0293,
      "step": 73700
    },
    {
      "epoch": 0.235904,
      "grad_norm": 0.1254765242542778,
      "learning_rate": 9.848204792694258e-05,
      "loss": 0.0282,
      "step": 73720
    },
    {
      "epoch": 0.235968,
      "grad_norm": 0.05062419509293313,
      "learning_rate": 9.848122837994947e-05,
      "loss": 0.0303,
      "step": 73740
    },
    {
      "epoch": 0.236032,
      "grad_norm": 0.06058153936585436,
      "learning_rate": 9.848040861519002e-05,
      "loss": 0.026,
      "step": 73760
    },
    {
      "epoch": 0.236096,
      "grad_norm": 0.08229034278063106,
      "learning_rate": 9.847958863266787e-05,
      "loss": 0.0274,
      "step": 73780
    },
    {
      "epoch": 0.23616,
      "grad_norm": 0.06160442766718873,
      "learning_rate": 9.847876843238672e-05,
      "loss": 0.0297,
      "step": 73800
    },
    {
      "epoch": 0.236224,
      "grad_norm": 0.07373141586076273,
      "learning_rate": 9.847794801435026e-05,
      "loss": 0.0308,
      "step": 73820
    },
    {
      "epoch": 0.236288,
      "grad_norm": 0.04087093346366814,
      "learning_rate": 9.847712737856218e-05,
      "loss": 0.0316,
      "step": 73840
    },
    {
      "epoch": 0.236352,
      "grad_norm": 0.10803671903985528,
      "learning_rate": 9.847630652502616e-05,
      "loss": 0.0307,
      "step": 73860
    },
    {
      "epoch": 0.236416,
      "grad_norm": 0.05267634464677613,
      "learning_rate": 9.847548545374587e-05,
      "loss": 0.0312,
      "step": 73880
    },
    {
      "epoch": 0.23648,
      "grad_norm": 0.08816769588836898,
      "learning_rate": 9.847466416472501e-05,
      "loss": 0.0292,
      "step": 73900
    },
    {
      "epoch": 0.236544,
      "grad_norm": 0.06608869805524964,
      "learning_rate": 9.847384265796728e-05,
      "loss": 0.0271,
      "step": 73920
    },
    {
      "epoch": 0.236608,
      "grad_norm": 0.11830898343450925,
      "learning_rate": 9.847302093347636e-05,
      "loss": 0.0304,
      "step": 73940
    },
    {
      "epoch": 0.236672,
      "grad_norm": 0.11833431684363141,
      "learning_rate": 9.847219899125594e-05,
      "loss": 0.0309,
      "step": 73960
    },
    {
      "epoch": 0.236736,
      "grad_norm": 0.10763763187066101,
      "learning_rate": 9.847137683130973e-05,
      "loss": 0.0306,
      "step": 73980
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.11666805473157174,
      "learning_rate": 9.847055445364139e-05,
      "loss": 0.0297,
      "step": 74000
    },
    {
      "epoch": 0.236864,
      "grad_norm": 0.06455038978450987,
      "learning_rate": 9.846973185825463e-05,
      "loss": 0.0338,
      "step": 74020
    },
    {
      "epoch": 0.236928,
      "grad_norm": 0.06422816194578176,
      "learning_rate": 9.846890904515315e-05,
      "loss": 0.0336,
      "step": 74040
    },
    {
      "epoch": 0.236992,
      "grad_norm": 0.06974785447800486,
      "learning_rate": 9.846808601434065e-05,
      "loss": 0.0318,
      "step": 74060
    },
    {
      "epoch": 0.237056,
      "grad_norm": 0.0621248139391275,
      "learning_rate": 9.846726276582081e-05,
      "loss": 0.0277,
      "step": 74080
    },
    {
      "epoch": 0.23712,
      "grad_norm": 0.0576323594134353,
      "learning_rate": 9.846643929959735e-05,
      "loss": 0.028,
      "step": 74100
    },
    {
      "epoch": 0.237184,
      "grad_norm": 0.07056610832566135,
      "learning_rate": 9.846561561567394e-05,
      "loss": 0.0311,
      "step": 74120
    },
    {
      "epoch": 0.237248,
      "grad_norm": 0.07671404815294516,
      "learning_rate": 9.84647917140543e-05,
      "loss": 0.0309,
      "step": 74140
    },
    {
      "epoch": 0.237312,
      "grad_norm": 0.09053077568032004,
      "learning_rate": 9.846396759474213e-05,
      "loss": 0.028,
      "step": 74160
    },
    {
      "epoch": 0.237376,
      "grad_norm": 0.08957798868528549,
      "learning_rate": 9.846314325774113e-05,
      "loss": 0.03,
      "step": 74180
    },
    {
      "epoch": 0.23744,
      "grad_norm": 0.05337466435179542,
      "learning_rate": 9.8462318703055e-05,
      "loss": 0.0315,
      "step": 74200
    },
    {
      "epoch": 0.237504,
      "grad_norm": 0.06968516692025764,
      "learning_rate": 9.846149393068744e-05,
      "loss": 0.0284,
      "step": 74220
    },
    {
      "epoch": 0.237568,
      "grad_norm": 0.05058248393066313,
      "learning_rate": 9.846066894064217e-05,
      "loss": 0.0279,
      "step": 74240
    },
    {
      "epoch": 0.237632,
      "grad_norm": 0.05316381100548303,
      "learning_rate": 9.845984373292286e-05,
      "loss": 0.0274,
      "step": 74260
    },
    {
      "epoch": 0.237696,
      "grad_norm": 0.10876095392449166,
      "learning_rate": 9.845901830753325e-05,
      "loss": 0.0255,
      "step": 74280
    },
    {
      "epoch": 0.23776,
      "grad_norm": 0.10985201297319612,
      "learning_rate": 9.845819266447705e-05,
      "loss": 0.026,
      "step": 74300
    },
    {
      "epoch": 0.237824,
      "grad_norm": 0.0937930379900109,
      "learning_rate": 9.845736680375795e-05,
      "loss": 0.0311,
      "step": 74320
    },
    {
      "epoch": 0.237888,
      "grad_norm": 0.091320114166907,
      "learning_rate": 9.845654072537967e-05,
      "loss": 0.0294,
      "step": 74340
    },
    {
      "epoch": 0.237952,
      "grad_norm": 0.10419620454802064,
      "learning_rate": 9.845571442934592e-05,
      "loss": 0.0322,
      "step": 74360
    },
    {
      "epoch": 0.238016,
      "grad_norm": 0.11630033619213617,
      "learning_rate": 9.845488791566039e-05,
      "loss": 0.035,
      "step": 74380
    },
    {
      "epoch": 0.23808,
      "grad_norm": 0.06448702426022326,
      "learning_rate": 9.845406118432685e-05,
      "loss": 0.031,
      "step": 74400
    },
    {
      "epoch": 0.238144,
      "grad_norm": 0.07934487373129798,
      "learning_rate": 9.845323423534895e-05,
      "loss": 0.031,
      "step": 74420
    },
    {
      "epoch": 0.238208,
      "grad_norm": 0.057226907174601424,
      "learning_rate": 9.845240706873042e-05,
      "loss": 0.0288,
      "step": 74440
    },
    {
      "epoch": 0.238272,
      "grad_norm": 0.05862630157613902,
      "learning_rate": 9.8451579684475e-05,
      "loss": 0.0272,
      "step": 74460
    },
    {
      "epoch": 0.238336,
      "grad_norm": 0.049791687938707814,
      "learning_rate": 9.84507520825864e-05,
      "loss": 0.0313,
      "step": 74480
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.10189010612878872,
      "learning_rate": 9.844992426306832e-05,
      "loss": 0.0279,
      "step": 74500
    },
    {
      "epoch": 0.238464,
      "grad_norm": 0.05469239053897695,
      "learning_rate": 9.844909622592449e-05,
      "loss": 0.0325,
      "step": 74520
    },
    {
      "epoch": 0.238528,
      "grad_norm": 0.1497191055849579,
      "learning_rate": 9.844826797115861e-05,
      "loss": 0.0316,
      "step": 74540
    },
    {
      "epoch": 0.238592,
      "grad_norm": 0.05846861111562548,
      "learning_rate": 9.844743949877442e-05,
      "loss": 0.0275,
      "step": 74560
    },
    {
      "epoch": 0.238656,
      "grad_norm": 0.051167784732405894,
      "learning_rate": 9.844661080877567e-05,
      "loss": 0.0285,
      "step": 74580
    },
    {
      "epoch": 0.23872,
      "grad_norm": 0.06046727060241974,
      "learning_rate": 9.844578190116602e-05,
      "loss": 0.0281,
      "step": 74600
    },
    {
      "epoch": 0.238784,
      "grad_norm": 0.06192622784986801,
      "learning_rate": 9.844495277594922e-05,
      "loss": 0.0267,
      "step": 74620
    },
    {
      "epoch": 0.238848,
      "grad_norm": 0.07386421502205073,
      "learning_rate": 9.844412343312901e-05,
      "loss": 0.0288,
      "step": 74640
    },
    {
      "epoch": 0.238912,
      "grad_norm": 0.1034401418418549,
      "learning_rate": 9.844329387270912e-05,
      "loss": 0.031,
      "step": 74660
    },
    {
      "epoch": 0.238976,
      "grad_norm": 0.05847352846245029,
      "learning_rate": 9.844246409469323e-05,
      "loss": 0.0284,
      "step": 74680
    },
    {
      "epoch": 0.23904,
      "grad_norm": 0.05030969306590917,
      "learning_rate": 9.844163409908512e-05,
      "loss": 0.028,
      "step": 74700
    },
    {
      "epoch": 0.239104,
      "grad_norm": 0.041788225454165134,
      "learning_rate": 9.844080388588848e-05,
      "loss": 0.0298,
      "step": 74720
    },
    {
      "epoch": 0.239168,
      "grad_norm": 0.06180616033186569,
      "learning_rate": 9.843997345510705e-05,
      "loss": 0.0313,
      "step": 74740
    },
    {
      "epoch": 0.239232,
      "grad_norm": 0.0632717980652912,
      "learning_rate": 9.843914280674458e-05,
      "loss": 0.0277,
      "step": 74760
    },
    {
      "epoch": 0.239296,
      "grad_norm": 0.05911849306000406,
      "learning_rate": 9.843831194080478e-05,
      "loss": 0.032,
      "step": 74780
    },
    {
      "epoch": 0.23936,
      "grad_norm": 0.1151497719910364,
      "learning_rate": 9.843748085729137e-05,
      "loss": 0.0288,
      "step": 74800
    },
    {
      "epoch": 0.239424,
      "grad_norm": 0.11722802954081228,
      "learning_rate": 9.843664955620813e-05,
      "loss": 0.0279,
      "step": 74820
    },
    {
      "epoch": 0.239488,
      "grad_norm": 0.05516803285041774,
      "learning_rate": 9.843581803755874e-05,
      "loss": 0.0303,
      "step": 74840
    },
    {
      "epoch": 0.239552,
      "grad_norm": 0.06453990585011933,
      "learning_rate": 9.843498630134698e-05,
      "loss": 0.0331,
      "step": 74860
    },
    {
      "epoch": 0.239616,
      "grad_norm": 0.07541387803486191,
      "learning_rate": 9.843415434757655e-05,
      "loss": 0.0326,
      "step": 74880
    },
    {
      "epoch": 0.23968,
      "grad_norm": 0.06242256556353007,
      "learning_rate": 9.84333221762512e-05,
      "loss": 0.0285,
      "step": 74900
    },
    {
      "epoch": 0.239744,
      "grad_norm": 0.0664522994274791,
      "learning_rate": 9.843248978737468e-05,
      "loss": 0.0314,
      "step": 74920
    },
    {
      "epoch": 0.239808,
      "grad_norm": 0.10259221337982401,
      "learning_rate": 9.843165718095071e-05,
      "loss": 0.0303,
      "step": 74940
    },
    {
      "epoch": 0.239872,
      "grad_norm": 0.06844757421631792,
      "learning_rate": 9.843082435698303e-05,
      "loss": 0.0283,
      "step": 74960
    },
    {
      "epoch": 0.239936,
      "grad_norm": 0.1294513965685381,
      "learning_rate": 9.842999131547542e-05,
      "loss": 0.029,
      "step": 74980
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.09107291860812793,
      "learning_rate": 9.842915805643155e-05,
      "loss": 0.0298,
      "step": 75000
    },
    {
      "epoch": 0.240064,
      "grad_norm": 0.065584023919824,
      "learning_rate": 9.842832457985524e-05,
      "loss": 0.0306,
      "step": 75020
    },
    {
      "epoch": 0.240128,
      "grad_norm": 0.09560901023483112,
      "learning_rate": 9.842749088575018e-05,
      "loss": 0.0325,
      "step": 75040
    },
    {
      "epoch": 0.240192,
      "grad_norm": 0.08385320206113882,
      "learning_rate": 9.842665697412015e-05,
      "loss": 0.0313,
      "step": 75060
    },
    {
      "epoch": 0.240256,
      "grad_norm": 0.11271104262567187,
      "learning_rate": 9.842582284496886e-05,
      "loss": 0.0326,
      "step": 75080
    },
    {
      "epoch": 0.24032,
      "grad_norm": 0.1306758567056416,
      "learning_rate": 9.842498849830009e-05,
      "loss": 0.0296,
      "step": 75100
    },
    {
      "epoch": 0.240384,
      "grad_norm": 0.08729741724764371,
      "learning_rate": 9.842415393411756e-05,
      "loss": 0.0319,
      "step": 75120
    },
    {
      "epoch": 0.240448,
      "grad_norm": 0.09138074500122444,
      "learning_rate": 9.842331915242503e-05,
      "loss": 0.0327,
      "step": 75140
    },
    {
      "epoch": 0.240512,
      "grad_norm": 0.07223615507656593,
      "learning_rate": 9.842248415322626e-05,
      "loss": 0.0312,
      "step": 75160
    },
    {
      "epoch": 0.240576,
      "grad_norm": 0.09092386466451736,
      "learning_rate": 9.842164893652498e-05,
      "loss": 0.0304,
      "step": 75180
    },
    {
      "epoch": 0.24064,
      "grad_norm": 0.1060830872137615,
      "learning_rate": 9.842081350232497e-05,
      "loss": 0.0295,
      "step": 75200
    },
    {
      "epoch": 0.240704,
      "grad_norm": 0.07253465442860489,
      "learning_rate": 9.841997785062996e-05,
      "loss": 0.0301,
      "step": 75220
    },
    {
      "epoch": 0.240768,
      "grad_norm": 0.12029569981983633,
      "learning_rate": 9.841914198144371e-05,
      "loss": 0.0305,
      "step": 75240
    },
    {
      "epoch": 0.240832,
      "grad_norm": 0.12878346882860503,
      "learning_rate": 9.841830589476997e-05,
      "loss": 0.0293,
      "step": 75260
    },
    {
      "epoch": 0.240896,
      "grad_norm": 0.11208580219226276,
      "learning_rate": 9.84174695906125e-05,
      "loss": 0.0318,
      "step": 75280
    },
    {
      "epoch": 0.24096,
      "grad_norm": 0.07272513327685043,
      "learning_rate": 9.841663306897506e-05,
      "loss": 0.0283,
      "step": 75300
    },
    {
      "epoch": 0.241024,
      "grad_norm": 0.08059159786577916,
      "learning_rate": 9.841579632986141e-05,
      "loss": 0.0321,
      "step": 75320
    },
    {
      "epoch": 0.241088,
      "grad_norm": 0.041763518377769,
      "learning_rate": 9.841495937327529e-05,
      "loss": 0.03,
      "step": 75340
    },
    {
      "epoch": 0.241152,
      "grad_norm": 0.12265735614200002,
      "learning_rate": 9.841412219922048e-05,
      "loss": 0.0326,
      "step": 75360
    },
    {
      "epoch": 0.241216,
      "grad_norm": 0.08370074327224666,
      "learning_rate": 9.841328480770072e-05,
      "loss": 0.0342,
      "step": 75380
    },
    {
      "epoch": 0.24128,
      "grad_norm": 0.07261776174199651,
      "learning_rate": 9.841244719871979e-05,
      "loss": 0.0337,
      "step": 75400
    },
    {
      "epoch": 0.241344,
      "grad_norm": 0.14367652055605545,
      "learning_rate": 9.841160937228144e-05,
      "loss": 0.0317,
      "step": 75420
    },
    {
      "epoch": 0.241408,
      "grad_norm": 0.06795748208057648,
      "learning_rate": 9.841077132838945e-05,
      "loss": 0.0336,
      "step": 75440
    },
    {
      "epoch": 0.241472,
      "grad_norm": 0.08862408875577264,
      "learning_rate": 9.840993306704758e-05,
      "loss": 0.0276,
      "step": 75460
    },
    {
      "epoch": 0.241536,
      "grad_norm": 0.100862640022274,
      "learning_rate": 9.840909458825957e-05,
      "loss": 0.0327,
      "step": 75480
    },
    {
      "epoch": 0.2416,
      "grad_norm": 0.06623897632055767,
      "learning_rate": 9.840825589202922e-05,
      "loss": 0.0338,
      "step": 75500
    },
    {
      "epoch": 0.241664,
      "grad_norm": 0.06960896485864733,
      "learning_rate": 9.840741697836027e-05,
      "loss": 0.0339,
      "step": 75520
    },
    {
      "epoch": 0.241728,
      "grad_norm": 0.055396091183682286,
      "learning_rate": 9.84065778472565e-05,
      "loss": 0.0333,
      "step": 75540
    },
    {
      "epoch": 0.241792,
      "grad_norm": 0.07051217244228872,
      "learning_rate": 9.840573849872168e-05,
      "loss": 0.0305,
      "step": 75560
    },
    {
      "epoch": 0.241856,
      "grad_norm": 0.08109862932951696,
      "learning_rate": 9.840489893275958e-05,
      "loss": 0.0309,
      "step": 75580
    },
    {
      "epoch": 0.24192,
      "grad_norm": 0.082116669636281,
      "learning_rate": 9.840405914937397e-05,
      "loss": 0.0303,
      "step": 75600
    },
    {
      "epoch": 0.241984,
      "grad_norm": 0.11144333995349691,
      "learning_rate": 9.840321914856862e-05,
      "loss": 0.0287,
      "step": 75620
    },
    {
      "epoch": 0.242048,
      "grad_norm": 0.07252721450558351,
      "learning_rate": 9.840237893034732e-05,
      "loss": 0.0319,
      "step": 75640
    },
    {
      "epoch": 0.242112,
      "grad_norm": 0.06338077105411824,
      "learning_rate": 9.840153849471382e-05,
      "loss": 0.0327,
      "step": 75660
    },
    {
      "epoch": 0.242176,
      "grad_norm": 0.0823634023370179,
      "learning_rate": 9.840069784167189e-05,
      "loss": 0.0279,
      "step": 75680
    },
    {
      "epoch": 0.24224,
      "grad_norm": 0.05633925323777528,
      "learning_rate": 9.839985697122535e-05,
      "loss": 0.0279,
      "step": 75700
    },
    {
      "epoch": 0.242304,
      "grad_norm": 0.11868043095235185,
      "learning_rate": 9.839901588337794e-05,
      "loss": 0.0332,
      "step": 75720
    },
    {
      "epoch": 0.242368,
      "grad_norm": 0.05167566744116622,
      "learning_rate": 9.839817457813343e-05,
      "loss": 0.0312,
      "step": 75740
    },
    {
      "epoch": 0.242432,
      "grad_norm": 0.07965503603273497,
      "learning_rate": 9.839733305549563e-05,
      "loss": 0.0311,
      "step": 75760
    },
    {
      "epoch": 0.242496,
      "grad_norm": 0.051797361580601234,
      "learning_rate": 9.83964913154683e-05,
      "loss": 0.0293,
      "step": 75780
    },
    {
      "epoch": 0.24256,
      "grad_norm": 0.08194270094632075,
      "learning_rate": 9.839564935805522e-05,
      "loss": 0.0303,
      "step": 75800
    },
    {
      "epoch": 0.242624,
      "grad_norm": 0.11614724221854153,
      "learning_rate": 9.839480718326018e-05,
      "loss": 0.0293,
      "step": 75820
    },
    {
      "epoch": 0.242688,
      "grad_norm": 0.10095941696256949,
      "learning_rate": 9.839396479108696e-05,
      "loss": 0.0274,
      "step": 75840
    },
    {
      "epoch": 0.242752,
      "grad_norm": 0.08656951949934724,
      "learning_rate": 9.839312218153936e-05,
      "loss": 0.0292,
      "step": 75860
    },
    {
      "epoch": 0.242816,
      "grad_norm": 0.05363075283005728,
      "learning_rate": 9.839227935462113e-05,
      "loss": 0.0263,
      "step": 75880
    },
    {
      "epoch": 0.24288,
      "grad_norm": 0.08136538396257342,
      "learning_rate": 9.839143631033609e-05,
      "loss": 0.0257,
      "step": 75900
    },
    {
      "epoch": 0.242944,
      "grad_norm": 0.11441507471062821,
      "learning_rate": 9.8390593048688e-05,
      "loss": 0.0282,
      "step": 75920
    },
    {
      "epoch": 0.243008,
      "grad_norm": 0.053824921405020966,
      "learning_rate": 9.838974956968065e-05,
      "loss": 0.031,
      "step": 75940
    },
    {
      "epoch": 0.243072,
      "grad_norm": 0.11311796096233652,
      "learning_rate": 9.838890587331787e-05,
      "loss": 0.033,
      "step": 75960
    },
    {
      "epoch": 0.243136,
      "grad_norm": 0.07760726689821014,
      "learning_rate": 9.838806195960339e-05,
      "loss": 0.031,
      "step": 75980
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.054907806782401654,
      "learning_rate": 9.838721782854103e-05,
      "loss": 0.0321,
      "step": 76000
    },
    {
      "epoch": 0.243264,
      "grad_norm": 0.05421980681761685,
      "learning_rate": 9.838637348013459e-05,
      "loss": 0.0284,
      "step": 76020
    },
    {
      "epoch": 0.243328,
      "grad_norm": 0.17211193283158316,
      "learning_rate": 9.838552891438783e-05,
      "loss": 0.0323,
      "step": 76040
    },
    {
      "epoch": 0.243392,
      "grad_norm": 0.12943102314118832,
      "learning_rate": 9.83846841313046e-05,
      "loss": 0.0331,
      "step": 76060
    },
    {
      "epoch": 0.243456,
      "grad_norm": 0.07306620831294458,
      "learning_rate": 9.838383913088865e-05,
      "loss": 0.0301,
      "step": 76080
    },
    {
      "epoch": 0.24352,
      "grad_norm": 0.09334050633062034,
      "learning_rate": 9.838299391314377e-05,
      "loss": 0.0303,
      "step": 76100
    },
    {
      "epoch": 0.243584,
      "grad_norm": 0.11094428704503621,
      "learning_rate": 9.838214847807378e-05,
      "loss": 0.0275,
      "step": 76120
    },
    {
      "epoch": 0.243648,
      "grad_norm": 0.06014980405667603,
      "learning_rate": 9.838130282568248e-05,
      "loss": 0.0289,
      "step": 76140
    },
    {
      "epoch": 0.243712,
      "grad_norm": 0.06511569587223197,
      "learning_rate": 9.838045695597366e-05,
      "loss": 0.0278,
      "step": 76160
    },
    {
      "epoch": 0.243776,
      "grad_norm": 0.12912756406288878,
      "learning_rate": 9.837961086895111e-05,
      "loss": 0.0279,
      "step": 76180
    },
    {
      "epoch": 0.24384,
      "grad_norm": 0.21140688177877892,
      "learning_rate": 9.837876456461863e-05,
      "loss": 0.0303,
      "step": 76200
    },
    {
      "epoch": 0.243904,
      "grad_norm": 0.11682353169127459,
      "learning_rate": 9.837791804298004e-05,
      "loss": 0.0303,
      "step": 76220
    },
    {
      "epoch": 0.243968,
      "grad_norm": 0.04890235485560692,
      "learning_rate": 9.837707130403914e-05,
      "loss": 0.0284,
      "step": 76240
    },
    {
      "epoch": 0.244032,
      "grad_norm": 0.1443420489632538,
      "learning_rate": 9.837622434779972e-05,
      "loss": 0.0321,
      "step": 76260
    },
    {
      "epoch": 0.244096,
      "grad_norm": 0.05551651036284427,
      "learning_rate": 9.837537717426558e-05,
      "loss": 0.0275,
      "step": 76280
    },
    {
      "epoch": 0.24416,
      "grad_norm": 0.05469018564943794,
      "learning_rate": 9.837452978344055e-05,
      "loss": 0.032,
      "step": 76300
    },
    {
      "epoch": 0.244224,
      "grad_norm": 0.14420695280174145,
      "learning_rate": 9.837368217532841e-05,
      "loss": 0.0321,
      "step": 76320
    },
    {
      "epoch": 0.244288,
      "grad_norm": 0.08072035424872051,
      "learning_rate": 9.837283434993299e-05,
      "loss": 0.0328,
      "step": 76340
    },
    {
      "epoch": 0.244352,
      "grad_norm": 0.08134410699162518,
      "learning_rate": 9.837198630725809e-05,
      "loss": 0.0304,
      "step": 76360
    },
    {
      "epoch": 0.244416,
      "grad_norm": 0.20766627533964196,
      "learning_rate": 9.837113804730748e-05,
      "loss": 0.0334,
      "step": 76380
    },
    {
      "epoch": 0.24448,
      "grad_norm": 0.07761996894839283,
      "learning_rate": 9.837028957008505e-05,
      "loss": 0.0304,
      "step": 76400
    },
    {
      "epoch": 0.244544,
      "grad_norm": 0.0718093416297512,
      "learning_rate": 9.836944087559454e-05,
      "loss": 0.0337,
      "step": 76420
    },
    {
      "epoch": 0.244608,
      "grad_norm": 0.09542797531609302,
      "learning_rate": 9.836859196383981e-05,
      "loss": 0.0328,
      "step": 76440
    },
    {
      "epoch": 0.244672,
      "grad_norm": 0.07118146419230027,
      "learning_rate": 9.836774283482465e-05,
      "loss": 0.0301,
      "step": 76460
    },
    {
      "epoch": 0.244736,
      "grad_norm": 0.07169651634961503,
      "learning_rate": 9.836689348855287e-05,
      "loss": 0.0327,
      "step": 76480
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.10067836871486986,
      "learning_rate": 9.83660439250283e-05,
      "loss": 0.0299,
      "step": 76500
    },
    {
      "epoch": 0.244864,
      "grad_norm": 0.0612769273747591,
      "learning_rate": 9.836519414425473e-05,
      "loss": 0.03,
      "step": 76520
    },
    {
      "epoch": 0.244928,
      "grad_norm": 0.05323430100573117,
      "learning_rate": 9.836434414623601e-05,
      "loss": 0.0338,
      "step": 76540
    },
    {
      "epoch": 0.244992,
      "grad_norm": 0.060166023215523064,
      "learning_rate": 9.836349393097595e-05,
      "loss": 0.0303,
      "step": 76560
    },
    {
      "epoch": 0.245056,
      "grad_norm": 0.06670798865807341,
      "learning_rate": 9.836264349847834e-05,
      "loss": 0.0276,
      "step": 76580
    },
    {
      "epoch": 0.24512,
      "grad_norm": 0.0924887380559937,
      "learning_rate": 9.836179284874705e-05,
      "loss": 0.0303,
      "step": 76600
    },
    {
      "epoch": 0.245184,
      "grad_norm": 0.1748014715501169,
      "learning_rate": 9.836094198178585e-05,
      "loss": 0.0306,
      "step": 76620
    },
    {
      "epoch": 0.245248,
      "grad_norm": 0.06334115605273537,
      "learning_rate": 9.836009089759858e-05,
      "loss": 0.0314,
      "step": 76640
    },
    {
      "epoch": 0.245312,
      "grad_norm": 0.07557922164391759,
      "learning_rate": 9.835923959618909e-05,
      "loss": 0.0305,
      "step": 76660
    },
    {
      "epoch": 0.245376,
      "grad_norm": 0.07202051052605302,
      "learning_rate": 9.835838807756117e-05,
      "loss": 0.0313,
      "step": 76680
    },
    {
      "epoch": 0.24544,
      "grad_norm": 0.057647582387074243,
      "learning_rate": 9.835753634171867e-05,
      "loss": 0.0305,
      "step": 76700
    },
    {
      "epoch": 0.245504,
      "grad_norm": 0.07739491268279507,
      "learning_rate": 9.835668438866539e-05,
      "loss": 0.0294,
      "step": 76720
    },
    {
      "epoch": 0.245568,
      "grad_norm": 0.055959057245121076,
      "learning_rate": 9.835583221840517e-05,
      "loss": 0.0311,
      "step": 76740
    },
    {
      "epoch": 0.245632,
      "grad_norm": 0.07899574307674032,
      "learning_rate": 9.835497983094183e-05,
      "loss": 0.0299,
      "step": 76760
    },
    {
      "epoch": 0.245696,
      "grad_norm": 0.057799453819936876,
      "learning_rate": 9.835412722627921e-05,
      "loss": 0.0321,
      "step": 76780
    },
    {
      "epoch": 0.24576,
      "grad_norm": 0.11643829837244915,
      "learning_rate": 9.835327440442115e-05,
      "loss": 0.0333,
      "step": 76800
    },
    {
      "epoch": 0.245824,
      "grad_norm": 0.08624893771687397,
      "learning_rate": 9.835242136537145e-05,
      "loss": 0.0328,
      "step": 76820
    },
    {
      "epoch": 0.245888,
      "grad_norm": 0.04596068917249059,
      "learning_rate": 9.835156810913396e-05,
      "loss": 0.0306,
      "step": 76840
    },
    {
      "epoch": 0.245952,
      "grad_norm": 0.07869583556877166,
      "learning_rate": 9.835071463571251e-05,
      "loss": 0.0312,
      "step": 76860
    },
    {
      "epoch": 0.246016,
      "grad_norm": 0.13684626957591095,
      "learning_rate": 9.834986094511094e-05,
      "loss": 0.0303,
      "step": 76880
    },
    {
      "epoch": 0.24608,
      "grad_norm": 0.1334043304577334,
      "learning_rate": 9.834900703733307e-05,
      "loss": 0.0313,
      "step": 76900
    },
    {
      "epoch": 0.246144,
      "grad_norm": 0.06703308575094528,
      "learning_rate": 9.834815291238275e-05,
      "loss": 0.0311,
      "step": 76920
    },
    {
      "epoch": 0.246208,
      "grad_norm": 0.06881031254180857,
      "learning_rate": 9.834729857026381e-05,
      "loss": 0.0273,
      "step": 76940
    },
    {
      "epoch": 0.246272,
      "grad_norm": 0.04849289519230238,
      "learning_rate": 9.834644401098008e-05,
      "loss": 0.0304,
      "step": 76960
    },
    {
      "epoch": 0.246336,
      "grad_norm": 0.05459818641608831,
      "learning_rate": 9.834558923453541e-05,
      "loss": 0.0285,
      "step": 76980
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.11798483005671742,
      "learning_rate": 9.834473424093364e-05,
      "loss": 0.0297,
      "step": 77000
    },
    {
      "epoch": 0.246464,
      "grad_norm": 0.12591111899375504,
      "learning_rate": 9.83438790301786e-05,
      "loss": 0.0305,
      "step": 77020
    },
    {
      "epoch": 0.246528,
      "grad_norm": 0.10548308955584164,
      "learning_rate": 9.834302360227414e-05,
      "loss": 0.0315,
      "step": 77040
    },
    {
      "epoch": 0.246592,
      "grad_norm": 0.060514481728976006,
      "learning_rate": 9.834216795722411e-05,
      "loss": 0.0331,
      "step": 77060
    },
    {
      "epoch": 0.246656,
      "grad_norm": 0.09798948715073799,
      "learning_rate": 9.834131209503234e-05,
      "loss": 0.0276,
      "step": 77080
    },
    {
      "epoch": 0.24672,
      "grad_norm": 0.1226635075811686,
      "learning_rate": 9.834045601570268e-05,
      "loss": 0.0283,
      "step": 77100
    },
    {
      "epoch": 0.246784,
      "grad_norm": 0.1133288002661007,
      "learning_rate": 9.833959971923896e-05,
      "loss": 0.0294,
      "step": 77120
    },
    {
      "epoch": 0.246848,
      "grad_norm": 0.08880995574568823,
      "learning_rate": 9.833874320564505e-05,
      "loss": 0.0303,
      "step": 77140
    },
    {
      "epoch": 0.246912,
      "grad_norm": 0.0680191401890256,
      "learning_rate": 9.833788647492476e-05,
      "loss": 0.0279,
      "step": 77160
    },
    {
      "epoch": 0.246976,
      "grad_norm": 0.11108621594750857,
      "learning_rate": 9.833702952708201e-05,
      "loss": 0.0321,
      "step": 77180
    },
    {
      "epoch": 0.24704,
      "grad_norm": 0.10269296161350197,
      "learning_rate": 9.833617236212058e-05,
      "loss": 0.0282,
      "step": 77200
    },
    {
      "epoch": 0.247104,
      "grad_norm": 0.06686281183308215,
      "learning_rate": 9.833531498004434e-05,
      "loss": 0.03,
      "step": 77220
    },
    {
      "epoch": 0.247168,
      "grad_norm": 0.06545199033933594,
      "learning_rate": 9.833445738085716e-05,
      "loss": 0.0302,
      "step": 77240
    },
    {
      "epoch": 0.247232,
      "grad_norm": 0.1063622710446205,
      "learning_rate": 9.833359956456286e-05,
      "loss": 0.0288,
      "step": 77260
    },
    {
      "epoch": 0.247296,
      "grad_norm": 0.06616559277544147,
      "learning_rate": 9.833274153116532e-05,
      "loss": 0.0305,
      "step": 77280
    },
    {
      "epoch": 0.24736,
      "grad_norm": 0.04785651257103933,
      "learning_rate": 9.833188328066838e-05,
      "loss": 0.0305,
      "step": 77300
    },
    {
      "epoch": 0.247424,
      "grad_norm": 0.12466527698517027,
      "learning_rate": 9.83310248130759e-05,
      "loss": 0.0295,
      "step": 77320
    },
    {
      "epoch": 0.247488,
      "grad_norm": 0.07278809306280792,
      "learning_rate": 9.833016612839174e-05,
      "loss": 0.0284,
      "step": 77340
    },
    {
      "epoch": 0.247552,
      "grad_norm": 0.09423818905593444,
      "learning_rate": 9.832930722661975e-05,
      "loss": 0.0312,
      "step": 77360
    },
    {
      "epoch": 0.247616,
      "grad_norm": 0.05177919790010331,
      "learning_rate": 9.832844810776381e-05,
      "loss": 0.0291,
      "step": 77380
    },
    {
      "epoch": 0.24768,
      "grad_norm": 0.10172456377581898,
      "learning_rate": 9.832758877182774e-05,
      "loss": 0.032,
      "step": 77400
    },
    {
      "epoch": 0.247744,
      "grad_norm": 0.048264535962026144,
      "learning_rate": 9.832672921881542e-05,
      "loss": 0.0305,
      "step": 77420
    },
    {
      "epoch": 0.247808,
      "grad_norm": 0.11135292699733396,
      "learning_rate": 9.832586944873071e-05,
      "loss": 0.0251,
      "step": 77440
    },
    {
      "epoch": 0.247872,
      "grad_norm": 0.10873800990550316,
      "learning_rate": 9.832500946157748e-05,
      "loss": 0.0278,
      "step": 77460
    },
    {
      "epoch": 0.247936,
      "grad_norm": 0.07030144709651247,
      "learning_rate": 9.832414925735958e-05,
      "loss": 0.0291,
      "step": 77480
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.12103864638116191,
      "learning_rate": 9.832328883608088e-05,
      "loss": 0.0313,
      "step": 77500
    },
    {
      "epoch": 0.248064,
      "grad_norm": 0.05490590115872208,
      "learning_rate": 9.832242819774524e-05,
      "loss": 0.029,
      "step": 77520
    },
    {
      "epoch": 0.248128,
      "grad_norm": 0.10682516899331987,
      "learning_rate": 9.832156734235655e-05,
      "loss": 0.0308,
      "step": 77540
    },
    {
      "epoch": 0.248192,
      "grad_norm": 0.08565029298773781,
      "learning_rate": 9.832070626991864e-05,
      "loss": 0.0321,
      "step": 77560
    },
    {
      "epoch": 0.248256,
      "grad_norm": 0.06830226989994787,
      "learning_rate": 9.83198449804354e-05,
      "loss": 0.0303,
      "step": 77580
    },
    {
      "epoch": 0.24832,
      "grad_norm": 0.06400127148481424,
      "learning_rate": 9.831898347391068e-05,
      "loss": 0.0304,
      "step": 77600
    },
    {
      "epoch": 0.248384,
      "grad_norm": 0.1289076541918976,
      "learning_rate": 9.831812175034839e-05,
      "loss": 0.0309,
      "step": 77620
    },
    {
      "epoch": 0.248448,
      "grad_norm": 0.10268903902974988,
      "learning_rate": 9.831725980975234e-05,
      "loss": 0.0292,
      "step": 77640
    },
    {
      "epoch": 0.248512,
      "grad_norm": 0.08131089624304555,
      "learning_rate": 9.831639765212646e-05,
      "loss": 0.0279,
      "step": 77660
    },
    {
      "epoch": 0.248576,
      "grad_norm": 0.06727296576277478,
      "learning_rate": 9.831553527747458e-05,
      "loss": 0.0302,
      "step": 77680
    },
    {
      "epoch": 0.24864,
      "grad_norm": 0.07896931175174525,
      "learning_rate": 9.831467268580058e-05,
      "loss": 0.0347,
      "step": 77700
    },
    {
      "epoch": 0.248704,
      "grad_norm": 0.07543986966319662,
      "learning_rate": 9.831380987710839e-05,
      "loss": 0.0276,
      "step": 77720
    },
    {
      "epoch": 0.248768,
      "grad_norm": 0.07853862265100248,
      "learning_rate": 9.831294685140181e-05,
      "loss": 0.0292,
      "step": 77740
    },
    {
      "epoch": 0.248832,
      "grad_norm": 0.07548178472344115,
      "learning_rate": 9.831208360868476e-05,
      "loss": 0.0313,
      "step": 77760
    },
    {
      "epoch": 0.248896,
      "grad_norm": 0.04356577268160738,
      "learning_rate": 9.831122014896109e-05,
      "loss": 0.0274,
      "step": 77780
    },
    {
      "epoch": 0.24896,
      "grad_norm": 0.07696284344124553,
      "learning_rate": 9.83103564722347e-05,
      "loss": 0.0315,
      "step": 77800
    },
    {
      "epoch": 0.249024,
      "grad_norm": 0.06451635893351533,
      "learning_rate": 9.830949257850947e-05,
      "loss": 0.0292,
      "step": 77820
    },
    {
      "epoch": 0.249088,
      "grad_norm": 0.06483559410974471,
      "learning_rate": 9.830862846778928e-05,
      "loss": 0.0275,
      "step": 77840
    },
    {
      "epoch": 0.249152,
      "grad_norm": 0.06257365637286286,
      "learning_rate": 9.830776414007799e-05,
      "loss": 0.0261,
      "step": 77860
    },
    {
      "epoch": 0.249216,
      "grad_norm": 0.06652426972771643,
      "learning_rate": 9.830689959537952e-05,
      "loss": 0.0284,
      "step": 77880
    },
    {
      "epoch": 0.24928,
      "grad_norm": 0.09662805890308412,
      "learning_rate": 9.83060348336977e-05,
      "loss": 0.0315,
      "step": 77900
    },
    {
      "epoch": 0.249344,
      "grad_norm": 0.049093729443121015,
      "learning_rate": 9.830516985503645e-05,
      "loss": 0.0307,
      "step": 77920
    },
    {
      "epoch": 0.249408,
      "grad_norm": 0.05306713163586091,
      "learning_rate": 9.830430465939966e-05,
      "loss": 0.032,
      "step": 77940
    },
    {
      "epoch": 0.249472,
      "grad_norm": 0.12642777448502335,
      "learning_rate": 9.830343924679121e-05,
      "loss": 0.0306,
      "step": 77960
    },
    {
      "epoch": 0.249536,
      "grad_norm": 0.07175161103336694,
      "learning_rate": 9.830257361721497e-05,
      "loss": 0.0323,
      "step": 77980
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.08937313958416067,
      "learning_rate": 9.830170777067485e-05,
      "loss": 0.0313,
      "step": 78000
    },
    {
      "epoch": 0.249664,
      "grad_norm": 0.10213694889388962,
      "learning_rate": 9.830084170717473e-05,
      "loss": 0.0321,
      "step": 78020
    },
    {
      "epoch": 0.249728,
      "grad_norm": 0.0891454155729414,
      "learning_rate": 9.829997542671851e-05,
      "loss": 0.0279,
      "step": 78040
    },
    {
      "epoch": 0.249792,
      "grad_norm": 0.08296183027519251,
      "learning_rate": 9.829910892931007e-05,
      "loss": 0.0303,
      "step": 78060
    },
    {
      "epoch": 0.249856,
      "grad_norm": 0.06329615025836577,
      "learning_rate": 9.82982422149533e-05,
      "loss": 0.033,
      "step": 78080
    },
    {
      "epoch": 0.24992,
      "grad_norm": 0.050042055448042175,
      "learning_rate": 9.82973752836521e-05,
      "loss": 0.0317,
      "step": 78100
    },
    {
      "epoch": 0.249984,
      "grad_norm": 0.09103175259121889,
      "learning_rate": 9.829650813541036e-05,
      "loss": 0.0291,
      "step": 78120
    },
    {
      "epoch": 0.250048,
      "grad_norm": 0.11344347331378879,
      "learning_rate": 9.829564077023197e-05,
      "loss": 0.0313,
      "step": 78140
    },
    {
      "epoch": 0.250112,
      "grad_norm": 0.05607198401695192,
      "learning_rate": 9.829477318812083e-05,
      "loss": 0.0305,
      "step": 78160
    },
    {
      "epoch": 0.250176,
      "grad_norm": 0.057861448233872556,
      "learning_rate": 9.829390538908086e-05,
      "loss": 0.0294,
      "step": 78180
    },
    {
      "epoch": 0.25024,
      "grad_norm": 0.056910754285138004,
      "learning_rate": 9.829303737311593e-05,
      "loss": 0.0364,
      "step": 78200
    },
    {
      "epoch": 0.250304,
      "grad_norm": 0.05110854915484866,
      "learning_rate": 9.829216914022994e-05,
      "loss": 0.0303,
      "step": 78220
    },
    {
      "epoch": 0.250368,
      "grad_norm": 0.06340253366776188,
      "learning_rate": 9.82913006904268e-05,
      "loss": 0.0303,
      "step": 78240
    },
    {
      "epoch": 0.250432,
      "grad_norm": 0.07060800008782184,
      "learning_rate": 9.829043202371041e-05,
      "loss": 0.0302,
      "step": 78260
    },
    {
      "epoch": 0.250496,
      "grad_norm": 0.058812205786097645,
      "learning_rate": 9.828956314008466e-05,
      "loss": 0.0317,
      "step": 78280
    },
    {
      "epoch": 0.25056,
      "grad_norm": 0.05669931385874617,
      "learning_rate": 9.828869403955348e-05,
      "loss": 0.0301,
      "step": 78300
    },
    {
      "epoch": 0.250624,
      "grad_norm": 0.24026646329345613,
      "learning_rate": 9.828782472212073e-05,
      "loss": 0.0302,
      "step": 78320
    },
    {
      "epoch": 0.250688,
      "grad_norm": 0.04951313476192179,
      "learning_rate": 9.828695518779037e-05,
      "loss": 0.0279,
      "step": 78340
    },
    {
      "epoch": 0.250752,
      "grad_norm": 0.0805412200847954,
      "learning_rate": 9.828608543656626e-05,
      "loss": 0.0285,
      "step": 78360
    },
    {
      "epoch": 0.250816,
      "grad_norm": 0.08549113639175138,
      "learning_rate": 9.828521546845232e-05,
      "loss": 0.031,
      "step": 78380
    },
    {
      "epoch": 0.25088,
      "grad_norm": 0.08029612634340495,
      "learning_rate": 9.828434528345246e-05,
      "loss": 0.0297,
      "step": 78400
    },
    {
      "epoch": 0.250944,
      "grad_norm": 0.06068178567996576,
      "learning_rate": 9.82834748815706e-05,
      "loss": 0.0314,
      "step": 78420
    },
    {
      "epoch": 0.251008,
      "grad_norm": 0.06426209848275896,
      "learning_rate": 9.828260426281062e-05,
      "loss": 0.0277,
      "step": 78440
    },
    {
      "epoch": 0.251072,
      "grad_norm": 0.050895077060587296,
      "learning_rate": 9.828173342717648e-05,
      "loss": 0.0271,
      "step": 78460
    },
    {
      "epoch": 0.251136,
      "grad_norm": 0.13159640576956252,
      "learning_rate": 9.828086237467204e-05,
      "loss": 0.0314,
      "step": 78480
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.06978428213278695,
      "learning_rate": 9.827999110530123e-05,
      "loss": 0.033,
      "step": 78500
    },
    {
      "epoch": 0.251264,
      "grad_norm": 0.06668744407271042,
      "learning_rate": 9.827911961906799e-05,
      "loss": 0.0319,
      "step": 78520
    },
    {
      "epoch": 0.251328,
      "grad_norm": 0.07810984220809664,
      "learning_rate": 9.82782479159762e-05,
      "loss": 0.0304,
      "step": 78540
    },
    {
      "epoch": 0.251392,
      "grad_norm": 0.07176983446722066,
      "learning_rate": 9.827737599602977e-05,
      "loss": 0.0309,
      "step": 78560
    },
    {
      "epoch": 0.251456,
      "grad_norm": 0.13246234366306997,
      "learning_rate": 9.827650385923266e-05,
      "loss": 0.0342,
      "step": 78580
    },
    {
      "epoch": 0.25152,
      "grad_norm": 0.06782392818550931,
      "learning_rate": 9.827563150558874e-05,
      "loss": 0.0286,
      "step": 78600
    },
    {
      "epoch": 0.251584,
      "grad_norm": 0.15766432061444388,
      "learning_rate": 9.827475893510197e-05,
      "loss": 0.0272,
      "step": 78620
    },
    {
      "epoch": 0.251648,
      "grad_norm": 0.06517815181701653,
      "learning_rate": 9.827388614777622e-05,
      "loss": 0.0284,
      "step": 78640
    },
    {
      "epoch": 0.251712,
      "grad_norm": 0.04449363377826685,
      "learning_rate": 9.827301314361547e-05,
      "loss": 0.0281,
      "step": 78660
    },
    {
      "epoch": 0.251776,
      "grad_norm": 0.05972258737737138,
      "learning_rate": 9.82721399226236e-05,
      "loss": 0.0321,
      "step": 78680
    },
    {
      "epoch": 0.25184,
      "grad_norm": 0.04642535453077361,
      "learning_rate": 9.827126648480454e-05,
      "loss": 0.0302,
      "step": 78700
    },
    {
      "epoch": 0.251904,
      "grad_norm": 0.07230552143316371,
      "learning_rate": 9.827039283016222e-05,
      "loss": 0.03,
      "step": 78720
    },
    {
      "epoch": 0.251968,
      "grad_norm": 0.04400990805093012,
      "learning_rate": 9.826951895870056e-05,
      "loss": 0.0321,
      "step": 78740
    },
    {
      "epoch": 0.252032,
      "grad_norm": 0.05823823757675434,
      "learning_rate": 9.826864487042349e-05,
      "loss": 0.0322,
      "step": 78760
    },
    {
      "epoch": 0.252096,
      "grad_norm": 0.13236327909933257,
      "learning_rate": 9.826777056533491e-05,
      "loss": 0.0336,
      "step": 78780
    },
    {
      "epoch": 0.25216,
      "grad_norm": 0.04819873422211765,
      "learning_rate": 9.82668960434388e-05,
      "loss": 0.031,
      "step": 78800
    },
    {
      "epoch": 0.252224,
      "grad_norm": 0.08645905562891312,
      "learning_rate": 9.826602130473903e-05,
      "loss": 0.0308,
      "step": 78820
    },
    {
      "epoch": 0.252288,
      "grad_norm": 0.07233498534487104,
      "learning_rate": 9.826514634923958e-05,
      "loss": 0.0298,
      "step": 78840
    },
    {
      "epoch": 0.252352,
      "grad_norm": 0.0744801491601935,
      "learning_rate": 9.826427117694435e-05,
      "loss": 0.0274,
      "step": 78860
    },
    {
      "epoch": 0.252416,
      "grad_norm": 0.10590792200145402,
      "learning_rate": 9.826339578785726e-05,
      "loss": 0.0317,
      "step": 78880
    },
    {
      "epoch": 0.25248,
      "grad_norm": 0.06164106718259327,
      "learning_rate": 9.826252018198228e-05,
      "loss": 0.0321,
      "step": 78900
    },
    {
      "epoch": 0.252544,
      "grad_norm": 0.06458212225610689,
      "learning_rate": 9.826164435932332e-05,
      "loss": 0.0342,
      "step": 78920
    },
    {
      "epoch": 0.252608,
      "grad_norm": 0.05582948480120334,
      "learning_rate": 9.826076831988432e-05,
      "loss": 0.0294,
      "step": 78940
    },
    {
      "epoch": 0.252672,
      "grad_norm": 0.10019100228415243,
      "learning_rate": 9.825989206366919e-05,
      "loss": 0.0278,
      "step": 78960
    },
    {
      "epoch": 0.252736,
      "grad_norm": 0.06861413856339732,
      "learning_rate": 9.82590155906819e-05,
      "loss": 0.0285,
      "step": 78980
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.07821143363812459,
      "learning_rate": 9.825813890092637e-05,
      "loss": 0.0327,
      "step": 79000
    },
    {
      "epoch": 0.252864,
      "grad_norm": 0.058331578974219166,
      "learning_rate": 9.825726199440656e-05,
      "loss": 0.0298,
      "step": 79020
    },
    {
      "epoch": 0.252928,
      "grad_norm": 0.09366912172003448,
      "learning_rate": 9.825638487112639e-05,
      "loss": 0.0266,
      "step": 79040
    },
    {
      "epoch": 0.252992,
      "grad_norm": 0.06255353050511842,
      "learning_rate": 9.825550753108979e-05,
      "loss": 0.0291,
      "step": 79060
    },
    {
      "epoch": 0.253056,
      "grad_norm": 0.0688141245874151,
      "learning_rate": 9.825462997430071e-05,
      "loss": 0.0339,
      "step": 79080
    },
    {
      "epoch": 0.25312,
      "grad_norm": 0.05495070999806289,
      "learning_rate": 9.82537522007631e-05,
      "loss": 0.0263,
      "step": 79100
    },
    {
      "epoch": 0.253184,
      "grad_norm": 0.08118166147858945,
      "learning_rate": 9.825287421048088e-05,
      "loss": 0.0285,
      "step": 79120
    },
    {
      "epoch": 0.253248,
      "grad_norm": 0.06552850220555453,
      "learning_rate": 9.825199600345802e-05,
      "loss": 0.0299,
      "step": 79140
    },
    {
      "epoch": 0.253312,
      "grad_norm": 0.13817780316877504,
      "learning_rate": 9.825111757969846e-05,
      "loss": 0.0314,
      "step": 79160
    },
    {
      "epoch": 0.253376,
      "grad_norm": 0.07176870823192916,
      "learning_rate": 9.825023893920614e-05,
      "loss": 0.0286,
      "step": 79180
    },
    {
      "epoch": 0.25344,
      "grad_norm": 0.056512643913864444,
      "learning_rate": 9.8249360081985e-05,
      "loss": 0.0288,
      "step": 79200
    },
    {
      "epoch": 0.253504,
      "grad_norm": 0.06100558479497491,
      "learning_rate": 9.824848100803901e-05,
      "loss": 0.0325,
      "step": 79220
    },
    {
      "epoch": 0.253568,
      "grad_norm": 0.05868749562230104,
      "learning_rate": 9.824760171737208e-05,
      "loss": 0.0302,
      "step": 79240
    },
    {
      "epoch": 0.253632,
      "grad_norm": 0.05669320044494591,
      "learning_rate": 9.82467222099882e-05,
      "loss": 0.0266,
      "step": 79260
    },
    {
      "epoch": 0.253696,
      "grad_norm": 0.056992850294694815,
      "learning_rate": 9.82458424858913e-05,
      "loss": 0.029,
      "step": 79280
    },
    {
      "epoch": 0.25376,
      "grad_norm": 0.05279529883271108,
      "learning_rate": 9.824496254508533e-05,
      "loss": 0.0326,
      "step": 79300
    },
    {
      "epoch": 0.253824,
      "grad_norm": 0.0681924422686678,
      "learning_rate": 9.824408238757426e-05,
      "loss": 0.0318,
      "step": 79320
    },
    {
      "epoch": 0.253888,
      "grad_norm": 0.11506294693731017,
      "learning_rate": 9.824320201336204e-05,
      "loss": 0.0312,
      "step": 79340
    },
    {
      "epoch": 0.253952,
      "grad_norm": 0.12897682111765474,
      "learning_rate": 9.824232142245259e-05,
      "loss": 0.0284,
      "step": 79360
    },
    {
      "epoch": 0.254016,
      "grad_norm": 0.06372258651627359,
      "learning_rate": 9.82414406148499e-05,
      "loss": 0.0303,
      "step": 79380
    },
    {
      "epoch": 0.25408,
      "grad_norm": 0.06616387326001123,
      "learning_rate": 9.824055959055791e-05,
      "loss": 0.0329,
      "step": 79400
    },
    {
      "epoch": 0.254144,
      "grad_norm": 0.07605244762096397,
      "learning_rate": 9.823967834958059e-05,
      "loss": 0.0306,
      "step": 79420
    },
    {
      "epoch": 0.254208,
      "grad_norm": 0.058875584959462234,
      "learning_rate": 9.82387968919219e-05,
      "loss": 0.0336,
      "step": 79440
    },
    {
      "epoch": 0.254272,
      "grad_norm": 0.07709415911169192,
      "learning_rate": 9.823791521758579e-05,
      "loss": 0.0306,
      "step": 79460
    },
    {
      "epoch": 0.254336,
      "grad_norm": 0.13684115385125947,
      "learning_rate": 9.823703332657621e-05,
      "loss": 0.0315,
      "step": 79480
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.10821203828357712,
      "learning_rate": 9.823615121889716e-05,
      "loss": 0.0296,
      "step": 79500
    },
    {
      "epoch": 0.254464,
      "grad_norm": 0.08244829791429087,
      "learning_rate": 9.823526889455255e-05,
      "loss": 0.0281,
      "step": 79520
    },
    {
      "epoch": 0.254528,
      "grad_norm": 0.07710309520883259,
      "learning_rate": 9.823438635354639e-05,
      "loss": 0.0303,
      "step": 79540
    },
    {
      "epoch": 0.254592,
      "grad_norm": 0.05271271298933364,
      "learning_rate": 9.82335035958826e-05,
      "loss": 0.0315,
      "step": 79560
    },
    {
      "epoch": 0.254656,
      "grad_norm": 0.05915432849330216,
      "learning_rate": 9.823262062156517e-05,
      "loss": 0.0322,
      "step": 79580
    },
    {
      "epoch": 0.25472,
      "grad_norm": 0.07801281949559437,
      "learning_rate": 9.823173743059809e-05,
      "loss": 0.0346,
      "step": 79600
    },
    {
      "epoch": 0.254784,
      "grad_norm": 0.07361694461158655,
      "learning_rate": 9.823085402298528e-05,
      "loss": 0.032,
      "step": 79620
    },
    {
      "epoch": 0.254848,
      "grad_norm": 0.0800530107945764,
      "learning_rate": 9.822997039873073e-05,
      "loss": 0.0332,
      "step": 79640
    },
    {
      "epoch": 0.254912,
      "grad_norm": 0.05549395167229514,
      "learning_rate": 9.822908655783841e-05,
      "loss": 0.0284,
      "step": 79660
    },
    {
      "epoch": 0.254976,
      "grad_norm": 0.054152509955608365,
      "learning_rate": 9.822820250031229e-05,
      "loss": 0.0314,
      "step": 79680
    },
    {
      "epoch": 0.25504,
      "grad_norm": 0.05952221985471428,
      "learning_rate": 9.822731822615634e-05,
      "loss": 0.0287,
      "step": 79700
    },
    {
      "epoch": 0.255104,
      "grad_norm": 0.059836099855398575,
      "learning_rate": 9.822643373537454e-05,
      "loss": 0.0295,
      "step": 79720
    },
    {
      "epoch": 0.255168,
      "grad_norm": 0.06715782651072263,
      "learning_rate": 9.822554902797085e-05,
      "loss": 0.0302,
      "step": 79740
    },
    {
      "epoch": 0.255232,
      "grad_norm": 0.07561743503481089,
      "learning_rate": 9.822466410394926e-05,
      "loss": 0.0292,
      "step": 79760
    },
    {
      "epoch": 0.255296,
      "grad_norm": 0.05845715434568501,
      "learning_rate": 9.82237789633137e-05,
      "loss": 0.0313,
      "step": 79780
    },
    {
      "epoch": 0.25536,
      "grad_norm": 0.13798946482568997,
      "learning_rate": 9.82228936060682e-05,
      "loss": 0.0304,
      "step": 79800
    },
    {
      "epoch": 0.255424,
      "grad_norm": 0.07440087246092897,
      "learning_rate": 9.822200803221673e-05,
      "loss": 0.0316,
      "step": 79820
    },
    {
      "epoch": 0.255488,
      "grad_norm": 0.058707283427543944,
      "learning_rate": 9.822112224176323e-05,
      "loss": 0.0311,
      "step": 79840
    },
    {
      "epoch": 0.255552,
      "grad_norm": 0.06006530261997314,
      "learning_rate": 9.822023623471172e-05,
      "loss": 0.0299,
      "step": 79860
    },
    {
      "epoch": 0.255616,
      "grad_norm": 0.10956573571804336,
      "learning_rate": 9.821935001106615e-05,
      "loss": 0.0293,
      "step": 79880
    },
    {
      "epoch": 0.25568,
      "grad_norm": 0.06294482674982198,
      "learning_rate": 9.821846357083051e-05,
      "loss": 0.034,
      "step": 79900
    },
    {
      "epoch": 0.255744,
      "grad_norm": 0.09169174510257477,
      "learning_rate": 9.821757691400879e-05,
      "loss": 0.0305,
      "step": 79920
    },
    {
      "epoch": 0.255808,
      "grad_norm": 0.0653400476858161,
      "learning_rate": 9.821669004060497e-05,
      "loss": 0.0323,
      "step": 79940
    },
    {
      "epoch": 0.255872,
      "grad_norm": 0.057565416350614775,
      "learning_rate": 9.821580295062303e-05,
      "loss": 0.0337,
      "step": 79960
    },
    {
      "epoch": 0.255936,
      "grad_norm": 0.04684698250802921,
      "learning_rate": 9.821491564406696e-05,
      "loss": 0.0275,
      "step": 79980
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.051481881448666805,
      "learning_rate": 9.821402812094073e-05,
      "loss": 0.0301,
      "step": 80000
    },
    {
      "epoch": 0.256064,
      "grad_norm": 0.10348352407832796,
      "learning_rate": 9.821314038124836e-05,
      "loss": 0.0303,
      "step": 80020
    },
    {
      "epoch": 0.256128,
      "grad_norm": 0.07998212865699095,
      "learning_rate": 9.821225242499379e-05,
      "loss": 0.0343,
      "step": 80040
    },
    {
      "epoch": 0.256192,
      "grad_norm": 0.05699575727399758,
      "learning_rate": 9.821136425218104e-05,
      "loss": 0.0317,
      "step": 80060
    },
    {
      "epoch": 0.256256,
      "grad_norm": 0.09179057759407547,
      "learning_rate": 9.821047586281412e-05,
      "loss": 0.0298,
      "step": 80080
    },
    {
      "epoch": 0.25632,
      "grad_norm": 0.0404718997503838,
      "learning_rate": 9.820958725689695e-05,
      "loss": 0.0292,
      "step": 80100
    },
    {
      "epoch": 0.256384,
      "grad_norm": 0.05867817751504825,
      "learning_rate": 9.820869843443358e-05,
      "loss": 0.0266,
      "step": 80120
    },
    {
      "epoch": 0.256448,
      "grad_norm": 0.05012720250689934,
      "learning_rate": 9.820780939542799e-05,
      "loss": 0.0293,
      "step": 80140
    },
    {
      "epoch": 0.256512,
      "grad_norm": 0.050060013154556236,
      "learning_rate": 9.820692013988418e-05,
      "loss": 0.032,
      "step": 80160
    },
    {
      "epoch": 0.256576,
      "grad_norm": 0.09957734596690702,
      "learning_rate": 9.820603066780613e-05,
      "loss": 0.028,
      "step": 80180
    },
    {
      "epoch": 0.25664,
      "grad_norm": 0.06763112401289502,
      "learning_rate": 9.820514097919784e-05,
      "loss": 0.0348,
      "step": 80200
    },
    {
      "epoch": 0.256704,
      "grad_norm": 0.06737574112005623,
      "learning_rate": 9.82042510740633e-05,
      "loss": 0.0332,
      "step": 80220
    },
    {
      "epoch": 0.256768,
      "grad_norm": 0.06701179871594416,
      "learning_rate": 9.820336095240652e-05,
      "loss": 0.0277,
      "step": 80240
    },
    {
      "epoch": 0.256832,
      "grad_norm": 0.14272412703173623,
      "learning_rate": 9.82024706142315e-05,
      "loss": 0.0295,
      "step": 80260
    },
    {
      "epoch": 0.256896,
      "grad_norm": 0.06712952188686684,
      "learning_rate": 9.820158005954223e-05,
      "loss": 0.029,
      "step": 80280
    },
    {
      "epoch": 0.25696,
      "grad_norm": 0.06127182934757832,
      "learning_rate": 9.82006892883427e-05,
      "loss": 0.0357,
      "step": 80300
    },
    {
      "epoch": 0.257024,
      "grad_norm": 0.07637282180157111,
      "learning_rate": 9.819979830063693e-05,
      "loss": 0.0306,
      "step": 80320
    },
    {
      "epoch": 0.257088,
      "grad_norm": 0.06050276703049385,
      "learning_rate": 9.81989070964289e-05,
      "loss": 0.0308,
      "step": 80340
    },
    {
      "epoch": 0.257152,
      "grad_norm": 0.16482091044791472,
      "learning_rate": 9.819801567572264e-05,
      "loss": 0.0319,
      "step": 80360
    },
    {
      "epoch": 0.257216,
      "grad_norm": 0.11106276428262839,
      "learning_rate": 9.819712403852215e-05,
      "loss": 0.0314,
      "step": 80380
    },
    {
      "epoch": 0.25728,
      "grad_norm": 0.07282805275781835,
      "learning_rate": 9.819623218483141e-05,
      "loss": 0.034,
      "step": 80400
    },
    {
      "epoch": 0.257344,
      "grad_norm": 0.05225038639125422,
      "learning_rate": 9.819534011465445e-05,
      "loss": 0.0276,
      "step": 80420
    },
    {
      "epoch": 0.257408,
      "grad_norm": 0.1945117131428148,
      "learning_rate": 9.819444782799527e-05,
      "loss": 0.0337,
      "step": 80440
    },
    {
      "epoch": 0.257472,
      "grad_norm": 0.11048494777938277,
      "learning_rate": 9.819355532485789e-05,
      "loss": 0.0332,
      "step": 80460
    },
    {
      "epoch": 0.257536,
      "grad_norm": 0.07946331243942782,
      "learning_rate": 9.819266260524629e-05,
      "loss": 0.0321,
      "step": 80480
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.04945339282303996,
      "learning_rate": 9.81917696691645e-05,
      "loss": 0.03,
      "step": 80500
    },
    {
      "epoch": 0.257664,
      "grad_norm": 0.05342191180754064,
      "learning_rate": 9.819087651661654e-05,
      "loss": 0.0345,
      "step": 80520
    },
    {
      "epoch": 0.257728,
      "grad_norm": 0.0857724606332447,
      "learning_rate": 9.81899831476064e-05,
      "loss": 0.0301,
      "step": 80540
    },
    {
      "epoch": 0.257792,
      "grad_norm": 0.04679502073647181,
      "learning_rate": 9.81890895621381e-05,
      "loss": 0.0281,
      "step": 80560
    },
    {
      "epoch": 0.257856,
      "grad_norm": 0.05525005697882699,
      "learning_rate": 9.818819576021566e-05,
      "loss": 0.0298,
      "step": 80580
    },
    {
      "epoch": 0.25792,
      "grad_norm": 0.0663905514849343,
      "learning_rate": 9.818730174184307e-05,
      "loss": 0.0329,
      "step": 80600
    },
    {
      "epoch": 0.257984,
      "grad_norm": 0.12153188529194182,
      "learning_rate": 9.818640750702439e-05,
      "loss": 0.0323,
      "step": 80620
    },
    {
      "epoch": 0.258048,
      "grad_norm": 0.0863666060499636,
      "learning_rate": 9.818551305576361e-05,
      "loss": 0.0292,
      "step": 80640
    },
    {
      "epoch": 0.258112,
      "grad_norm": 0.06580074043203675,
      "learning_rate": 9.818461838806475e-05,
      "loss": 0.0274,
      "step": 80660
    },
    {
      "epoch": 0.258176,
      "grad_norm": 0.08597577257820976,
      "learning_rate": 9.818372350393183e-05,
      "loss": 0.0286,
      "step": 80680
    },
    {
      "epoch": 0.25824,
      "grad_norm": 0.07692577917454702,
      "learning_rate": 9.818282840336887e-05,
      "loss": 0.0299,
      "step": 80700
    },
    {
      "epoch": 0.258304,
      "grad_norm": 0.051625804774256365,
      "learning_rate": 9.818193308637989e-05,
      "loss": 0.0307,
      "step": 80720
    },
    {
      "epoch": 0.258368,
      "grad_norm": 0.0941947497599387,
      "learning_rate": 9.81810375529689e-05,
      "loss": 0.0331,
      "step": 80740
    },
    {
      "epoch": 0.258432,
      "grad_norm": 0.062537354762688,
      "learning_rate": 9.818014180313995e-05,
      "loss": 0.0287,
      "step": 80760
    },
    {
      "epoch": 0.258496,
      "grad_norm": 0.10654082457070405,
      "learning_rate": 9.817924583689703e-05,
      "loss": 0.0321,
      "step": 80780
    },
    {
      "epoch": 0.25856,
      "grad_norm": 0.06335092396578564,
      "learning_rate": 9.817834965424418e-05,
      "loss": 0.0311,
      "step": 80800
    },
    {
      "epoch": 0.258624,
      "grad_norm": 0.0510586329974211,
      "learning_rate": 9.817745325518544e-05,
      "loss": 0.0304,
      "step": 80820
    },
    {
      "epoch": 0.258688,
      "grad_norm": 0.054574368054886954,
      "learning_rate": 9.817655663972482e-05,
      "loss": 0.0294,
      "step": 80840
    },
    {
      "epoch": 0.258752,
      "grad_norm": 0.053816337085745486,
      "learning_rate": 9.817565980786634e-05,
      "loss": 0.0287,
      "step": 80860
    },
    {
      "epoch": 0.258816,
      "grad_norm": 0.07031536363302589,
      "learning_rate": 9.817476275961405e-05,
      "loss": 0.0316,
      "step": 80880
    },
    {
      "epoch": 0.25888,
      "grad_norm": 0.056513539865396076,
      "learning_rate": 9.817386549497198e-05,
      "loss": 0.0316,
      "step": 80900
    },
    {
      "epoch": 0.258944,
      "grad_norm": 0.08594161849582678,
      "learning_rate": 9.817296801394413e-05,
      "loss": 0.0277,
      "step": 80920
    },
    {
      "epoch": 0.259008,
      "grad_norm": 0.06124775758700676,
      "learning_rate": 9.817207031653457e-05,
      "loss": 0.0298,
      "step": 80940
    },
    {
      "epoch": 0.259072,
      "grad_norm": 0.09469645615054358,
      "learning_rate": 9.817117240274729e-05,
      "loss": 0.0277,
      "step": 80960
    },
    {
      "epoch": 0.259136,
      "grad_norm": 0.05574095694641624,
      "learning_rate": 9.817027427258636e-05,
      "loss": 0.0298,
      "step": 80980
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.059973070323330366,
      "learning_rate": 9.816937592605579e-05,
      "loss": 0.0281,
      "step": 81000
    },
    {
      "epoch": 0.259264,
      "grad_norm": 0.10666801523911035,
      "learning_rate": 9.816847736315963e-05,
      "loss": 0.029,
      "step": 81020
    },
    {
      "epoch": 0.259328,
      "grad_norm": 0.06975186943306917,
      "learning_rate": 9.816757858390191e-05,
      "loss": 0.0316,
      "step": 81040
    },
    {
      "epoch": 0.259392,
      "grad_norm": 0.08111864832528527,
      "learning_rate": 9.816667958828667e-05,
      "loss": 0.0331,
      "step": 81060
    },
    {
      "epoch": 0.259456,
      "grad_norm": 0.04915575394458525,
      "learning_rate": 9.816578037631795e-05,
      "loss": 0.0308,
      "step": 81080
    },
    {
      "epoch": 0.25952,
      "grad_norm": 0.0731447427936237,
      "learning_rate": 9.816488094799979e-05,
      "loss": 0.0289,
      "step": 81100
    },
    {
      "epoch": 0.259584,
      "grad_norm": 0.08194905614355694,
      "learning_rate": 9.81639813033362e-05,
      "loss": 0.0286,
      "step": 81120
    },
    {
      "epoch": 0.259648,
      "grad_norm": 0.09500970904970563,
      "learning_rate": 9.816308144233127e-05,
      "loss": 0.0286,
      "step": 81140
    },
    {
      "epoch": 0.259712,
      "grad_norm": 0.06518560360686543,
      "learning_rate": 9.8162181364989e-05,
      "loss": 0.0285,
      "step": 81160
    },
    {
      "epoch": 0.259776,
      "grad_norm": 0.09664734863207758,
      "learning_rate": 9.816128107131347e-05,
      "loss": 0.029,
      "step": 81180
    },
    {
      "epoch": 0.25984,
      "grad_norm": 0.09088977944237343,
      "learning_rate": 9.81603805613087e-05,
      "loss": 0.0286,
      "step": 81200
    },
    {
      "epoch": 0.259904,
      "grad_norm": 0.11827952083425156,
      "learning_rate": 9.815947983497872e-05,
      "loss": 0.0305,
      "step": 81220
    },
    {
      "epoch": 0.259968,
      "grad_norm": 0.06716928447437376,
      "learning_rate": 9.815857889232762e-05,
      "loss": 0.0325,
      "step": 81240
    },
    {
      "epoch": 0.260032,
      "grad_norm": 0.15848059358519304,
      "learning_rate": 9.815767773335943e-05,
      "loss": 0.0311,
      "step": 81260
    },
    {
      "epoch": 0.260096,
      "grad_norm": 0.08449594589566033,
      "learning_rate": 9.815677635807817e-05,
      "loss": 0.0305,
      "step": 81280
    },
    {
      "epoch": 0.26016,
      "grad_norm": 0.08708967121740034,
      "learning_rate": 9.815587476648791e-05,
      "loss": 0.0298,
      "step": 81300
    },
    {
      "epoch": 0.260224,
      "grad_norm": 0.11327293866982925,
      "learning_rate": 9.81549729585927e-05,
      "loss": 0.0318,
      "step": 81320
    },
    {
      "epoch": 0.260288,
      "grad_norm": 0.07392135189078142,
      "learning_rate": 9.815407093439662e-05,
      "loss": 0.0297,
      "step": 81340
    },
    {
      "epoch": 0.260352,
      "grad_norm": 0.06756293763526075,
      "learning_rate": 9.815316869390365e-05,
      "loss": 0.0299,
      "step": 81360
    },
    {
      "epoch": 0.260416,
      "grad_norm": 0.07012657181568799,
      "learning_rate": 9.81522662371179e-05,
      "loss": 0.0277,
      "step": 81380
    },
    {
      "epoch": 0.26048,
      "grad_norm": 0.08621584889473753,
      "learning_rate": 9.81513635640434e-05,
      "loss": 0.03,
      "step": 81400
    },
    {
      "epoch": 0.260544,
      "grad_norm": 0.05720849290507598,
      "learning_rate": 9.815046067468423e-05,
      "loss": 0.0306,
      "step": 81420
    },
    {
      "epoch": 0.260608,
      "grad_norm": 0.10446105306100466,
      "learning_rate": 9.814955756904441e-05,
      "loss": 0.0301,
      "step": 81440
    },
    {
      "epoch": 0.260672,
      "grad_norm": 0.2408105831405315,
      "learning_rate": 9.814865424712803e-05,
      "loss": 0.0261,
      "step": 81460
    },
    {
      "epoch": 0.260736,
      "grad_norm": 0.09839830869178157,
      "learning_rate": 9.814775070893913e-05,
      "loss": 0.0286,
      "step": 81480
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.0697326903528802,
      "learning_rate": 9.814684695448175e-05,
      "loss": 0.0286,
      "step": 81500
    },
    {
      "epoch": 0.260864,
      "grad_norm": 0.09794311869679777,
      "learning_rate": 9.814594298375998e-05,
      "loss": 0.0276,
      "step": 81520
    },
    {
      "epoch": 0.260928,
      "grad_norm": 0.09780757500744494,
      "learning_rate": 9.814503879677787e-05,
      "loss": 0.0305,
      "step": 81540
    },
    {
      "epoch": 0.260992,
      "grad_norm": 0.1197732211908016,
      "learning_rate": 9.81441343935395e-05,
      "loss": 0.028,
      "step": 81560
    },
    {
      "epoch": 0.261056,
      "grad_norm": 0.081949988141081,
      "learning_rate": 9.814322977404891e-05,
      "loss": 0.0313,
      "step": 81580
    },
    {
      "epoch": 0.26112,
      "grad_norm": 0.06800502240732292,
      "learning_rate": 9.814232493831014e-05,
      "loss": 0.0304,
      "step": 81600
    },
    {
      "epoch": 0.261184,
      "grad_norm": 0.06035202843635463,
      "learning_rate": 9.814141988632731e-05,
      "loss": 0.0312,
      "step": 81620
    },
    {
      "epoch": 0.261248,
      "grad_norm": 0.060216976246327776,
      "learning_rate": 9.814051461810444e-05,
      "loss": 0.0312,
      "step": 81640
    },
    {
      "epoch": 0.261312,
      "grad_norm": 0.06026072292505581,
      "learning_rate": 9.813960913364561e-05,
      "loss": 0.0342,
      "step": 81660
    },
    {
      "epoch": 0.261376,
      "grad_norm": 0.06469011581823055,
      "learning_rate": 9.81387034329549e-05,
      "loss": 0.0336,
      "step": 81680
    },
    {
      "epoch": 0.26144,
      "grad_norm": 0.05568897461195142,
      "learning_rate": 9.813779751603638e-05,
      "loss": 0.0323,
      "step": 81700
    },
    {
      "epoch": 0.261504,
      "grad_norm": 0.09271259854842587,
      "learning_rate": 9.813689138289409e-05,
      "loss": 0.0292,
      "step": 81720
    },
    {
      "epoch": 0.261568,
      "grad_norm": 0.04448803758439845,
      "learning_rate": 9.813598503353213e-05,
      "loss": 0.0296,
      "step": 81740
    },
    {
      "epoch": 0.261632,
      "grad_norm": 0.0700163238975115,
      "learning_rate": 9.813507846795455e-05,
      "loss": 0.0313,
      "step": 81760
    },
    {
      "epoch": 0.261696,
      "grad_norm": 0.10372909526588295,
      "learning_rate": 9.813417168616543e-05,
      "loss": 0.0288,
      "step": 81780
    },
    {
      "epoch": 0.26176,
      "grad_norm": 0.0689318972573089,
      "learning_rate": 9.813326468816886e-05,
      "loss": 0.0283,
      "step": 81800
    },
    {
      "epoch": 0.261824,
      "grad_norm": 0.05376779469467516,
      "learning_rate": 9.813235747396887e-05,
      "loss": 0.0293,
      "step": 81820
    },
    {
      "epoch": 0.261888,
      "grad_norm": 0.04745857654412596,
      "learning_rate": 9.813145004356959e-05,
      "loss": 0.0289,
      "step": 81840
    },
    {
      "epoch": 0.261952,
      "grad_norm": 0.10358046582279584,
      "learning_rate": 9.813054239697506e-05,
      "loss": 0.0279,
      "step": 81860
    },
    {
      "epoch": 0.262016,
      "grad_norm": 0.11327081371182941,
      "learning_rate": 9.812963453418935e-05,
      "loss": 0.0314,
      "step": 81880
    },
    {
      "epoch": 0.26208,
      "grad_norm": 0.06805392779208723,
      "learning_rate": 9.812872645521659e-05,
      "loss": 0.0318,
      "step": 81900
    },
    {
      "epoch": 0.262144,
      "grad_norm": 0.08826098576115303,
      "learning_rate": 9.81278181600608e-05,
      "loss": 0.0298,
      "step": 81920
    },
    {
      "epoch": 0.262208,
      "grad_norm": 0.0743733919726987,
      "learning_rate": 9.812690964872607e-05,
      "loss": 0.0313,
      "step": 81940
    },
    {
      "epoch": 0.262272,
      "grad_norm": 0.08141661011693588,
      "learning_rate": 9.812600092121651e-05,
      "loss": 0.0267,
      "step": 81960
    },
    {
      "epoch": 0.262336,
      "grad_norm": 0.05339682099320481,
      "learning_rate": 9.812509197753618e-05,
      "loss": 0.029,
      "step": 81980
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.06527011641043304,
      "learning_rate": 9.812418281768918e-05,
      "loss": 0.0291,
      "step": 82000
    },
    {
      "epoch": 0.262464,
      "grad_norm": 0.10724814188083759,
      "learning_rate": 9.812327344167957e-05,
      "loss": 0.0329,
      "step": 82020
    },
    {
      "epoch": 0.262528,
      "grad_norm": 0.09267235220214855,
      "learning_rate": 9.812236384951145e-05,
      "loss": 0.0309,
      "step": 82040
    },
    {
      "epoch": 0.262592,
      "grad_norm": 0.0787347844346524,
      "learning_rate": 9.81214540411889e-05,
      "loss": 0.0335,
      "step": 82060
    },
    {
      "epoch": 0.262656,
      "grad_norm": 0.06652226314305634,
      "learning_rate": 9.812054401671601e-05,
      "loss": 0.0306,
      "step": 82080
    },
    {
      "epoch": 0.26272,
      "grad_norm": 0.11702629384103384,
      "learning_rate": 9.811963377609687e-05,
      "loss": 0.0312,
      "step": 82100
    },
    {
      "epoch": 0.262784,
      "grad_norm": 0.09740386779261498,
      "learning_rate": 9.811872331933556e-05,
      "loss": 0.0316,
      "step": 82120
    },
    {
      "epoch": 0.262848,
      "grad_norm": 0.08625983478789148,
      "learning_rate": 9.811781264643618e-05,
      "loss": 0.031,
      "step": 82140
    },
    {
      "epoch": 0.262912,
      "grad_norm": 0.08435834094911722,
      "learning_rate": 9.81169017574028e-05,
      "loss": 0.0293,
      "step": 82160
    },
    {
      "epoch": 0.262976,
      "grad_norm": 0.054182967548826455,
      "learning_rate": 9.811599065223955e-05,
      "loss": 0.0309,
      "step": 82180
    },
    {
      "epoch": 0.26304,
      "grad_norm": 0.09404408733885183,
      "learning_rate": 9.811507933095049e-05,
      "loss": 0.0297,
      "step": 82200
    },
    {
      "epoch": 0.263104,
      "grad_norm": 0.07798906024146565,
      "learning_rate": 9.811416779353973e-05,
      "loss": 0.0282,
      "step": 82220
    },
    {
      "epoch": 0.263168,
      "grad_norm": 0.05644303330300428,
      "learning_rate": 9.811325604001134e-05,
      "loss": 0.0295,
      "step": 82240
    },
    {
      "epoch": 0.263232,
      "grad_norm": 0.08238391090596367,
      "learning_rate": 9.811234407036943e-05,
      "loss": 0.0293,
      "step": 82260
    },
    {
      "epoch": 0.263296,
      "grad_norm": 0.1043279599805744,
      "learning_rate": 9.811143188461811e-05,
      "loss": 0.0287,
      "step": 82280
    },
    {
      "epoch": 0.26336,
      "grad_norm": 0.12285385131147136,
      "learning_rate": 9.811051948276146e-05,
      "loss": 0.0325,
      "step": 82300
    },
    {
      "epoch": 0.263424,
      "grad_norm": 0.05591431016466163,
      "learning_rate": 9.81096068648036e-05,
      "loss": 0.0352,
      "step": 82320
    },
    {
      "epoch": 0.263488,
      "grad_norm": 0.15812167649990463,
      "learning_rate": 9.81086940307486e-05,
      "loss": 0.0331,
      "step": 82340
    },
    {
      "epoch": 0.263552,
      "grad_norm": 0.0860341796119538,
      "learning_rate": 9.810778098060057e-05,
      "loss": 0.0315,
      "step": 82360
    },
    {
      "epoch": 0.263616,
      "grad_norm": 0.04860840060452707,
      "learning_rate": 9.810686771436363e-05,
      "loss": 0.0298,
      "step": 82380
    },
    {
      "epoch": 0.26368,
      "grad_norm": 0.08782150963846318,
      "learning_rate": 9.810595423204185e-05,
      "loss": 0.0299,
      "step": 82400
    },
    {
      "epoch": 0.263744,
      "grad_norm": 0.06470179903630253,
      "learning_rate": 9.810504053363936e-05,
      "loss": 0.0316,
      "step": 82420
    },
    {
      "epoch": 0.263808,
      "grad_norm": 0.04362726244937285,
      "learning_rate": 9.810412661916026e-05,
      "loss": 0.0296,
      "step": 82440
    },
    {
      "epoch": 0.263872,
      "grad_norm": 0.05823542292676939,
      "learning_rate": 9.810321248860864e-05,
      "loss": 0.0286,
      "step": 82460
    },
    {
      "epoch": 0.263936,
      "grad_norm": 0.052556805970796185,
      "learning_rate": 9.810229814198861e-05,
      "loss": 0.0287,
      "step": 82480
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.05246565378324967,
      "learning_rate": 9.81013835793043e-05,
      "loss": 0.0278,
      "step": 82500
    },
    {
      "epoch": 0.264064,
      "grad_norm": 0.05098062108331092,
      "learning_rate": 9.810046880055979e-05,
      "loss": 0.0281,
      "step": 82520
    },
    {
      "epoch": 0.264128,
      "grad_norm": 0.06358754218972872,
      "learning_rate": 9.809955380575921e-05,
      "loss": 0.0298,
      "step": 82540
    },
    {
      "epoch": 0.264192,
      "grad_norm": 0.053068448530542565,
      "learning_rate": 9.809863859490665e-05,
      "loss": 0.0314,
      "step": 82560
    },
    {
      "epoch": 0.264256,
      "grad_norm": 0.08909274805819939,
      "learning_rate": 9.809772316800622e-05,
      "loss": 0.0282,
      "step": 82580
    },
    {
      "epoch": 0.26432,
      "grad_norm": 0.0533745311320274,
      "learning_rate": 9.809680752506207e-05,
      "loss": 0.031,
      "step": 82600
    },
    {
      "epoch": 0.264384,
      "grad_norm": 0.05552295021353528,
      "learning_rate": 9.809589166607827e-05,
      "loss": 0.0303,
      "step": 82620
    },
    {
      "epoch": 0.264448,
      "grad_norm": 0.07063557717636143,
      "learning_rate": 9.809497559105893e-05,
      "loss": 0.0307,
      "step": 82640
    },
    {
      "epoch": 0.264512,
      "grad_norm": 0.08525692346644853,
      "learning_rate": 9.809405930000821e-05,
      "loss": 0.0302,
      "step": 82660
    },
    {
      "epoch": 0.264576,
      "grad_norm": 0.06904069494601878,
      "learning_rate": 9.809314279293019e-05,
      "loss": 0.0299,
      "step": 82680
    },
    {
      "epoch": 0.26464,
      "grad_norm": 0.07834860143495333,
      "learning_rate": 9.809222606982899e-05,
      "loss": 0.0327,
      "step": 82700
    },
    {
      "epoch": 0.264704,
      "grad_norm": 0.048476885117785806,
      "learning_rate": 9.809130913070875e-05,
      "loss": 0.0287,
      "step": 82720
    },
    {
      "epoch": 0.264768,
      "grad_norm": 0.07594934709559249,
      "learning_rate": 9.809039197557357e-05,
      "loss": 0.0328,
      "step": 82740
    },
    {
      "epoch": 0.264832,
      "grad_norm": 0.05329317919173235,
      "learning_rate": 9.808947460442757e-05,
      "loss": 0.0275,
      "step": 82760
    },
    {
      "epoch": 0.264896,
      "grad_norm": 0.048546923206690254,
      "learning_rate": 9.808855701727486e-05,
      "loss": 0.026,
      "step": 82780
    },
    {
      "epoch": 0.26496,
      "grad_norm": 0.08896429148318381,
      "learning_rate": 9.80876392141196e-05,
      "loss": 0.0332,
      "step": 82800
    },
    {
      "epoch": 0.265024,
      "grad_norm": 0.09207320437853551,
      "learning_rate": 9.808672119496587e-05,
      "loss": 0.0324,
      "step": 82820
    },
    {
      "epoch": 0.265088,
      "grad_norm": 0.07183155953399545,
      "learning_rate": 9.808580295981782e-05,
      "loss": 0.0278,
      "step": 82840
    },
    {
      "epoch": 0.265152,
      "grad_norm": 0.054770862998715815,
      "learning_rate": 9.808488450867955e-05,
      "loss": 0.0286,
      "step": 82860
    },
    {
      "epoch": 0.265216,
      "grad_norm": 0.10969675561424654,
      "learning_rate": 9.808396584155521e-05,
      "loss": 0.0279,
      "step": 82880
    },
    {
      "epoch": 0.26528,
      "grad_norm": 0.044993427871510186,
      "learning_rate": 9.808304695844892e-05,
      "loss": 0.0261,
      "step": 82900
    },
    {
      "epoch": 0.265344,
      "grad_norm": 0.13350018965163324,
      "learning_rate": 9.808212785936479e-05,
      "loss": 0.0278,
      "step": 82920
    },
    {
      "epoch": 0.265408,
      "grad_norm": 0.0962440979448633,
      "learning_rate": 9.808120854430698e-05,
      "loss": 0.0303,
      "step": 82940
    },
    {
      "epoch": 0.265472,
      "grad_norm": 0.07901939686419454,
      "learning_rate": 9.808028901327959e-05,
      "loss": 0.0298,
      "step": 82960
    },
    {
      "epoch": 0.265536,
      "grad_norm": 0.056455710362152016,
      "learning_rate": 9.807936926628679e-05,
      "loss": 0.0356,
      "step": 82980
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.0799307569450036,
      "learning_rate": 9.807844930333265e-05,
      "loss": 0.0334,
      "step": 83000
    },
    {
      "epoch": 0.265664,
      "grad_norm": 0.08242803749427387,
      "learning_rate": 9.807752912442134e-05,
      "loss": 0.0314,
      "step": 83020
    },
    {
      "epoch": 0.265728,
      "grad_norm": 0.20927871116377614,
      "learning_rate": 9.8076608729557e-05,
      "loss": 0.0292,
      "step": 83040
    },
    {
      "epoch": 0.265792,
      "grad_norm": 0.0539293873528177,
      "learning_rate": 9.807568811874375e-05,
      "loss": 0.0295,
      "step": 83060
    },
    {
      "epoch": 0.265856,
      "grad_norm": 0.08907445720381324,
      "learning_rate": 9.807476729198574e-05,
      "loss": 0.026,
      "step": 83080
    },
    {
      "epoch": 0.26592,
      "grad_norm": 0.05382542527044014,
      "learning_rate": 9.807384624928708e-05,
      "loss": 0.0289,
      "step": 83100
    },
    {
      "epoch": 0.265984,
      "grad_norm": 0.061018822787795975,
      "learning_rate": 9.807292499065192e-05,
      "loss": 0.0307,
      "step": 83120
    },
    {
      "epoch": 0.266048,
      "grad_norm": 0.05502075686613906,
      "learning_rate": 9.807200351608442e-05,
      "loss": 0.0289,
      "step": 83140
    },
    {
      "epoch": 0.266112,
      "grad_norm": 0.059400822046276024,
      "learning_rate": 9.807108182558868e-05,
      "loss": 0.0264,
      "step": 83160
    },
    {
      "epoch": 0.266176,
      "grad_norm": 0.056793519015407815,
      "learning_rate": 9.807015991916886e-05,
      "loss": 0.0287,
      "step": 83180
    },
    {
      "epoch": 0.26624,
      "grad_norm": 0.08116013394870043,
      "learning_rate": 9.80692377968291e-05,
      "loss": 0.0292,
      "step": 83200
    },
    {
      "epoch": 0.266304,
      "grad_norm": 0.12305114272001146,
      "learning_rate": 9.806831545857355e-05,
      "loss": 0.0306,
      "step": 83220
    },
    {
      "epoch": 0.266368,
      "grad_norm": 0.08576420917547242,
      "learning_rate": 9.806739290440634e-05,
      "loss": 0.0311,
      "step": 83240
    },
    {
      "epoch": 0.266432,
      "grad_norm": 0.06050547962807207,
      "learning_rate": 9.806647013433163e-05,
      "loss": 0.0287,
      "step": 83260
    },
    {
      "epoch": 0.266496,
      "grad_norm": 0.06380217200415908,
      "learning_rate": 9.806554714835354e-05,
      "loss": 0.0303,
      "step": 83280
    },
    {
      "epoch": 0.26656,
      "grad_norm": 0.05784158302046477,
      "learning_rate": 9.806462394647625e-05,
      "loss": 0.0306,
      "step": 83300
    },
    {
      "epoch": 0.266624,
      "grad_norm": 0.0821086176670607,
      "learning_rate": 9.806370052870387e-05,
      "loss": 0.0322,
      "step": 83320
    },
    {
      "epoch": 0.266688,
      "grad_norm": 0.12418416797770163,
      "learning_rate": 9.806277689504055e-05,
      "loss": 0.0325,
      "step": 83340
    },
    {
      "epoch": 0.266752,
      "grad_norm": 0.0795882345431432,
      "learning_rate": 9.806185304549047e-05,
      "loss": 0.0298,
      "step": 83360
    },
    {
      "epoch": 0.266816,
      "grad_norm": 0.05904477827471279,
      "learning_rate": 9.806092898005776e-05,
      "loss": 0.0315,
      "step": 83380
    },
    {
      "epoch": 0.26688,
      "grad_norm": 0.05886312890314173,
      "learning_rate": 9.806000469874658e-05,
      "loss": 0.0297,
      "step": 83400
    },
    {
      "epoch": 0.266944,
      "grad_norm": 0.11337657251818192,
      "learning_rate": 9.805908020156107e-05,
      "loss": 0.03,
      "step": 83420
    },
    {
      "epoch": 0.267008,
      "grad_norm": 0.13213416437650924,
      "learning_rate": 9.805815548850539e-05,
      "loss": 0.031,
      "step": 83440
    },
    {
      "epoch": 0.267072,
      "grad_norm": 0.14603095590654483,
      "learning_rate": 9.805723055958369e-05,
      "loss": 0.0318,
      "step": 83460
    },
    {
      "epoch": 0.267136,
      "grad_norm": 0.05654691084481549,
      "learning_rate": 9.805630541480011e-05,
      "loss": 0.0265,
      "step": 83480
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.05286593249076137,
      "learning_rate": 9.805538005415883e-05,
      "loss": 0.0272,
      "step": 83500
    },
    {
      "epoch": 0.267264,
      "grad_norm": 0.11100359696754704,
      "learning_rate": 9.805445447766402e-05,
      "loss": 0.0305,
      "step": 83520
    },
    {
      "epoch": 0.267328,
      "grad_norm": 0.1095437781787013,
      "learning_rate": 9.805352868531978e-05,
      "loss": 0.0317,
      "step": 83540
    },
    {
      "epoch": 0.267392,
      "grad_norm": 0.11758156960394733,
      "learning_rate": 9.805260267713032e-05,
      "loss": 0.0327,
      "step": 83560
    },
    {
      "epoch": 0.267456,
      "grad_norm": 0.06142819496947849,
      "learning_rate": 9.80516764530998e-05,
      "loss": 0.0306,
      "step": 83580
    },
    {
      "epoch": 0.26752,
      "grad_norm": 0.08461361778639025,
      "learning_rate": 9.805075001323235e-05,
      "loss": 0.0337,
      "step": 83600
    },
    {
      "epoch": 0.267584,
      "grad_norm": 0.11341523994067702,
      "learning_rate": 9.804982335753213e-05,
      "loss": 0.0318,
      "step": 83620
    },
    {
      "epoch": 0.267648,
      "grad_norm": 0.17135941316363298,
      "learning_rate": 9.804889648600333e-05,
      "loss": 0.0315,
      "step": 83640
    },
    {
      "epoch": 0.267712,
      "grad_norm": 0.05719203022538088,
      "learning_rate": 9.80479693986501e-05,
      "loss": 0.0319,
      "step": 83660
    },
    {
      "epoch": 0.267776,
      "grad_norm": 0.06846239563936252,
      "learning_rate": 9.804704209547662e-05,
      "loss": 0.0302,
      "step": 83680
    },
    {
      "epoch": 0.26784,
      "grad_norm": 0.060188672940843686,
      "learning_rate": 9.804611457648701e-05,
      "loss": 0.0321,
      "step": 83700
    },
    {
      "epoch": 0.267904,
      "grad_norm": 0.07048526257122847,
      "learning_rate": 9.804518684168549e-05,
      "loss": 0.0296,
      "step": 83720
    },
    {
      "epoch": 0.267968,
      "grad_norm": 0.08617592330735553,
      "learning_rate": 9.804425889107619e-05,
      "loss": 0.0302,
      "step": 83740
    },
    {
      "epoch": 0.268032,
      "grad_norm": 0.10785136787932685,
      "learning_rate": 9.80433307246633e-05,
      "loss": 0.03,
      "step": 83760
    },
    {
      "epoch": 0.268096,
      "grad_norm": 0.04709386912577561,
      "learning_rate": 9.804240234245096e-05,
      "loss": 0.0311,
      "step": 83780
    },
    {
      "epoch": 0.26816,
      "grad_norm": 0.07624198765432086,
      "learning_rate": 9.804147374444339e-05,
      "loss": 0.027,
      "step": 83800
    },
    {
      "epoch": 0.268224,
      "grad_norm": 0.05659355702614735,
      "learning_rate": 9.804054493064472e-05,
      "loss": 0.0285,
      "step": 83820
    },
    {
      "epoch": 0.268288,
      "grad_norm": 0.09442541728789391,
      "learning_rate": 9.803961590105913e-05,
      "loss": 0.0326,
      "step": 83840
    },
    {
      "epoch": 0.268352,
      "grad_norm": 0.08145683024820768,
      "learning_rate": 9.80386866556908e-05,
      "loss": 0.0288,
      "step": 83860
    },
    {
      "epoch": 0.268416,
      "grad_norm": 0.06367600734575908,
      "learning_rate": 9.80377571945439e-05,
      "loss": 0.0273,
      "step": 83880
    },
    {
      "epoch": 0.26848,
      "grad_norm": 0.14422940249471647,
      "learning_rate": 9.80368275176226e-05,
      "loss": 0.0292,
      "step": 83900
    },
    {
      "epoch": 0.268544,
      "grad_norm": 0.07948842822171882,
      "learning_rate": 9.80358976249311e-05,
      "loss": 0.0315,
      "step": 83920
    },
    {
      "epoch": 0.268608,
      "grad_norm": 0.04827399032183594,
      "learning_rate": 9.803496751647354e-05,
      "loss": 0.0299,
      "step": 83940
    },
    {
      "epoch": 0.268672,
      "grad_norm": 0.07905905307559835,
      "learning_rate": 9.803403719225412e-05,
      "loss": 0.028,
      "step": 83960
    },
    {
      "epoch": 0.268736,
      "grad_norm": 0.06400415304780636,
      "learning_rate": 9.803310665227702e-05,
      "loss": 0.0273,
      "step": 83980
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.08879650397370734,
      "learning_rate": 9.80321758965464e-05,
      "loss": 0.0301,
      "step": 84000
    },
    {
      "epoch": 0.268864,
      "grad_norm": 0.05051466954464443,
      "learning_rate": 9.803124492506649e-05,
      "loss": 0.0297,
      "step": 84020
    },
    {
      "epoch": 0.268928,
      "grad_norm": 0.08875681379309433,
      "learning_rate": 9.803031373784139e-05,
      "loss": 0.0312,
      "step": 84040
    },
    {
      "epoch": 0.268992,
      "grad_norm": 0.04905621779177208,
      "learning_rate": 9.802938233487537e-05,
      "loss": 0.0312,
      "step": 84060
    },
    {
      "epoch": 0.269056,
      "grad_norm": 0.061605606064430204,
      "learning_rate": 9.802845071617255e-05,
      "loss": 0.0323,
      "step": 84080
    },
    {
      "epoch": 0.26912,
      "grad_norm": 0.13002920965100176,
      "learning_rate": 9.802751888173714e-05,
      "loss": 0.0323,
      "step": 84100
    },
    {
      "epoch": 0.269184,
      "grad_norm": 0.12527330086309482,
      "learning_rate": 9.802658683157332e-05,
      "loss": 0.0342,
      "step": 84120
    },
    {
      "epoch": 0.269248,
      "grad_norm": 0.05306600849477869,
      "learning_rate": 9.802565456568532e-05,
      "loss": 0.0288,
      "step": 84140
    },
    {
      "epoch": 0.269312,
      "grad_norm": 0.08326756145931723,
      "learning_rate": 9.802472208407725e-05,
      "loss": 0.0317,
      "step": 84160
    },
    {
      "epoch": 0.269376,
      "grad_norm": 0.05991642605912518,
      "learning_rate": 9.802378938675334e-05,
      "loss": 0.029,
      "step": 84180
    },
    {
      "epoch": 0.26944,
      "grad_norm": 0.06939870452093788,
      "learning_rate": 9.802285647371777e-05,
      "loss": 0.0318,
      "step": 84200
    },
    {
      "epoch": 0.269504,
      "grad_norm": 0.08732350545099776,
      "learning_rate": 9.802192334497475e-05,
      "loss": 0.0313,
      "step": 84220
    },
    {
      "epoch": 0.269568,
      "grad_norm": 0.06525631033888081,
      "learning_rate": 9.802099000052844e-05,
      "loss": 0.0292,
      "step": 84240
    },
    {
      "epoch": 0.269632,
      "grad_norm": 0.05811240368582541,
      "learning_rate": 9.802005644038307e-05,
      "loss": 0.0295,
      "step": 84260
    },
    {
      "epoch": 0.269696,
      "grad_norm": 0.05498861911976698,
      "learning_rate": 9.80191226645428e-05,
      "loss": 0.0297,
      "step": 84280
    },
    {
      "epoch": 0.26976,
      "grad_norm": 0.05978738507642877,
      "learning_rate": 9.801818867301185e-05,
      "loss": 0.0323,
      "step": 84300
    },
    {
      "epoch": 0.269824,
      "grad_norm": 0.06846160899227903,
      "learning_rate": 9.801725446579439e-05,
      "loss": 0.0285,
      "step": 84320
    },
    {
      "epoch": 0.269888,
      "grad_norm": 0.07560469691925452,
      "learning_rate": 9.801632004289464e-05,
      "loss": 0.0323,
      "step": 84340
    },
    {
      "epoch": 0.269952,
      "grad_norm": 0.05342238755106254,
      "learning_rate": 9.801538540431678e-05,
      "loss": 0.0333,
      "step": 84360
    },
    {
      "epoch": 0.270016,
      "grad_norm": 0.07723935859970293,
      "learning_rate": 9.801445055006502e-05,
      "loss": 0.0296,
      "step": 84380
    },
    {
      "epoch": 0.27008,
      "grad_norm": 0.08018040919385412,
      "learning_rate": 9.801351548014355e-05,
      "loss": 0.0298,
      "step": 84400
    },
    {
      "epoch": 0.270144,
      "grad_norm": 0.24518639464800812,
      "learning_rate": 9.801258019455657e-05,
      "loss": 0.0303,
      "step": 84420
    },
    {
      "epoch": 0.270208,
      "grad_norm": 0.07175643329712977,
      "learning_rate": 9.801164469330828e-05,
      "loss": 0.0307,
      "step": 84440
    },
    {
      "epoch": 0.270272,
      "grad_norm": 0.06497103123223065,
      "learning_rate": 9.80107089764029e-05,
      "loss": 0.0309,
      "step": 84460
    },
    {
      "epoch": 0.270336,
      "grad_norm": 0.07397703204474573,
      "learning_rate": 9.800977304384463e-05,
      "loss": 0.0291,
      "step": 84480
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.08838116531025192,
      "learning_rate": 9.800883689563763e-05,
      "loss": 0.0324,
      "step": 84500
    },
    {
      "epoch": 0.270464,
      "grad_norm": 0.0878010237333341,
      "learning_rate": 9.800790053178617e-05,
      "loss": 0.0304,
      "step": 84520
    },
    {
      "epoch": 0.270528,
      "grad_norm": 0.060596572739442287,
      "learning_rate": 9.80069639522944e-05,
      "loss": 0.031,
      "step": 84540
    },
    {
      "epoch": 0.270592,
      "grad_norm": 0.08069378972392388,
      "learning_rate": 9.800602715716657e-05,
      "loss": 0.0318,
      "step": 84560
    },
    {
      "epoch": 0.270656,
      "grad_norm": 0.09604190548341528,
      "learning_rate": 9.800509014640687e-05,
      "loss": 0.0278,
      "step": 84580
    },
    {
      "epoch": 0.27072,
      "grad_norm": 0.05566169449220183,
      "learning_rate": 9.80041529200195e-05,
      "loss": 0.0268,
      "step": 84600
    },
    {
      "epoch": 0.270784,
      "grad_norm": 0.05497926504454757,
      "learning_rate": 9.800321547800868e-05,
      "loss": 0.0315,
      "step": 84620
    },
    {
      "epoch": 0.270848,
      "grad_norm": 0.09314957843132894,
      "learning_rate": 9.80022778203786e-05,
      "loss": 0.0323,
      "step": 84640
    },
    {
      "epoch": 0.270912,
      "grad_norm": 0.041308005308699346,
      "learning_rate": 9.800133994713353e-05,
      "loss": 0.0274,
      "step": 84660
    },
    {
      "epoch": 0.270976,
      "grad_norm": 0.1677917064111496,
      "learning_rate": 9.800040185827761e-05,
      "loss": 0.0324,
      "step": 84680
    },
    {
      "epoch": 0.27104,
      "grad_norm": 0.06273966244738766,
      "learning_rate": 9.799946355381509e-05,
      "loss": 0.0302,
      "step": 84700
    },
    {
      "epoch": 0.271104,
      "grad_norm": 0.06352611855355872,
      "learning_rate": 9.799852503375019e-05,
      "loss": 0.0273,
      "step": 84720
    },
    {
      "epoch": 0.271168,
      "grad_norm": 0.09325996628082922,
      "learning_rate": 9.799758629808712e-05,
      "loss": 0.0297,
      "step": 84740
    },
    {
      "epoch": 0.271232,
      "grad_norm": 0.0786642599073224,
      "learning_rate": 9.79966473468301e-05,
      "loss": 0.0292,
      "step": 84760
    },
    {
      "epoch": 0.271296,
      "grad_norm": 0.06626413740482451,
      "learning_rate": 9.799570817998334e-05,
      "loss": 0.0304,
      "step": 84780
    },
    {
      "epoch": 0.27136,
      "grad_norm": 0.08519917166108687,
      "learning_rate": 9.799476879755105e-05,
      "loss": 0.0293,
      "step": 84800
    },
    {
      "epoch": 0.271424,
      "grad_norm": 0.06089092400708726,
      "learning_rate": 9.799382919953745e-05,
      "loss": 0.0338,
      "step": 84820
    },
    {
      "epoch": 0.271488,
      "grad_norm": 0.11995367248914196,
      "learning_rate": 9.79928893859468e-05,
      "loss": 0.0309,
      "step": 84840
    },
    {
      "epoch": 0.271552,
      "grad_norm": 0.0681922965306965,
      "learning_rate": 9.799194935678327e-05,
      "loss": 0.0304,
      "step": 84860
    },
    {
      "epoch": 0.271616,
      "grad_norm": 0.09819432056694928,
      "learning_rate": 9.79910091120511e-05,
      "loss": 0.0318,
      "step": 84880
    },
    {
      "epoch": 0.27168,
      "grad_norm": 0.12725861957601556,
      "learning_rate": 9.799006865175453e-05,
      "loss": 0.0331,
      "step": 84900
    },
    {
      "epoch": 0.271744,
      "grad_norm": 0.08678271465884582,
      "learning_rate": 9.798912797589777e-05,
      "loss": 0.0301,
      "step": 84920
    },
    {
      "epoch": 0.271808,
      "grad_norm": 0.0801701541304339,
      "learning_rate": 9.798818708448503e-05,
      "loss": 0.0285,
      "step": 84940
    },
    {
      "epoch": 0.271872,
      "grad_norm": 0.05660896989207953,
      "learning_rate": 9.798724597752057e-05,
      "loss": 0.0292,
      "step": 84960
    },
    {
      "epoch": 0.271936,
      "grad_norm": 0.09016039784040258,
      "learning_rate": 9.79863046550086e-05,
      "loss": 0.0299,
      "step": 84980
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.08174356912198062,
      "learning_rate": 9.798536311695334e-05,
      "loss": 0.0312,
      "step": 85000
    },
    {
      "epoch": 0.272064,
      "grad_norm": 0.12707304076724268,
      "learning_rate": 9.798442136335904e-05,
      "loss": 0.0293,
      "step": 85020
    },
    {
      "epoch": 0.272128,
      "grad_norm": 0.12311919714449544,
      "learning_rate": 9.79834793942299e-05,
      "loss": 0.03,
      "step": 85040
    },
    {
      "epoch": 0.272192,
      "grad_norm": 0.10883787152805918,
      "learning_rate": 9.798253720957017e-05,
      "loss": 0.0338,
      "step": 85060
    },
    {
      "epoch": 0.272256,
      "grad_norm": 0.054824874470380695,
      "learning_rate": 9.798159480938409e-05,
      "loss": 0.031,
      "step": 85080
    },
    {
      "epoch": 0.27232,
      "grad_norm": 0.06097059615035825,
      "learning_rate": 9.798065219367589e-05,
      "loss": 0.0288,
      "step": 85100
    },
    {
      "epoch": 0.272384,
      "grad_norm": 0.05836905962488298,
      "learning_rate": 9.79797093624498e-05,
      "loss": 0.0297,
      "step": 85120
    },
    {
      "epoch": 0.272448,
      "grad_norm": 0.08518501764553253,
      "learning_rate": 9.797876631571004e-05,
      "loss": 0.0306,
      "step": 85140
    },
    {
      "epoch": 0.272512,
      "grad_norm": 0.05333231558663774,
      "learning_rate": 9.797782305346086e-05,
      "loss": 0.0296,
      "step": 85160
    },
    {
      "epoch": 0.272576,
      "grad_norm": 0.05500228079502022,
      "learning_rate": 9.79768795757065e-05,
      "loss": 0.03,
      "step": 85180
    },
    {
      "epoch": 0.27264,
      "grad_norm": 0.058086025985596784,
      "learning_rate": 9.797593588245119e-05,
      "loss": 0.0311,
      "step": 85200
    },
    {
      "epoch": 0.272704,
      "grad_norm": 0.056115054169460964,
      "learning_rate": 9.797499197369917e-05,
      "loss": 0.0316,
      "step": 85220
    },
    {
      "epoch": 0.272768,
      "grad_norm": 0.08240041059262236,
      "learning_rate": 9.797404784945468e-05,
      "loss": 0.0309,
      "step": 85240
    },
    {
      "epoch": 0.272832,
      "grad_norm": 0.11274368765566864,
      "learning_rate": 9.797310350972197e-05,
      "loss": 0.0317,
      "step": 85260
    },
    {
      "epoch": 0.272896,
      "grad_norm": 0.06876873384694675,
      "learning_rate": 9.797215895450528e-05,
      "loss": 0.0322,
      "step": 85280
    },
    {
      "epoch": 0.27296,
      "grad_norm": 0.052225760597196046,
      "learning_rate": 9.797121418380883e-05,
      "loss": 0.0323,
      "step": 85300
    },
    {
      "epoch": 0.273024,
      "grad_norm": 0.06015037346163621,
      "learning_rate": 9.79702691976369e-05,
      "loss": 0.0296,
      "step": 85320
    },
    {
      "epoch": 0.273088,
      "grad_norm": 0.05781054238714294,
      "learning_rate": 9.796932399599371e-05,
      "loss": 0.032,
      "step": 85340
    },
    {
      "epoch": 0.273152,
      "grad_norm": 0.06317369040919812,
      "learning_rate": 9.796837857888351e-05,
      "loss": 0.0316,
      "step": 85360
    },
    {
      "epoch": 0.273216,
      "grad_norm": 0.0832702442050206,
      "learning_rate": 9.796743294631055e-05,
      "loss": 0.0315,
      "step": 85380
    },
    {
      "epoch": 0.27328,
      "grad_norm": 0.06266493999264361,
      "learning_rate": 9.796648709827907e-05,
      "loss": 0.0285,
      "step": 85400
    },
    {
      "epoch": 0.273344,
      "grad_norm": 0.05567813190490739,
      "learning_rate": 9.796554103479334e-05,
      "loss": 0.0262,
      "step": 85420
    },
    {
      "epoch": 0.273408,
      "grad_norm": 0.055038755296454446,
      "learning_rate": 9.796459475585757e-05,
      "loss": 0.0306,
      "step": 85440
    },
    {
      "epoch": 0.273472,
      "grad_norm": 0.04596768925943805,
      "learning_rate": 9.796364826147606e-05,
      "loss": 0.0291,
      "step": 85460
    },
    {
      "epoch": 0.273536,
      "grad_norm": 0.05376378355457439,
      "learning_rate": 9.796270155165301e-05,
      "loss": 0.03,
      "step": 85480
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.09836295804457233,
      "learning_rate": 9.796175462639272e-05,
      "loss": 0.0302,
      "step": 85500
    },
    {
      "epoch": 0.273664,
      "grad_norm": 0.038182229175833506,
      "learning_rate": 9.79608074856994e-05,
      "loss": 0.031,
      "step": 85520
    },
    {
      "epoch": 0.273728,
      "grad_norm": 0.0825642382254262,
      "learning_rate": 9.795986012957735e-05,
      "loss": 0.0299,
      "step": 85540
    },
    {
      "epoch": 0.273792,
      "grad_norm": 0.07299668852744007,
      "learning_rate": 9.795891255803078e-05,
      "loss": 0.0291,
      "step": 85560
    },
    {
      "epoch": 0.273856,
      "grad_norm": 0.08299507101785107,
      "learning_rate": 9.795796477106398e-05,
      "loss": 0.0305,
      "step": 85580
    },
    {
      "epoch": 0.27392,
      "grad_norm": 0.06617500607608204,
      "learning_rate": 9.795701676868118e-05,
      "loss": 0.0299,
      "step": 85600
    },
    {
      "epoch": 0.273984,
      "grad_norm": 0.06268138452121712,
      "learning_rate": 9.795606855088667e-05,
      "loss": 0.0297,
      "step": 85620
    },
    {
      "epoch": 0.274048,
      "grad_norm": 0.07579649670096585,
      "learning_rate": 9.795512011768469e-05,
      "loss": 0.031,
      "step": 85640
    },
    {
      "epoch": 0.274112,
      "grad_norm": 0.06705169163430981,
      "learning_rate": 9.795417146907949e-05,
      "loss": 0.0309,
      "step": 85660
    },
    {
      "epoch": 0.274176,
      "grad_norm": 0.047804243192109644,
      "learning_rate": 9.795322260507535e-05,
      "loss": 0.0279,
      "step": 85680
    },
    {
      "epoch": 0.27424,
      "grad_norm": 0.14898783175267707,
      "learning_rate": 9.795227352567653e-05,
      "loss": 0.0281,
      "step": 85700
    },
    {
      "epoch": 0.274304,
      "grad_norm": 0.06547951319468213,
      "learning_rate": 9.795132423088728e-05,
      "loss": 0.0301,
      "step": 85720
    },
    {
      "epoch": 0.274368,
      "grad_norm": 0.061865644974783925,
      "learning_rate": 9.795037472071187e-05,
      "loss": 0.0301,
      "step": 85740
    },
    {
      "epoch": 0.274432,
      "grad_norm": 0.10018796097965492,
      "learning_rate": 9.794942499515458e-05,
      "loss": 0.031,
      "step": 85760
    },
    {
      "epoch": 0.274496,
      "grad_norm": 0.05287937747053099,
      "learning_rate": 9.794847505421964e-05,
      "loss": 0.0283,
      "step": 85780
    },
    {
      "epoch": 0.27456,
      "grad_norm": 0.06792134738717569,
      "learning_rate": 9.794752489791137e-05,
      "loss": 0.0278,
      "step": 85800
    },
    {
      "epoch": 0.274624,
      "grad_norm": 0.0657432201599237,
      "learning_rate": 9.794657452623399e-05,
      "loss": 0.0296,
      "step": 85820
    },
    {
      "epoch": 0.274688,
      "grad_norm": 0.130538813508102,
      "learning_rate": 9.79456239391918e-05,
      "loss": 0.0297,
      "step": 85840
    },
    {
      "epoch": 0.274752,
      "grad_norm": 0.09722925913876694,
      "learning_rate": 9.794467313678903e-05,
      "loss": 0.0307,
      "step": 85860
    },
    {
      "epoch": 0.274816,
      "grad_norm": 0.06820036369345822,
      "learning_rate": 9.794372211903e-05,
      "loss": 0.0275,
      "step": 85880
    },
    {
      "epoch": 0.27488,
      "grad_norm": 0.0648979535393599,
      "learning_rate": 9.794277088591896e-05,
      "loss": 0.0326,
      "step": 85900
    },
    {
      "epoch": 0.274944,
      "grad_norm": 0.07450109670677589,
      "learning_rate": 9.794181943746016e-05,
      "loss": 0.0335,
      "step": 85920
    },
    {
      "epoch": 0.275008,
      "grad_norm": 0.05501593972194541,
      "learning_rate": 9.794086777365792e-05,
      "loss": 0.0312,
      "step": 85940
    },
    {
      "epoch": 0.275072,
      "grad_norm": 0.09658042504712852,
      "learning_rate": 9.793991589451649e-05,
      "loss": 0.0341,
      "step": 85960
    },
    {
      "epoch": 0.275136,
      "grad_norm": 0.06867279535277838,
      "learning_rate": 9.793896380004013e-05,
      "loss": 0.0289,
      "step": 85980
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.08318097974867286,
      "learning_rate": 9.793801149023315e-05,
      "loss": 0.0346,
      "step": 86000
    },
    {
      "epoch": 0.275264,
      "grad_norm": 0.0643437635406813,
      "learning_rate": 9.793705896509979e-05,
      "loss": 0.0327,
      "step": 86020
    },
    {
      "epoch": 0.275328,
      "grad_norm": 0.10777496131867699,
      "learning_rate": 9.793610622464436e-05,
      "loss": 0.0293,
      "step": 86040
    },
    {
      "epoch": 0.275392,
      "grad_norm": 0.1042368934969462,
      "learning_rate": 9.793515326887112e-05,
      "loss": 0.0312,
      "step": 86060
    },
    {
      "epoch": 0.275456,
      "grad_norm": 0.05918410850329582,
      "learning_rate": 9.793420009778439e-05,
      "loss": 0.0291,
      "step": 86080
    },
    {
      "epoch": 0.27552,
      "grad_norm": 0.07314888757026075,
      "learning_rate": 9.793324671138838e-05,
      "loss": 0.0294,
      "step": 86100
    },
    {
      "epoch": 0.275584,
      "grad_norm": 0.11125913626107348,
      "learning_rate": 9.793229310968744e-05,
      "loss": 0.0314,
      "step": 86120
    },
    {
      "epoch": 0.275648,
      "grad_norm": 0.06474536870651333,
      "learning_rate": 9.793133929268579e-05,
      "loss": 0.0306,
      "step": 86140
    },
    {
      "epoch": 0.275712,
      "grad_norm": 0.1269847018114356,
      "learning_rate": 9.793038526038778e-05,
      "loss": 0.0319,
      "step": 86160
    },
    {
      "epoch": 0.275776,
      "grad_norm": 0.06180642748263615,
      "learning_rate": 9.792943101279765e-05,
      "loss": 0.027,
      "step": 86180
    },
    {
      "epoch": 0.27584,
      "grad_norm": 0.0540963517270991,
      "learning_rate": 9.792847654991973e-05,
      "loss": 0.0264,
      "step": 86200
    },
    {
      "epoch": 0.275904,
      "grad_norm": 0.050657832243577366,
      "learning_rate": 9.792752187175824e-05,
      "loss": 0.0304,
      "step": 86220
    },
    {
      "epoch": 0.275968,
      "grad_norm": 0.0594789426264427,
      "learning_rate": 9.792656697831752e-05,
      "loss": 0.0304,
      "step": 86240
    },
    {
      "epoch": 0.276032,
      "grad_norm": 0.10940930600609011,
      "learning_rate": 9.792561186960187e-05,
      "loss": 0.0333,
      "step": 86260
    },
    {
      "epoch": 0.276096,
      "grad_norm": 0.07878726246716143,
      "learning_rate": 9.792465654561553e-05,
      "loss": 0.0264,
      "step": 86280
    },
    {
      "epoch": 0.27616,
      "grad_norm": 0.049459638481452045,
      "learning_rate": 9.792370100636284e-05,
      "loss": 0.0295,
      "step": 86300
    },
    {
      "epoch": 0.276224,
      "grad_norm": 0.1534288336008078,
      "learning_rate": 9.792274525184804e-05,
      "loss": 0.0277,
      "step": 86320
    },
    {
      "epoch": 0.276288,
      "grad_norm": 0.06056755514828449,
      "learning_rate": 9.792178928207547e-05,
      "loss": 0.0319,
      "step": 86340
    },
    {
      "epoch": 0.276352,
      "grad_norm": 0.05531651290280109,
      "learning_rate": 9.79208330970494e-05,
      "loss": 0.0283,
      "step": 86360
    },
    {
      "epoch": 0.276416,
      "grad_norm": 0.09022758450309691,
      "learning_rate": 9.791987669677413e-05,
      "loss": 0.0322,
      "step": 86380
    },
    {
      "epoch": 0.27648,
      "grad_norm": 0.10694658017729007,
      "learning_rate": 9.791892008125396e-05,
      "loss": 0.0322,
      "step": 86400
    },
    {
      "epoch": 0.276544,
      "grad_norm": 0.06339716168520947,
      "learning_rate": 9.791796325049318e-05,
      "loss": 0.0314,
      "step": 86420
    },
    {
      "epoch": 0.276608,
      "grad_norm": 0.07350140643381871,
      "learning_rate": 9.791700620449611e-05,
      "loss": 0.0294,
      "step": 86440
    },
    {
      "epoch": 0.276672,
      "grad_norm": 0.0728987286265031,
      "learning_rate": 9.791604894326702e-05,
      "loss": 0.0268,
      "step": 86460
    },
    {
      "epoch": 0.276736,
      "grad_norm": 0.060632471717695625,
      "learning_rate": 9.791509146681021e-05,
      "loss": 0.029,
      "step": 86480
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.05662697976667785,
      "learning_rate": 9.791413377513e-05,
      "loss": 0.0318,
      "step": 86500
    },
    {
      "epoch": 0.276864,
      "grad_norm": 0.09638368246998033,
      "learning_rate": 9.791317586823069e-05,
      "loss": 0.0281,
      "step": 86520
    },
    {
      "epoch": 0.276928,
      "grad_norm": 0.05952625489701873,
      "learning_rate": 9.791221774611657e-05,
      "loss": 0.0312,
      "step": 86540
    },
    {
      "epoch": 0.276992,
      "grad_norm": 0.051886649453004,
      "learning_rate": 9.791125940879195e-05,
      "loss": 0.0289,
      "step": 86560
    },
    {
      "epoch": 0.277056,
      "grad_norm": 0.09019776516560665,
      "learning_rate": 9.791030085626113e-05,
      "loss": 0.0288,
      "step": 86580
    },
    {
      "epoch": 0.27712,
      "grad_norm": 0.07869405139886636,
      "learning_rate": 9.790934208852842e-05,
      "loss": 0.0308,
      "step": 86600
    },
    {
      "epoch": 0.277184,
      "grad_norm": 0.041619912820924906,
      "learning_rate": 9.790838310559813e-05,
      "loss": 0.0317,
      "step": 86620
    },
    {
      "epoch": 0.277248,
      "grad_norm": 0.0919733048092292,
      "learning_rate": 9.790742390747456e-05,
      "loss": 0.0308,
      "step": 86640
    },
    {
      "epoch": 0.277312,
      "grad_norm": 0.05977085425331287,
      "learning_rate": 9.790646449416203e-05,
      "loss": 0.0305,
      "step": 86660
    },
    {
      "epoch": 0.277376,
      "grad_norm": 0.053444572976496886,
      "learning_rate": 9.790550486566484e-05,
      "loss": 0.0344,
      "step": 86680
    },
    {
      "epoch": 0.27744,
      "grad_norm": 0.04987945064223151,
      "learning_rate": 9.790454502198729e-05,
      "loss": 0.029,
      "step": 86700
    },
    {
      "epoch": 0.277504,
      "grad_norm": 0.14874682594634941,
      "learning_rate": 9.79035849631337e-05,
      "loss": 0.0328,
      "step": 86720
    },
    {
      "epoch": 0.277568,
      "grad_norm": 0.08329816196199069,
      "learning_rate": 9.79026246891084e-05,
      "loss": 0.0318,
      "step": 86740
    },
    {
      "epoch": 0.277632,
      "grad_norm": 0.10139743005476297,
      "learning_rate": 9.790166419991569e-05,
      "loss": 0.0283,
      "step": 86760
    },
    {
      "epoch": 0.277696,
      "grad_norm": 0.058987790897106034,
      "learning_rate": 9.790070349555988e-05,
      "loss": 0.029,
      "step": 86780
    },
    {
      "epoch": 0.27776,
      "grad_norm": 0.04690977078573306,
      "learning_rate": 9.78997425760453e-05,
      "loss": 0.0266,
      "step": 86800
    },
    {
      "epoch": 0.277824,
      "grad_norm": 0.10533020413123005,
      "learning_rate": 9.789878144137624e-05,
      "loss": 0.0304,
      "step": 86820
    },
    {
      "epoch": 0.277888,
      "grad_norm": 0.06928994150015012,
      "learning_rate": 9.789782009155703e-05,
      "loss": 0.0323,
      "step": 86840
    },
    {
      "epoch": 0.277952,
      "grad_norm": 0.05024198716775345,
      "learning_rate": 9.789685852659201e-05,
      "loss": 0.0286,
      "step": 86860
    },
    {
      "epoch": 0.278016,
      "grad_norm": 0.05769235583202409,
      "learning_rate": 9.789589674648546e-05,
      "loss": 0.03,
      "step": 86880
    },
    {
      "epoch": 0.27808,
      "grad_norm": 0.06799772548319964,
      "learning_rate": 9.789493475124172e-05,
      "loss": 0.0295,
      "step": 86900
    },
    {
      "epoch": 0.278144,
      "grad_norm": 0.05499796267403035,
      "learning_rate": 9.789397254086512e-05,
      "loss": 0.0307,
      "step": 86920
    },
    {
      "epoch": 0.278208,
      "grad_norm": 0.056765407475772786,
      "learning_rate": 9.789301011535997e-05,
      "loss": 0.0342,
      "step": 86940
    },
    {
      "epoch": 0.278272,
      "grad_norm": 0.10057380979106006,
      "learning_rate": 9.78920474747306e-05,
      "loss": 0.0291,
      "step": 86960
    },
    {
      "epoch": 0.278336,
      "grad_norm": 0.044651434140292524,
      "learning_rate": 9.789108461898134e-05,
      "loss": 0.0286,
      "step": 86980
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.08231344306035984,
      "learning_rate": 9.789012154811647e-05,
      "loss": 0.0276,
      "step": 87000
    },
    {
      "epoch": 0.278464,
      "grad_norm": 0.08359464122419687,
      "learning_rate": 9.788915826214038e-05,
      "loss": 0.0268,
      "step": 87020
    },
    {
      "epoch": 0.278528,
      "grad_norm": 0.05069940259484946,
      "learning_rate": 9.788819476105735e-05,
      "loss": 0.0322,
      "step": 87040
    },
    {
      "epoch": 0.278592,
      "grad_norm": 0.04606302440688619,
      "learning_rate": 9.788723104487173e-05,
      "loss": 0.0275,
      "step": 87060
    },
    {
      "epoch": 0.278656,
      "grad_norm": 0.10052722766795257,
      "learning_rate": 9.788626711358784e-05,
      "loss": 0.0315,
      "step": 87080
    },
    {
      "epoch": 0.27872,
      "grad_norm": 0.046607637651675256,
      "learning_rate": 9.788530296721004e-05,
      "loss": 0.0299,
      "step": 87100
    },
    {
      "epoch": 0.278784,
      "grad_norm": 0.085825876056137,
      "learning_rate": 9.788433860574259e-05,
      "loss": 0.0284,
      "step": 87120
    },
    {
      "epoch": 0.278848,
      "grad_norm": 0.0483105038535408,
      "learning_rate": 9.78833740291899e-05,
      "loss": 0.0292,
      "step": 87140
    },
    {
      "epoch": 0.278912,
      "grad_norm": 0.08396270922012711,
      "learning_rate": 9.788240923755626e-05,
      "loss": 0.0314,
      "step": 87160
    },
    {
      "epoch": 0.278976,
      "grad_norm": 0.06600495869368793,
      "learning_rate": 9.788144423084602e-05,
      "loss": 0.0318,
      "step": 87180
    },
    {
      "epoch": 0.27904,
      "grad_norm": 0.07039616227869977,
      "learning_rate": 9.78804790090635e-05,
      "loss": 0.0289,
      "step": 87200
    },
    {
      "epoch": 0.279104,
      "grad_norm": 0.05084539090153172,
      "learning_rate": 9.787951357221304e-05,
      "loss": 0.0295,
      "step": 87220
    },
    {
      "epoch": 0.279168,
      "grad_norm": 0.05869937692400422,
      "learning_rate": 9.787854792029898e-05,
      "loss": 0.029,
      "step": 87240
    },
    {
      "epoch": 0.279232,
      "grad_norm": 0.058435245175246585,
      "learning_rate": 9.787758205332565e-05,
      "loss": 0.0313,
      "step": 87260
    },
    {
      "epoch": 0.279296,
      "grad_norm": 0.10909701838162907,
      "learning_rate": 9.78766159712974e-05,
      "loss": 0.0296,
      "step": 87280
    },
    {
      "epoch": 0.27936,
      "grad_norm": 0.07962040098009483,
      "learning_rate": 9.787564967421856e-05,
      "loss": 0.0302,
      "step": 87300
    },
    {
      "epoch": 0.279424,
      "grad_norm": 0.05777992700468173,
      "learning_rate": 9.787468316209348e-05,
      "loss": 0.03,
      "step": 87320
    },
    {
      "epoch": 0.279488,
      "grad_norm": 0.10068539971746267,
      "learning_rate": 9.78737164349265e-05,
      "loss": 0.0294,
      "step": 87340
    },
    {
      "epoch": 0.279552,
      "grad_norm": 0.12867784239491714,
      "learning_rate": 9.787274949272196e-05,
      "loss": 0.0296,
      "step": 87360
    },
    {
      "epoch": 0.279616,
      "grad_norm": 0.05918472376299408,
      "learning_rate": 9.78717823354842e-05,
      "loss": 0.0296,
      "step": 87380
    },
    {
      "epoch": 0.27968,
      "grad_norm": 0.11037426451433513,
      "learning_rate": 9.787081496321755e-05,
      "loss": 0.0268,
      "step": 87400
    },
    {
      "epoch": 0.279744,
      "grad_norm": 0.07750467271927361,
      "learning_rate": 9.786984737592639e-05,
      "loss": 0.0285,
      "step": 87420
    },
    {
      "epoch": 0.279808,
      "grad_norm": 0.07153689931213025,
      "learning_rate": 9.786887957361504e-05,
      "loss": 0.0298,
      "step": 87440
    },
    {
      "epoch": 0.279872,
      "grad_norm": 0.05622509774366207,
      "learning_rate": 9.786791155628785e-05,
      "loss": 0.0304,
      "step": 87460
    },
    {
      "epoch": 0.279936,
      "grad_norm": 0.06928629182959103,
      "learning_rate": 9.786694332394917e-05,
      "loss": 0.0297,
      "step": 87480
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.07343317426812289,
      "learning_rate": 9.786597487660337e-05,
      "loss": 0.0274,
      "step": 87500
    },
    {
      "epoch": 0.280064,
      "grad_norm": 0.05053321047334571,
      "learning_rate": 9.786500621425476e-05,
      "loss": 0.0305,
      "step": 87520
    },
    {
      "epoch": 0.280128,
      "grad_norm": 0.06271978577819856,
      "learning_rate": 9.786403733690773e-05,
      "loss": 0.0283,
      "step": 87540
    },
    {
      "epoch": 0.280192,
      "grad_norm": 0.07466438604798549,
      "learning_rate": 9.786306824456661e-05,
      "loss": 0.0315,
      "step": 87560
    },
    {
      "epoch": 0.280256,
      "grad_norm": 0.04870267024623838,
      "learning_rate": 9.786209893723576e-05,
      "loss": 0.0328,
      "step": 87580
    },
    {
      "epoch": 0.28032,
      "grad_norm": 0.07132627744862043,
      "learning_rate": 9.786112941491951e-05,
      "loss": 0.0321,
      "step": 87600
    },
    {
      "epoch": 0.280384,
      "grad_norm": 0.054736281379201224,
      "learning_rate": 9.786015967762227e-05,
      "loss": 0.0304,
      "step": 87620
    },
    {
      "epoch": 0.280448,
      "grad_norm": 0.13911064240644316,
      "learning_rate": 9.785918972534835e-05,
      "loss": 0.0299,
      "step": 87640
    },
    {
      "epoch": 0.280512,
      "grad_norm": 0.06041006297236142,
      "learning_rate": 9.785821955810211e-05,
      "loss": 0.0277,
      "step": 87660
    },
    {
      "epoch": 0.280576,
      "grad_norm": 0.08371421081887791,
      "learning_rate": 9.785724917588793e-05,
      "loss": 0.0312,
      "step": 87680
    },
    {
      "epoch": 0.28064,
      "grad_norm": 0.05380178955558852,
      "learning_rate": 9.785627857871014e-05,
      "loss": 0.0288,
      "step": 87700
    },
    {
      "epoch": 0.280704,
      "grad_norm": 0.0633165202959439,
      "learning_rate": 9.785530776657311e-05,
      "loss": 0.0293,
      "step": 87720
    },
    {
      "epoch": 0.280768,
      "grad_norm": 0.10383334516992913,
      "learning_rate": 9.785433673948122e-05,
      "loss": 0.0302,
      "step": 87740
    },
    {
      "epoch": 0.280832,
      "grad_norm": 0.06836653180060898,
      "learning_rate": 9.785336549743882e-05,
      "loss": 0.0293,
      "step": 87760
    },
    {
      "epoch": 0.280896,
      "grad_norm": 0.08977274507134558,
      "learning_rate": 9.785239404045026e-05,
      "loss": 0.026,
      "step": 87780
    },
    {
      "epoch": 0.28096,
      "grad_norm": 0.07882766459491623,
      "learning_rate": 9.785142236851992e-05,
      "loss": 0.028,
      "step": 87800
    },
    {
      "epoch": 0.281024,
      "grad_norm": 0.0473756964153374,
      "learning_rate": 9.785045048165215e-05,
      "loss": 0.0294,
      "step": 87820
    },
    {
      "epoch": 0.281088,
      "grad_norm": 0.08741708088111487,
      "learning_rate": 9.784947837985135e-05,
      "loss": 0.03,
      "step": 87840
    },
    {
      "epoch": 0.281152,
      "grad_norm": 0.08896864533232335,
      "learning_rate": 9.784850606312183e-05,
      "loss": 0.0325,
      "step": 87860
    },
    {
      "epoch": 0.281216,
      "grad_norm": 0.07191041666580815,
      "learning_rate": 9.784753353146799e-05,
      "loss": 0.03,
      "step": 87880
    },
    {
      "epoch": 0.28128,
      "grad_norm": 0.06807424602043183,
      "learning_rate": 9.78465607848942e-05,
      "loss": 0.0333,
      "step": 87900
    },
    {
      "epoch": 0.281344,
      "grad_norm": 0.059038763684752214,
      "learning_rate": 9.784558782340484e-05,
      "loss": 0.03,
      "step": 87920
    },
    {
      "epoch": 0.281408,
      "grad_norm": 0.052960339839825524,
      "learning_rate": 9.784461464700425e-05,
      "loss": 0.0306,
      "step": 87940
    },
    {
      "epoch": 0.281472,
      "grad_norm": 0.07398003151996829,
      "learning_rate": 9.784364125569682e-05,
      "loss": 0.0315,
      "step": 87960
    },
    {
      "epoch": 0.281536,
      "grad_norm": 0.13746150670390714,
      "learning_rate": 9.784266764948693e-05,
      "loss": 0.0303,
      "step": 87980
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.06126668560269124,
      "learning_rate": 9.784169382837893e-05,
      "loss": 0.0303,
      "step": 88000
    },
    {
      "epoch": 0.281664,
      "grad_norm": 0.12349929981244709,
      "learning_rate": 9.784071979237722e-05,
      "loss": 0.0322,
      "step": 88020
    },
    {
      "epoch": 0.281728,
      "grad_norm": 0.049660911312167676,
      "learning_rate": 9.783974554148614e-05,
      "loss": 0.0321,
      "step": 88040
    },
    {
      "epoch": 0.281792,
      "grad_norm": 0.05332389690175779,
      "learning_rate": 9.783877107571008e-05,
      "loss": 0.0324,
      "step": 88060
    },
    {
      "epoch": 0.281856,
      "grad_norm": 0.061465295396124386,
      "learning_rate": 9.783779639505347e-05,
      "loss": 0.03,
      "step": 88080
    },
    {
      "epoch": 0.28192,
      "grad_norm": 0.05223477104142059,
      "learning_rate": 9.78368214995206e-05,
      "loss": 0.0308,
      "step": 88100
    },
    {
      "epoch": 0.281984,
      "grad_norm": 0.07960575393553908,
      "learning_rate": 9.783584638911591e-05,
      "loss": 0.0307,
      "step": 88120
    },
    {
      "epoch": 0.282048,
      "grad_norm": 0.09587232676052003,
      "learning_rate": 9.783487106384377e-05,
      "loss": 0.0313,
      "step": 88140
    },
    {
      "epoch": 0.282112,
      "grad_norm": 0.05224901400640773,
      "learning_rate": 9.783389552370854e-05,
      "loss": 0.0263,
      "step": 88160
    },
    {
      "epoch": 0.282176,
      "grad_norm": 0.06589659869829143,
      "learning_rate": 9.783291976871461e-05,
      "loss": 0.0302,
      "step": 88180
    },
    {
      "epoch": 0.28224,
      "grad_norm": 0.09856512467752102,
      "learning_rate": 9.783194379886638e-05,
      "loss": 0.0297,
      "step": 88200
    },
    {
      "epoch": 0.282304,
      "grad_norm": 0.06724834841550711,
      "learning_rate": 9.783096761416821e-05,
      "loss": 0.0284,
      "step": 88220
    },
    {
      "epoch": 0.282368,
      "grad_norm": 0.13464014024573914,
      "learning_rate": 9.78299912146245e-05,
      "loss": 0.0313,
      "step": 88240
    },
    {
      "epoch": 0.282432,
      "grad_norm": 0.0751026318896103,
      "learning_rate": 9.782901460023964e-05,
      "loss": 0.0297,
      "step": 88260
    },
    {
      "epoch": 0.282496,
      "grad_norm": 0.049440990259487685,
      "learning_rate": 9.7828037771018e-05,
      "loss": 0.0286,
      "step": 88280
    },
    {
      "epoch": 0.28256,
      "grad_norm": 0.06006985393059307,
      "learning_rate": 9.782706072696397e-05,
      "loss": 0.0314,
      "step": 88300
    },
    {
      "epoch": 0.282624,
      "grad_norm": 0.04658429990932494,
      "learning_rate": 9.782608346808197e-05,
      "loss": 0.028,
      "step": 88320
    },
    {
      "epoch": 0.282688,
      "grad_norm": 0.05097101886833978,
      "learning_rate": 9.782510599437634e-05,
      "loss": 0.0282,
      "step": 88340
    },
    {
      "epoch": 0.282752,
      "grad_norm": 0.04749484404470977,
      "learning_rate": 9.78241283058515e-05,
      "loss": 0.03,
      "step": 88360
    },
    {
      "epoch": 0.282816,
      "grad_norm": 0.05305739924693055,
      "learning_rate": 9.782315040251184e-05,
      "loss": 0.0324,
      "step": 88380
    },
    {
      "epoch": 0.28288,
      "grad_norm": 0.06833958649238049,
      "learning_rate": 9.782217228436174e-05,
      "loss": 0.0329,
      "step": 88400
    },
    {
      "epoch": 0.282944,
      "grad_norm": 0.07680255434765057,
      "learning_rate": 9.782119395140562e-05,
      "loss": 0.0318,
      "step": 88420
    },
    {
      "epoch": 0.283008,
      "grad_norm": 0.0696481173159462,
      "learning_rate": 9.782021540364785e-05,
      "loss": 0.0293,
      "step": 88440
    },
    {
      "epoch": 0.283072,
      "grad_norm": 0.055033808746435,
      "learning_rate": 9.781923664109282e-05,
      "loss": 0.0285,
      "step": 88460
    },
    {
      "epoch": 0.283136,
      "grad_norm": 0.0548995321521546,
      "learning_rate": 9.781825766374496e-05,
      "loss": 0.03,
      "step": 88480
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.059826105208188235,
      "learning_rate": 9.781727847160865e-05,
      "loss": 0.0337,
      "step": 88500
    },
    {
      "epoch": 0.283264,
      "grad_norm": 0.06404081555250492,
      "learning_rate": 9.781629906468826e-05,
      "loss": 0.0302,
      "step": 88520
    },
    {
      "epoch": 0.283328,
      "grad_norm": 0.09659911763500836,
      "learning_rate": 9.781531944298823e-05,
      "loss": 0.0272,
      "step": 88540
    },
    {
      "epoch": 0.283392,
      "grad_norm": 0.06928993105979961,
      "learning_rate": 9.781433960651294e-05,
      "loss": 0.0279,
      "step": 88560
    },
    {
      "epoch": 0.283456,
      "grad_norm": 0.2261126099663581,
      "learning_rate": 9.781335955526678e-05,
      "loss": 0.0286,
      "step": 88580
    },
    {
      "epoch": 0.28352,
      "grad_norm": 0.05803965003481927,
      "learning_rate": 9.78123792892542e-05,
      "loss": 0.0326,
      "step": 88600
    },
    {
      "epoch": 0.283584,
      "grad_norm": 0.05696573251131896,
      "learning_rate": 9.781139880847954e-05,
      "loss": 0.0276,
      "step": 88620
    },
    {
      "epoch": 0.283648,
      "grad_norm": 0.051599573783895,
      "learning_rate": 9.781041811294725e-05,
      "loss": 0.0286,
      "step": 88640
    },
    {
      "epoch": 0.283712,
      "grad_norm": 0.12841100196525285,
      "learning_rate": 9.780943720266171e-05,
      "loss": 0.0283,
      "step": 88660
    },
    {
      "epoch": 0.283776,
      "grad_norm": 0.11013377575501265,
      "learning_rate": 9.780845607762735e-05,
      "loss": 0.0284,
      "step": 88680
    },
    {
      "epoch": 0.28384,
      "grad_norm": 0.14117356580801682,
      "learning_rate": 9.780747473784855e-05,
      "loss": 0.0302,
      "step": 88700
    },
    {
      "epoch": 0.283904,
      "grad_norm": 0.04854178685906144,
      "learning_rate": 9.780649318332972e-05,
      "loss": 0.0301,
      "step": 88720
    },
    {
      "epoch": 0.283968,
      "grad_norm": 0.057751928754091617,
      "learning_rate": 9.780551141407532e-05,
      "loss": 0.0296,
      "step": 88740
    },
    {
      "epoch": 0.284032,
      "grad_norm": 0.05281744898626129,
      "learning_rate": 9.780452943008968e-05,
      "loss": 0.0307,
      "step": 88760
    },
    {
      "epoch": 0.284096,
      "grad_norm": 0.09741459905430251,
      "learning_rate": 9.780354723137726e-05,
      "loss": 0.0302,
      "step": 88780
    },
    {
      "epoch": 0.28416,
      "grad_norm": 0.06582916777482836,
      "learning_rate": 9.780256481794248e-05,
      "loss": 0.029,
      "step": 88800
    },
    {
      "epoch": 0.284224,
      "grad_norm": 0.046021894485924426,
      "learning_rate": 9.780158218978973e-05,
      "loss": 0.0281,
      "step": 88820
    },
    {
      "epoch": 0.284288,
      "grad_norm": 0.054715010439494824,
      "learning_rate": 9.78005993469234e-05,
      "loss": 0.0281,
      "step": 88840
    },
    {
      "epoch": 0.284352,
      "grad_norm": 0.06949680922523226,
      "learning_rate": 9.779961628934797e-05,
      "loss": 0.0291,
      "step": 88860
    },
    {
      "epoch": 0.284416,
      "grad_norm": 0.0702222477731458,
      "learning_rate": 9.77986330170678e-05,
      "loss": 0.0322,
      "step": 88880
    },
    {
      "epoch": 0.28448,
      "grad_norm": 0.15491450208978916,
      "learning_rate": 9.779764953008732e-05,
      "loss": 0.0284,
      "step": 88900
    },
    {
      "epoch": 0.284544,
      "grad_norm": 0.05502071593515309,
      "learning_rate": 9.779666582841096e-05,
      "loss": 0.0304,
      "step": 88920
    },
    {
      "epoch": 0.284608,
      "grad_norm": 0.09695113134036062,
      "learning_rate": 9.779568191204313e-05,
      "loss": 0.0311,
      "step": 88940
    },
    {
      "epoch": 0.284672,
      "grad_norm": 0.056357622199396516,
      "learning_rate": 9.779469778098826e-05,
      "loss": 0.0303,
      "step": 88960
    },
    {
      "epoch": 0.284736,
      "grad_norm": 0.07533571126966745,
      "learning_rate": 9.779371343525074e-05,
      "loss": 0.0274,
      "step": 88980
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.05293558131064359,
      "learning_rate": 9.779272887483504e-05,
      "loss": 0.0276,
      "step": 89000
    },
    {
      "epoch": 0.284864,
      "grad_norm": 0.06895046497164596,
      "learning_rate": 9.779174409974554e-05,
      "loss": 0.028,
      "step": 89020
    },
    {
      "epoch": 0.284928,
      "grad_norm": 0.08111736348789243,
      "learning_rate": 9.779075910998669e-05,
      "loss": 0.0301,
      "step": 89040
    },
    {
      "epoch": 0.284992,
      "grad_norm": 0.07301832095757135,
      "learning_rate": 9.778977390556289e-05,
      "loss": 0.031,
      "step": 89060
    },
    {
      "epoch": 0.285056,
      "grad_norm": 0.08312772368567646,
      "learning_rate": 9.778878848647859e-05,
      "loss": 0.0269,
      "step": 89080
    },
    {
      "epoch": 0.28512,
      "grad_norm": 0.07371294642975473,
      "learning_rate": 9.778780285273819e-05,
      "loss": 0.0285,
      "step": 89100
    },
    {
      "epoch": 0.285184,
      "grad_norm": 0.044083604692719096,
      "learning_rate": 9.778681700434615e-05,
      "loss": 0.0301,
      "step": 89120
    },
    {
      "epoch": 0.285248,
      "grad_norm": 0.05618575810808776,
      "learning_rate": 9.778583094130686e-05,
      "loss": 0.0304,
      "step": 89140
    },
    {
      "epoch": 0.285312,
      "grad_norm": 0.05329057691846767,
      "learning_rate": 9.77848446636248e-05,
      "loss": 0.0276,
      "step": 89160
    },
    {
      "epoch": 0.285376,
      "grad_norm": 0.04884853007009725,
      "learning_rate": 9.778385817130435e-05,
      "loss": 0.0326,
      "step": 89180
    },
    {
      "epoch": 0.28544,
      "grad_norm": 0.06506324466841085,
      "learning_rate": 9.778287146434996e-05,
      "loss": 0.0312,
      "step": 89200
    },
    {
      "epoch": 0.285504,
      "grad_norm": 0.055351407225570345,
      "learning_rate": 9.778188454276606e-05,
      "loss": 0.0302,
      "step": 89220
    },
    {
      "epoch": 0.285568,
      "grad_norm": 0.09047239717841353,
      "learning_rate": 9.77808974065571e-05,
      "loss": 0.0264,
      "step": 89240
    },
    {
      "epoch": 0.285632,
      "grad_norm": 0.05122396788105196,
      "learning_rate": 9.777991005572749e-05,
      "loss": 0.0264,
      "step": 89260
    },
    {
      "epoch": 0.285696,
      "grad_norm": 0.05358990156616446,
      "learning_rate": 9.777892249028167e-05,
      "loss": 0.0284,
      "step": 89280
    },
    {
      "epoch": 0.28576,
      "grad_norm": 0.06251029989484211,
      "learning_rate": 9.777793471022409e-05,
      "loss": 0.027,
      "step": 89300
    },
    {
      "epoch": 0.285824,
      "grad_norm": 0.08001392537360158,
      "learning_rate": 9.777694671555917e-05,
      "loss": 0.0328,
      "step": 89320
    },
    {
      "epoch": 0.285888,
      "grad_norm": 0.06365740828699938,
      "learning_rate": 9.777595850629135e-05,
      "loss": 0.0289,
      "step": 89340
    },
    {
      "epoch": 0.285952,
      "grad_norm": 0.06501786766443653,
      "learning_rate": 9.777497008242509e-05,
      "loss": 0.029,
      "step": 89360
    },
    {
      "epoch": 0.286016,
      "grad_norm": 0.05542452668656113,
      "learning_rate": 9.777398144396481e-05,
      "loss": 0.0333,
      "step": 89380
    },
    {
      "epoch": 0.28608,
      "grad_norm": 0.08471202894154078,
      "learning_rate": 9.777299259091495e-05,
      "loss": 0.0284,
      "step": 89400
    },
    {
      "epoch": 0.286144,
      "grad_norm": 0.058125520702654525,
      "learning_rate": 9.777200352327996e-05,
      "loss": 0.028,
      "step": 89420
    },
    {
      "epoch": 0.286208,
      "grad_norm": 0.04964450714328324,
      "learning_rate": 9.777101424106427e-05,
      "loss": 0.0314,
      "step": 89440
    },
    {
      "epoch": 0.286272,
      "grad_norm": 0.12373044477651093,
      "learning_rate": 9.777002474427235e-05,
      "loss": 0.0314,
      "step": 89460
    },
    {
      "epoch": 0.286336,
      "grad_norm": 0.051312192267298405,
      "learning_rate": 9.776903503290861e-05,
      "loss": 0.03,
      "step": 89480
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.06508992516174161,
      "learning_rate": 9.776804510697752e-05,
      "loss": 0.0292,
      "step": 89500
    },
    {
      "epoch": 0.286464,
      "grad_norm": 0.08404045329784773,
      "learning_rate": 9.776705496648353e-05,
      "loss": 0.0297,
      "step": 89520
    },
    {
      "epoch": 0.286528,
      "grad_norm": 0.15481356869500665,
      "learning_rate": 9.776606461143105e-05,
      "loss": 0.035,
      "step": 89540
    },
    {
      "epoch": 0.286592,
      "grad_norm": 0.11139813415110017,
      "learning_rate": 9.776507404182458e-05,
      "loss": 0.0341,
      "step": 89560
    },
    {
      "epoch": 0.286656,
      "grad_norm": 0.06342343650175972,
      "learning_rate": 9.776408325766854e-05,
      "loss": 0.0318,
      "step": 89580
    },
    {
      "epoch": 0.28672,
      "grad_norm": 0.062287289389653715,
      "learning_rate": 9.776309225896738e-05,
      "loss": 0.029,
      "step": 89600
    },
    {
      "epoch": 0.286784,
      "grad_norm": 0.05686312506214288,
      "learning_rate": 9.776210104572556e-05,
      "loss": 0.0303,
      "step": 89620
    },
    {
      "epoch": 0.286848,
      "grad_norm": 0.10491833774174011,
      "learning_rate": 9.776110961794752e-05,
      "loss": 0.0296,
      "step": 89640
    },
    {
      "epoch": 0.286912,
      "grad_norm": 0.12425883020021465,
      "learning_rate": 9.776011797563774e-05,
      "loss": 0.0315,
      "step": 89660
    },
    {
      "epoch": 0.286976,
      "grad_norm": 0.08080751842535337,
      "learning_rate": 9.775912611880062e-05,
      "loss": 0.029,
      "step": 89680
    },
    {
      "epoch": 0.28704,
      "grad_norm": 0.05938281173314217,
      "learning_rate": 9.775813404744069e-05,
      "loss": 0.031,
      "step": 89700
    },
    {
      "epoch": 0.287104,
      "grad_norm": 0.0774763110433501,
      "learning_rate": 9.775714176156235e-05,
      "loss": 0.0298,
      "step": 89720
    },
    {
      "epoch": 0.287168,
      "grad_norm": 0.07109720900874707,
      "learning_rate": 9.775614926117008e-05,
      "loss": 0.0306,
      "step": 89740
    },
    {
      "epoch": 0.287232,
      "grad_norm": 0.07870570994947514,
      "learning_rate": 9.775515654626833e-05,
      "loss": 0.0322,
      "step": 89760
    },
    {
      "epoch": 0.287296,
      "grad_norm": 0.0938561685924632,
      "learning_rate": 9.775416361686155e-05,
      "loss": 0.0302,
      "step": 89780
    },
    {
      "epoch": 0.28736,
      "grad_norm": 0.055573550608340246,
      "learning_rate": 9.775317047295423e-05,
      "loss": 0.0296,
      "step": 89800
    },
    {
      "epoch": 0.287424,
      "grad_norm": 0.055709014989606516,
      "learning_rate": 9.77521771145508e-05,
      "loss": 0.0282,
      "step": 89820
    },
    {
      "epoch": 0.287488,
      "grad_norm": 0.05250988161200879,
      "learning_rate": 9.775118354165576e-05,
      "loss": 0.0282,
      "step": 89840
    },
    {
      "epoch": 0.287552,
      "grad_norm": 0.0675032718202841,
      "learning_rate": 9.775018975427352e-05,
      "loss": 0.0296,
      "step": 89860
    },
    {
      "epoch": 0.287616,
      "grad_norm": 0.04785461887105399,
      "learning_rate": 9.774919575240857e-05,
      "loss": 0.03,
      "step": 89880
    },
    {
      "epoch": 0.28768,
      "grad_norm": 0.06139017218692497,
      "learning_rate": 9.774820153606538e-05,
      "loss": 0.0328,
      "step": 89900
    },
    {
      "epoch": 0.287744,
      "grad_norm": 0.04763281257710071,
      "learning_rate": 9.774720710524842e-05,
      "loss": 0.0317,
      "step": 89920
    },
    {
      "epoch": 0.287808,
      "grad_norm": 0.052932917411860646,
      "learning_rate": 9.774621245996216e-05,
      "loss": 0.0269,
      "step": 89940
    },
    {
      "epoch": 0.287872,
      "grad_norm": 0.10611065462391918,
      "learning_rate": 9.774521760021105e-05,
      "loss": 0.0303,
      "step": 89960
    },
    {
      "epoch": 0.287936,
      "grad_norm": 0.09951662292814249,
      "learning_rate": 9.774422252599956e-05,
      "loss": 0.0322,
      "step": 89980
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.04299500614826532,
      "learning_rate": 9.774322723733216e-05,
      "loss": 0.0284,
      "step": 90000
    },
    {
      "epoch": 0.288064,
      "grad_norm": 0.04282735269483895,
      "learning_rate": 9.774223173421332e-05,
      "loss": 0.0271,
      "step": 90020
    },
    {
      "epoch": 0.288128,
      "grad_norm": 0.08442666608917483,
      "learning_rate": 9.774123601664754e-05,
      "loss": 0.0296,
      "step": 90040
    },
    {
      "epoch": 0.288192,
      "grad_norm": 0.0583383875958434,
      "learning_rate": 9.774024008463924e-05,
      "loss": 0.0303,
      "step": 90060
    },
    {
      "epoch": 0.288256,
      "grad_norm": 0.06620937697411836,
      "learning_rate": 9.773924393819294e-05,
      "loss": 0.0298,
      "step": 90080
    },
    {
      "epoch": 0.28832,
      "grad_norm": 0.07063913117986942,
      "learning_rate": 9.77382475773131e-05,
      "loss": 0.0299,
      "step": 90100
    },
    {
      "epoch": 0.288384,
      "grad_norm": 0.0563817252766543,
      "learning_rate": 9.773725100200418e-05,
      "loss": 0.0361,
      "step": 90120
    },
    {
      "epoch": 0.288448,
      "grad_norm": 0.0723818380257318,
      "learning_rate": 9.773625421227069e-05,
      "loss": 0.035,
      "step": 90140
    },
    {
      "epoch": 0.288512,
      "grad_norm": 0.07440589480646423,
      "learning_rate": 9.773525720811707e-05,
      "loss": 0.0333,
      "step": 90160
    },
    {
      "epoch": 0.288576,
      "grad_norm": 0.0832625335975234,
      "learning_rate": 9.773425998954782e-05,
      "loss": 0.0335,
      "step": 90180
    },
    {
      "epoch": 0.28864,
      "grad_norm": 0.10574999276323388,
      "learning_rate": 9.773326255656741e-05,
      "loss": 0.0293,
      "step": 90200
    },
    {
      "epoch": 0.288704,
      "grad_norm": 0.10007504769718206,
      "learning_rate": 9.773226490918033e-05,
      "loss": 0.0295,
      "step": 90220
    },
    {
      "epoch": 0.288768,
      "grad_norm": 0.05524518377736703,
      "learning_rate": 9.773126704739105e-05,
      "loss": 0.0301,
      "step": 90240
    },
    {
      "epoch": 0.288832,
      "grad_norm": 0.07815601214509443,
      "learning_rate": 9.773026897120405e-05,
      "loss": 0.0281,
      "step": 90260
    },
    {
      "epoch": 0.288896,
      "grad_norm": 0.04091269842335948,
      "learning_rate": 9.772927068062384e-05,
      "loss": 0.0323,
      "step": 90280
    },
    {
      "epoch": 0.28896,
      "grad_norm": 0.08943291223939251,
      "learning_rate": 9.772827217565488e-05,
      "loss": 0.0308,
      "step": 90300
    },
    {
      "epoch": 0.289024,
      "grad_norm": 0.09665757665974707,
      "learning_rate": 9.772727345630166e-05,
      "loss": 0.0308,
      "step": 90320
    },
    {
      "epoch": 0.289088,
      "grad_norm": 0.07256219218147544,
      "learning_rate": 9.772627452256866e-05,
      "loss": 0.0301,
      "step": 90340
    },
    {
      "epoch": 0.289152,
      "grad_norm": 0.05793711996528834,
      "learning_rate": 9.772527537446037e-05,
      "loss": 0.0281,
      "step": 90360
    },
    {
      "epoch": 0.289216,
      "grad_norm": 0.06603996435925406,
      "learning_rate": 9.772427601198128e-05,
      "loss": 0.0306,
      "step": 90380
    },
    {
      "epoch": 0.28928,
      "grad_norm": 0.06249210786793127,
      "learning_rate": 9.77232764351359e-05,
      "loss": 0.0311,
      "step": 90400
    },
    {
      "epoch": 0.289344,
      "grad_norm": 0.04778339731662798,
      "learning_rate": 9.772227664392868e-05,
      "loss": 0.0315,
      "step": 90420
    },
    {
      "epoch": 0.289408,
      "grad_norm": 0.09962183509833568,
      "learning_rate": 9.772127663836415e-05,
      "loss": 0.0304,
      "step": 90440
    },
    {
      "epoch": 0.289472,
      "grad_norm": 0.13778806039425548,
      "learning_rate": 9.772027641844676e-05,
      "loss": 0.0313,
      "step": 90460
    },
    {
      "epoch": 0.289536,
      "grad_norm": 0.05904370517143128,
      "learning_rate": 9.771927598418104e-05,
      "loss": 0.0309,
      "step": 90480
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.06905550334897796,
      "learning_rate": 9.771827533557147e-05,
      "loss": 0.0306,
      "step": 90500
    },
    {
      "epoch": 0.289664,
      "grad_norm": 0.060002498503972074,
      "learning_rate": 9.771727447262253e-05,
      "loss": 0.0281,
      "step": 90520
    },
    {
      "epoch": 0.289728,
      "grad_norm": 0.05344135473375168,
      "learning_rate": 9.771627339533873e-05,
      "loss": 0.027,
      "step": 90540
    },
    {
      "epoch": 0.289792,
      "grad_norm": 0.16661956274098594,
      "learning_rate": 9.771527210372457e-05,
      "loss": 0.0293,
      "step": 90560
    },
    {
      "epoch": 0.289856,
      "grad_norm": 0.08545591020838353,
      "learning_rate": 9.771427059778456e-05,
      "loss": 0.0291,
      "step": 90580
    },
    {
      "epoch": 0.28992,
      "grad_norm": 0.07756818908169856,
      "learning_rate": 9.771326887752316e-05,
      "loss": 0.0302,
      "step": 90600
    },
    {
      "epoch": 0.289984,
      "grad_norm": 0.09640814905473873,
      "learning_rate": 9.77122669429449e-05,
      "loss": 0.03,
      "step": 90620
    },
    {
      "epoch": 0.290048,
      "grad_norm": 0.049310160843579275,
      "learning_rate": 9.771126479405426e-05,
      "loss": 0.0276,
      "step": 90640
    },
    {
      "epoch": 0.290112,
      "grad_norm": 0.10786784429403422,
      "learning_rate": 9.771026243085577e-05,
      "loss": 0.0313,
      "step": 90660
    },
    {
      "epoch": 0.290176,
      "grad_norm": 0.04125065896468611,
      "learning_rate": 9.77092598533539e-05,
      "loss": 0.0257,
      "step": 90680
    },
    {
      "epoch": 0.29024,
      "grad_norm": 0.11787465830200179,
      "learning_rate": 9.770825706155319e-05,
      "loss": 0.0304,
      "step": 90700
    },
    {
      "epoch": 0.290304,
      "grad_norm": 0.08234966042402382,
      "learning_rate": 9.770725405545811e-05,
      "loss": 0.0279,
      "step": 90720
    },
    {
      "epoch": 0.290368,
      "grad_norm": 0.05925705715683261,
      "learning_rate": 9.770625083507319e-05,
      "loss": 0.0282,
      "step": 90740
    },
    {
      "epoch": 0.290432,
      "grad_norm": 0.10707354793322338,
      "learning_rate": 9.77052474004029e-05,
      "loss": 0.0294,
      "step": 90760
    },
    {
      "epoch": 0.290496,
      "grad_norm": 0.052827395927943194,
      "learning_rate": 9.77042437514518e-05,
      "loss": 0.031,
      "step": 90780
    },
    {
      "epoch": 0.29056,
      "grad_norm": 0.1228298536754665,
      "learning_rate": 9.770323988822435e-05,
      "loss": 0.0293,
      "step": 90800
    },
    {
      "epoch": 0.290624,
      "grad_norm": 0.11183444491597545,
      "learning_rate": 9.770223581072508e-05,
      "loss": 0.0256,
      "step": 90820
    },
    {
      "epoch": 0.290688,
      "grad_norm": 0.11024128961720699,
      "learning_rate": 9.770123151895851e-05,
      "loss": 0.0297,
      "step": 90840
    },
    {
      "epoch": 0.290752,
      "grad_norm": 0.07327689541635074,
      "learning_rate": 9.770022701292913e-05,
      "loss": 0.0297,
      "step": 90860
    },
    {
      "epoch": 0.290816,
      "grad_norm": 0.11274652585358554,
      "learning_rate": 9.769922229264148e-05,
      "loss": 0.0314,
      "step": 90880
    },
    {
      "epoch": 0.29088,
      "grad_norm": 0.15273051205803598,
      "learning_rate": 9.769821735810004e-05,
      "loss": 0.0303,
      "step": 90900
    },
    {
      "epoch": 0.290944,
      "grad_norm": 0.08526491956939158,
      "learning_rate": 9.769721220930934e-05,
      "loss": 0.0297,
      "step": 90920
    },
    {
      "epoch": 0.291008,
      "grad_norm": 0.11502833731827337,
      "learning_rate": 9.76962068462739e-05,
      "loss": 0.0302,
      "step": 90940
    },
    {
      "epoch": 0.291072,
      "grad_norm": 0.04695453241942728,
      "learning_rate": 9.769520126899823e-05,
      "loss": 0.028,
      "step": 90960
    },
    {
      "epoch": 0.291136,
      "grad_norm": 0.09808236898860505,
      "learning_rate": 9.769419547748683e-05,
      "loss": 0.0292,
      "step": 90980
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.14480822981144173,
      "learning_rate": 9.769318947174426e-05,
      "loss": 0.031,
      "step": 91000
    },
    {
      "epoch": 0.291264,
      "grad_norm": 0.07866717198496924,
      "learning_rate": 9.7692183251775e-05,
      "loss": 0.032,
      "step": 91020
    },
    {
      "epoch": 0.291328,
      "grad_norm": 0.049650311672941816,
      "learning_rate": 9.769117681758358e-05,
      "loss": 0.0302,
      "step": 91040
    },
    {
      "epoch": 0.291392,
      "grad_norm": 0.06965456403528936,
      "learning_rate": 9.769017016917454e-05,
      "loss": 0.028,
      "step": 91060
    },
    {
      "epoch": 0.291456,
      "grad_norm": 0.0572071517883108,
      "learning_rate": 9.768916330655237e-05,
      "loss": 0.0273,
      "step": 91080
    },
    {
      "epoch": 0.29152,
      "grad_norm": 0.06540073909124824,
      "learning_rate": 9.76881562297216e-05,
      "loss": 0.0308,
      "step": 91100
    },
    {
      "epoch": 0.291584,
      "grad_norm": 0.10395635642015878,
      "learning_rate": 9.768714893868678e-05,
      "loss": 0.0312,
      "step": 91120
    },
    {
      "epoch": 0.291648,
      "grad_norm": 0.10317713023235398,
      "learning_rate": 9.76861414334524e-05,
      "loss": 0.0291,
      "step": 91140
    },
    {
      "epoch": 0.291712,
      "grad_norm": 0.08379218884760899,
      "learning_rate": 9.768513371402302e-05,
      "loss": 0.0296,
      "step": 91160
    },
    {
      "epoch": 0.291776,
      "grad_norm": 0.06275444638801035,
      "learning_rate": 9.768412578040314e-05,
      "loss": 0.0304,
      "step": 91180
    },
    {
      "epoch": 0.29184,
      "grad_norm": 0.1441161861802795,
      "learning_rate": 9.76831176325973e-05,
      "loss": 0.0317,
      "step": 91200
    },
    {
      "epoch": 0.291904,
      "grad_norm": 0.07582917438235694,
      "learning_rate": 9.768210927061001e-05,
      "loss": 0.0319,
      "step": 91220
    },
    {
      "epoch": 0.291968,
      "grad_norm": 0.06907292510389078,
      "learning_rate": 9.768110069444583e-05,
      "loss": 0.0326,
      "step": 91240
    },
    {
      "epoch": 0.292032,
      "grad_norm": 0.056168450011103786,
      "learning_rate": 9.768009190410925e-05,
      "loss": 0.0309,
      "step": 91260
    },
    {
      "epoch": 0.292096,
      "grad_norm": 0.059905400701916564,
      "learning_rate": 9.767908289960485e-05,
      "loss": 0.0336,
      "step": 91280
    },
    {
      "epoch": 0.29216,
      "grad_norm": 0.068418325137712,
      "learning_rate": 9.767807368093712e-05,
      "loss": 0.0293,
      "step": 91300
    },
    {
      "epoch": 0.292224,
      "grad_norm": 0.12201716790175107,
      "learning_rate": 9.767706424811062e-05,
      "loss": 0.0294,
      "step": 91320
    },
    {
      "epoch": 0.292288,
      "grad_norm": 0.0656391123052192,
      "learning_rate": 9.767605460112987e-05,
      "loss": 0.0312,
      "step": 91340
    },
    {
      "epoch": 0.292352,
      "grad_norm": 0.07313453415323429,
      "learning_rate": 9.76750447399994e-05,
      "loss": 0.0321,
      "step": 91360
    },
    {
      "epoch": 0.292416,
      "grad_norm": 0.05311425433808709,
      "learning_rate": 9.767403466472377e-05,
      "loss": 0.0312,
      "step": 91380
    },
    {
      "epoch": 0.29248,
      "grad_norm": 0.05100215923486794,
      "learning_rate": 9.76730243753075e-05,
      "loss": 0.0319,
      "step": 91400
    },
    {
      "epoch": 0.292544,
      "grad_norm": 0.058368682684162135,
      "learning_rate": 9.767201387175513e-05,
      "loss": 0.0289,
      "step": 91420
    },
    {
      "epoch": 0.292608,
      "grad_norm": 0.05295764885521145,
      "learning_rate": 9.767100315407118e-05,
      "loss": 0.0276,
      "step": 91440
    },
    {
      "epoch": 0.292672,
      "grad_norm": 0.11181656899197412,
      "learning_rate": 9.766999222226024e-05,
      "loss": 0.0303,
      "step": 91460
    },
    {
      "epoch": 0.292736,
      "grad_norm": 0.05581452207360544,
      "learning_rate": 9.76689810763268e-05,
      "loss": 0.0336,
      "step": 91480
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.07865797959959958,
      "learning_rate": 9.766796971627543e-05,
      "loss": 0.031,
      "step": 91500
    },
    {
      "epoch": 0.292864,
      "grad_norm": 0.07081477593630005,
      "learning_rate": 9.766695814211067e-05,
      "loss": 0.0259,
      "step": 91520
    },
    {
      "epoch": 0.292928,
      "grad_norm": 0.08020682934050305,
      "learning_rate": 9.766594635383703e-05,
      "loss": 0.0277,
      "step": 91540
    },
    {
      "epoch": 0.292992,
      "grad_norm": 0.09197806165680074,
      "learning_rate": 9.766493435145911e-05,
      "loss": 0.0323,
      "step": 91560
    },
    {
      "epoch": 0.293056,
      "grad_norm": 0.0715514169888002,
      "learning_rate": 9.766392213498143e-05,
      "loss": 0.0324,
      "step": 91580
    },
    {
      "epoch": 0.29312,
      "grad_norm": 0.06449296342457878,
      "learning_rate": 9.766290970440852e-05,
      "loss": 0.033,
      "step": 91600
    },
    {
      "epoch": 0.293184,
      "grad_norm": 0.04727015296580667,
      "learning_rate": 9.766189705974495e-05,
      "loss": 0.0284,
      "step": 91620
    },
    {
      "epoch": 0.293248,
      "grad_norm": 0.06958421543175881,
      "learning_rate": 9.766088420099526e-05,
      "loss": 0.0299,
      "step": 91640
    },
    {
      "epoch": 0.293312,
      "grad_norm": 0.06023564953660223,
      "learning_rate": 9.765987112816401e-05,
      "loss": 0.0294,
      "step": 91660
    },
    {
      "epoch": 0.293376,
      "grad_norm": 0.0628297333038737,
      "learning_rate": 9.765885784125572e-05,
      "loss": 0.0307,
      "step": 91680
    },
    {
      "epoch": 0.29344,
      "grad_norm": 0.09645617750849343,
      "learning_rate": 9.765784434027499e-05,
      "loss": 0.0291,
      "step": 91700
    },
    {
      "epoch": 0.293504,
      "grad_norm": 0.11391629473489072,
      "learning_rate": 9.765683062522633e-05,
      "loss": 0.0293,
      "step": 91720
    },
    {
      "epoch": 0.293568,
      "grad_norm": 0.08001957907025346,
      "learning_rate": 9.765581669611431e-05,
      "loss": 0.0285,
      "step": 91740
    },
    {
      "epoch": 0.293632,
      "grad_norm": 0.04834159808894664,
      "learning_rate": 9.765480255294348e-05,
      "loss": 0.0306,
      "step": 91760
    },
    {
      "epoch": 0.293696,
      "grad_norm": 0.08007300543894137,
      "learning_rate": 9.76537881957184e-05,
      "loss": 0.0301,
      "step": 91780
    },
    {
      "epoch": 0.29376,
      "grad_norm": 0.04759108679956382,
      "learning_rate": 9.765277362444363e-05,
      "loss": 0.0321,
      "step": 91800
    },
    {
      "epoch": 0.293824,
      "grad_norm": 0.07865830657976951,
      "learning_rate": 9.765175883912372e-05,
      "loss": 0.0276,
      "step": 91820
    },
    {
      "epoch": 0.293888,
      "grad_norm": 0.06130030804815428,
      "learning_rate": 9.765074383976324e-05,
      "loss": 0.0305,
      "step": 91840
    },
    {
      "epoch": 0.293952,
      "grad_norm": 0.06814356764303563,
      "learning_rate": 9.764972862636672e-05,
      "loss": 0.0318,
      "step": 91860
    },
    {
      "epoch": 0.294016,
      "grad_norm": 0.0650452328637573,
      "learning_rate": 9.764871319893876e-05,
      "loss": 0.029,
      "step": 91880
    },
    {
      "epoch": 0.29408,
      "grad_norm": 0.06966640918520409,
      "learning_rate": 9.764769755748388e-05,
      "loss": 0.0314,
      "step": 91900
    },
    {
      "epoch": 0.294144,
      "grad_norm": 0.04622342552874327,
      "learning_rate": 9.764668170200667e-05,
      "loss": 0.0285,
      "step": 91920
    },
    {
      "epoch": 0.294208,
      "grad_norm": 0.08146967694424521,
      "learning_rate": 9.764566563251169e-05,
      "loss": 0.0316,
      "step": 91940
    },
    {
      "epoch": 0.294272,
      "grad_norm": 0.05955156799717587,
      "learning_rate": 9.76446493490035e-05,
      "loss": 0.0295,
      "step": 91960
    },
    {
      "epoch": 0.294336,
      "grad_norm": 0.13353790737355584,
      "learning_rate": 9.764363285148666e-05,
      "loss": 0.0331,
      "step": 91980
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.04756594618684242,
      "learning_rate": 9.764261613996573e-05,
      "loss": 0.0278,
      "step": 92000
    },
    {
      "epoch": 0.294464,
      "grad_norm": 0.07477437839456276,
      "learning_rate": 9.764159921444531e-05,
      "loss": 0.0268,
      "step": 92020
    },
    {
      "epoch": 0.294528,
      "grad_norm": 0.07978564942842624,
      "learning_rate": 9.764058207492992e-05,
      "loss": 0.0289,
      "step": 92040
    },
    {
      "epoch": 0.294592,
      "grad_norm": 0.07627036368404372,
      "learning_rate": 9.763956472142417e-05,
      "loss": 0.0276,
      "step": 92060
    },
    {
      "epoch": 0.294656,
      "grad_norm": 0.09178556239511186,
      "learning_rate": 9.763854715393261e-05,
      "loss": 0.0264,
      "step": 92080
    },
    {
      "epoch": 0.29472,
      "grad_norm": 0.13607374133071756,
      "learning_rate": 9.763752937245981e-05,
      "loss": 0.0303,
      "step": 92100
    },
    {
      "epoch": 0.294784,
      "grad_norm": 0.0664654959912239,
      "learning_rate": 9.763651137701036e-05,
      "loss": 0.0295,
      "step": 92120
    },
    {
      "epoch": 0.294848,
      "grad_norm": 0.06940529587042338,
      "learning_rate": 9.76354931675888e-05,
      "loss": 0.0279,
      "step": 92140
    },
    {
      "epoch": 0.294912,
      "grad_norm": 0.04316829998102194,
      "learning_rate": 9.763447474419973e-05,
      "loss": 0.028,
      "step": 92160
    },
    {
      "epoch": 0.294976,
      "grad_norm": 0.07582613427334536,
      "learning_rate": 9.76334561068477e-05,
      "loss": 0.0292,
      "step": 92180
    },
    {
      "epoch": 0.29504,
      "grad_norm": 0.04694063326748292,
      "learning_rate": 9.763243725553732e-05,
      "loss": 0.0273,
      "step": 92200
    },
    {
      "epoch": 0.295104,
      "grad_norm": 0.08714637332164257,
      "learning_rate": 9.763141819027316e-05,
      "loss": 0.0287,
      "step": 92220
    },
    {
      "epoch": 0.295168,
      "grad_norm": 0.07274383846249166,
      "learning_rate": 9.763039891105976e-05,
      "loss": 0.0296,
      "step": 92240
    },
    {
      "epoch": 0.295232,
      "grad_norm": 0.04738449931225696,
      "learning_rate": 9.762937941790173e-05,
      "loss": 0.0299,
      "step": 92260
    },
    {
      "epoch": 0.295296,
      "grad_norm": 0.03534793937859938,
      "learning_rate": 9.762835971080365e-05,
      "loss": 0.0249,
      "step": 92280
    },
    {
      "epoch": 0.29536,
      "grad_norm": 0.05646974144703749,
      "learning_rate": 9.76273397897701e-05,
      "loss": 0.0304,
      "step": 92300
    },
    {
      "epoch": 0.295424,
      "grad_norm": 0.06437554700087936,
      "learning_rate": 9.762631965480564e-05,
      "loss": 0.0305,
      "step": 92320
    },
    {
      "epoch": 0.295488,
      "grad_norm": 0.06365464219128028,
      "learning_rate": 9.762529930591487e-05,
      "loss": 0.0261,
      "step": 92340
    },
    {
      "epoch": 0.295552,
      "grad_norm": 0.06366934408995589,
      "learning_rate": 9.762427874310237e-05,
      "loss": 0.0267,
      "step": 92360
    },
    {
      "epoch": 0.295616,
      "grad_norm": 0.041541166168540145,
      "learning_rate": 9.762325796637273e-05,
      "loss": 0.0279,
      "step": 92380
    },
    {
      "epoch": 0.29568,
      "grad_norm": 0.07629269445902416,
      "learning_rate": 9.762223697573052e-05,
      "loss": 0.0307,
      "step": 92400
    },
    {
      "epoch": 0.295744,
      "grad_norm": 0.06917241613386792,
      "learning_rate": 9.762121577118035e-05,
      "loss": 0.0286,
      "step": 92420
    },
    {
      "epoch": 0.295808,
      "grad_norm": 0.04713584219006878,
      "learning_rate": 9.762019435272677e-05,
      "loss": 0.0293,
      "step": 92440
    },
    {
      "epoch": 0.295872,
      "grad_norm": 0.07325613370387413,
      "learning_rate": 9.761917272037442e-05,
      "loss": 0.0281,
      "step": 92460
    },
    {
      "epoch": 0.295936,
      "grad_norm": 0.05508016049038129,
      "learning_rate": 9.761815087412785e-05,
      "loss": 0.0294,
      "step": 92480
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.07920364568934207,
      "learning_rate": 9.761712881399164e-05,
      "loss": 0.0281,
      "step": 92500
    },
    {
      "epoch": 0.296064,
      "grad_norm": 0.04133992778118721,
      "learning_rate": 9.761610653997042e-05,
      "loss": 0.0267,
      "step": 92520
    },
    {
      "epoch": 0.296128,
      "grad_norm": 0.04760126596766222,
      "learning_rate": 9.761508405206875e-05,
      "loss": 0.0303,
      "step": 92540
    },
    {
      "epoch": 0.296192,
      "grad_norm": 0.06717560025692335,
      "learning_rate": 9.761406135029124e-05,
      "loss": 0.0316,
      "step": 92560
    },
    {
      "epoch": 0.296256,
      "grad_norm": 0.050695331222928505,
      "learning_rate": 9.761303843464247e-05,
      "loss": 0.0292,
      "step": 92580
    },
    {
      "epoch": 0.29632,
      "grad_norm": 0.07452957385808104,
      "learning_rate": 9.761201530512705e-05,
      "loss": 0.0291,
      "step": 92600
    },
    {
      "epoch": 0.296384,
      "grad_norm": 0.08772283476796751,
      "learning_rate": 9.761099196174958e-05,
      "loss": 0.0272,
      "step": 92620
    },
    {
      "epoch": 0.296448,
      "grad_norm": 0.05481834453119384,
      "learning_rate": 9.760996840451464e-05,
      "loss": 0.0332,
      "step": 92640
    },
    {
      "epoch": 0.296512,
      "grad_norm": 0.06807851974280342,
      "learning_rate": 9.760894463342682e-05,
      "loss": 0.0304,
      "step": 92660
    },
    {
      "epoch": 0.296576,
      "grad_norm": 0.08789378473903786,
      "learning_rate": 9.760792064849074e-05,
      "loss": 0.0287,
      "step": 92680
    },
    {
      "epoch": 0.29664,
      "grad_norm": 0.0620620489546058,
      "learning_rate": 9.7606896449711e-05,
      "loss": 0.0286,
      "step": 92700
    },
    {
      "epoch": 0.296704,
      "grad_norm": 0.05037463710001375,
      "learning_rate": 9.760587203709217e-05,
      "loss": 0.0282,
      "step": 92720
    },
    {
      "epoch": 0.296768,
      "grad_norm": 0.05326190850822441,
      "learning_rate": 9.760484741063889e-05,
      "loss": 0.0294,
      "step": 92740
    },
    {
      "epoch": 0.296832,
      "grad_norm": 0.06612417240506965,
      "learning_rate": 9.760382257035574e-05,
      "loss": 0.0305,
      "step": 92760
    },
    {
      "epoch": 0.296896,
      "grad_norm": 0.03826444620431855,
      "learning_rate": 9.760279751624733e-05,
      "loss": 0.0262,
      "step": 92780
    },
    {
      "epoch": 0.29696,
      "grad_norm": 0.05057680813634849,
      "learning_rate": 9.760177224831826e-05,
      "loss": 0.0283,
      "step": 92800
    },
    {
      "epoch": 0.297024,
      "grad_norm": 0.09875891620513237,
      "learning_rate": 9.760074676657314e-05,
      "loss": 0.0292,
      "step": 92820
    },
    {
      "epoch": 0.297088,
      "grad_norm": 0.050771519436738806,
      "learning_rate": 9.759972107101657e-05,
      "loss": 0.0301,
      "step": 92840
    },
    {
      "epoch": 0.297152,
      "grad_norm": 0.053507149160257624,
      "learning_rate": 9.759869516165316e-05,
      "loss": 0.0291,
      "step": 92860
    },
    {
      "epoch": 0.297216,
      "grad_norm": 0.06966717668877542,
      "learning_rate": 9.759766903848754e-05,
      "loss": 0.0304,
      "step": 92880
    },
    {
      "epoch": 0.29728,
      "grad_norm": 0.050124412811470107,
      "learning_rate": 9.759664270152429e-05,
      "loss": 0.0285,
      "step": 92900
    },
    {
      "epoch": 0.297344,
      "grad_norm": 0.043830289315342955,
      "learning_rate": 9.759561615076802e-05,
      "loss": 0.0266,
      "step": 92920
    },
    {
      "epoch": 0.297408,
      "grad_norm": 0.03874883852979017,
      "learning_rate": 9.759458938622334e-05,
      "loss": 0.0273,
      "step": 92940
    },
    {
      "epoch": 0.297472,
      "grad_norm": 0.06363942452364184,
      "learning_rate": 9.75935624078949e-05,
      "loss": 0.0339,
      "step": 92960
    },
    {
      "epoch": 0.297536,
      "grad_norm": 0.05080533622856413,
      "learning_rate": 9.759253521578727e-05,
      "loss": 0.0278,
      "step": 92980
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.04644300734170224,
      "learning_rate": 9.759150780990507e-05,
      "loss": 0.0271,
      "step": 93000
    },
    {
      "epoch": 0.297664,
      "grad_norm": 0.04911397203948263,
      "learning_rate": 9.759048019025294e-05,
      "loss": 0.0291,
      "step": 93020
    },
    {
      "epoch": 0.297728,
      "grad_norm": 0.04211893247353645,
      "learning_rate": 9.758945235683548e-05,
      "loss": 0.0283,
      "step": 93040
    },
    {
      "epoch": 0.297792,
      "grad_norm": 0.04748009191090313,
      "learning_rate": 9.758842430965729e-05,
      "loss": 0.0294,
      "step": 93060
    },
    {
      "epoch": 0.297856,
      "grad_norm": 0.07385990905838628,
      "learning_rate": 9.758739604872302e-05,
      "loss": 0.0338,
      "step": 93080
    },
    {
      "epoch": 0.29792,
      "grad_norm": 0.10180001775422177,
      "learning_rate": 9.758636757403726e-05,
      "loss": 0.0313,
      "step": 93100
    },
    {
      "epoch": 0.297984,
      "grad_norm": 0.10042417589797091,
      "learning_rate": 9.758533888560463e-05,
      "loss": 0.0308,
      "step": 93120
    },
    {
      "epoch": 0.298048,
      "grad_norm": 0.09651787509293541,
      "learning_rate": 9.75843099834298e-05,
      "loss": 0.0304,
      "step": 93140
    },
    {
      "epoch": 0.298112,
      "grad_norm": 0.06690495891199258,
      "learning_rate": 9.758328086751733e-05,
      "loss": 0.0296,
      "step": 93160
    },
    {
      "epoch": 0.298176,
      "grad_norm": 0.0631208581702279,
      "learning_rate": 9.758225153787187e-05,
      "loss": 0.0305,
      "step": 93180
    },
    {
      "epoch": 0.29824,
      "grad_norm": 0.10269969248795853,
      "learning_rate": 9.758122199449803e-05,
      "loss": 0.0314,
      "step": 93200
    },
    {
      "epoch": 0.298304,
      "grad_norm": 0.059109484347261425,
      "learning_rate": 9.758019223740047e-05,
      "loss": 0.0336,
      "step": 93220
    },
    {
      "epoch": 0.298368,
      "grad_norm": 0.06054948833443805,
      "learning_rate": 9.757916226658379e-05,
      "loss": 0.0322,
      "step": 93240
    },
    {
      "epoch": 0.298432,
      "grad_norm": 0.05096099556971214,
      "learning_rate": 9.75781320820526e-05,
      "loss": 0.03,
      "step": 93260
    },
    {
      "epoch": 0.298496,
      "grad_norm": 0.04648841938022175,
      "learning_rate": 9.757710168381156e-05,
      "loss": 0.0257,
      "step": 93280
    },
    {
      "epoch": 0.29856,
      "grad_norm": 0.05743972877335001,
      "learning_rate": 9.757607107186526e-05,
      "loss": 0.0291,
      "step": 93300
    },
    {
      "epoch": 0.298624,
      "grad_norm": 0.07420712486854056,
      "learning_rate": 9.757504024621837e-05,
      "loss": 0.0294,
      "step": 93320
    },
    {
      "epoch": 0.298688,
      "grad_norm": 0.04184720958373901,
      "learning_rate": 9.75740092068755e-05,
      "loss": 0.0277,
      "step": 93340
    },
    {
      "epoch": 0.298752,
      "grad_norm": 0.04987237949332882,
      "learning_rate": 9.757297795384127e-05,
      "loss": 0.0322,
      "step": 93360
    },
    {
      "epoch": 0.298816,
      "grad_norm": 0.05930230311028524,
      "learning_rate": 9.757194648712033e-05,
      "loss": 0.032,
      "step": 93380
    },
    {
      "epoch": 0.29888,
      "grad_norm": 0.0533940352684878,
      "learning_rate": 9.757091480671732e-05,
      "loss": 0.0299,
      "step": 93400
    },
    {
      "epoch": 0.298944,
      "grad_norm": 0.06024413847768373,
      "learning_rate": 9.756988291263687e-05,
      "loss": 0.0298,
      "step": 93420
    },
    {
      "epoch": 0.299008,
      "grad_norm": 0.0473554272099614,
      "learning_rate": 9.756885080488359e-05,
      "loss": 0.0324,
      "step": 93440
    },
    {
      "epoch": 0.299072,
      "grad_norm": 0.06022235069705834,
      "learning_rate": 9.756781848346213e-05,
      "loss": 0.0324,
      "step": 93460
    },
    {
      "epoch": 0.299136,
      "grad_norm": 0.04044960357924723,
      "learning_rate": 9.756678594837713e-05,
      "loss": 0.0317,
      "step": 93480
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.09569020584469361,
      "learning_rate": 9.756575319963324e-05,
      "loss": 0.028,
      "step": 93500
    },
    {
      "epoch": 0.299264,
      "grad_norm": 0.10281577721148137,
      "learning_rate": 9.756472023723509e-05,
      "loss": 0.031,
      "step": 93520
    },
    {
      "epoch": 0.299328,
      "grad_norm": 0.10847561896768765,
      "learning_rate": 9.756368706118731e-05,
      "loss": 0.0302,
      "step": 93540
    },
    {
      "epoch": 0.299392,
      "grad_norm": 0.06936352661580504,
      "learning_rate": 9.756265367149455e-05,
      "loss": 0.0289,
      "step": 93560
    },
    {
      "epoch": 0.299456,
      "grad_norm": 0.08971338998454124,
      "learning_rate": 9.756162006816146e-05,
      "loss": 0.026,
      "step": 93580
    },
    {
      "epoch": 0.29952,
      "grad_norm": 0.10501111062829009,
      "learning_rate": 9.756058625119266e-05,
      "loss": 0.0278,
      "step": 93600
    },
    {
      "epoch": 0.299584,
      "grad_norm": 0.05390507571589922,
      "learning_rate": 9.755955222059281e-05,
      "loss": 0.0271,
      "step": 93620
    },
    {
      "epoch": 0.299648,
      "grad_norm": 0.08296315077328113,
      "learning_rate": 9.755851797636655e-05,
      "loss": 0.0262,
      "step": 93640
    },
    {
      "epoch": 0.299712,
      "grad_norm": 0.05938851280829022,
      "learning_rate": 9.755748351851852e-05,
      "loss": 0.0291,
      "step": 93660
    },
    {
      "epoch": 0.299776,
      "grad_norm": 0.0900857015641943,
      "learning_rate": 9.755644884705337e-05,
      "loss": 0.0315,
      "step": 93680
    },
    {
      "epoch": 0.29984,
      "grad_norm": 0.07835228758017287,
      "learning_rate": 9.755541396197577e-05,
      "loss": 0.0257,
      "step": 93700
    },
    {
      "epoch": 0.299904,
      "grad_norm": 0.0537520764195435,
      "learning_rate": 9.755437886329033e-05,
      "loss": 0.0285,
      "step": 93720
    },
    {
      "epoch": 0.299968,
      "grad_norm": 0.057121313293937576,
      "learning_rate": 9.755334355100171e-05,
      "loss": 0.0297,
      "step": 93740
    },
    {
      "epoch": 0.300032,
      "grad_norm": 0.07360851673712984,
      "learning_rate": 9.755230802511459e-05,
      "loss": 0.0323,
      "step": 93760
    },
    {
      "epoch": 0.300096,
      "grad_norm": 0.08795637001847535,
      "learning_rate": 9.75512722856336e-05,
      "loss": 0.0315,
      "step": 93780
    },
    {
      "epoch": 0.30016,
      "grad_norm": 0.056263459602137085,
      "learning_rate": 9.755023633256338e-05,
      "loss": 0.0274,
      "step": 93800
    },
    {
      "epoch": 0.300224,
      "grad_norm": 0.1397017486075912,
      "learning_rate": 9.75492001659086e-05,
      "loss": 0.032,
      "step": 93820
    },
    {
      "epoch": 0.300288,
      "grad_norm": 0.10216143165055774,
      "learning_rate": 9.754816378567392e-05,
      "loss": 0.0319,
      "step": 93840
    },
    {
      "epoch": 0.300352,
      "grad_norm": 0.06788687760245449,
      "learning_rate": 9.754712719186397e-05,
      "loss": 0.0322,
      "step": 93860
    },
    {
      "epoch": 0.300416,
      "grad_norm": 0.06559939588754048,
      "learning_rate": 9.754609038448343e-05,
      "loss": 0.0303,
      "step": 93880
    },
    {
      "epoch": 0.30048,
      "grad_norm": 0.06814221975988273,
      "learning_rate": 9.754505336353694e-05,
      "loss": 0.0299,
      "step": 93900
    },
    {
      "epoch": 0.300544,
      "grad_norm": 0.04963864249364729,
      "learning_rate": 9.754401612902917e-05,
      "loss": 0.0304,
      "step": 93920
    },
    {
      "epoch": 0.300608,
      "grad_norm": 0.04562470172151278,
      "learning_rate": 9.754297868096478e-05,
      "loss": 0.0279,
      "step": 93940
    },
    {
      "epoch": 0.300672,
      "grad_norm": 0.05252628317861611,
      "learning_rate": 9.754194101934843e-05,
      "loss": 0.0287,
      "step": 93960
    },
    {
      "epoch": 0.300736,
      "grad_norm": 0.051878531476474435,
      "learning_rate": 9.754090314418476e-05,
      "loss": 0.0311,
      "step": 93980
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.052972617369619106,
      "learning_rate": 9.753986505547845e-05,
      "loss": 0.0303,
      "step": 94000
    },
    {
      "epoch": 0.300864,
      "grad_norm": 0.05312557816667071,
      "learning_rate": 9.753882675323418e-05,
      "loss": 0.0316,
      "step": 94020
    },
    {
      "epoch": 0.300928,
      "grad_norm": 0.11002007188600196,
      "learning_rate": 9.753778823745657e-05,
      "loss": 0.031,
      "step": 94040
    },
    {
      "epoch": 0.300992,
      "grad_norm": 0.1029225368164262,
      "learning_rate": 9.753674950815032e-05,
      "loss": 0.034,
      "step": 94060
    },
    {
      "epoch": 0.301056,
      "grad_norm": 0.06604733607269084,
      "learning_rate": 9.753571056532009e-05,
      "loss": 0.0287,
      "step": 94080
    },
    {
      "epoch": 0.30112,
      "grad_norm": 0.07882769172343433,
      "learning_rate": 9.753467140897054e-05,
      "loss": 0.0293,
      "step": 94100
    },
    {
      "epoch": 0.301184,
      "grad_norm": 0.08866181267311185,
      "learning_rate": 9.753363203910634e-05,
      "loss": 0.0311,
      "step": 94120
    },
    {
      "epoch": 0.301248,
      "grad_norm": 0.05555129589892021,
      "learning_rate": 9.753259245573215e-05,
      "loss": 0.0293,
      "step": 94140
    },
    {
      "epoch": 0.301312,
      "grad_norm": 0.07447333259261675,
      "learning_rate": 9.753155265885265e-05,
      "loss": 0.0291,
      "step": 94160
    },
    {
      "epoch": 0.301376,
      "grad_norm": 0.055388936824571765,
      "learning_rate": 9.753051264847251e-05,
      "loss": 0.0331,
      "step": 94180
    },
    {
      "epoch": 0.30144,
      "grad_norm": 0.057413310152814374,
      "learning_rate": 9.75294724245964e-05,
      "loss": 0.0277,
      "step": 94200
    },
    {
      "epoch": 0.301504,
      "grad_norm": 0.08903227362528963,
      "learning_rate": 9.752843198722901e-05,
      "loss": 0.0328,
      "step": 94220
    },
    {
      "epoch": 0.301568,
      "grad_norm": 0.07969510804598866,
      "learning_rate": 9.752739133637496e-05,
      "loss": 0.0316,
      "step": 94240
    },
    {
      "epoch": 0.301632,
      "grad_norm": 0.08473942158004477,
      "learning_rate": 9.752635047203899e-05,
      "loss": 0.0287,
      "step": 94260
    },
    {
      "epoch": 0.301696,
      "grad_norm": 0.05706151591545048,
      "learning_rate": 9.752530939422573e-05,
      "loss": 0.0268,
      "step": 94280
    },
    {
      "epoch": 0.30176,
      "grad_norm": 0.06707821647345207,
      "learning_rate": 9.752426810293987e-05,
      "loss": 0.0301,
      "step": 94300
    },
    {
      "epoch": 0.301824,
      "grad_norm": 0.059785595828966934,
      "learning_rate": 9.75232265981861e-05,
      "loss": 0.032,
      "step": 94320
    },
    {
      "epoch": 0.301888,
      "grad_norm": 0.0512415827104712,
      "learning_rate": 9.752218487996909e-05,
      "loss": 0.0288,
      "step": 94340
    },
    {
      "epoch": 0.301952,
      "grad_norm": 0.06911418771091334,
      "learning_rate": 9.752114294829349e-05,
      "loss": 0.0275,
      "step": 94360
    },
    {
      "epoch": 0.302016,
      "grad_norm": 0.08650974095761418,
      "learning_rate": 9.752010080316402e-05,
      "loss": 0.0278,
      "step": 94380
    },
    {
      "epoch": 0.30208,
      "grad_norm": 0.09545349751644608,
      "learning_rate": 9.751905844458535e-05,
      "loss": 0.0277,
      "step": 94400
    },
    {
      "epoch": 0.302144,
      "grad_norm": 0.08237602237927703,
      "learning_rate": 9.751801587256217e-05,
      "loss": 0.0286,
      "step": 94420
    },
    {
      "epoch": 0.302208,
      "grad_norm": 0.06379308069638082,
      "learning_rate": 9.751697308709915e-05,
      "loss": 0.0283,
      "step": 94440
    },
    {
      "epoch": 0.302272,
      "grad_norm": 0.055015364650830116,
      "learning_rate": 9.751593008820097e-05,
      "loss": 0.0294,
      "step": 94460
    },
    {
      "epoch": 0.302336,
      "grad_norm": 0.07225704636302945,
      "learning_rate": 9.751488687587232e-05,
      "loss": 0.0293,
      "step": 94480
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.061038777135115484,
      "learning_rate": 9.751384345011787e-05,
      "loss": 0.0283,
      "step": 94500
    },
    {
      "epoch": 0.302464,
      "grad_norm": 0.04907033046012558,
      "learning_rate": 9.751279981094234e-05,
      "loss": 0.0283,
      "step": 94520
    },
    {
      "epoch": 0.302528,
      "grad_norm": 0.0680471578699037,
      "learning_rate": 9.75117559583504e-05,
      "loss": 0.0303,
      "step": 94540
    },
    {
      "epoch": 0.302592,
      "grad_norm": 0.07070786385281531,
      "learning_rate": 9.751071189234675e-05,
      "loss": 0.0296,
      "step": 94560
    },
    {
      "epoch": 0.302656,
      "grad_norm": 0.059115955144646536,
      "learning_rate": 9.750966761293606e-05,
      "loss": 0.0327,
      "step": 94580
    },
    {
      "epoch": 0.30272,
      "grad_norm": 0.05771918871239152,
      "learning_rate": 9.750862312012303e-05,
      "loss": 0.0323,
      "step": 94600
    },
    {
      "epoch": 0.302784,
      "grad_norm": 0.04967366675824461,
      "learning_rate": 9.750757841391236e-05,
      "loss": 0.03,
      "step": 94620
    },
    {
      "epoch": 0.302848,
      "grad_norm": 0.06555586395922491,
      "learning_rate": 9.750653349430873e-05,
      "loss": 0.0277,
      "step": 94640
    },
    {
      "epoch": 0.302912,
      "grad_norm": 0.058920360079252825,
      "learning_rate": 9.750548836131684e-05,
      "loss": 0.0285,
      "step": 94660
    },
    {
      "epoch": 0.302976,
      "grad_norm": 0.0460230943989658,
      "learning_rate": 9.750444301494139e-05,
      "loss": 0.0308,
      "step": 94680
    },
    {
      "epoch": 0.30304,
      "grad_norm": 0.04231715216312257,
      "learning_rate": 9.750339745518705e-05,
      "loss": 0.0286,
      "step": 94700
    },
    {
      "epoch": 0.303104,
      "grad_norm": 0.07388294955860458,
      "learning_rate": 9.750235168205855e-05,
      "loss": 0.0289,
      "step": 94720
    },
    {
      "epoch": 0.303168,
      "grad_norm": 0.08791046597744546,
      "learning_rate": 9.750130569556057e-05,
      "loss": 0.0318,
      "step": 94740
    },
    {
      "epoch": 0.303232,
      "grad_norm": 0.06405538489248172,
      "learning_rate": 9.75002594956978e-05,
      "loss": 0.0262,
      "step": 94760
    },
    {
      "epoch": 0.303296,
      "grad_norm": 0.054764885265559456,
      "learning_rate": 9.749921308247496e-05,
      "loss": 0.0298,
      "step": 94780
    },
    {
      "epoch": 0.30336,
      "grad_norm": 0.07739645263379448,
      "learning_rate": 9.749816645589674e-05,
      "loss": 0.0314,
      "step": 94800
    },
    {
      "epoch": 0.303424,
      "grad_norm": 0.05386418854229771,
      "learning_rate": 9.749711961596784e-05,
      "loss": 0.0324,
      "step": 94820
    },
    {
      "epoch": 0.303488,
      "grad_norm": 0.12389060784160438,
      "learning_rate": 9.749607256269296e-05,
      "loss": 0.0303,
      "step": 94840
    },
    {
      "epoch": 0.303552,
      "grad_norm": 0.09090788685668025,
      "learning_rate": 9.74950252960768e-05,
      "loss": 0.0319,
      "step": 94860
    },
    {
      "epoch": 0.303616,
      "grad_norm": 0.1360376053731009,
      "learning_rate": 9.749397781612409e-05,
      "loss": 0.0323,
      "step": 94880
    },
    {
      "epoch": 0.30368,
      "grad_norm": 0.09341251073244318,
      "learning_rate": 9.74929301228395e-05,
      "loss": 0.0303,
      "step": 94900
    },
    {
      "epoch": 0.303744,
      "grad_norm": 0.055143071529215694,
      "learning_rate": 9.749188221622776e-05,
      "loss": 0.0301,
      "step": 94920
    },
    {
      "epoch": 0.303808,
      "grad_norm": 0.08780404272319904,
      "learning_rate": 9.749083409629356e-05,
      "loss": 0.0289,
      "step": 94940
    },
    {
      "epoch": 0.303872,
      "grad_norm": 0.06374780153433633,
      "learning_rate": 9.748978576304162e-05,
      "loss": 0.0312,
      "step": 94960
    },
    {
      "epoch": 0.303936,
      "grad_norm": 0.0760821747070278,
      "learning_rate": 9.748873721647664e-05,
      "loss": 0.0256,
      "step": 94980
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.11453883299068271,
      "learning_rate": 9.748768845660334e-05,
      "loss": 0.0282,
      "step": 95000
    },
    {
      "epoch": 0.304064,
      "grad_norm": 0.07998729821796635,
      "learning_rate": 9.748663948342644e-05,
      "loss": 0.031,
      "step": 95020
    },
    {
      "epoch": 0.304128,
      "grad_norm": 0.1033771312945872,
      "learning_rate": 9.748559029695061e-05,
      "loss": 0.0284,
      "step": 95040
    },
    {
      "epoch": 0.304192,
      "grad_norm": 0.044207039882107196,
      "learning_rate": 9.748454089718062e-05,
      "loss": 0.0266,
      "step": 95060
    },
    {
      "epoch": 0.304256,
      "grad_norm": 0.08766516195245479,
      "learning_rate": 9.748349128412113e-05,
      "loss": 0.0308,
      "step": 95080
    },
    {
      "epoch": 0.30432,
      "grad_norm": 0.06853870518347974,
      "learning_rate": 9.74824414577769e-05,
      "loss": 0.0313,
      "step": 95100
    },
    {
      "epoch": 0.304384,
      "grad_norm": 0.10316892233800863,
      "learning_rate": 9.748139141815261e-05,
      "loss": 0.0296,
      "step": 95120
    },
    {
      "epoch": 0.304448,
      "grad_norm": 0.054818415540439924,
      "learning_rate": 9.7480341165253e-05,
      "loss": 0.0264,
      "step": 95140
    },
    {
      "epoch": 0.304512,
      "grad_norm": 0.05612375000815914,
      "learning_rate": 9.747929069908277e-05,
      "loss": 0.0291,
      "step": 95160
    },
    {
      "epoch": 0.304576,
      "grad_norm": 0.07442466363001046,
      "learning_rate": 9.747824001964665e-05,
      "loss": 0.0335,
      "step": 95180
    },
    {
      "epoch": 0.30464,
      "grad_norm": 0.048591995862759696,
      "learning_rate": 9.747718912694935e-05,
      "loss": 0.029,
      "step": 95200
    },
    {
      "epoch": 0.304704,
      "grad_norm": 0.06145006317758279,
      "learning_rate": 9.74761380209956e-05,
      "loss": 0.0273,
      "step": 95220
    },
    {
      "epoch": 0.304768,
      "grad_norm": 0.10021955076680264,
      "learning_rate": 9.747508670179011e-05,
      "loss": 0.0332,
      "step": 95240
    },
    {
      "epoch": 0.304832,
      "grad_norm": 0.06274187059524505,
      "learning_rate": 9.747403516933763e-05,
      "loss": 0.0303,
      "step": 95260
    },
    {
      "epoch": 0.304896,
      "grad_norm": 0.07070028183757589,
      "learning_rate": 9.747298342364284e-05,
      "loss": 0.0327,
      "step": 95280
    },
    {
      "epoch": 0.30496,
      "grad_norm": 0.03639384910484367,
      "learning_rate": 9.747193146471051e-05,
      "loss": 0.028,
      "step": 95300
    },
    {
      "epoch": 0.305024,
      "grad_norm": 0.055260214284431855,
      "learning_rate": 9.747087929254532e-05,
      "loss": 0.027,
      "step": 95320
    },
    {
      "epoch": 0.305088,
      "grad_norm": 0.08552672212087975,
      "learning_rate": 9.746982690715206e-05,
      "loss": 0.031,
      "step": 95340
    },
    {
      "epoch": 0.305152,
      "grad_norm": 0.08830685513841095,
      "learning_rate": 9.746877430853538e-05,
      "loss": 0.0278,
      "step": 95360
    },
    {
      "epoch": 0.305216,
      "grad_norm": 0.08341111441675421,
      "learning_rate": 9.746772149670005e-05,
      "loss": 0.0294,
      "step": 95380
    },
    {
      "epoch": 0.30528,
      "grad_norm": 0.05592153437164781,
      "learning_rate": 9.746666847165077e-05,
      "loss": 0.0299,
      "step": 95400
    },
    {
      "epoch": 0.305344,
      "grad_norm": 0.050315700205101975,
      "learning_rate": 9.746561523339232e-05,
      "loss": 0.0332,
      "step": 95420
    },
    {
      "epoch": 0.305408,
      "grad_norm": 0.06599171782823489,
      "learning_rate": 9.746456178192942e-05,
      "loss": 0.0332,
      "step": 95440
    },
    {
      "epoch": 0.305472,
      "grad_norm": 0.13047133943811084,
      "learning_rate": 9.746350811726677e-05,
      "loss": 0.031,
      "step": 95460
    },
    {
      "epoch": 0.305536,
      "grad_norm": 0.12478517770615456,
      "learning_rate": 9.74624542394091e-05,
      "loss": 0.0292,
      "step": 95480
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.049734732453163684,
      "learning_rate": 9.746140014836118e-05,
      "loss": 0.0279,
      "step": 95500
    }
  ],
  "logging_steps": 20,
  "max_steps": 937500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
