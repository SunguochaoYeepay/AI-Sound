# 音频混合引擎设计

## 🎯 功能目标

基于时间轴控制文件，将多轨音频（对话、环境音、音效）智能混合成最终的沉浸式音频体验。

## 🎛️ 核心技术架构

### 音频混合流水线
```python
class AudioMixingEngine:
    def __init__(self):
        self.audio_processor = AudioProcessor()
        self.quality_analyzer = AudioQualityAnalyzer()
        self.export_manager = AudioExportManager()
    
    def mix_audio(self, timeline: Timeline) -> MixedAudio:
        # 1. 预处理所有音频轨道
        processed_tracks = self._preprocess_tracks(timeline.tracks)
        
        # 2. 执行多轨混合
        mixed_audio = self._perform_mixing(processed_tracks, timeline)
        
        # 3. 后处理和质量优化
        enhanced_audio = self._post_process(mixed_audio)
        
        # 4. 质量分析和验证
        quality_report = self._analyze_quality(enhanced_audio)
        
        return MixedAudio(enhanced_audio, quality_report)
```

## 🔧 音频预处理模块

### 1. 音频标准化
```python
def _normalize_audio_tracks(self, tracks: List[AudioTrack]) -> List[AudioTrack]:
    """统一音频格式和质量"""
    
    normalized_tracks = []
    
    for track in tracks:
        # 标准化采样率
        if track.sample_rate != self.target_sample_rate:
            track = self._resample_audio(track, self.target_sample_rate)
        
        # 标准化声道数
        if track.channels != self.target_channels:
            track = self._convert_channels(track, self.target_channels)
        
        # 标准化位深度
        if track.bit_depth != self.target_bit_depth:
            track = self._convert_bit_depth(track, self.target_bit_depth)
        
        # 音频增益标准化
        track = self._normalize_gain(track)
        
        normalized_tracks.append(track)
    
    return normalized_tracks

def _normalize_gain(self, audio_track: AudioTrack) -> AudioTrack:
    """音频增益标准化"""
    
    # 分析音频峰值
    peak_level = audio_track.get_peak_level()
    rms_level = audio_track.get_rms_level()
    
    # 根据轨道类型设置目标电平
    if audio_track.type == "dialogue":
        target_rms = -12.0  # dB
    elif audio_track.type == "environment":
        target_rms = -18.0  # dB
    elif audio_track.type == "effects":
        target_rms = -15.0  # dB
    
    # 计算增益调整
    gain_adjustment = target_rms - rms_level
    
    # 应用增益，确保不削波
    max_gain = -1.0 - peak_level  # 留1dB余量
    final_gain = min(gain_adjustment, max_gain)
    
    return audio_track.apply_gain(final_gain)
```

### 2. 音频分段处理
```python
def _segment_audio_tracks(self, tracks: List[AudioTrack], timeline: Timeline) -> List[AudioSegment]:
    """根据时间轴分段处理音频"""
    
    segments = []
    
    for track in tracks:
        for timeline_segment in timeline.get_segments_for_track(track.type):
            # 提取对应时间段的音频
            audio_segment = track.extract_segment(
                start=timeline_segment.start,
                end=timeline_segment.end
            )
            
            # 应用淡入淡出
            if timeline_segment.fade_in > 0:
                audio_segment = audio_segment.fade_in(timeline_segment.fade_in * 1000)  # ms
            
            if timeline_segment.fade_out > 0:
                audio_segment = audio_segment.fade_out(timeline_segment.fade_out * 1000)  # ms
            
            # 应用音量调节
            volume_db = timeline_segment.volume_db
            audio_segment = audio_segment.apply_gain(volume_db)
            
            segments.append({
                "segment": audio_segment,
                "start_time": timeline_segment.start,
                "end_time": timeline_segment.end,
                "track_type": track.type,
                "metadata": timeline_segment.metadata
            })
    
    return segments
```

## 🎵 智能混合算法

### 1. 多轨混合核心算法
```python
def _perform_intelligent_mixing(self, segments: List[AudioSegment], timeline: Timeline) -> AudioTrack:
    """执行智能多轨混合"""
    
    # 创建主音轨（最长时长）
    total_duration = timeline.total_duration
    master_track = AudioTrack.create_silence(
        duration=total_duration,
        sample_rate=self.target_sample_rate,
        channels=self.target_channels
    )
    
    # 按轨道类型分组
    track_groups = self._group_segments_by_type(segments)
    
    # 按优先级混合轨道
    mixing_order = ["environment", "effects", "dialogue"]  # 对话轨最后混合，保证清晰度
    
    for track_type in mixing_order:
        if track_type in track_groups:
            master_track = self._mix_track_group(
                master_track, 
                track_groups[track_type],
                mix_strategy=self._get_mix_strategy(track_type)
            )
    
    return master_track

def _mix_track_group(self, master_track: AudioTrack, segments: List[AudioSegment], mix_strategy: str) -> AudioTrack:
    """混合单个轨道组"""
    
    for segment in segments:
        start_sample = int(segment.start_time * self.target_sample_rate)
        
        if mix_strategy == "overlay":
            # 叠加混合（适用于环境音）
            master_track = master_track.overlay(segment.audio, position=start_sample)
        
        elif mix_strategy == "ducking":
            # 闪避混合（环境音在对话时自动降低）
            master_track = self._apply_ducking(master_track, segment, start_sample)
        
        elif mix_strategy == "priority":
            # 优先级混合（对话轨优先）
            master_track = self._apply_priority_mix(master_track, segment, start_sample)
    
    return master_track
```

### 2. 智能闪避（Ducking）算法
```python
def _apply_intelligent_ducking(self, background_track: AudioTrack, dialogue_segments: List[AudioSegment]) -> AudioTrack:
    """智能闪避：对话时自动降低背景音"""
    
    ducked_track = background_track.copy()
    
    for dialogue_segment in dialogue_segments:
        start_time = dialogue_segment.start_time
        end_time = dialogue_segment.end_time
        
        # 分析对话音量
        dialogue_rms = dialogue_segment.audio.get_rms_level()
        
        # 计算闪避参数
        duck_amount = self._calculate_duck_amount(dialogue_rms)
        duck_attack = 0.1  # 100ms attack
        duck_release = 0.3  # 300ms release
        
        # 应用闪避效果
        ducked_track = ducked_track.apply_ducking(
            start_time=start_time - duck_attack,
            end_time=end_time + duck_release,
            reduction_db=duck_amount,
            attack_time=duck_attack,
            release_time=duck_release
        )
    
    return ducked_track

def _calculate_duck_amount(self, dialogue_rms: float) -> float:
    """根据对话音量计算闪避量"""
    
    # 对话越响，背景音降低越多
    if dialogue_rms > -6:  # 很响的对话
        return -8.0  # 背景音降低8dB
    elif dialogue_rms > -12:  # 正常对话
        return -5.0  # 背景音降低5dB
    else:  # 轻声对话
        return -3.0  # 背景音降低3dB
```

### 3. 动态范围控制
```python
def _apply_dynamic_range_control(self, audio_track: AudioTrack) -> AudioTrack:
    """应用动态范围控制，确保音频平衡"""
    
    # 多段压缩器设置
    compressor_settings = {
        "low_freq": {
            "threshold": -20.0,
            "ratio": 3.0,
            "attack": 10.0,
            "release": 50.0
        },
        "mid_freq": {
            "threshold": -15.0,
            "ratio": 4.0,
            "attack": 5.0,
            "release": 30.0
        },
        "high_freq": {
            "threshold": -12.0,
            "ratio": 2.5,
            "attack": 2.0,
            "release": 20.0
        }
    }
    
    # 应用多段压缩
    compressed_track = audio_track
    for freq_band, settings in compressor_settings.items():
        compressed_track = compressed_track.apply_multiband_compressor(
            freq_band=freq_band,
            **settings
        )
    
    # 限制器防止削波
    limited_track = compressed_track.apply_limiter(
        threshold=-1.0,
        release=5.0
    )
    
    return limited_track
```

## 🎚️ 音频后处理模块

### 1. 音质增强
```python
def _enhance_audio_quality(self, mixed_audio: AudioTrack) -> AudioTrack:
    """音质增强处理"""
    
    enhanced_audio = mixed_audio
    
    # 1. 空间增强
    enhanced_audio = self._apply_spatial_enhancement(enhanced_audio)
    
    # 2. 频率平衡
    enhanced_audio = self._apply_eq_optimization(enhanced_audio)
    
    # 3. 立体声扩展
    enhanced_audio = self._apply_stereo_widening(enhanced_audio)
    
    # 4. 细节增强
    enhanced_audio = self._apply_detail_enhancement(enhanced_audio)
    
    return enhanced_audio

def _apply_spatial_enhancement(self, audio: AudioTrack) -> AudioTrack:
    """空间音效增强"""
    
    # 为不同类型的音频应用不同的空间效果
    enhanced = audio
    
    # 对话：保持中央定位，轻微混响
    dialogue_reverb = Reverb(
        room_size=0.2,
        damping=0.7,
        wet_level=0.15
    )
    
    # 环境音：增加空间感
    environment_reverb = Reverb(
        room_size=0.6,
        damping=0.4,
        wet_level=0.3
    )
    
    return enhanced.apply_contextual_reverb(
        dialogue_reverb=dialogue_reverb,
        environment_reverb=environment_reverb
    )
```

### 2. 自适应均衡
```python
def _apply_adaptive_eq(self, audio: AudioTrack) -> AudioTrack:
    """自适应频率均衡"""
    
    # 分析频谱特征
    spectrum_analysis = audio.analyze_spectrum()
    
    # 检测问题频段
    problem_frequencies = self._detect_problematic_frequencies(spectrum_analysis)
    
    # 生成均衡曲线
    eq_curve = self._generate_eq_curve(spectrum_analysis, problem_frequencies)
    
    # 应用均衡
    equalized_audio = audio.apply_parametric_eq(eq_curve)
    
    return equalized_audio

def _detect_problematic_frequencies(self, spectrum: SpectrumAnalysis) -> List[ProblemFreq]:
    """检测有问题的频段"""
    
    problems = []
    
    # 检测低频轰鸣
    if spectrum.low_freq_energy > 0.3:
        problems.append(ProblemFreq(
            freq=80,
            type="rumble",
            severity=spectrum.low_freq_energy
        ))
    
    # 检测中频泥泞
    if spectrum.mid_freq_clarity < 0.7:
        problems.append(ProblemFreq(
            freq=500,
            type="muddy",
            severity=1.0 - spectrum.mid_freq_clarity
        ))
    
    # 检测高频刺激
    if spectrum.high_freq_harshness > 0.4:
        problems.append(ProblemFreq(
            freq=8000,
            type="harsh",
            severity=spectrum.high_freq_harshness
        ))
    
    return problems
```

## 📊 质量分析与验证

### 1. 音频质量指标
```python
class AudioQualityAnalyzer:
    def analyze_quality(self, mixed_audio: AudioTrack) -> QualityReport:
        """分析音频质量"""
        
        report = QualityReport()
        
        # 1. 动态范围分析
        report.dynamic_range = self._analyze_dynamic_range(mixed_audio)
        
        # 2. 频率平衡分析
        report.frequency_balance = self._analyze_frequency_balance(mixed_audio)
        
        # 3. 立体声成像分析
        report.stereo_imaging = self._analyze_stereo_imaging(mixed_audio)
        
        # 4. 声音清晰度分析
        report.clarity = self._analyze_clarity(mixed_audio)
        
        # 5. 整体响度分析
        report.loudness = self._analyze_loudness(mixed_audio)
        
        # 6. 生成建议
        report.recommendations = self._generate_quality_recommendations(report)
        
        return report
    
    def _analyze_dynamic_range(self, audio: AudioTrack) -> DynamicRangeMetrics:
        """动态范围分析"""
        
        peak_level = audio.get_peak_level()
        rms_level = audio.get_rms_level()
        crest_factor = peak_level - rms_level
        
        return DynamicRangeMetrics(
            peak_level=peak_level,
            rms_level=rms_level,
            crest_factor=crest_factor,
            dr_score=self._calculate_dr_score(audio)
        )
```

### 2. 自动质量优化
```python
def _auto_optimize_quality(self, mixed_audio: AudioTrack, quality_report: QualityReport) -> AudioTrack:
    """基于质量分析自动优化音频"""
    
    optimized_audio = mixed_audio
    
    # 根据质量报告应用优化
    for issue in quality_report.issues:
        if issue.type == "low_dynamic_range":
            optimized_audio = self._enhance_dynamic_range(optimized_audio)
        
        elif issue.type == "frequency_imbalance":
            optimized_audio = self._correct_frequency_balance(optimized_audio, issue.parameters)
        
        elif issue.type == "poor_stereo_imaging":
            optimized_audio = self._improve_stereo_imaging(optimized_audio)
        
        elif issue.type == "clarity_issues":
            optimized_audio = self._enhance_clarity(optimized_audio)
    
    return optimized_audio
```

## 🚀 导出和格式支持

### 多格式导出
```python
class AudioExportManager:
    def export_mixed_audio(self, mixed_audio: AudioTrack, export_config: ExportConfig) -> ExportResult:
        """导出混合音频到多种格式"""
        
        results = []
        
        for format_config in export_config.formats:
            exported_file = self._export_to_format(mixed_audio, format_config)
            
            # 验证导出质量
            quality_check = self._verify_export_quality(exported_file, format_config)
            
            results.append(ExportResult(
                file_path=exported_file.path,
                format=format_config.format,
                quality_score=quality_check.score,
                file_size=exported_file.size,
                duration=exported_file.duration
            ))
        
        return ExportResults(results)

EXPORT_FORMATS = {
    "high_quality": {
        "format": "wav",
        "sample_rate": 48000,
        "bit_depth": 24,
        "channels": 2
    },
    "streaming": {
        "format": "mp3",
        "bitrate": 320,
        "vbr": True,
        "channels": 2
    },
    "mobile": {
        "format": "aac",
        "bitrate": 128,
        "profile": "LC",
        "channels": 2
    }
}
```

## 📋 API接口设计

```python
@router.post("/api/v1/audio-mixing/mix")
async def mix_audio(request: AudioMixingRequest):
    """执行音频混合"""
    
    mixer = AudioMixingEngine()
    
    try:
        # 执行混合
        result = mixer.mix_audio(request.timeline)
        
        # 导出音频
        export_results = mixer.export_audio(
            result.mixed_audio,
            request.export_config
        )
        
        return {
            "success": True,
            "data": {
                "mixed_audio_url": export_results.primary_file.url,
                "alternative_formats": [f.url for f in export_results.alternative_files],
                "quality_report": result.quality_report.to_dict(),
                "mixing_stats": result.mixing_stats
            }
        }
        
    except AudioMixingException as e:
        return {
            "success": False,
            "error": {
                "type": "mixing_error",
                "message": str(e),
                "details": e.details
            }
        }

@router.get("/api/v1/audio-mixing/preview")
async def preview_mix(timeline_id: str, preview_duration: int = 30):
    """生成混合预览（前30秒）"""
    
    mixer = AudioMixingEngine()
    
    # 生成预览片段
    preview_audio = mixer.generate_preview(
        timeline_id=timeline_id,
        duration=preview_duration
    )
    
    return {
        "success": True,
        "data": {
            "preview_url": preview_audio.url,
            "duration": preview_audio.duration,
            "quality_preview": preview_audio.quality_metrics
        }
    }
```

---

**总结**: 至此，环境音混合系统的核心技术模块设计完成。包括场景分析、时间轴生成、音频混合三大核心引擎，能够实现从"听书"到"听电影"的智能化音频体验升级。