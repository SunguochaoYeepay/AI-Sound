# 环境音混合系统设计方案

## 🎯 项目目标

将 **TTS3对话音频** + **TangoFlux环境音** 智能混合，实现从"听书"到"听电影"的沉浸式音频体验。

## 🏗️ 系统架构

```
小说JSON → [场景分析] → [时间轴规划] → [顺序音频生成] → [智能混合] → 沉浸式音频
                ↓             ↓             ↓            ↓
            场景标签      时间轴控制文件      分离音频文件    多轨混音引擎
                                              ↓
                                        1.对话音频.wav
                                        2.环境音.wav  
                                        3.音效.wav
```

## 🎵 核心技术方案

### 方案1：后端智能混合 (推荐主方案)
- **技术栈**：Python + pydub + ffmpeg
- **优势**：质量可控、用户体验好
- **适用**：标准播放模式

### 方案2：前端实时混合 (高级方案)  
- **技术栈**：Web Audio API + AudioContext
- **优势**：用户可自定义、服务器压力小
- **适用**：高级用户自定义模式

### 方案3：混合策略 (最终方案)
- **默认**：后端预混合，即用体验
- **高级**：前端分轨播放，个性化调节

## 🕐 核心挑战：时间轴同步

### 问题
```
对话音频: [0-5s] [5-12s] [12-18s] [18-25s]
场景描述: "雨夜" → "室内" → "街道" → "咖啡厅"  
环境音应该: 何时开始？持续多久？何时切换？
```

### 解决策略
1. **智能场景检测**：AI提取场景信息
2. **时长预估**：基于文本预估音频时长
3. **动态调整**：根据实际TTS输出调整时间轴
4. **平滑过渡**：场景切换时的淡入淡出

## 📊 数据流设计

### 输入：增强的JSON结构
```json
{
  "segments": [
    {
      "type": "scene_description",
      "content": "夜深了，外面下着小雨",
      "scene_tags": {
        "location": "outdoor",
        "weather": "rainy", 
        "time": "night",
        "atmosphere": "calm"
      },
      "environment_sound": "rain_light.wav",
      "duration_estimate": 3.5
    },
    {
      "type": "dialogue",
      "content": "你怎么还不睡？", 
      "speaker": "张三",
      "voice_id": "voice_001",
      "environment_sound": "rain_light.wav",
      "duration_estimate": 2.8
    }
  ]
}
```

### 输出：时间轴控制文件
```json
{
  "total_duration": 180.5,
  "tracks": {
    "dialogue": [
      {"start": 0, "end": 3.2, "file": "seg_001.wav"},
      {"start": 3.5, "end": 7.8, "file": "seg_002.wav"}
    ],
    "environment": [
      {"start": 0, "end": 15.0, "file": "rain.wav", "volume": 0.3},
      {"start": 15.0, "end": 30.0, "file": "indoor.wav", "volume": 0.2, "fade_in": 2.0}
    ],
    "effects": [
      {"start": 12.5, "end": 13.0, "file": "door_close.wav", "volume": 0.6}
    ]
  }
}
```

## 🎛️ 多轨音频设计

### 轨道分层
- **轨道1**：主对话 (TTS3输出，-6dB到0dB)
- **轨道2**：环境音底层 (持续性，-20dB到-12dB)  
- **轨道3**：音效层 (瞬间音效，-10dB到-3dB)
- **轨道4**：氛围层 (情绪背景，-25dB到-15dB)

### 音量控制策略
- **对话时**：环境音降低到-18dB
- **描述时**：环境音提升到-12dB
- **紧张情节**：环境音增强到-8dB
- **平静情节**：环境音降低到-20dB

## 🔧 技术实现路径

### 阶段1：基础功能 (MVP)
1. 场景标签提取
2. 基础时间轴生成
3. 简单音频混合
4. 基本播放功能

### 阶段2：智能优化
1. AI驱动的场景检测
2. 动态音量调节
3. 智能场景切换
4. 音频质量优化

### 阶段3：高级功能
1. 用户自定义混音
2. 实时音效调节
3. 多种混音预设
4. 导出功能

## 📋 开发任务分解

### 后端任务
- [ ] 场景分析服务 (scene_analyzer.py)
- [ ] 时间轴生成器 (timeline_generator.py)  
- [ ] 音频混合引擎 (audio_mixer.py)
- [ ] API接口设计 (mixing_api.py)

### 前端任务  
- [ ] 混音控制面板
- [ ] 实时播放器
- [ ] 音量调节器
- [ ] 预览功能

### 数据库任务
- [ ] 混音配置表
- [ ] 时间轴缓存表
- [ ] 音效资源表

## 🎯 预期效果

### 用户体验
- 🎧 **沉浸感**：从单纯朗读到电影级音频体验
- 🎛️ **可控性**：用户可调节环境音强度
- 🚀 **流畅性**：无缝播放，不中断体验

### 技术效果
- ⚡ **性能**：后端预混合保证播放流畅
- 🎵 **质量**：专业级音频混合效果
- 🔄 **扩展性**：支持更多音效类型和混音模式

---

**下一步**：详细设计各个技术模块的实现方案