# 环境音混合系统实现计划

## 🚀 开发路线图

### 阶段1：MVP开发 (2-3周)
**目标**: 实现基础的环境音混合功能

#### Week 1: 场景分析基础框架
- [ ] **场景分析服务**
  - [x] 创建 `app/services/scene_analyzer.py`
  - [ ] 实现基础关键词匹配算法
  - [ ] 集成现有的Ollama AI模型
  - [ ] 创建场景标签数据库表
  - [ ] API接口开发 `/api/v1/scene-analysis/*`

- [ ] **数据库设计**
  ```sql
  -- 场景信息表
  CREATE TABLE scene_info (
      id SERIAL PRIMARY KEY,
      segment_id INTEGER REFERENCES text_segments(id),
      location VARCHAR(50),
      weather VARCHAR(50), 
      time VARCHAR(50),
      atmosphere VARCHAR(50),
      confidence FLOAT,
      created_at TIMESTAMP DEFAULT NOW()
  );
  
  -- 环境音资源表
  CREATE TABLE environment_sounds (
      id SERIAL PRIMARY KEY,
      file_name VARCHAR(255),
      scene_tags JSONB,
      duration FLOAT,
      file_path VARCHAR(255),
      created_at TIMESTAMP DEFAULT NOW()
  );
  ```

#### Week 2: 时间轴生成器
- [ ] **时间轴服务**
  - [ ] 创建 `app/services/timeline_generator.py`
  - [ ] 实现文本时长预估算法
  - [ ] 场景持续性分析逻辑
  - [ ] 时间轴数据结构设计
  - [ ] API接口 `/api/v1/timeline/*`

- [ ] **与现有系统集成**
  - [ ] 集成到 `SynthesisCenter.vue`
  - [ ] 修改合成流程，增加时间轴生成步骤
  - [ ] 更新数据库schema，支持时间轴存储

#### Week 3: 基础音频混合
- [ ] **音频混合引擎**
  - [ ] 创建 `app/services/audio_mixer.py`
  - [ ] 使用pydub实现基础混合功能
  - [ ] 简单的音量调节算法
  - [ ] 基础导出功能

- [ ] **前端界面**
  - [ ] 在 `SynthesisCenter.vue` 中添加环境音选项
  - [ ] 音量调节滑块
  - [ ] 预览功能
  - [ ] 导出多种格式

### 阶段2：智能优化 (3-4周)

#### Week 4-5: AI驱动增强
- [ ] **智能场景检测**
  - [ ] 训练/微调场景分析模型
  - [ ] 提升场景识别准确率到85%+
  - [ ] 实现场景切换点精确检测
  - [ ] 添加场景置信度评分

- [ ] **智能时间轴优化**
  - [ ] 基于实际TTS输出调整时间轴
  - [ ] 时间轴漂移自动修正
  - [ ] 冲突检测和解决算法

#### Week 6-7: 高级混合算法
- [ ] **智能闪避（Ducking）**
  - [ ] 对话时环境音自动降低
  - [ ] 根据对话音量动态调节
  - [ ] 平滑的淡入淡出效果

- [ ] **音质优化**
  - [ ] 动态范围控制
  - [ ] 自适应均衡
  - [ ] 空间音效增强

### 阶段3：用户体验优化 (2-3周)

#### Week 8-9: 前端高级功能
- [ ] **混音控制面板**
  - [ ] 实时波形显示
  - [ ] 多轨道可视化时间轴
  - [ ] 精细的音量控制
  - [ ] 环境音库管理界面

- [ ] **用户自定义**
  - [ ] 混音预设保存/加载
  - [ ] 个人偏好设置
  - [ ] 混音效果实时预览

#### Week 10: 性能优化与测试
- [ ] **性能优化**
  - [ ] 音频处理流水线优化
  - [ ] 缓存策略优化
  - [ ] 并行处理支持

- [ ] **质量保证**
  - [ ] 完整测试套件
  - [ ] 性能基准测试
  - [ ] 用户接受测试

## 🔧 技术实现细节

### 1. 核心服务类设计
```python
# app/services/scene_analyzer.py
class SceneAnalyzer:
    def __init__(self):
        self.ollama_client = OllamaClient()
        self.keyword_matcher = KeywordMatcher()
    
    async def analyze_segments(self, segments: List[dict]) -> List[SceneInfo]:
        # 批量场景分析
        pass
    
    async def detect_scene_changes(self, scenes: List[SceneInfo]) -> List[SceneChange]:
        # 场景切换检测
        pass

# app/services/timeline_generator.py  
class TimelineGenerator:
    def __init__(self):
        self.scene_analyzer = SceneAnalyzer()
        self.duration_estimator = DurationEstimator()
    
    async def generate_timeline(self, segments: List[dict]) -> Timeline:
        # 生成完整时间轴
        pass
    
    async def adjust_timeline(self, timeline: Timeline, audio_files: List[str]) -> Timeline:
        # 基于实际音频调整
        pass

# app/services/audio_mixer.py
class AudioMixer:
    def __init__(self):
        self.processor = AudioProcessor()
        self.quality_analyzer = QualityAnalyzer()
    
    async def mix_audio(self, timeline: Timeline) -> MixedAudio:
        # 执行音频混合
        pass
    
    async def generate_preview(self, timeline: Timeline, duration: int = 30) -> PreviewAudio:
        # 生成预览
        pass
```

### 2. API路由集成
```python
# app/api/v1/__init__.py 中添加
from .environment_mixing import router as environment_mixing_router

api.include_router(environment_mixing_router, prefix="/environment-mixing", tags=["environment-mixing"])

# 新建 app/api/v1/environment_mixing.py
@router.post("/analyze-scenes")
async def analyze_scenes(request: SceneAnalysisRequest):
    # 场景分析接口
    pass

@router.post("/generate-timeline") 
async def generate_timeline(request: TimelineRequest):
    # 时间轴生成接口
    pass

@router.post("/mix-audio")
async def mix_audio(request: MixingRequest):
    # 音频混合接口
    pass
```

### 3. 前端组件集成
```vue
<!-- SynthesisCenter.vue 中添加环境音控制 -->
<template>
  <div class="synthesis-center">
    <!-- 现有内容 -->
    
    <!-- 新增：环境音混合控制面板 -->
    <a-card title="环境音设置" class="environment-section">
      <a-switch 
        v-model:checked="enableEnvironmentSound"
        checked-children="启用环境音" 
        un-checked-children="关闭环境音"
      />
      
      <div v-if="enableEnvironmentSound" class="environment-controls">
        <!-- 环境音音量控制 -->
        <div class="volume-control">
          <label>环境音音量:</label>
          <a-slider 
            v-model:value="environmentVolume"
            :min="0" 
            :max="100"
            :tooltip-formatter="(v) => `${v}%`"
          />
        </div>
        
        <!-- 混音预览 -->
        <a-button @click="previewMix" type="primary">
          预览混合效果
        </a-button>
      </div>
    </a-card>
  </div>
</template>

<script setup>
import { ref } from 'vue'
import { environmentMixingAPI } from '@/api/environmentMixing.js'

const enableEnvironmentSound = ref(true)
const environmentVolume = ref(30)

const previewMix = async () => {
  try {
    const result = await environmentMixingAPI.generatePreview({
      project_id: projectId.value,
      environment_volume: environmentVolume.value / 100
    })
    
    // 播放预览音频
    playPreviewAudio(result.preview_url)
  } catch (error) {
    console.error('预览生成失败:', error)
  }
}
</script>
```

## 📊 关键指标和验收标准

### 技术指标
- **场景识别准确率**: ≥85%
- **时间轴同步精度**: ±0.5秒
- **音频处理延迟**: <10秒/分钟音频
- **混合音频质量**: THD+N <0.1%
- **系统响应时间**: <3秒

### 用户体验指标
- **混合效果满意度**: ≥4.0/5.0
- **操作流程便捷性**: ≤3步完成基础设置
- **预览生成速度**: <5秒
- **音频导出成功率**: ≥99%

### 系统性能指标
- **并发处理能力**: 支持5个项目同时混音
- **存储空间效率**: 临时文件自动清理
- **内存使用**: <2GB峰值内存
- **CPU使用率**: <80%平均负载

## 🧪 测试策略

### 1. 单元测试
```python
# tests/test_scene_analyzer.py
def test_scene_detection():
    analyzer = SceneAnalyzer()
    
    # 测试室内场景识别
    text = "他坐在房间里，外面下着雨"
    scene = analyzer.analyze_scene(text)
    assert scene.location == "indoor"
    assert scene.weather == "rainy"

# tests/test_timeline_generator.py  
def test_timeline_generation():
    generator = TimelineGenerator()
    
    segments = [
        {"content": "你好", "type": "dialogue"},
        {"content": "雨夜", "type": "description"}
    ]
    timeline = generator.generate_timeline(segments)
    assert len(timeline.tracks) > 0

# tests/test_audio_mixer.py
def test_audio_mixing():
    mixer = AudioMixer()
    
    timeline = create_test_timeline()
    result = mixer.mix_audio(timeline)
    assert result.duration > 0
    assert result.quality_score > 0.8
```

### 2. 集成测试
- 完整的合成流程测试
- API接口兼容性测试  
- 前后端数据流测试
- 多用户并发测试

### 3. 用户验收测试
- 典型小说文本混音测试
- 不同场景类型覆盖测试
- 音质主观评价测试
- 界面易用性测试

## 📋 风险分析与应对

### 技术风险
| 风险 | 影响 | 概率 | 应对策略 |
|------|------|------|----------|
| AI场景识别准确率低 | 高 | 中 | 多模型集成，关键词兜底 |
| 音频同步精度差 | 高 | 中 | 多次校准，用户手动调节 |
| 性能瓶颈 | 中 | 高 | 异步处理，任务队列 |
| 音质下降 | 中 | 低 | 质量监控，自动优化 |

### 业务风险  
| 风险 | 影响 | 概率 | 应对策略 |
|------|------|------|----------|
| 用户学习成本高 | 中 | 中 | 默认预设，智能推荐 |
| 存储成本增加 | 低 | 高 | 压缩算法，定期清理 |
| 处理时间过长 | 中 | 中 | 预览功能，进度显示 |

## 🎯 成功标准

### MVP验收标准
- [ ] 能够识别基本场景（室内/室外，天气，时间）
- [ ] 能够生成基础时间轴控制文件
- [ ] 能够混合对话和环境音，导出音频文件
- [ ] 前端界面支持基本设置和预览
- [ ] 系统稳定性良好，无严重bug

### 最终版本标准
- [ ] 场景识别准确率达到85%以上
- [ ] 混合音频质量达到专业标准
- [ ] 用户满意度达到4.0/5.0以上
- [ ] 系统性能满足并发需求
- [ ] 完整的测试覆盖和文档

---

**总结**: 这个实现计划将分3个阶段，循序渐进地构建环境音混合系统。从MVP的基础功能开始，逐步增加AI智能化和用户体验优化，最终实现完整的"听电影"音频体验。