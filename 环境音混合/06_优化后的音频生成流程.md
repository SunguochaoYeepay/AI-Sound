# ä¼˜åŒ–åçš„éŸ³é¢‘ç”Ÿæˆæµç¨‹è®¾è®¡

## ğŸš¨ åŸæ–¹æ¡ˆé—®é¢˜åˆ†æ

### å¹¶è¡Œç”Ÿæˆçš„è‡´å‘½ç¼ºé™·
```
âŒ åŸæ–¹æ¡ˆ: TTS3 + TangoFlux å¹¶è¡Œè¿è¡Œ
é—®é¢˜: 
1. GPUæ˜¾å­˜çˆ†ç‚¸ (TTS3éœ€è¦å¤§é‡æ˜¾å­˜ï¼ŒTangoFluxä¹Ÿéœ€è¦)
2. èµ„æºç«äº‰å¯¼è‡´ç”Ÿæˆå¤±è´¥
3. ç³»ç»Ÿä¸ç¨³å®šï¼Œå®¹æ˜“å´©æºƒ
4. æ— æ³•æœ‰æ•ˆæ§åˆ¶èµ„æºåˆ†é…
```

## âœ… ä¼˜åŒ–åçš„é¡ºåºç”Ÿæˆæ–¹æ¡ˆ

### æ–°çš„å·¥ä½œæµç¨‹
```
å°è¯´JSON â†’ [åœºæ™¯åˆ†æ] â†’ [æ—¶é—´è½´è§„åˆ’] â†’ [é¡ºåºéŸ³é¢‘ç”Ÿæˆ] â†’ [æ™ºèƒ½æ··åˆ] â†’ æ²‰æµ¸å¼éŸ³é¢‘
                â†“             â†“             â†“            â†“
            åœºæ™¯æ ‡ç­¾      æ—¶é—´è½´æ§åˆ¶æ–‡ä»¶      åˆ†ç¦»éŸ³é¢‘æ–‡ä»¶    å¤šè½¨æ··éŸ³å¼•æ“
                                              â†“
                                        1.å¯¹è¯éŸ³é¢‘.wav
                                        2.ç¯å¢ƒéŸ³.wav
                                        3.éŸ³æ•ˆ.wav
```

### è¯¦ç»†çš„åˆ†æ­¥éª¤ç”Ÿæˆç­–ç•¥

#### é˜¶æ®µ1: å¯¹è¯éŸ³é¢‘ç”Ÿæˆ (TTS3)
```python
class SequentialAudioGenerator:
    def __init__(self):
        self.tts3_service = TTS3Service()
        self.tango_service = TangoFluxService()
        self.gpu_manager = GPUResourceManager()
    
    async def generate_dialogue_audio(self, timeline: Timeline) -> List[AudioFile]:
        """ç¬¬ä¸€é˜¶æ®µï¼šä¸“æ³¨ç”Ÿæˆæ‰€æœ‰å¯¹è¯éŸ³é¢‘"""
        
        dialogue_files = []
        
        # ç¡®ä¿TTS3ç‹¬å GPUèµ„æº
        async with self.gpu_manager.exclusive_lock("tts3"):
            
            for segment in timeline.dialogue_segments:
                # é€ä¸ªç”Ÿæˆå¯¹è¯éŸ³é¢‘
                audio_file = await self.tts3_service.synthesize(
                    text=segment.content,
                    voice_id=segment.voice_id,
                    emotion=segment.emotion
                )
                
                # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
                saved_path = await self._save_dialogue_audio(audio_file, segment.id)
                dialogue_files.append({
                    "segment_id": segment.id,
                    "file_path": saved_path,
                    "duration": audio_file.duration,
                    "speaker": segment.speaker
                })
                
                # æ›´æ–°å®é™…æ—¶é•¿åˆ°æ—¶é—´è½´
                timeline.update_actual_duration(segment.id, audio_file.duration)
        
        return dialogue_files
```

#### é˜¶æ®µ2: ç¯å¢ƒéŸ³ç”Ÿæˆ (TangoFlux)
```python
    async def generate_environment_audio(self, timeline: Timeline) -> List[AudioFile]:
        """ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆç¯å¢ƒéŸ³é¢‘"""
        
        environment_files = []
        
        # é‡Šæ”¾TTS3èµ„æºï¼ŒTangoFluxç‹¬å GPU
        async with self.gpu_manager.exclusive_lock("tango"):
            
            # åŸºäºæ›´æ–°åçš„æ—¶é—´è½´ç”Ÿæˆç¯å¢ƒéŸ³
            for env_segment in timeline.environment_segments:
                
                # ç”Ÿæˆç¯å¢ƒéŸ³æç¤ºè¯
                prompt = self._build_environment_prompt(env_segment)
                
                # ç”ŸæˆæŒ‡å®šæ—¶é•¿çš„ç¯å¢ƒéŸ³
                audio_file = await self.tango_service.generate(
                    prompt=prompt,
                    duration=env_segment.duration,
                    style=env_segment.style
                )
                
                # ä¿å­˜ç¯å¢ƒéŸ³æ–‡ä»¶
                saved_path = await self._save_environment_audio(audio_file, env_segment.id)
                environment_files.append({
                    "segment_id": env_segment.id,
                    "file_path": saved_path,
                    "duration": audio_file.duration,
                    "scene_type": env_segment.scene_type
                })
        
        return environment_files
```

#### é˜¶æ®µ3: éŸ³æ•ˆç”Ÿæˆ (å¯é€‰)
```python
    async def generate_effect_audio(self, timeline: Timeline) -> List[AudioFile]:
        """ç¬¬ä¸‰é˜¶æ®µï¼šç”Ÿæˆç‰¹æ®ŠéŸ³æ•ˆ"""
        
        effect_files = []
        
        # å¤ç”¨TangoFluxæˆ–ä½¿ç”¨ä¸“é—¨çš„éŸ³æ•ˆåº“
        async with self.gpu_manager.exclusive_lock("effects"):
            
            for effect in timeline.effect_segments:
                if effect.type == "generated":
                    # ä½¿ç”¨TangoFluxç”Ÿæˆ
                    audio_file = await self.tango_service.generate(
                        prompt=effect.prompt,
                        duration=effect.duration
                    )
                    saved_path = await self._save_effect_audio(audio_file, effect.id)
                
                elif effect.type == "library":
                    # ä»éŸ³æ•ˆåº“ä¸­é€‰æ‹©
                    audio_file = await self._load_from_effect_library(effect.library_id)
                    saved_path = audio_file.path
                
                effect_files.append({
                    "effect_id": effect.id,
                    "file_path": saved_path,
                    "duration": audio_file.duration,
                    "trigger_time": effect.start_time
                })
        
        return effect_files
```

## ğŸ›ï¸ æ™ºèƒ½æ··åˆé˜¶æ®µ

### åŸºäºæ–‡ä»¶çš„æ··åˆå¤„ç†
```python
class FileBasedAudioMixer:
    def __init__(self):
        self.audio_processor = AudioProcessor()
        self.timeline_adjuster = TimelineAdjuster()
    
    async def mix_separated_audio_files(
        self,
        dialogue_files: List[AudioFile],
        environment_files: List[AudioFile], 
        effect_files: List[AudioFile],
        timeline: Timeline
    ) -> MixedAudio:
        """åŸºäºåˆ†ç¦»æ–‡ä»¶çš„æ™ºèƒ½æ··åˆ"""
        
        # 1. è°ƒæ•´æ—¶é—´è½´ (åŸºäºå®é™…ç”Ÿæˆçš„éŸ³é¢‘æ—¶é•¿)
        adjusted_timeline = self.timeline_adjuster.adjust_for_actual_durations(
            timeline, dialogue_files
        )
        
        # 2. é¢„å¤„ç†æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        processed_dialogue = await self._preprocess_dialogue_files(dialogue_files)
        processed_environment = await self._preprocess_environment_files(environment_files)
        processed_effects = await self._preprocess_effect_files(effect_files)
        
        # 3. åˆ›å»ºä¸»éŸ³è½¨
        total_duration = adjusted_timeline.total_duration
        master_track = AudioTrack.create_silence(total_duration)
        
        # 4. æŒ‰å±‚çº§æ··åˆ
        # 4.1 ç¯å¢ƒéŸ³å±‚ (æœ€åº•å±‚)
        master_track = await self._mix_environment_layer(
            master_track, processed_environment, adjusted_timeline
        )
        
        # 4.2 éŸ³æ•ˆå±‚ 
        master_track = await self._mix_effects_layer(
            master_track, processed_effects, adjusted_timeline
        )
        
        # 4.3 å¯¹è¯å±‚ (æœ€é¡¶å±‚ï¼Œä¿è¯æ¸…æ™°åº¦)
        master_track = await self._mix_dialogue_layer(
            master_track, processed_dialogue, adjusted_timeline
        )
        
        # 5. åå¤„ç†å’Œè´¨é‡ä¼˜åŒ–
        final_audio = await self._post_process_mixed_audio(master_track)
        
        return MixedAudio(final_audio, adjusted_timeline)
```

## ğŸ”§ GPUèµ„æºç®¡ç†ç­–ç•¥

### æ™ºèƒ½èµ„æºè°ƒåº¦
```python
class GPUResourceManager:
    def __init__(self):
        self.gpu_info = self._get_gpu_info()
        self.resource_locks = {}
        self.memory_monitor = GPUMemoryMonitor()
    
    @asynccontextmanager
    async def exclusive_lock(self, service_name: str):
        """GPUç‹¬å é”"""
        
        # ç­‰å¾…å…¶ä»–æœåŠ¡é‡Šæ”¾GPU
        await self._wait_for_gpu_available()
        
        # æ¸…ç†GPUç¼“å­˜
        await self._clear_gpu_memory()
        
        # æ ‡è®°èµ„æºå ç”¨
        self.resource_locks[service_name] = True
        
        try:
            yield
        finally:
            # é‡Šæ”¾èµ„æº
            del self.resource_locks[service_name]
            await self._clear_gpu_memory()
    
    async def _clear_gpu_memory(self):
        """æ¸…ç†GPUæ˜¾å­˜"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
    
    async def _wait_for_gpu_available(self):
        """ç­‰å¾…GPUå¯ç”¨"""
        while len(self.resource_locks) > 0:
            await asyncio.sleep(1)
            
        # ç­‰å¾…æ˜¾å­˜é‡Šæ”¾
        while self.memory_monitor.get_used_memory() > 0.8:  # è¶…è¿‡80%ç­‰å¾…
            await asyncio.sleep(0.5)
```

## ğŸ“Š ä¼˜åŒ–åçš„æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | GPUæ˜¾å­˜ä½¿ç”¨ | æˆåŠŸç‡ | å¤„ç†æ—¶é—´ | ç¨³å®šæ€§ |
|------|------------|--------|----------|--------|
| å¹¶è¡Œç”Ÿæˆ | ğŸ’¥ çˆ†ç‚¸ | ~30% | N/A | âŒ ä¸ç¨³å®š |
| é¡ºåºç”Ÿæˆ | âœ… å¯æ§ | ~95% | +20% | âœ… ç¨³å®š |

### æ—¶é—´æˆæœ¬åˆ†æ
```
é¡ºåºç”Ÿæˆæ€»æ—¶é—´ = TTS3æ—¶é—´ + TangoFluxæ—¶é—´ + æ··åˆæ—¶é—´
è™½ç„¶æ€»æ—¶é—´ç¨é•¿ï¼Œä½†æˆåŠŸç‡å¤§å¹…æå‡ï¼Œå®é™…æ•ˆç‡æ›´é«˜
```

## ğŸš€ å®ç°ä»£ç ç¤ºä¾‹

### ä¸»æµç¨‹æ§åˆ¶å™¨
```python
class OptimizedAudioPipeline:
    def __init__(self):
        self.generator = SequentialAudioGenerator()
        self.mixer = FileBasedAudioMixer()
        self.progress_tracker = ProgressTracker()
    
    async def process_novel_audio(self, novel_json: dict) -> FinalAudio:
        """ä¼˜åŒ–åçš„å°è¯´éŸ³é¢‘å¤„ç†æµç¨‹"""
        
        # é˜¶æ®µ1: åœºæ™¯åˆ†æ (æ— GPUéœ€æ±‚)
        self.progress_tracker.update("æ­£åœ¨åˆ†æåœºæ™¯...")
        scene_info = await self.analyze_scenes(novel_json)
        
        # é˜¶æ®µ2: æ—¶é—´è½´è§„åˆ’ (æ— GPUéœ€æ±‚)
        self.progress_tracker.update("æ­£åœ¨ç”Ÿæˆæ—¶é—´è½´...")
        timeline = await self.generate_timeline(novel_json, scene_info)
        
        # é˜¶æ®µ3: å¯¹è¯éŸ³é¢‘ç”Ÿæˆ (TTS3ç‹¬å GPU)
        self.progress_tracker.update("æ­£åœ¨ç”Ÿæˆå¯¹è¯éŸ³é¢‘...", stage="dialogue")
        dialogue_files = await self.generator.generate_dialogue_audio(timeline)
        
        # é˜¶æ®µ4: ç¯å¢ƒéŸ³ç”Ÿæˆ (TangoFluxç‹¬å GPU)
        self.progress_tracker.update("æ­£åœ¨ç”Ÿæˆç¯å¢ƒéŸ³...", stage="environment")
        environment_files = await self.generator.generate_environment_audio(timeline)
        
        # é˜¶æ®µ5: éŸ³æ•ˆç”Ÿæˆ (å¯é€‰)
        self.progress_tracker.update("æ­£åœ¨ç”ŸæˆéŸ³æ•ˆ...", stage="effects")
        effect_files = await self.generator.generate_effect_audio(timeline)
        
        # é˜¶æ®µ6: æ™ºèƒ½æ··åˆ (CPUå¤„ç†)
        self.progress_tracker.update("æ­£åœ¨æ··åˆéŸ³é¢‘...", stage="mixing")
        final_audio = await self.mixer.mix_separated_audio_files(
            dialogue_files, environment_files, effect_files, timeline
        )
        
        # é˜¶æ®µ7: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        await self._cleanup_temp_files(dialogue_files, environment_files, effect_files)
        
        return final_audio
```

### APIæ¥å£æ›´æ–°
```python
@router.post("/api/v1/audio-generation/sequential")
async def sequential_audio_generation(request: AudioGenerationRequest):
    """é¡ºåºéŸ³é¢‘ç”Ÿæˆæ¥å£"""
    
    pipeline = OptimizedAudioPipeline()
    
    try:
        # åˆ›å»ºä»»åŠ¡
        task_id = await pipeline.create_task(request.novel_data)
        
        # å¼‚æ­¥å¤„ç†
        background_task = BackgroundTask(
            pipeline.process_novel_audio,
            request.novel_data
        )
        
        return {
            "success": True,
            "data": {
                "task_id": task_id,
                "estimated_time": pipeline.estimate_processing_time(request.novel_data),
                "stages": ["dialogue", "environment", "effects", "mixing"],
                "progress_url": f"/api/v1/tasks/{task_id}/progress"
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": {
                "type": "generation_error",
                "message": str(e)
            }
        }

@router.get("/api/v1/tasks/{task_id}/progress")
async def get_task_progress(task_id: str):
    """è·å–ä»»åŠ¡è¿›åº¦"""
    
    progress = await pipeline.get_task_progress(task_id)
    
    return {
        "success": True,
        "data": {
            "task_id": task_id,
            "current_stage": progress.current_stage,
            "progress_percentage": progress.percentage,
            "estimated_remaining": progress.estimated_remaining,
            "stage_details": progress.stage_details
        }
    }
```

## ğŸ¯ ç”¨æˆ·ä½“éªŒä¼˜åŒ–

### è¿›åº¦æ˜¾ç¤ºä¼˜åŒ–
```vue
<!-- å‰ç«¯è¿›åº¦æ˜¾ç¤ºç»„ä»¶ -->
<template>
  <div class="audio-generation-progress">
    <a-steps :current="currentStage" direction="vertical">
      <a-step title="åœºæ™¯åˆ†æ" description="AIåˆ†æå°è¯´åœºæ™¯ä¿¡æ¯" />
      <a-step title="æ—¶é—´è½´ç”Ÿæˆ" description="è§„åˆ’éŸ³é¢‘æ—¶é—´è½´" />
      <a-step title="å¯¹è¯ç”Ÿæˆ" description="TTS3ç”Ÿæˆè§’è‰²å¯¹è¯" />
      <a-step title="ç¯å¢ƒéŸ³ç”Ÿæˆ" description="TangoFluxç”Ÿæˆç¯å¢ƒéŸ³æ•ˆ" />
      <a-step title="éŸ³æ•ˆç”Ÿæˆ" description="ç”Ÿæˆç‰¹æ®ŠéŸ³æ•ˆ" />
      <a-step title="æ™ºèƒ½æ··åˆ" description="å¤šè½¨éŸ³é¢‘æ··åˆ" />
    </a-steps>
    
    <div class="stage-progress">
      <a-progress 
        :percent="stageProgress" 
        :status="progressStatus"
        :format="progressFormatter"
      />
      <p class="stage-info">{{ stageInfo }}</p>
    </div>
  </div>
</template>

<script setup>
const stageInfo = computed(() => {
  switch(currentStage.value) {
    case 2: return `æ­£åœ¨ç”Ÿæˆå¯¹è¯ ${currentDialogue.value}/${totalDialogues.value}`
    case 3: return `æ­£åœ¨ç”Ÿæˆç¯å¢ƒéŸ³ ${currentEnv.value}/${totalEnvs.value}`
    case 4: return `æ­£åœ¨ç”ŸæˆéŸ³æ•ˆ ${currentEffect.value}/${totalEffects.value}`
    case 5: return 'æ­£åœ¨æ··åˆéŸ³é¢‘è½¨é“...'
    default: return 'å¤„ç†ä¸­...'
  }
})
</script>
```

---

**æ€»ç»“**: æ„Ÿè°¢ä½ çš„é‡è¦æŒ‡æ­£ï¼é¡ºåºç”Ÿæˆæ–¹æ¡ˆé¿å…äº†GPUæ˜¾å­˜çˆ†ç‚¸é—®é¢˜ï¼Œè™½ç„¶æ—¶é—´ç¨é•¿ä½†å¤§å¹…æå‡äº†æˆåŠŸç‡å’Œç¨³å®šæ€§ã€‚è¿™æ‰æ˜¯çœŸæ­£å¯è¡Œçš„å·¥ç¨‹æ–¹æ¡ˆï¼ğŸ› ï¸