# 时间轴生成器设计

## 🎯 功能目标

将场景分析结果和音频文件信息转换为精确的多轨时间轴控制文件，确保对话和环境音完美同步。

## ⏰ 核心挑战

### 时间轴同步难题
```
问题1: TTS音频时长不可预知
预估: "你好吗？" → 2.5秒
实际: TTS生成 → 3.2秒

问题2: 场景边界模糊  
文本: "走出房间，来到花园里"
环境音: 室内音 → ? → 户外音

问题3: 多轨协调复杂
对话轨: [0-3s] [4-7s] [8-12s]
环境轨: [0-?] [?-?] [?-12s] 
音效轨: [5.5s] [9.2s]
```

## 🔧 解决方案架构

### 1. 两阶段时间轴生成
```python
class TimelineGenerator:
    def generate_timeline(self, segments: List[dict]) -> Timeline:
        # 阶段1: 预估时间轴 (基于文本)
        estimated_timeline = self._generate_estimated_timeline(segments)
        
        # 阶段2: 精确时间轴 (基于实际音频)
        precise_timeline = self._adjust_with_actual_audio(estimated_timeline)
        
        return precise_timeline
```

### 2. 预估时间轴生成
```python
def _generate_estimated_timeline(self, segments: List[dict]) -> EstimatedTimeline:
    """基于文本内容预估时间轴"""
    
    timeline = EstimatedTimeline()
    current_time = 0.0
    current_scene = None
    
    for segment in segments:
        # 预估段落时长
        estimated_duration = self._estimate_segment_duration(segment)
        
        # 场景分析
        scene_info = self.scene_analyzer.analyze_scene(segment["content"])
        
        # 检测场景切换
        scene_change = self._detect_scene_change(current_scene, scene_info)
        
        # 添加到时间轴
        timeline.add_segment({
            "start": current_time,
            "end": current_time + estimated_duration,
            "type": segment["type"],
            "content": segment["content"], 
            "scene": scene_info,
            "scene_change": scene_change,
            "estimated_duration": estimated_duration
        })
        
        current_time += estimated_duration
        current_scene = scene_info
        
    return timeline
```

### 3. 时长预估算法
```python
def _estimate_segment_duration(self, segment: dict) -> float:
    """预估单个段落的音频时长"""
    
    content = segment["content"]
    segment_type = segment["type"]
    
    if segment_type == "dialogue":
        return self._estimate_dialogue_duration(content)
    elif segment_type == "description":
        return self._estimate_description_duration(content)
    else:
        return self._estimate_default_duration(content)

def _estimate_dialogue_duration(self, text: str) -> float:
    """预估对话时长"""
    
    # 基础参数
    char_count = len(text)
    punctuation_count = text.count('，') + text.count('。') + text.count('！') + text.count('？')
    
    # 时长计算
    base_duration = char_count * 0.25  # 每字0.25秒
    pause_duration = punctuation_count * 0.3  # 每个标点0.3秒停顿
    
    # 语速调整
    if '!' in text or '？' in text:
        speed_factor = 1.1  # 疑问句/感叹句稍慢
    else:
        speed_factor = 1.0
        
    total_duration = (base_duration + pause_duration) * speed_factor
    
    return max(total_duration, 1.0)  # 最少1秒

def _estimate_description_duration(self, text: str) -> float:
    """预估描述性文本时长"""
    
    char_count = len(text)
    
    # 描述性文本通常读得较慢
    base_duration = char_count * 0.35
    
    return max(base_duration, 2.0)  # 最少2秒
```

## 🎵 环境音时间轴规划

### 场景持续性分析
```python
def _plan_environment_audio(self, segments: List[dict]) -> List[EnvironmentTrack]:
    """规划环境音时间轴"""
    
    env_tracks = []
    current_scene = None
    scene_start_time = 0.0
    
    for i, segment in enumerate(segments):
        scene_info = segment["scene"]
        
        # 检测场景切换
        if self._is_scene_change(current_scene, scene_info):
            
            # 结束当前场景的环境音
            if current_scene is not None:
                env_tracks.append(EnvironmentTrack(
                    start=scene_start_time,
                    end=segment["start"],
                    scene=current_scene,
                    sound_file=self._get_environment_sound(current_scene),
                    volume=self._get_environment_volume(current_scene),
                    fade_out=1.0  # 1秒淡出
                ))
            
            # 开始新场景的环境音
            scene_start_time = segment["start"]
            current_scene = scene_info
    
    # 处理最后一个场景
    if current_scene is not None:
        env_tracks.append(EnvironmentTrack(
            start=scene_start_time,
            end=segments[-1]["end"],
            scene=current_scene,
            sound_file=self._get_environment_sound(current_scene),
            volume=self._get_environment_volume(current_scene)
        ))
    
    return env_tracks
```

### 音量动态调节策略
```python
def _calculate_dynamic_volume(self, segment: dict, base_volume: float) -> float:
    """根据内容动态调节音量"""
    
    content = segment["content"]
    segment_type = segment["type"]
    scene = segment["scene"]
    
    # 基础音量
    volume = base_volume
    
    # 根据段落类型调节
    if segment_type == "dialogue":
        volume *= 0.7  # 对话时环境音降低
    elif segment_type == "description":
        volume *= 1.0  # 描述时保持正常
    
    # 根据场景氛围调节
    if scene.atmosphere == "tense":
        volume *= 1.2  # 紧张时增强
    elif scene.atmosphere == "calm":
        volume *= 0.8  # 平静时减弱
    
    # 根据内容关键词调节
    if any(word in content for word in ["大喊", "尖叫", "巨响"]):
        volume *= 0.5  # 大声内容时环境音更低
    elif any(word in content for word in ["静静", "悄悄", "轻声"]):
        volume *= 1.3  # 安静内容时环境音可适当增强
    
    return max(0.1, min(1.0, volume))  # 限制在0.1-1.0范围
```

## 📊 精确时间轴调整

### 基于实际音频的调整
```python
def _adjust_with_actual_audio(self, estimated_timeline: EstimatedTimeline) -> PreciseTimeline:
    """基于实际生成的音频文件调整时间轴"""
    
    precise_timeline = PreciseTimeline()
    current_time = 0.0
    
    for segment in estimated_timeline.segments:
        # 获取实际音频时长
        audio_file = segment.get("audio_file")
        if audio_file and os.path.exists(audio_file):
            actual_duration = self._get_audio_duration(audio_file)
        else:
            actual_duration = segment["estimated_duration"]
        
        # 调整时间轴
        precise_segment = {
            **segment,
            "start": current_time,
            "end": current_time + actual_duration,
            "actual_duration": actual_duration,
            "duration_drift": actual_duration - segment["estimated_duration"]
        }
        
        precise_timeline.add_segment(precise_segment)
        current_time += actual_duration
    
    # 重新计算环境音时间轴
    precise_timeline.environment_tracks = self._recalculate_environment_tracks(
        precise_timeline.segments
    )
    
    return precise_timeline
```

### 时间轴漂移处理
```python
def _handle_timeline_drift(self, segments: List[dict]) -> List[dict]:
    """处理时间轴累积漂移问题"""
    
    adjusted_segments = []
    cumulative_drift = 0.0
    
    for segment in segments:
        drift = segment["duration_drift"]
        cumulative_drift += drift
        
        # 如果累积漂移超过阈值，进行全局调整
        if abs(cumulative_drift) > 2.0:  # 超过2秒
            segment = self._apply_drift_correction(segment, cumulative_drift)
            cumulative_drift = 0.0
        
        adjusted_segments.append(segment)
    
    return adjusted_segments
```

## 🎛️ 多轨协调算法

### 轨道冲突检测
```python
def _detect_track_conflicts(self, timeline: PreciseTimeline) -> List[Conflict]:
    """检测不同轨道间的冲突"""
    
    conflicts = []
    
    # 检测音量冲突
    for i, segment in enumerate(timeline.segments):
        if segment["type"] == "dialogue":
            # 检查同时间的环境音是否过响
            env_volume = self._get_environment_volume_at_time(
                timeline.environment_tracks, segment["start"]
            )
            if env_volume > 0.4:  # 环境音过响
                conflicts.append(Conflict(
                    type="volume_conflict",
                    time=segment["start"],
                    description=f"对话时环境音音量过高: {env_volume}"
                ))
    
    return conflicts

def _resolve_conflicts(self, timeline: PreciseTimeline, conflicts: List[Conflict]) -> PreciseTimeline:
    """解决轨道冲突"""
    
    for conflict in conflicts:
        if conflict.type == "volume_conflict":
            # 降低环境音音量
            self._reduce_environment_volume_at_time(
                timeline.environment_tracks, conflict.time, target_volume=0.3
            )
    
    return timeline
```

## 📋 输出数据结构

### 最终时间轴文件
```json
{
  "timeline_version": "1.0",
  "total_duration": 180.5,
  "created_at": "2024-01-01T12:00:00Z",
  "tracks": {
    "dialogue": [
      {
        "id": "dialogue_001",
        "start": 0.0,
        "end": 3.2,
        "file": "seg_001.wav",
        "speaker": "张三",
        "content": "你怎么还不睡？",
        "volume": 1.0
      }
    ],
    "environment": [
      {
        "id": "env_001", 
        "start": 0.0,
        "end": 15.0,
        "file": "rain_night.wav",
        "scene": "rainy_night_outdoor",
        "volume": 0.3,
        "fade_in": 0.0,
        "fade_out": 1.0
      }
    ],
    "effects": [
      {
        "id": "effect_001",
        "start": 12.5,
        "end": 13.0, 
        "file": "door_close.wav",
        "volume": 0.6,
        "trigger": "scene_change"
      }
    ]
  },
  "scene_changes": [
    {
      "time": 15.0,
      "from_scene": "indoor_night",
      "to_scene": "outdoor_rainy",
      "transition_type": "cross_fade",
      "duration": 2.0
    }
  ],
  "quality_metrics": {
    "total_segments": 25,
    "scene_changes": 4,
    "average_drift": 0.3,
    "max_drift": 1.2,
    "conflicts_resolved": 2
  }
}
```

### API接口
```python
@router.post("/api/v1/timeline/generate")
async def generate_timeline(request: TimelineGenerationRequest):
    """生成音频时间轴"""
    
    generator = TimelineGenerator()
    timeline = generator.generate_timeline(request.segments)
    
    return {
        "success": True,
        "data": {
            "timeline": timeline.to_dict(),
            "quality_metrics": timeline.quality_metrics,
            "warnings": timeline.warnings
        }
    }

@router.post("/api/v1/timeline/adjust")
async def adjust_timeline(request: TimelineAdjustmentRequest):
    """基于实际音频调整时间轴"""
    
    generator = TimelineGenerator()
    adjusted_timeline = generator.adjust_with_actual_audio(
        request.estimated_timeline,
        request.audio_files
    )
    
    return {
        "success": True,
        "data": {
            "adjusted_timeline": adjusted_timeline.to_dict(),
            "adjustments_made": adjusted_timeline.adjustments,
            "quality_improvement": adjusted_timeline.quality_delta
        }
    }
```

---

**下一步**：设计音频混合引擎，将时间轴控制文件转换为最终的混合音频