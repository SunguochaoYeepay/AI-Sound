# æ—¶é—´è½´ç”Ÿæˆå™¨è®¾è®¡

## ğŸ¯ åŠŸèƒ½ç›®æ ‡

å°†åœºæ™¯åˆ†æç»“æœå’ŒéŸ³é¢‘æ–‡ä»¶ä¿¡æ¯è½¬æ¢ä¸ºç²¾ç¡®çš„å¤šè½¨æ—¶é—´è½´æ§åˆ¶æ–‡ä»¶ï¼Œç¡®ä¿å¯¹è¯å’Œç¯å¢ƒéŸ³å®Œç¾åŒæ­¥ã€‚

## â° æ ¸å¿ƒæŒ‘æˆ˜

### æ—¶é—´è½´åŒæ­¥éš¾é¢˜
```
é—®é¢˜1: TTSéŸ³é¢‘æ—¶é•¿ä¸å¯é¢„çŸ¥
é¢„ä¼°: "ä½ å¥½å—ï¼Ÿ" â†’ 2.5ç§’
å®é™…: TTSç”Ÿæˆ â†’ 3.2ç§’

é—®é¢˜2: åœºæ™¯è¾¹ç•Œæ¨¡ç³Š  
æ–‡æœ¬: "èµ°å‡ºæˆ¿é—´ï¼Œæ¥åˆ°èŠ±å›­é‡Œ"
ç¯å¢ƒéŸ³: å®¤å†…éŸ³ â†’ ? â†’ æˆ·å¤–éŸ³

é—®é¢˜3: å¤šè½¨åè°ƒå¤æ‚
å¯¹è¯è½¨: [0-3s] [4-7s] [8-12s]
ç¯å¢ƒè½¨: [0-?] [?-?] [?-12s] 
éŸ³æ•ˆè½¨: [5.5s] [9.2s]
```

## ğŸ”§ è§£å†³æ–¹æ¡ˆæ¶æ„

### 1. ä¸¤é˜¶æ®µæ—¶é—´è½´ç”Ÿæˆ
```python
class TimelineGenerator:
    def generate_timeline(self, segments: List[dict]) -> Timeline:
        # é˜¶æ®µ1: é¢„ä¼°æ—¶é—´è½´ (åŸºäºæ–‡æœ¬)
        estimated_timeline = self._generate_estimated_timeline(segments)
        
        # é˜¶æ®µ2: ç²¾ç¡®æ—¶é—´è½´ (åŸºäºå®é™…éŸ³é¢‘)
        precise_timeline = self._adjust_with_actual_audio(estimated_timeline)
        
        return precise_timeline
```

### 2. é¢„ä¼°æ—¶é—´è½´ç”Ÿæˆ
```python
def _generate_estimated_timeline(self, segments: List[dict]) -> EstimatedTimeline:
    """åŸºäºæ–‡æœ¬å†…å®¹é¢„ä¼°æ—¶é—´è½´"""
    
    timeline = EstimatedTimeline()
    current_time = 0.0
    current_scene = None
    
    for segment in segments:
        # é¢„ä¼°æ®µè½æ—¶é•¿
        estimated_duration = self._estimate_segment_duration(segment)
        
        # åœºæ™¯åˆ†æ
        scene_info = self.scene_analyzer.analyze_scene(segment["content"])
        
        # æ£€æµ‹åœºæ™¯åˆ‡æ¢
        scene_change = self._detect_scene_change(current_scene, scene_info)
        
        # æ·»åŠ åˆ°æ—¶é—´è½´
        timeline.add_segment({
            "start": current_time,
            "end": current_time + estimated_duration,
            "type": segment["type"],
            "content": segment["content"], 
            "scene": scene_info,
            "scene_change": scene_change,
            "estimated_duration": estimated_duration
        })
        
        current_time += estimated_duration
        current_scene = scene_info
        
    return timeline
```

### 3. æ—¶é•¿é¢„ä¼°ç®—æ³•
```python
def _estimate_segment_duration(self, segment: dict) -> float:
    """é¢„ä¼°å•ä¸ªæ®µè½çš„éŸ³é¢‘æ—¶é•¿"""
    
    content = segment["content"]
    segment_type = segment["type"]
    
    if segment_type == "dialogue":
        return self._estimate_dialogue_duration(content)
    elif segment_type == "description":
        return self._estimate_description_duration(content)
    else:
        return self._estimate_default_duration(content)

def _estimate_dialogue_duration(self, text: str) -> float:
    """é¢„ä¼°å¯¹è¯æ—¶é•¿"""
    
    # åŸºç¡€å‚æ•°
    char_count = len(text)
    punctuation_count = text.count('ï¼Œ') + text.count('ã€‚') + text.count('ï¼') + text.count('ï¼Ÿ')
    
    # æ—¶é•¿è®¡ç®—
    base_duration = char_count * 0.25  # æ¯å­—0.25ç§’
    pause_duration = punctuation_count * 0.3  # æ¯ä¸ªæ ‡ç‚¹0.3ç§’åœé¡¿
    
    # è¯­é€Ÿè°ƒæ•´
    if '!' in text or 'ï¼Ÿ' in text:
        speed_factor = 1.1  # ç–‘é—®å¥/æ„Ÿå¹å¥ç¨æ…¢
    else:
        speed_factor = 1.0
        
    total_duration = (base_duration + pause_duration) * speed_factor
    
    return max(total_duration, 1.0)  # æœ€å°‘1ç§’

def _estimate_description_duration(self, text: str) -> float:
    """é¢„ä¼°æè¿°æ€§æ–‡æœ¬æ—¶é•¿"""
    
    char_count = len(text)
    
    # æè¿°æ€§æ–‡æœ¬é€šå¸¸è¯»å¾—è¾ƒæ…¢
    base_duration = char_count * 0.35
    
    return max(base_duration, 2.0)  # æœ€å°‘2ç§’
```

## ğŸµ ç¯å¢ƒéŸ³æ—¶é—´è½´è§„åˆ’

### åœºæ™¯æŒç»­æ€§åˆ†æ
```python
def _plan_environment_audio(self, segments: List[dict]) -> List[EnvironmentTrack]:
    """è§„åˆ’ç¯å¢ƒéŸ³æ—¶é—´è½´"""
    
    env_tracks = []
    current_scene = None
    scene_start_time = 0.0
    
    for i, segment in enumerate(segments):
        scene_info = segment["scene"]
        
        # æ£€æµ‹åœºæ™¯åˆ‡æ¢
        if self._is_scene_change(current_scene, scene_info):
            
            # ç»“æŸå½“å‰åœºæ™¯çš„ç¯å¢ƒéŸ³
            if current_scene is not None:
                env_tracks.append(EnvironmentTrack(
                    start=scene_start_time,
                    end=segment["start"],
                    scene=current_scene,
                    sound_file=self._get_environment_sound(current_scene),
                    volume=self._get_environment_volume(current_scene),
                    fade_out=1.0  # 1ç§’æ·¡å‡º
                ))
            
            # å¼€å§‹æ–°åœºæ™¯çš„ç¯å¢ƒéŸ³
            scene_start_time = segment["start"]
            current_scene = scene_info
    
    # å¤„ç†æœ€åä¸€ä¸ªåœºæ™¯
    if current_scene is not None:
        env_tracks.append(EnvironmentTrack(
            start=scene_start_time,
            end=segments[-1]["end"],
            scene=current_scene,
            sound_file=self._get_environment_sound(current_scene),
            volume=self._get_environment_volume(current_scene)
        ))
    
    return env_tracks
```

### éŸ³é‡åŠ¨æ€è°ƒèŠ‚ç­–ç•¥
```python
def _calculate_dynamic_volume(self, segment: dict, base_volume: float) -> float:
    """æ ¹æ®å†…å®¹åŠ¨æ€è°ƒèŠ‚éŸ³é‡"""
    
    content = segment["content"]
    segment_type = segment["type"]
    scene = segment["scene"]
    
    # åŸºç¡€éŸ³é‡
    volume = base_volume
    
    # æ ¹æ®æ®µè½ç±»å‹è°ƒèŠ‚
    if segment_type == "dialogue":
        volume *= 0.7  # å¯¹è¯æ—¶ç¯å¢ƒéŸ³é™ä½
    elif segment_type == "description":
        volume *= 1.0  # æè¿°æ—¶ä¿æŒæ­£å¸¸
    
    # æ ¹æ®åœºæ™¯æ°›å›´è°ƒèŠ‚
    if scene.atmosphere == "tense":
        volume *= 1.2  # ç´§å¼ æ—¶å¢å¼º
    elif scene.atmosphere == "calm":
        volume *= 0.8  # å¹³é™æ—¶å‡å¼±
    
    # æ ¹æ®å†…å®¹å…³é”®è¯è°ƒèŠ‚
    if any(word in content for word in ["å¤§å–Š", "å°–å«", "å·¨å“"]):
        volume *= 0.5  # å¤§å£°å†…å®¹æ—¶ç¯å¢ƒéŸ³æ›´ä½
    elif any(word in content for word in ["é™é™", "æ‚„æ‚„", "è½»å£°"]):
        volume *= 1.3  # å®‰é™å†…å®¹æ—¶ç¯å¢ƒéŸ³å¯é€‚å½“å¢å¼º
    
    return max(0.1, min(1.0, volume))  # é™åˆ¶åœ¨0.1-1.0èŒƒå›´
```

## ğŸ“Š ç²¾ç¡®æ—¶é—´è½´è°ƒæ•´

### åŸºäºå®é™…éŸ³é¢‘çš„è°ƒæ•´
```python
def _adjust_with_actual_audio(self, estimated_timeline: EstimatedTimeline) -> PreciseTimeline:
    """åŸºäºå®é™…ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è°ƒæ•´æ—¶é—´è½´"""
    
    precise_timeline = PreciseTimeline()
    current_time = 0.0
    
    for segment in estimated_timeline.segments:
        # è·å–å®é™…éŸ³é¢‘æ—¶é•¿
        audio_file = segment.get("audio_file")
        if audio_file and os.path.exists(audio_file):
            actual_duration = self._get_audio_duration(audio_file)
        else:
            actual_duration = segment["estimated_duration"]
        
        # è°ƒæ•´æ—¶é—´è½´
        precise_segment = {
            **segment,
            "start": current_time,
            "end": current_time + actual_duration,
            "actual_duration": actual_duration,
            "duration_drift": actual_duration - segment["estimated_duration"]
        }
        
        precise_timeline.add_segment(precise_segment)
        current_time += actual_duration
    
    # é‡æ–°è®¡ç®—ç¯å¢ƒéŸ³æ—¶é—´è½´
    precise_timeline.environment_tracks = self._recalculate_environment_tracks(
        precise_timeline.segments
    )
    
    return precise_timeline
```

### æ—¶é—´è½´æ¼‚ç§»å¤„ç†
```python
def _handle_timeline_drift(self, segments: List[dict]) -> List[dict]:
    """å¤„ç†æ—¶é—´è½´ç´¯ç§¯æ¼‚ç§»é—®é¢˜"""
    
    adjusted_segments = []
    cumulative_drift = 0.0
    
    for segment in segments:
        drift = segment["duration_drift"]
        cumulative_drift += drift
        
        # å¦‚æœç´¯ç§¯æ¼‚ç§»è¶…è¿‡é˜ˆå€¼ï¼Œè¿›è¡Œå…¨å±€è°ƒæ•´
        if abs(cumulative_drift) > 2.0:  # è¶…è¿‡2ç§’
            segment = self._apply_drift_correction(segment, cumulative_drift)
            cumulative_drift = 0.0
        
        adjusted_segments.append(segment)
    
    return adjusted_segments
```

## ğŸ›ï¸ å¤šè½¨åè°ƒç®—æ³•

### è½¨é“å†²çªæ£€æµ‹
```python
def _detect_track_conflicts(self, timeline: PreciseTimeline) -> List[Conflict]:
    """æ£€æµ‹ä¸åŒè½¨é“é—´çš„å†²çª"""
    
    conflicts = []
    
    # æ£€æµ‹éŸ³é‡å†²çª
    for i, segment in enumerate(timeline.segments):
        if segment["type"] == "dialogue":
            # æ£€æŸ¥åŒæ—¶é—´çš„ç¯å¢ƒéŸ³æ˜¯å¦è¿‡å“
            env_volume = self._get_environment_volume_at_time(
                timeline.environment_tracks, segment["start"]
            )
            if env_volume > 0.4:  # ç¯å¢ƒéŸ³è¿‡å“
                conflicts.append(Conflict(
                    type="volume_conflict",
                    time=segment["start"],
                    description=f"å¯¹è¯æ—¶ç¯å¢ƒéŸ³éŸ³é‡è¿‡é«˜: {env_volume}"
                ))
    
    return conflicts

def _resolve_conflicts(self, timeline: PreciseTimeline, conflicts: List[Conflict]) -> PreciseTimeline:
    """è§£å†³è½¨é“å†²çª"""
    
    for conflict in conflicts:
        if conflict.type == "volume_conflict":
            # é™ä½ç¯å¢ƒéŸ³éŸ³é‡
            self._reduce_environment_volume_at_time(
                timeline.environment_tracks, conflict.time, target_volume=0.3
            )
    
    return timeline
```

## ğŸ“‹ è¾“å‡ºæ•°æ®ç»“æ„

### æœ€ç»ˆæ—¶é—´è½´æ–‡ä»¶
```json
{
  "timeline_version": "1.0",
  "total_duration": 180.5,
  "created_at": "2024-01-01T12:00:00Z",
  "tracks": {
    "dialogue": [
      {
        "id": "dialogue_001",
        "start": 0.0,
        "end": 3.2,
        "file": "seg_001.wav",
        "speaker": "å¼ ä¸‰",
        "content": "ä½ æ€ä¹ˆè¿˜ä¸ç¡ï¼Ÿ",
        "volume": 1.0
      }
    ],
    "environment": [
      {
        "id": "env_001", 
        "start": 0.0,
        "end": 15.0,
        "file": "rain_night.wav",
        "scene": "rainy_night_outdoor",
        "volume": 0.3,
        "fade_in": 0.0,
        "fade_out": 1.0
      }
    ],
    "effects": [
      {
        "id": "effect_001",
        "start": 12.5,
        "end": 13.0, 
        "file": "door_close.wav",
        "volume": 0.6,
        "trigger": "scene_change"
      }
    ]
  },
  "scene_changes": [
    {
      "time": 15.0,
      "from_scene": "indoor_night",
      "to_scene": "outdoor_rainy",
      "transition_type": "cross_fade",
      "duration": 2.0
    }
  ],
  "quality_metrics": {
    "total_segments": 25,
    "scene_changes": 4,
    "average_drift": 0.3,
    "max_drift": 1.2,
    "conflicts_resolved": 2
  }
}
```

### APIæ¥å£
```python
@router.post("/api/v1/timeline/generate")
async def generate_timeline(request: TimelineGenerationRequest):
    """ç”ŸæˆéŸ³é¢‘æ—¶é—´è½´"""
    
    generator = TimelineGenerator()
    timeline = generator.generate_timeline(request.segments)
    
    return {
        "success": True,
        "data": {
            "timeline": timeline.to_dict(),
            "quality_metrics": timeline.quality_metrics,
            "warnings": timeline.warnings
        }
    }

@router.post("/api/v1/timeline/adjust")
async def adjust_timeline(request: TimelineAdjustmentRequest):
    """åŸºäºå®é™…éŸ³é¢‘è°ƒæ•´æ—¶é—´è½´"""
    
    generator = TimelineGenerator()
    adjusted_timeline = generator.adjust_with_actual_audio(
        request.estimated_timeline,
        request.audio_files
    )
    
    return {
        "success": True,
        "data": {
            "adjusted_timeline": adjusted_timeline.to_dict(),
            "adjustments_made": adjusted_timeline.adjustments,
            "quality_improvement": adjusted_timeline.quality_delta
        }
    }
```

---

**ä¸‹ä¸€æ­¥**ï¼šè®¾è®¡éŸ³é¢‘æ··åˆå¼•æ“ï¼Œå°†æ—¶é—´è½´æ§åˆ¶æ–‡ä»¶è½¬æ¢ä¸ºæœ€ç»ˆçš„æ··åˆéŸ³é¢‘