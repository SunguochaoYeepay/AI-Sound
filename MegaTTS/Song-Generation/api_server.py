import os
import sys
import time
import json
import uuid
import tempfile
from pathlib import Path
from typing import Optional, List
import torch
import torchaudio
import numpy as np
from omegaconf import OmegaConf

from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uvicorn

from codeclm.trainer.codec_song_pl import CodecLM_PL
from codeclm.models import CodecLM
from tools.gradio.separator import Separator

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['USER'] = 'root'
os.environ['PYTHONDONTWRITEBYTECODE'] = '1'
os.environ['TRANSFORMERS_CACHE'] = f"{os.getcwd()}/third_party/hub"
os.environ['NCCL_HOME'] = '/usr/local/tccl'
os.environ['PYTHONPATH'] = f"{os.getcwd()}/codeclm/tokenizer/:{os.getcwd()}:{os.getcwd()}/codeclm/tokenizer/Flow1dVAE/:{os.getcwd()}/codeclm/tokenizer/:{os.environ.get('PYTHONPATH', '')}"

app = FastAPI(title="SongGeneration API", description="é«˜è´¨é‡æ­Œæ›²ç”ŸæˆAPI", version="1.0.0")

# å…¨å±€å˜é‡
model = None
separator = None
auto_prompt = None
cfg = None
device = None

class SongRequest(BaseModel):
    lyrics: str
    descriptions: Optional[str] = None
    auto_prompt_audio_type: Optional[str] = None
    cfg_coef: Optional[float] = 1.5
    temperature: Optional[float] = 0.9
    top_k: Optional[int] = 50

class SongResponse(BaseModel):
    success: bool
    message: str
    file_id: Optional[str] = None
    file_path: Optional[str] = None
    generation_time: Optional[float] = None

# æ”¯æŒçš„è‡ªåŠ¨æç¤ºç±»å‹
AUTO_PROMPT_TYPES = ['Pop', 'R&B', 'Dance', 'Jazz', 'Folk', 'Rock', 'Chinese Style', 'Chinese Tradition', 'Metal', 'Reggae', 'Chinese Opera', 'Auto']

def initialize_model(ckpt_path: str):
    """åˆå§‹åŒ–æ¨¡å‹"""
    global model, separator, auto_prompt, cfg
    
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–SongGenerationæ¨¡å‹...")
    
    # è®¾ç½®OmegaConfè§£æå™¨
    torch.backends.cudnn.enabled = False
    OmegaConf.register_new_resolver("eval", lambda x: eval(x))
    OmegaConf.register_new_resolver("concat", lambda *x: [xxx for xx in x for xxx in xx])
    OmegaConf.register_new_resolver("get_fname", lambda: 'api_server')
    OmegaConf.register_new_resolver("load_yaml", lambda x: list(OmegaConf.load(x)))
    
    # åŠ è½½é…ç½®
    cfg_path = os.path.join(ckpt_path, 'config.yaml')
    model_path = os.path.join(ckpt_path, 'model.pt')
    cfg = OmegaConf.load(cfg_path)
    cfg.mode = 'inference'
    max_duration = cfg.max_dur
    
    # åˆå§‹åŒ–æ¨¡å‹
    model_light = CodecLM_PL(cfg, model_path)
    
    # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡ï¼ˆæ”¯æŒCPU/GPUå…¼å®¹ï¼‰
    global device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    model_light = model_light.eval().to(device)
    model_light.audiolm.cfg = cfg
    
    model = CodecLM(
        name="song_generation_api",
        lm=model_light.audiolm,
        audiotokenizer=model_light.audio_tokenizer,
        max_duration=max_duration,
        seperate_tokenizer=model_light.seperate_tokenizer,
    )
    
    # åˆå§‹åŒ–åˆ†ç¦»å™¨
    separator = Separator()
    
    # åŠ è½½è‡ªåŠ¨æç¤º
    auto_prompt = torch.load('ckpt/ckpt/prompt.pt')
    
    print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨¡å‹"""
    ckpt_path = sys.argv[1] if len(sys.argv) > 1 else "ckpt/songgeneration_base"
    initialize_model(ckpt_path)

@app.get("/")
async def root():
    """APIæ ¹è·¯å¾„"""
    return {"message": "SongGeneration API Server", "status": "running", "version": "1.0.0"}

@app.get("/ping")
async def ping():
    """ç®€å•å­˜æ´»æ£€æŸ¥"""
    return {"status": "pong", "timestamp": time.time()}

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    import psutil
    import platform
    
    # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
    model_status = model is not None
    
    # æ£€æŸ¥GPUçŠ¶æ€
    gpu_info = {}
    if torch.cuda.is_available():
        gpu_info = {
            "available": True,
            "device_count": torch.cuda.device_count(),
            "current_device": torch.cuda.current_device(),
            "device_name": torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "Unknown",
            "memory_allocated": f"{torch.cuda.memory_allocated(0) / 1024**3:.2f} GB" if torch.cuda.device_count() > 0 else "0 GB",
            "memory_reserved": f"{torch.cuda.memory_reserved(0) / 1024**3:.2f} GB" if torch.cuda.device_count() > 0 else "0 GB"
        }
    else:
        gpu_info = {"available": False}
    
    # ç³»ç»Ÿä¿¡æ¯
    system_info = {
        "platform": platform.system(),
        "python_version": platform.python_version(),
        "cpu_percent": psutil.cpu_percent(interval=1),
        "memory_percent": psutil.virtual_memory().percent,
        "disk_usage": psutil.disk_usage('/').percent if platform.system() != 'Windows' else psutil.disk_usage('C:').percent
    }
    
    # æ•´ä½“çŠ¶æ€
    overall_status = "healthy" if model_status and torch.cuda.is_available() else "degraded"
    
    return {
        "status": overall_status,
        "timestamp": time.time(),
        "model": {
            "loaded": model_status,
            "ready": model_status
        },
        "gpu": gpu_info,
        "system": system_info,
        "api_version": "1.0.0",
        "endpoints": {
            "generate": "/generate",
            "generate_with_audio": "/generate_with_audio", 
            "download": "/download/{file_id}",
            "supported_genres": "/supported_genres"
        }
    }

@app.get("/supported_genres")
async def get_supported_genres():
    """è·å–æ”¯æŒçš„éŸ³ä¹é£æ ¼"""
    return {"genres": AUTO_PROMPT_TYPES}

@app.post("/generate", response_model=SongResponse)
async def generate_song(request: SongRequest, background_tasks: BackgroundTasks):
    """ç”Ÿæˆæ­Œæ›²"""
    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåˆå§‹åŒ–")
    
    try:
        start_time = time.time()
        
        # éªŒè¯è¾“å…¥
        if not request.lyrics.strip():
            raise HTTPException(status_code=400, detail="æ­Œè¯ä¸èƒ½ä¸ºç©º")
        
        if request.auto_prompt_audio_type and request.auto_prompt_audio_type not in AUTO_PROMPT_TYPES:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„éŸ³ä¹é£æ ¼: {request.auto_prompt_audio_type}")
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶ID
        file_id = str(uuid.uuid4())
        output_dir = "output/api_generated"
        os.makedirs(output_dir, exist_ok=True)
        target_wav_path = f"{output_dir}/{file_id}.flac"
        
        # å‡†å¤‡ç”Ÿæˆå‚æ•°
        lyric = request.lyrics.replace("  ", " ")
        descriptions = request.descriptions
        
        # å¤„ç†éŸ³é¢‘æç¤º
        pmt_wav = None
        vocal_wav = None
        bgm_wav = None
        melody_is_wav = True
        
        if request.auto_prompt_audio_type:
            merge_prompt = [item for sublist in auto_prompt.values() for item in sublist]
            if request.auto_prompt_audio_type == "Auto":
                prompt_token = merge_prompt[np.random.randint(0, len(merge_prompt))]
            else:
                prompt_token = auto_prompt[request.auto_prompt_audio_type][np.random.randint(0, len(auto_prompt[request.auto_prompt_audio_type]))]
            
            pmt_wav = prompt_token[:,[0],:]
            vocal_wav = prompt_token[:,[1],:]
            bgm_wav = prompt_token[:,[2],:]
            melody_is_wav = False
        
        # è®¾ç½®ç”Ÿæˆå‚æ•°
        model.set_generation_params(
            duration=cfg.max_dur,
            extend_stride=5,
            temperature=request.temperature,
            cfg_coef=request.cfg_coef,
            top_k=request.top_k,
            top_p=0.0,
            record_tokens=True,
            record_window=50
        )
        
        # å‡†å¤‡ç”Ÿæˆè¾“å…¥
        generate_inp = {
            'lyrics': [lyric],
            'descriptions': [descriptions],
            'melody_wavs': pmt_wav,
            'vocal_wavs': vocal_wav,
            'bgm_wavs': bgm_wav,
            'melody_is_wav': melody_is_wav,
        }
        
        print(f"ğŸµ å¼€å§‹ç”Ÿæˆæ­Œæ›² (ID: {file_id})...")
        
        # ç”Ÿæˆtokens
        if device == 'cuda':
            with torch.autocast(device_type="cuda", dtype=torch.float16):
                tokens = model.generate(**generate_inp, return_tokens=True)
        else:
            tokens = model.generate(**generate_inp, return_tokens=True)
        
        # ç”ŸæˆéŸ³é¢‘
        with torch.no_grad():
            if melody_is_wav:
                wav_seperate = model.generate_audio(tokens, pmt_wav, vocal_wav, bgm_wav)
            else:
                wav_seperate = model.generate_audio(tokens)
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        torchaudio.save(target_wav_path, wav_seperate[0].cpu().float(), cfg.sample_rate)
        
        generation_time = time.time() - start_time
        print(f"âœ… æ­Œæ›²ç”Ÿæˆå®Œæˆ (ID: {file_id}), è€—æ—¶: {generation_time:.2f}ç§’")
        
        # æ·»åŠ åå°ä»»åŠ¡æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆ1å°æ—¶åï¼‰
        background_tasks.add_task(cleanup_file, target_wav_path, delay=3600)
        
        return SongResponse(
            success=True,
            message="æ­Œæ›²ç”ŸæˆæˆåŠŸ",
            file_id=file_id,
            file_path=target_wav_path,
            generation_time=generation_time
        )
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ­Œæ›²æ—¶å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.post("/generate_with_audio", response_model=SongResponse)
async def generate_song_with_audio(
    lyrics: str,
    descriptions: Optional[str] = None,
    audio_file: UploadFile = File(...),
    cfg_coef: float = 1.5,
    temperature: float = 0.9,
    top_k: int = 50,
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    """ä½¿ç”¨éŸ³é¢‘æç¤ºç”Ÿæˆæ­Œæ›²"""
    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåˆå§‹åŒ–")
    
    try:
        start_time = time.time()
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        if not audio_file.content_type.startswith('audio/'):
            raise HTTPException(status_code=400, detail="è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")
        
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            content = await audio_file.read()
            temp_audio.write(content)
            temp_audio_path = temp_audio.name
        
        try:
            # åˆ†ç¦»éŸ³é¢‘
            pmt_wav, vocal_wav, bgm_wav = separator.run(temp_audio_path)
            melody_is_wav = True
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            output_dir = "output/api_generated"
            os.makedirs(output_dir, exist_ok=True)
            target_wav_path = f"{output_dir}/{file_id}.flac"
            
            # è®¾ç½®ç”Ÿæˆå‚æ•°
            model.set_generation_params(
                duration=cfg.max_dur,
                extend_stride=5,
                temperature=temperature,
                cfg_coef=cfg_coef,
                top_k=top_k,
                top_p=0.0,
                record_tokens=True,
                record_window=50
            )
            
            # å‡†å¤‡ç”Ÿæˆè¾“å…¥
            generate_inp = {
                'lyrics': [lyrics.replace("  ", " ")],
                'descriptions': [descriptions],
                'melody_wavs': pmt_wav,
                'vocal_wavs': vocal_wav,
                'bgm_wavs': bgm_wav,
                'melody_is_wav': melody_is_wav,
            }
            
            print(f"ğŸµ å¼€å§‹ç”Ÿæˆæ­Œæ›² (ID: {file_id}), ä½¿ç”¨éŸ³é¢‘æç¤º...")
            
            # ç”Ÿæˆtokens
            if device == 'cuda':
                with torch.autocast(device_type="cuda", dtype=torch.float16):
                    tokens = model.generate(**generate_inp, return_tokens=True)
            else:
                tokens = model.generate(**generate_inp, return_tokens=True)
            
            # ç”ŸæˆéŸ³é¢‘
            with torch.no_grad():
                wav_seperate = model.generate_audio(tokens, pmt_wav, vocal_wav, bgm_wav)
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            torchaudio.save(target_wav_path, wav_seperate[0].cpu().float(), cfg.sample_rate)
            
            generation_time = time.time() - start_time
            print(f"âœ… æ­Œæ›²ç”Ÿæˆå®Œæˆ (ID: {file_id}), è€—æ—¶: {generation_time:.2f}ç§’")
            
            # æ·»åŠ åå°ä»»åŠ¡æ¸…ç†æ–‡ä»¶
            background_tasks.add_task(cleanup_file, target_wav_path, delay=3600)
            background_tasks.add_task(cleanup_file, temp_audio_path, delay=10)
            
            return SongResponse(
                success=True,
                message="æ­Œæ›²ç”ŸæˆæˆåŠŸ",
                file_id=file_id,
                file_path=target_wav_path,
                generation_time=generation_time
            )
            
        finally:
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            if os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
                
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ­Œæ›²æ—¶å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")

@app.get("/download/{file_id}")
async def download_song(file_id: str):
    """ä¸‹è½½ç”Ÿæˆçš„æ­Œæ›²"""
    file_path = f"output/api_generated/{file_id}.flac"
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    return FileResponse(
        path=file_path,
        filename=f"song_{file_id}.flac",
        media_type="audio/flac"
    )

async def cleanup_file(file_path: str, delay: int = 0):
    """æ¸…ç†æ–‡ä»¶çš„åå°ä»»åŠ¡"""
    if delay > 0:
        await asyncio.sleep(delay)
    
    try:
        if os.path.exists(file_path):
            os.unlink(file_path)
            print(f"ğŸ—‘ï¸ å·²æ¸…ç†æ–‡ä»¶: {file_path}")
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    import asyncio
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python api_server.py <ckpt_path> [port]")
        print("ç¤ºä¾‹: python api_server.py ckpt/songgeneration_base 8000")
        sys.exit(1)
    
    port = int(sys.argv[2]) if len(sys.argv) > 2 else 8000
    
    print(f"ğŸµ SongGeneration API Server å¯åŠ¨ä¸­...")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {sys.argv[1]}")
    print(f"ğŸŒ ç«¯å£: {port}")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=port,
        reload=False,
        log_level="info"
    ) 