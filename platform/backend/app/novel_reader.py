"""
å°è¯´æœ—è¯»APIæ¨¡å—
å¯¹åº” NovelReader.vue åŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, Query, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import FileResponse
from sqlalchemy.orm import Session
from sqlalchemy import desc, asc, func, or_, and_
from typing import Dict, List, Any, Optional
import os
import json
import time
import logging
import asyncio
import re
from datetime import datetime, timedelta

from app.database import get_db
from .models import NovelProject, VoiceProfile, Book, SystemLog, AudioFile, BookChapter  # ğŸš€ TextSegmentå·²åˆ é™¤
from app.tts_client import MegaTTS3Client, TTSRequest, get_tts_client
from app.utils import log_system_event, update_usage_stats, save_upload_file
from app.websocket.manager import websocket_manager
# from tts_memory_optimizer import synthesis_context, optimize_tts_memory  # æš‚æ—¶ç¦ç”¨ä»¥é¿å…torchä¾èµ–

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/novel-reader", tags=["å°è¯´æœ—è¯»"])

# æ–‡ä»¶å­˜å‚¨è·¯å¾„
PROJECTS_DIR = os.getenv("PROJECTS_DIR", "data/projects")
TEXTS_DIR = os.getenv("TEXTS_DIR", "data/texts")
AUDIO_DIR = os.getenv("AUDIO_DIR", "data/audio")

@router.post("/projects")
async def create_project(
    name: str = Form(...),
    description: str = Form(""),
    content: str = Form(""),
    book_id: Optional[int] = Form(None),
    initial_characters: str = Form("[]"),
    settings: str = Form("{}"),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºæ–°çš„æœ—è¯»é¡¹ç›®ï¼ˆæ”¯æŒä¸¤ç§æ–¹å¼ï¼‰
    æ–¹å¼1ï¼šåŸºäºä¹¦ç±å¼•ç”¨ (book_id)
    æ–¹å¼2ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹ (content)
    """
    try:
        # éªŒè¯é¡¹ç›®åç§°
        if not name or len(name.strip()) == 0:
            raise HTTPException(status_code=400, detail="é¡¹ç›®åç§°ä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥é¡¹ç›®åç§°æ˜¯å¦å·²å­˜åœ¨
        existing = db.query(NovelProject).filter(NovelProject.name == name).first()
        if existing:
            raise HTTPException(status_code=400, detail="é¡¹ç›®åç§°å·²å­˜åœ¨")
        
        # è·å–æ–‡æœ¬å†…å®¹ï¼šä¼˜å…ˆä½¿ç”¨ä¹¦ç±ï¼Œå…¶æ¬¡ä½¿ç”¨ç›´æ¥è¾“å…¥çš„å†…å®¹
        text_content = ""
        actual_book_id = None
        
        if book_id:
            # æ–¹å¼1ï¼šåŸºäºä¹¦ç±
            book = db.query(Book).filter(Book.id == book_id).first()
            if not book:
                raise HTTPException(status_code=404, detail="æŒ‡å®šçš„ä¹¦ç±ä¸å­˜åœ¨")
            
            if not book.content or len(book.content.strip()) == 0:
                raise HTTPException(status_code=400, detail="ä¹¦ç±å†…å®¹ä¸ºç©ºï¼Œæ— æ³•åˆ›å»ºé¡¹ç›®")
            
            text_content = book.content
            actual_book_id = book_id
        elif content and content.strip():
            # æ–¹å¼2ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬
            text_content = content.strip()
            actual_book_id = None
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›ä¹¦ç±IDæˆ–æ–‡æœ¬å†…å®¹")

            
        # è§£æåˆå§‹è§’è‰²æ˜ å°„
        try:
            initial_chars = json.loads(initial_characters) if initial_characters else []
            logger.info(f"[DEBUG] è§£æåˆå§‹è§’è‰² - åŸå§‹: {initial_characters}")
            logger.info(f"[DEBUG] è§£æåˆå§‹è§’è‰² - ç»“æœ: {initial_chars}")
        except json.JSONDecodeError as e:
            logger.error(f"[DEBUG] åˆå§‹è§’è‰²JSONè§£æå¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail="åˆå§‹è§’è‰²æ ¼å¼é”™è¯¯")
        
        # è§£æé¡¹ç›®è®¾ç½®
        try:
            project_settings = json.loads(settings) if settings else {}
            logger.info(f"[DEBUG] è§£æé¡¹ç›®è®¾ç½® - åŸå§‹: {settings}")
            logger.info(f"[DEBUG] è§£æé¡¹ç›®è®¾ç½® - ç»“æœ: {project_settings}")
        except json.JSONDecodeError as e:
            logger.error(f"[DEBUG] é¡¹ç›®è®¾ç½®JSONè§£æå¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail="é¡¹ç›®è®¾ç½®æ ¼å¼é”™è¯¯")
        
        # åˆ›å»ºé¡¹ç›®è®°å½•ï¼ˆæ”¯æŒä¸¤ç§æ–¹å¼ï¼‰
        project = NovelProject(
            name=name,
            description=description,
            book_id=actual_book_id,
            status='pending'
        )
        
        # è®¾ç½®åˆå§‹è§’è‰²æ˜ å°„ï¼ˆå¦‚æœæœ‰ï¼‰
        char_mapping = {}
        if initial_chars:
            for char_info in initial_chars:
                if isinstance(char_info, dict) and 'name' in char_info and 'voice_id' in char_info:
                    char_mapping[char_info['name']] = char_info['voice_id']
        project.set_character_mapping(char_mapping)
        
        # è®¾ç½®é¡¹ç›®é…ç½®
        if project_settings:
            project.set_settings(project_settings)
        
        db.add(project)
        logger.info(f"[DEBUG] é¡¹ç›®æ·»åŠ åˆ°ä¼šè¯: {project.name}")
        
        # ä¸åœ¨è¿™é‡Œæäº¤ï¼Œç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆåä¸€èµ·æäº¤
        db.flush()  # åˆ·æ–°ä»¥è·å–é¡¹ç›®ID
        logger.info(f"[DEBUG] é¡¹ç›®åˆ·æ–°è·å–ID: {project.id}")
        
        # ğŸš€ æ–°æ¶æ„ï¼šä¸å†éœ€è¦ä¼ ç»Ÿåˆ†æ®µï¼Œç›´æ¥ä½¿ç”¨æ™ºèƒ½å‡†å¤‡æ¨¡å¼
        # é¡¹ç›®åˆ›å»ºæ—¶ä¸è¿›è¡Œåˆ†æ®µï¼Œç­‰å¾…æ™ºèƒ½å‡†å¤‡ç»“æœ
        segments_count = 0
        logger.info(f"é¡¹ç›® {project.id} åˆ›å»ºå®Œæˆï¼Œæ–°æ¶æ„å°†ä½¿ç”¨æ™ºèƒ½å‡†å¤‡ç»“æœè¿›è¡Œåˆæˆ")
        
        # è®°å½•åˆ›å»ºæ—¥å¿—
        try:
            logger.info(f"[DEBUG] å¼€å§‹è®°å½•åˆ›å»ºæ—¥å¿—: {project.id}")
            
            # å®‰å…¨è·å–bookä¿¡æ¯
            book_title = "ç›´æ¥è¾“å…¥æ–‡æœ¬"
            if book_id:
                book = db.query(Book).filter(Book.id == book_id).first()
                if book:
                    book_title = book.title
            
            await log_system_event(
                db=db,
                level="info",
                message=f"æœ—è¯»é¡¹ç›®åˆ›å»º: {name}",
                module="novel_reader",
                details={
                    "project_id": project.id,
                    "book_id": book_id,
                    "book_title": book_title,
                    "text_length": len(text_content),
                    "initial_character_count": len(initial_chars),
                    "segments_count": segments_count
                }
            )
            logger.info(f"[DEBUG] åˆ›å»ºæ—¥å¿—è®°å½•å®Œæˆ: {project.id}")
        except Exception as log_error:
            logger.error(f"åˆ›å»ºæ—¥å¿—è®°å½•å¤±è´¥: {str(log_error)}")
            # æ—¥å¿—å¤±è´¥ä¸å½±å“é¡¹ç›®åˆ›å»º
        
        # æœ€ç»ˆä¸€æ¬¡æ€§æäº¤æ‰€æœ‰æ›´æ”¹
        try:
            db.commit()
            logger.info(f"[DEBUG] æœ€ç»ˆæäº¤å®Œæˆ: {project.id}")
        except Exception as final_commit_error:
            logger.error(f"æœ€ç»ˆæäº¤å¤±è´¥: {str(final_commit_error)}")
            db.rollback()
            raise HTTPException(status_code=500, detail=f"ä¿å­˜é¡¹ç›®å¤±è´¥: {str(final_commit_error)}")
        
        return {
            "success": True,
            "message": "é¡¹ç›®åˆ›å»ºæˆåŠŸ",
            "data": project.to_dict()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ›å»ºé¡¹ç›®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå¤±è´¥: {str(e)}")

@router.get("/projects")
async def get_projects(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    search: str = Query("", description="æœç´¢å…³é”®è¯"),
    status: str = Query("", description="çŠ¶æ€è¿‡æ»¤"),
    sort_by: str = Query("created_at", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘"),
    db: Session = Depends(get_db)
):
    """
    è·å–æœ—è¯»é¡¹ç›®åˆ—è¡¨
    å¯¹åº”å‰ç«¯é¡¹ç›®åˆ—è¡¨æ˜¾ç¤ºåŠŸèƒ½
    """
    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(NovelProject)
        
        # æœç´¢è¿‡æ»¤
        if search:
            search_pattern = f"%{search}%"
            query = query.filter(
                or_(
                    NovelProject.name.like(search_pattern),
                    NovelProject.description.like(search_pattern)
                )
            )
        
        # çŠ¶æ€è¿‡æ»¤
        if status and status in ['pending', 'processing', 'paused', 'completed', 'failed']:
            query = query.filter(NovelProject.status == status)
        
        # æ’åº
        sort_field = getattr(NovelProject, sort_by, NovelProject.created_at)
        if sort_order == "asc":
            query = query.order_by(asc(sort_field))
        else:
            query = query.order_by(desc(sort_field))
        
        # ç»Ÿè®¡æ€»æ•°
        total = query.count()
        
        # åˆ†é¡µ
        offset = (page - 1) * page_size
        projects = query.offset(offset).limit(page_size).all()
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        project_list = [project.to_dict() for project in projects]
        
        # åˆ†é¡µä¿¡æ¯
        total_pages = (total + page_size - 1) // page_size
        
        return {
            "success": True,
            "data": project_list,
            "pagination": {
                "page": page,
                "pageSize": page_size,
                "total": total,
                "totalPages": total_pages,
                "hasMore": page < total_pages
            },
            "filters": {
                "search": search,
                "status": status
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ—è¡¨å¤±è´¥: {str(e)}")

@router.get("/projects/{project_id}")
async def get_project_detail(
    project_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–é¡¹ç›®è¯¦æƒ…
    å¯¹åº”å‰ç«¯é¡¹ç›®è¯¦æƒ…é¡µåŠŸèƒ½
    """
    try:
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        project_data = project.to_dict()
        
        # è·å–å…³è”çš„ä¹¦ç±ä¿¡æ¯
        book_info = None
        book_content_length = 0
        if hasattr(project, 'book_id') and project.book_id:
            from app.models import Book
            book = db.query(Book).filter(Book.id == project.book_id).first()
            if book:
                book_info = {
                    "id": book.id,
                    "title": book.title,
                    "author": book.author,
                    "word_count": book.word_count,
                    "status": book.status,
                    "description": book.description
                }
                book_content_length = len(book.content) if book.content else 0
        
        # ğŸš€ æ–°æ¶æ„ï¼šåºŸå¼ƒTextSegmentï¼Œä½¿ç”¨AudioFile
        project_data['segments'] = []  # æ®µè½åˆ—è¡¨å·²åºŸå¼ƒ
        project_data['book'] = book_info  # æ·»åŠ ä¹¦ç±ä¿¡æ¯
        
        # ğŸš€ æ–°æ¶æ„ï¼šåŸºäºAudioFileçš„ç»Ÿè®¡ä¿¡æ¯  
        total_chars = book_content_length if book_content_length > 0 else (
            len(project.original_text) if hasattr(project, 'original_text') and project.original_text else 0
        )
        
        # ä»AudioFileè·å–å®é™…ç»Ÿè®¡
        audio_files = db.query(AudioFile).filter(
            AudioFile.project_id == project_id,
            AudioFile.audio_type == 'segment'
        ).all()
        
        completed_segments = len(audio_files)  # æœ‰AudioFile = å®Œæˆ
        
        # ğŸš¨ é¡¹ç›®çº§åˆ«ç»Ÿè®¡å·²åºŸå¼ƒ
        logger.warning(f"âš ï¸ é¡¹ç›®è¯¦æƒ…APIä¸­çš„è·¨ç« èŠ‚ç»Ÿè®¡å·²åºŸå¼ƒï¼Œé¡¹ç›®ID: {project_id}")
        
        project_data['statistics'] = {
            "totalCharacters": total_chars,
            "totalSegments": 0,  # é¡¹ç›®çº§åˆ«ç»Ÿè®¡å·²åºŸå¼ƒ
            "completedSegments": completed_segments,  # ä»…ä¿ç•™AudioFileè®¡æ•°
            "failedSegments": 0,  # é¡¹ç›®çº§åˆ«ç»Ÿè®¡å·²åºŸå¼ƒ
            "pendingSegments": 0,  # é¡¹ç›®çº§åˆ«ç»Ÿè®¡å·²åºŸå¼ƒ
            "processingSegments": 0  # æ–°æ¶æ„æ²¡æœ‰processingçŠ¶æ€
        }
        
        return {
            "success": True,
            "data": project_data
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")

@router.put("/projects/{project_id}")
async def update_project(
    project_id: int,
    name: str = Form(...),
    description: str = Form(""),
    character_mapping: str = Form("{}"),
    book_id: Optional[int] = Form(None),
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°é¡¹ç›®ä¿¡æ¯
    å¯¹åº”å‰ç«¯é¡¹ç›®ç¼–è¾‘åŠŸèƒ½
    """
    try:
        logger.info(f"[DEBUG] PUTè¯·æ±‚å¼€å§‹ - project_id: {project_id}")
        logger.info(f"[DEBUG] å‚æ•° - name: {name}, description: {description}")
        logger.info(f"[DEBUG] character_mappingåŸå§‹å€¼: {character_mapping}")
        logger.info(f"[DEBUG] character_mappingç±»å‹: {type(character_mapping)}")
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        # éªŒè¯é¡¹ç›®åç§°
        if not name or name.strip() == "" or name.lower() == "undefined":
            logger.error(f"[DEBUG] é¡¹ç›®åç§°æ— æ•ˆ: '{name}'")
            raise HTTPException(status_code=400, detail="é¡¹ç›®åç§°ä¸èƒ½ä¸ºç©ºæˆ–æ— æ•ˆ")
        
        # æ£€æŸ¥åç§°é‡å¤ï¼ˆæ’é™¤è‡ªå·±ï¼‰
        logger.info(f"[DEBUG] æ£€æŸ¥åç§°é‡å¤...")
        existing = db.query(NovelProject).filter(
            and_(
                NovelProject.name == name,
                NovelProject.id != project_id
            )
        ).first()
        
        if existing:
            logger.error(f"[DEBUG] é¡¹ç›®åç§°å·²å­˜åœ¨: {name}")
            raise HTTPException(status_code=400, detail="é¡¹ç›®åç§°å·²å­˜åœ¨")
        
        # è§£æè§’è‰²æ˜ å°„
        try:
            char_mapping = json.loads(character_mapping) if character_mapping else {}
            logger.info(f"[DEBUG] è§£æè§’è‰²æ˜ å°„ - åŸå§‹: {character_mapping}")
            logger.info(f"[DEBUG] è§£æè§’è‰²æ˜ å°„ - ç»“æœ: {char_mapping}")
            logger.info(f"[DEBUG] è§£æè§’è‰²æ˜ å°„ - ç±»å‹: {type(char_mapping)}")
        except json.JSONDecodeError as e:
            logger.error(f"[DEBUG] è§’è‰²æ˜ å°„JSONè§£æå¤±è´¥: {e}")
            raise HTTPException(status_code=400, detail="è§’è‰²æ˜ å°„æ ¼å¼é”™è¯¯")
        
        # æ›´æ–°é¡¹ç›®ä¿¡æ¯
        old_name = project.name
        project.name = name
        project.description = description
        
        # æ›´æ–°ä¹¦ç±å…³è”
        if book_id is not None:
            project.book_id = book_id
            logger.info(f"[DEBUG] æ›´æ–°book_id: {book_id}")
        
        project.set_character_mapping(char_mapping)
        
        # ğŸš€ æ–°æ¶æ„ï¼šä¸å†éœ€è¦æ›´æ–°TextSegmentï¼Œè§’è‰²æ˜ å°„ä¿å­˜åœ¨é¡¹ç›®é…ç½®ä¸­
        # if char_mapping:
        #     await update_segments_voice_mapping_no_commit(project_id, char_mapping, db)
        
        # è®°å½•æ›´æ–°æ—¥å¿—ï¼ˆä¸è‡ªåŠ¨æäº¤ï¼‰
        try:
            await log_system_event(
                db=db,
                level="info",
                message=f"é¡¹ç›®æ›´æ–°: {old_name} -> {name}",
                module="novel_reader",
                details={
                    "project_id": project_id,
                    "old_name": old_name,
                    "new_name": name,
                    "character_mapping": char_mapping
                }
            )
        except Exception as log_error:
            logger.error(f"è®°å½•æ›´æ–°æ—¥å¿—å¤±è´¥: {str(log_error)}")
            # æ—¥å¿—å¤±è´¥ä¸å½±å“é¡¹ç›®æ›´æ–°
        
        # æœ€ç»ˆä¸€æ¬¡æ€§æäº¤æ‰€æœ‰æ›´æ”¹
        try:
            db.commit()
            db.refresh(project)
            logger.info(f"[DEBUG] é¡¹ç›®æ›´æ–°æäº¤æˆåŠŸ: {project_id}")
        except Exception as commit_error:
            logger.error(f"é¡¹ç›®æ›´æ–°æäº¤å¤±è´¥: {str(commit_error)}")
            db.rollback()
            raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±è´¥: {str(commit_error)}")
        
        return {
            "success": True,
            "message": "é¡¹ç›®æ›´æ–°æˆåŠŸ",
            "data": project.to_dict()
        }
        
    except HTTPException as he:
        logger.error(f"[DEBUG] PUTè¯·æ±‚HTTPException: {he.detail}")
        raise
    except Exception as e:
        logger.error(f"[DEBUG] PUTè¯·æ±‚Exception: {str(e)}")
        import traceback
        logger.error(f"[DEBUG] PUTè¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±è´¥: {str(e)}")

@router.delete("/projects/{project_id}")
async def delete_project(
    project_id: int,
    force: bool = Query(False, description="å¼ºåˆ¶åˆ é™¤"),
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤é¡¹ç›®
    å¯¹åº”å‰ç«¯é¡¹ç›®åˆ é™¤åŠŸèƒ½
    """
    try:
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†ä¸­
        if not force and project.status == 'processing':
            raise HTTPException(status_code=400, detail="é¡¹ç›®æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ä½¿ç”¨å¼ºåˆ¶åˆ é™¤")
        
        project_name = project.name
        
        # åˆ é™¤ç›¸å…³æ–‡ä»¶
        files_to_delete = []
        
        # åˆ é™¤æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶
        if project.final_audio_path and os.path.exists(project.final_audio_path):
            files_to_delete.append(project.final_audio_path)
        
        # ğŸš€ æ–°æ¶æ„ï¼šä¸å†éœ€è¦æŸ¥è¯¢TextSegmentï¼Œç›´æ¥å¤„ç†AudioFile
        
        # åˆ é™¤AudioFileè¡¨ä¸­çš„å…³è”è®°å½•
        from app.models import AudioFile
        audio_files = db.query(AudioFile).filter(AudioFile.project_id == project_id).all()
        for audio_file in audio_files:
            if audio_file.file_path and os.path.exists(audio_file.file_path):
                if audio_file.file_path not in files_to_delete:
                    files_to_delete.append(audio_file.file_path)
            db.delete(audio_file)
        
        # åˆ é™¤æ•°æ®åº“è®°å½•ï¼ˆçº§è”åˆ é™¤æ®µè½ï¼‰
        db.delete(project)
        db.commit()
        
        # åˆ é™¤ç‰©ç†æ–‡ä»¶
        deleted_files = []
        for file_path in files_to_delete:
            try:
                os.remove(file_path)
                deleted_files.append(file_path)
            except Exception as e:
                logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        # è®°å½•åˆ é™¤æ—¥å¿—
        await log_system_event(
            db=db,
            level="info",
            message=f"é¡¹ç›®åˆ é™¤: {project_name}",
            module="novel_reader",
            details={
                "project_id": project_id,
                "project_name": project_name,
                "deleted_files": len(deleted_files),
                "force": force
            }
        )
        
        return {
            "success": True,
            "message": f"é¡¹ç›® '{project_name}' åˆ é™¤æˆåŠŸ",
            "deletedFiles": len(deleted_files)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤é¡¹ç›®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

# ä¼ ç»Ÿåˆ†æ®µåŠŸèƒ½å·²åºŸå¼ƒ - ç»Ÿä¸€ä½¿ç”¨æ™ºèƒ½å‡†å¤‡æ¨¡å¼
# @router.post("/projects/{project_id}/segments")
# async def regenerate_segments(...): å·²åˆ é™¤

@router.post("/projects/{project_id}/start-generation")
async def start_audio_generation(
    project_id: int,
    background_tasks: BackgroundTasks,
    parallel_tasks: int = Form(1, description="å¹¶è¡Œä»»åŠ¡æ•°"),
    enable_environment: bool = Form(False, description="å¯ç”¨ç¯å¢ƒéŸ³æ··åˆ"),
    environment_volume: float = Form(0.3, description="ç¯å¢ƒéŸ³éŸ³é‡"),
    db: Session = Depends(get_db)
):
    """
    å¼€å§‹éŸ³é¢‘ç”Ÿæˆ - æ™ºèƒ½å‡†å¤‡å”¯ä¸€ç­–ç•¥
    åªæ”¯æŒä½¿ç”¨æ™ºèƒ½å‡†å¤‡ç»“æœè¿›è¡Œåˆæˆ
    """
    logger.info(f"[DEBUG] å¼€å§‹éŸ³é¢‘ç”Ÿæˆè¯·æ±‚: project_id={project_id}, parallel_tasks={parallel_tasks}, enable_environment={enable_environment}")
    
    try:
        # æŸ¥è¯¢é¡¹ç›®
        logger.info(f"[DEBUG] æŸ¥è¯¢é¡¹ç›® {project_id}...")
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            logger.error(f"[DEBUG] é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        logger.info(f"[DEBUG] æ‰¾åˆ°é¡¹ç›®: {project.name}, çŠ¶æ€: {project.status}")
        
        if project.status == 'processing':
            logger.warning(f"[DEBUG] é¡¹ç›®å·²åœ¨å¤„ç†ä¸­: {project.id}")
            raise HTTPException(status_code=400, detail="é¡¹ç›®å·²åœ¨å¤„ç†ä¸­")
        
        # æ£€æŸ¥æ™ºèƒ½å‡†å¤‡ç»“æœï¼ˆå”¯ä¸€æ•°æ®æºï¼‰
        logger.info(f"[DEBUG] æ£€æŸ¥æ™ºèƒ½å‡†å¤‡ç»“æœ...")
        if not project.book_id:
            logger.error(f"[DEBUG] é¡¹ç›®æœªå…³è”ä¹¦ç±")
            raise HTTPException(status_code=400, detail="é¡¹ç›®æœªå…³è”ä¹¦ç±ï¼Œæ— æ³•ä½¿ç”¨æ™ºèƒ½å‡†å¤‡")
        
        # è·å–æ™ºèƒ½å‡†å¤‡ç»“æœ
        from .models import AnalysisResult
        analysis_results = db.query(AnalysisResult).join(
            BookChapter, AnalysisResult.chapter_id == BookChapter.id
        ).filter(
            BookChapter.book_id == project.book_id,
            AnalysisResult.status == 'completed',
            AnalysisResult.synthesis_plan.isnot(None)
        ).all()
        
        logger.info(f"[DEBUG] æ‰¾åˆ° {len(analysis_results)} ä¸ªæ™ºèƒ½å‡†å¤‡ç»“æœ")
        
        if not analysis_results:
            logger.error(f"[DEBUG] æœªæ‰¾åˆ°æ™ºèƒ½å‡†å¤‡ç»“æœ")
            raise HTTPException(
                status_code=400, 
                detail="æœªæ‰¾åˆ°æ™ºèƒ½å‡†å¤‡ç»“æœï¼Œè¯·å…ˆåœ¨ä¹¦ç±ç®¡ç†é¡µé¢å®Œæˆæ™ºèƒ½å‡†å¤‡"
            )
        
        # æ”¶é›†æ‰€æœ‰åˆæˆæ®µè½æ•°æ®
        synthesis_data = []
        for result in analysis_results:
            if result.synthesis_plan and 'synthesis_plan' in result.synthesis_plan:
                plan_segments = result.synthesis_plan['synthesis_plan']
                synthesis_data.extend(plan_segments)
        
        if not synthesis_data:
            logger.error(f"[DEBUG] æ™ºèƒ½å‡†å¤‡ç»“æœä¸­æ²¡æœ‰åˆæˆæ®µè½æ•°æ®")
            raise HTTPException(
                status_code=400, 
                detail="æ™ºèƒ½å‡†å¤‡ç»“æœä¸­æ²¡æœ‰åˆæˆæ®µè½æ•°æ®ï¼Œè¯·é‡æ–°è¿›è¡Œæ™ºèƒ½å‡†å¤‡"
            )
        
        logger.info(f"[DEBUG] ä»æ™ºèƒ½å‡†å¤‡ç»“æœè·å– {len(synthesis_data)} ä¸ªåˆæˆæ®µè½")
        
        # éªŒè¯æ™ºèƒ½å‡†å¤‡ç»“æœä¸­çš„å£°éŸ³IDæœ‰æ•ˆæ€§
        logger.info(f"[DEBUG] éªŒè¯å£°éŸ³æ¡£æ¡ˆ...")
        voice_ids_to_check = set()
        segments_without_voice = []
        
        for i, segment in enumerate(synthesis_data):
            voice_id = segment.get('voice_id')
            if voice_id:
                voice_ids_to_check.add(voice_id)
            else:
                segments_without_voice.append(i + 1)
        
        if segments_without_voice:
            logger.error(f"[DEBUG] éƒ¨åˆ†æ®µè½ç¼ºå°‘å£°éŸ³é…ç½®: {segments_without_voice[:10]}...")  # åªæ˜¾ç¤ºå‰10ä¸ª
            raise HTTPException(
                status_code=400, 
                detail=f"æœ‰ {len(segments_without_voice)} ä¸ªæ®µè½ç¼ºå°‘å£°éŸ³é…ç½®ï¼Œè¯·åœ¨ä¹¦ç±ç®¡ç†é¡µé¢é‡æ–°è¿›è¡Œæ™ºèƒ½å‡†å¤‡"
            )
        
        # æ‰¹é‡éªŒè¯å£°éŸ³æ¡£æ¡ˆ
        invalid_voices = []
        for voice_id in voice_ids_to_check:
            voice = db.query(VoiceProfile).filter(VoiceProfile.id == voice_id).first()
            if not voice or voice.status != 'active':
                invalid_voices.append(voice_id)
                logger.error(f"[DEBUG] å£°éŸ³æ¡£æ¡ˆæ— æ•ˆ: voice_id={voice_id}")
            else:
                logger.info(f"[DEBUG] å£°éŸ³æ¡£æ¡ˆéªŒè¯é€šè¿‡: {voice.name} (ID: {voice_id})")
        
        if invalid_voices:
            raise HTTPException(
                status_code=400, 
                detail=f"å£°éŸ³æ¡£æ¡ˆæ— æ•ˆæˆ–æœªæ¿€æ´»: {invalid_voices}ï¼Œè¯·æ£€æŸ¥å£°éŸ³é…ç½®"
            )
        
        logger.info(f"[DEBUG] æ‰€æœ‰éªŒè¯é€šè¿‡ï¼Œå¼€å§‹å¯åŠ¨åˆæˆ...")
        
        # ğŸ”¥ éŸ³é¢‘æ–‡ä»¶æ¸…ç†é€»è¾‘å·²ç§»è‡³ start_project_generation ä¸­å¤„ç†
        # è¿™é‡Œä¸å†éœ€è¦æ¸…ç†éŸ³é¢‘æ–‡ä»¶ï¼Œå› ä¸ºè°ƒç”¨æ­¤å‡½æ•°å‰å·²ç»æ¸…ç†è¿‡äº†
        logger.info(f"[DEBUG] è·³è¿‡éŸ³é¢‘æ–‡ä»¶æ¸…ç†ï¼Œå·²åœ¨å¯åŠ¨æ—¶å¤„ç†")
        
        # æ›´æ–°é¡¹ç›®çŠ¶æ€
        project.status = 'processing'
        project.started_at = datetime.utcnow()
        # ğŸš€ æ–°æ¶æ„ï¼šç§»é™¤æ—§è¿›åº¦å­—æ®µçš„è®¾ç½®
        # project.current_segment = 0
        # project.processed_segments = 0
        # project.total_segments = len(synthesis_data)
        
        logger.info(f"[DEBUG] æäº¤æ•°æ®åº“æ›´æ”¹...")
        db.commit()
        
        logger.info(f"[DEBUG] å¯åŠ¨æ™ºèƒ½å‡†å¤‡æ¨¡å¼çš„åå°ä»»åŠ¡...")
        
        if enable_environment:
            # ä½¿ç”¨ç¯å¢ƒéŸ³æ··åˆåè°ƒå™¨
            from app.services.sequential_synthesis_coordinator import SequentialSynthesisCoordinator
            coordinator = SequentialSynthesisCoordinator()
            
            async def environment_synthesis_wrapper():
                try:
                    result = await coordinator.synthesize_with_environment(
                        project_id=project_id,
                        synthesis_data=synthesis_data,
                        enable_environment=True,
                        environment_volume=environment_volume,
                        parallel_tasks=parallel_tasks
                    )
                    logger.info(f"[ENV_SYNTHESIS] ç¯å¢ƒéŸ³æ··åˆå®Œæˆ: {result}")
                except Exception as e:
                    logger.error(f"[ENV_SYNTHESIS] ç¯å¢ƒéŸ³æ··åˆå¤±è´¥: {str(e)}")
                    
            background_tasks.add_task(environment_synthesis_wrapper)
        else:
            # ä¼ ç»ŸTTSåˆæˆ
            background_tasks.add_task(
                process_audio_generation_from_synthesis_plan,
                project_id,
                synthesis_data,
                parallel_tasks
            )
        
        # è®°å½•å¼€å§‹ç”Ÿæˆæ—¥å¿—
        await log_system_event(
            db=db,
            level="info",
            message=f"å¼€å§‹éŸ³é¢‘ç”Ÿæˆï¼ˆæ™ºèƒ½å‡†å¤‡æ¨¡å¼ï¼‰: {project.name}",
            module="novel_reader",
            details={
                "project_id": project_id,
                "total_segments": len(synthesis_data),
                "parallel_tasks": parallel_tasks,
                "data_source": "æ™ºèƒ½å‡†å¤‡ç»“æœ"
            }
        )
        
        logger.info(f"[DEBUG] æ™ºèƒ½å‡†å¤‡æ¨¡å¼ä»»åŠ¡å¯åŠ¨æˆåŠŸ")
        synthesis_mode = "ç¯å¢ƒéŸ³æ··åˆæ¨¡å¼" if enable_environment else "æ™ºèƒ½å‡†å¤‡æ¨¡å¼"
        return {
            "success": True,
            "message": f"éŸ³é¢‘ç”Ÿæˆå·²å¯åŠ¨ï¼ˆ{synthesis_mode}ï¼‰",
            "total_segments": len(synthesis_data),
            "parallel_tasks": parallel_tasks,
            "enable_environment": enable_environment,
            "environment_volume": environment_volume if enable_environment else None
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[DEBUG] å¯åŠ¨éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.post("/projects/{project_id}/pause")
async def pause_generation(
    project_id: int,
    db: Session = Depends(get_db)
):
    """
    æš‚åœéŸ³é¢‘ç”Ÿæˆ
    å¯¹åº”å‰ç«¯æš‚åœåŠŸèƒ½
    """
    try:
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        if project.status != 'processing':
            raise HTTPException(status_code=400, detail="é¡¹ç›®æœªåœ¨å¤„ç†ä¸­")
        
        # æ›´æ–°é¡¹ç›®çŠ¶æ€
        project.status = 'paused'
        db.commit()
        
        # è®°å½•æš‚åœæ—¥å¿—
        await log_system_event(
            db=db,
            level="info",
            message=f"éŸ³é¢‘ç”Ÿæˆæš‚åœ: {project.name}",
            module="novel_reader",
            details={
                "project_id": project_id,
                "status": project.status
            }
        )
        
        return {
            "success": True,
            "message": "éŸ³é¢‘ç”Ÿæˆå·²æš‚åœ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æš‚åœç”Ÿæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æš‚åœå¤±è´¥: {str(e)}")

@router.post("/projects/{project_id}/resume")
async def resume_generation(
    project_id: int,
    background_tasks: BackgroundTasks,
    parallel_tasks: int = Form(1, description="å¹¶è¡Œä»»åŠ¡æ•°"),
    db: Session = Depends(get_db)
):
    """
    æ¢å¤éŸ³é¢‘ç”Ÿæˆ
    å¯¹åº”å‰ç«¯æ¢å¤åŠŸèƒ½
    """
    try:
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        if project.status != 'paused':
            raise HTTPException(status_code=400, detail="é¡¹ç›®æœªå¤„äºæš‚åœçŠ¶æ€")
        
        # æ›´æ–°é¡¹ç›®çŠ¶æ€
        project.status = 'processing'
        db.commit()
        
        # ğŸš€ æ–°æ¶æ„ï¼šé‡æ–°å¯åŠ¨æ—¶ä¹Ÿä½¿ç”¨æ™ºèƒ½å‡†å¤‡æ¨¡å¼
        # æ¢å¤æ—¶éœ€è¦é‡æ–°è·å–æ™ºèƒ½å‡†å¤‡ç»“æœ
        # background_tasks.add_task(
        #     process_audio_generation_from_synthesis_plan,
        #     project_id,
        #     synthesis_data,
        #     parallel_tasks
        # )
        # æš‚æ—¶ä¸æ”¯æŒæ¢å¤åŠŸèƒ½ï¼Œéœ€è¦é‡æ–°å¯åŠ¨
        raise HTTPException(status_code=400, detail="è¯·é‡æ–°å¯åŠ¨éŸ³é¢‘ç”Ÿæˆ")
        
        # è®°å½•æ¢å¤æ—¥å¿—
        await log_system_event(
            db=db,
            level="info",
            message=f"éŸ³é¢‘ç”Ÿæˆæ¢å¤: {project.name}",
            module="novel_reader",
            details={
                "project_id": project_id,
                "parallel_tasks": parallel_tasks
            }
        )
        
        return {
            "success": True,
            "message": "éŸ³é¢‘ç”Ÿæˆå·²æ¢å¤"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¢å¤ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¢å¤å¤±è´¥: {str(e)}")

@router.get("/projects/{project_id}/progress")
async def get_generation_progress(
    project_id: int,
    db: Session = Depends(get_db)
):
    """
    ğŸš¨ åºŸå¼ƒè­¦å‘Šï¼šé¡¹ç›®çº§åˆ«è¿›åº¦APIå·²åºŸå¼ƒ
    è¯·ä½¿ç”¨ç« èŠ‚çº§åˆ«çš„è¿›åº¦API: /projects/{project_id}/chapters/{chapter_id}/progress
    """
    try:
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        logger.warning(f"âš ï¸ é¡¹ç›®çº§åˆ«è¿›åº¦APIå·²åºŸå¼ƒï¼Œé¡¹ç›®ID: {project_id}")
        
        return {
            "success": True,
            "deprecated": True,
            "message": "é¡¹ç›®çº§åˆ«è¿›åº¦APIå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ç« èŠ‚çº§åˆ«çš„è¿›åº¦API",
            "progress": {
                "projectId": project_id,
                "status": project.status,
                "progressPercent": 0,
                "statistics": {
                    "total": 0,
                    "completed": 0,
                    "failed": 0,
                    "processing": 0,
                    "pending": 0
                },
                "startedAt": project.started_at.isoformat() if project.started_at else None,
                "estimatedCompletion": None,
                "recentCompleted": []
            },
            "migration_info": {
                "recommended_api": f"/projects/{project_id}/chapters/{{chapter_id}}/progress",
                "description": "ç°åœ¨ä½¿ç”¨ç« èŠ‚çº§åˆ«çš„è¿›åº¦è¿½è¸ªï¼Œæ¯ä¸ªç« èŠ‚ç‹¬ç«‹ç®¡ç†"
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–è¿›åº¦å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è¿›åº¦å¤±è´¥: {str(e)}")

# ğŸ”§ ç§»é™¤é¡¹ç›®ä¸‹è½½åŠŸèƒ½ - ç”¨æˆ·ä¸éœ€è¦é¡¹ç›®ä¸‹è½½åŠŸèƒ½
# @router.get("/projects/{project_id}/download")
# async def download_final_audio(project_id: int, db: Session = Depends(get_db)):
#     """ä¸‹è½½æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶ - å·²ç§»é™¤"""
#     raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸‹è½½åŠŸèƒ½å·²ç§»é™¤")

# ä¼ ç»Ÿåˆ†æ®µå·¥å…·å‡½æ•°å·²åºŸå¼ƒ - ç»Ÿä¸€ä½¿ç”¨æ™ºèƒ½å‡†å¤‡æ¨¡å¼

# ğŸš€ å·²åˆ é™¤ï¼šsegment_text_by_strategy_no_commit - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸ä½¿ç”¨

# ğŸš€ å·²åˆ é™¤ï¼šsegment_text_by_strategy - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸ä½¿ç”¨

# ğŸš€ å·²åˆ é™¤ï¼šdetect_speaker - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä½¿ç”¨AIæ™ºèƒ½æ£€æµ‹å™¨

# ğŸš€ å·²åˆ é™¤ï¼šupdate_segments_voice_mapping - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸éœ€è¦

# ğŸš€ å·²åˆ é™¤ï¼šprocess_audio_generation - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä½¿ç”¨process_audio_generation_from_synthesis_plan

# ğŸš€ å·²åˆ é™¤ï¼šprocess_single_segment_sequential - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸ä½¿ç”¨

# ğŸš€ å·²åˆ é™¤ï¼šprocess_single_segment - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸ä½¿ç”¨

# ğŸš€ å·²åˆ é™¤ï¼šcheck_project_completion - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸ä½¿ç”¨

# ğŸš€ å·²åˆ é™¤ï¼šmerge_audio_files - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä½¿ç”¨merge_audio_files_from_plan

# ğŸš€ å·²åˆ é™¤ï¼šupdate_segments_voice_mapping_no_commit - æ—§æ¶æ„å‡½æ•°ï¼Œæ–°æ¶æ„ä¸ä½¿ç”¨ 

async def process_audio_generation_from_synthesis_plan(
    project_id: int, 
    synthesis_data: List[Dict], 
    parallel_tasks: int = 1
):
    """
    åŸºäºæ™ºèƒ½å‡†å¤‡ç»“æœç›´æ¥è¿›è¡ŒéŸ³é¢‘åˆæˆ
    ä¸ä¾èµ– TextSegment è¡¨ï¼Œç›´æ¥ä½¿ç”¨ JSON æ•°æ®
    """
    logger.info(f"[SYNTHESIS_PLAN] å¼€å§‹å¤„ç†é¡¹ç›® {project_id} çš„éŸ³é¢‘åˆæˆï¼Œå…± {len(synthesis_data)} ä¸ªæ®µè½")
    
    try:
        # è·å–æ•°æ®åº“è¿æ¥
        db = next(get_db())
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        if not project:
            logger.error(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            return
        
        # åˆå§‹åŒ–TTSå®¢æˆ·ç«¯
        tts_client = get_tts_client()
        
        logger.info(f"[SYNTHESIS_PLAN] TTSæœåŠ¡çŠ¶æ€æ£€æŸ¥...")
        health_status = await tts_client.health_check()
        if health_status.get("status") != "healthy":
            logger.error(f"[SYNTHESIS_PLAN] TTSæœåŠ¡ä¸å¯ç”¨: {health_status}")
            project.status = 'failed'
            project.error_message = f"TTSæœåŠ¡ä¸å¯ç”¨: {health_status.get('error', 'æœªçŸ¥é”™è¯¯')}"
            db.commit()
            return
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        project_output_dir = f"outputs/projects/{project_id}"
        os.makedirs(project_output_dir, exist_ok=True)
        
        # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(parallel_tasks)
        
        # åˆå§‹åŒ–WebSocketç®¡ç†å™¨ç”¨äºè¿›åº¦æ¨é€
        from app.websocket.manager import websocket_manager
        
        # å¤„ç†æ¯ä¸ªæ®µè½
        completed_count = 0
        failed_segments = []
        output_files = []
        
        async def process_segment(segment_data, segment_index):
            """å¤„ç†å•ä¸ªæ®µè½ - åºåˆ—åŒ–ç‰ˆæœ¬"""
            try:
                # ğŸš¨ åœ¨æ®µè½å¤„ç†å¼€å§‹æ—¶ä¹Ÿæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                db.refresh(project)
                if project.status == 'cancelled':
                    logger.warning(f"[SYNTHESIS_PLAN] æ®µè½å¤„ç†ä¸­æ£€æµ‹åˆ°é¡¹ç›®å·²å–æ¶ˆï¼Œåœæ­¢å¤„ç†æ®µè½ {segment_index + 1}")
                    return {"error": "é¡¹ç›®å·²è¢«å–æ¶ˆ"}
                
                segment_id = segment_data.get('segment_id', segment_index + 1)
                text = segment_data.get('text', '')
                speaker = segment_data.get('speaker', 'æœªçŸ¥')
                voice_id = segment_data.get('voice_id')
                character_id = segment_data.get('character_id')
                parameters = segment_data.get('parameters', {})
                
                logger.info(f"[SYNTHESIS_PLAN] å¤„ç†æ®µè½ {segment_id}: {speaker} - {text[:50]}...")
                
                if not text.strip():
                    logger.warning(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
                    return None
                
                # ğŸš€ æ¶æ„æ”¹è¿›ï¼šæ”¯æŒä¸¤ç§æ–¹å¼è·å–éŸ³é¢‘é…ç½®
                # æ–¹å¼1ï¼ˆæ¨èï¼‰ï¼šé€šè¿‡character_idè·å–æœ€æ–°é…éŸ³
                # æ–¹å¼2ï¼ˆå‘åå…¼å®¹ï¼‰ï¼šé€šè¿‡voice_idè·å–VoiceProfile
                character = None
                voice = None
                
                if character_id:
                    # ğŸ¯ æ–°æ¶æ„ï¼šé€šè¿‡character_idè·å–è§’è‰²æœ€æ–°é…éŸ³
                    try:
                        from app.models.character import Character
                        character = db.query(Character).filter(Character.id == character_id).first()
                        if character and character.reference_audio_path:
                            logger.info(f"[NEW_ARCH] æ®µè½ {segment_id} ä½¿ç”¨è§’è‰²é…éŸ³ï¼š{character.name} (ID: {character.id})")
                            # åˆ›å»ºå…¼å®¹çš„voiceå¯¹è±¡
                            class VoiceCompat:
                                def __init__(self, char):
                                    self.id = char.id
                                    self.name = char.name
                                    self.reference_audio_path = char.reference_audio_path
                                    self.latent_file_path = char.latent_file_path
                                    self.status = char.status
                                
                                def validate_files(self):
                                    return {'valid': True, 'missing_files': []}
                            
                            voice = VoiceCompat(character)
                        else:
                            logger.error(f"[NEW_ARCH] æ®µè½ {segment_id} è§’è‰²ID {character_id} ä¸å­˜åœ¨æˆ–æœªé…ç½®éŸ³é¢‘ï¼Œè¯·åœ¨è§’è‰²é…éŸ³åº“ä¸­é…ç½®å£°éŸ³")
                            return {"error": f"æ®µè½ {segment_id} è§’è‰²'{speaker}'æœªé…ç½®å£°éŸ³ï¼Œè¯·åœ¨è§’è‰²é…éŸ³åº“ä¸­ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"}
                    except Exception as e:
                        logger.error(f"[NEW_ARCH] æ®µè½ {segment_id} æŸ¥æ‰¾è§’è‰²å¤±è´¥: {e}")
                        return {"error": f"æ®µè½ {segment_id} è§’è‰²æŸ¥æ‰¾å¤±è´¥: {e}"}
                
                elif voice_id:
                    # ğŸ”„ æ—§æ¶æ„ï¼šé€šè¿‡voice_idè·å–VoiceProfileï¼ˆå‘åå…¼å®¹ï¼‰
                    try:
                        voice = db.query(VoiceProfile).filter(VoiceProfile.id == voice_id).first()
                        if voice:
                            logger.info(f"[OLD_ARCH] æ®µè½ {segment_id} ä½¿ç”¨VoiceProfileï¼š{voice.name} (ID: {voice.id})")
                        else:
                            logger.error(f"[OLD_ARCH] æ®µè½ {segment_id} VoiceProfileä¸å­˜åœ¨: {voice_id}")
                    except Exception as e:
                        logger.error(f"[OLD_ARCH] æ®µè½ {segment_id} æŸ¥æ‰¾VoiceProfileå¤±è´¥: {e}")
                
                if not voice:
                    logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} æ— æ³•è·å–å£°éŸ³é…ç½® (character_id: {character_id}, voice_id: {voice_id})")
                    return {"error": f"æ®µè½ {segment_id} ç¼ºå°‘å£°éŸ³é…ç½®"}
                
                # éªŒè¯å£°éŸ³æ–‡ä»¶
                file_validation = voice.validate_files()
                if not file_validation['valid']:
                    logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} å£°éŸ³æ–‡ä»¶ç¼ºå¤±: {file_validation['missing_files']}")
                    return {"error": f"æ®µè½ {segment_id} å£°éŸ³æ–‡ä»¶ç¼ºå¤±"}
                
                # ç”ŸæˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„
                safe_speaker = "".join(c for c in speaker if c.isalnum() or c in (' ', '-', '_')).rstrip()
                # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®å®é™…ä½¿ç”¨çš„voiceå¯¹è±¡IDç”Ÿæˆæ–‡ä»¶åï¼Œé¿å…IDæ··ç”¨
                voice_identifier = voice.id if hasattr(voice, 'id') else 'unknown'
                
                # ğŸš¨ é‡è¦ä¿®å¤ï¼šåœ¨æ–‡ä»¶åä¸­æ·»åŠ ç« èŠ‚IDï¼Œé¿å…ä¸åŒç« èŠ‚çš„æ®µè½æ–‡ä»¶ç›¸äº’è¦†ç›–
                chapter_id = segment_data.get('chapter_id', 'unknown')
                audio_filename = f"chapter_{chapter_id}_segment_{segment_id:04d}_{safe_speaker}_{voice_identifier}.wav"
                audio_path = os.path.join(project_output_dir, audio_filename)
                
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨è§’è‰²é…éŸ³åº“çš„ä¸ªæ€§åŒ–å‚æ•°
                final_parameters = {}
                
                # æ–¹å¼1ï¼šä»è§’è‰²é…éŸ³åº“è·å–å‚æ•°ï¼ˆæ¨èï¼‰
                if character and hasattr(character, 'voice_parameters') and character.voice_parameters:
                    try:
                        import json
                        char_params = json.loads(character.voice_parameters) if isinstance(character.voice_parameters, str) else character.voice_parameters
                        logger.info(f"[PARAMS] ä½¿ç”¨è§’è‰²é…éŸ³åº“å‚æ•°ï¼š{char_params}")
                        final_parameters = {
                            'timeStep': char_params.get('timeStep', char_params.get('time_step', 32)),
                            'pWeight': char_params.get('pWeight', char_params.get('p_weight', 1.4)),
                            'tWeight': char_params.get('tWeight', char_params.get('t_weight', 3.0))
                        }
                    except Exception as e:
                        logger.warning(f"[PARAMS] è§£æè§’è‰²å‚æ•°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°: {e}")
                        final_parameters = {'timeStep': 32, 'pWeight': 1.4, 'tWeight': 3.0}
                else:
                    # æ–¹å¼2ï¼šä½¿ç”¨synthesis_plançš„é€šç”¨å‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
                    final_parameters = {
                        'timeStep': parameters.get('timeStep', 32),
                        'pWeight': parameters.get('pWeight', 1.4),
                        'tWeight': parameters.get('tWeight', 3.0)
                    }
                    logger.info(f"[PARAMS] ä½¿ç”¨é€šç”¨å‚æ•°ï¼š{final_parameters}")
                
                # å‡†å¤‡TTSè¯·æ±‚
                tts_request = TTSRequest(
                    text=text,
                    reference_audio_path=voice.reference_audio_path,
                    output_audio_path=audio_path,
                    time_step=final_parameters['timeStep'],
                    p_weight=final_parameters['pWeight'],
                    t_weight=final_parameters['tWeight'],
                    latent_file_path=voice.latent_file_path
                )
                
                # è°ƒç”¨TTSåˆæˆ
                start_time = time.time()
                response = await tts_client.synthesize_speech(tts_request)
                processing_time = time.time() - start_time
                
                if response.success:
                    # éªŒè¯ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
                    if os.path.exists(audio_path):
                        file_size = os.path.getsize(audio_path)
                        
                        # è·å–éŸ³é¢‘æ—¶é•¿
                        try:
                            from app.utils import get_audio_duration
                            duration = get_audio_duration(audio_path)
                        except:
                            duration = 0.0
                        
                        # ğŸš€ è·å–ç« èŠ‚ä¿¡æ¯ç”¨äºæ–°æ¶æ„
                        chapter_number = segment_data.get('chapter_number')
                        chapter_id = segment_data.get('chapter_id')
                        if not chapter_number and chapter_id:
                            # å°è¯•ä»æ•°æ®åº“è·å–ç« èŠ‚å·
                            try:
                                from app.models import BookChapter
                                chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
                                if chapter:
                                    chapter_number = chapter.chapter_number
                                    logger.info(f"[NEW_ARCH] æ®µè½ {segment_id} ä»æ•°æ®åº“è·å–ç« èŠ‚å·: {chapter_number}")
                            except Exception as e:
                                logger.error(f"[NEW_ARCH] è·å–ç« èŠ‚ä¿¡æ¯å¤±è´¥: {e}")
                        
                        # ğŸš€ æ³¨é‡Šæ‰é˜²é‡å¤æ£€æŸ¥ï¼šç”¨æˆ·ç‚¹å‡»é‡æ–°åˆæˆæ—¶å·²æ¸…ç†äº†æ‰€æœ‰ç°æœ‰æ–‡ä»¶
                        # é‡æ–°åˆæˆæ—¶ä¸éœ€è¦æ£€æŸ¥é‡å¤ï¼Œå› ä¸ºå¯åŠ¨æ—¶å·²ç»æ¸…ç†è¿‡äº†
                        logger.debug(f"[SYNTHESIS_PLAN] å¼€å§‹åˆæˆæ®µè½ {segment_id}ï¼Œè§’è‰²: {speaker}")
                        
                        # ğŸ”¥ ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®character_idå’Œvoice_profile_idï¼Œé¿å…IDç©ºé—´å†²çª
                        # æ ¹æ®voiceå¯¹è±¡çš„æ¥æºæ­£ç¡®è®¾ç½®IDå­—æ®µ
                        audio_character_id = None
                        audio_voice_profile_id = None
                        
                        if character_id:
                            # æ–°æ¶æ„ï¼šä½¿ç”¨è§’è‰²é…éŸ³åº“
                            audio_character_id = character_id
                            logger.debug(f"[NEW_ARCH] AudioFileä½¿ç”¨character_id: {character_id}")
                        elif voice_id and hasattr(voice, 'id') and not hasattr(voice, '__dict__'):
                            # æ—§æ¶æ„ï¼šä½¿ç”¨VoiceProfileï¼ˆvoiceæ˜¯çœŸæ­£çš„VoiceProfileå¯¹è±¡ï¼‰
                            audio_voice_profile_id = voice.id
                            logger.debug(f"[OLD_ARCH] AudioFileä½¿ç”¨voice_profile_id: {voice.id}")
                        else:
                            logger.warning(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} æ— æ³•ç¡®å®šIDç±»å‹ï¼Œä½¿ç”¨voiceå¯¹è±¡ID")
                            # å¦‚æœæ— æ³•ç¡®å®šï¼Œæ ¹æ®voiceå¯¹è±¡ç±»å‹åˆ¤æ–­
                            if hasattr(voice, '__dict__') and 'VoiceCompat' in str(type(voice)):
                                # VoiceCompatå¯¹è±¡æ¥è‡ªCharacter
                                audio_character_id = voice.id
                            else:
                                # çœŸæ­£çš„VoiceProfileå¯¹è±¡
                                audio_voice_profile_id = voice.id if hasattr(voice, 'id') else None
                        
                        # ä¿å­˜AudioFileè®°å½•ï¼ˆæ–°æ¶æ„ï¼šåŒ…å«å®Œæ•´åˆæˆä¿¡æ¯ï¼‰
                        audio_file = AudioFile(
                            filename=audio_filename,
                            original_name=f"æ®µè½{segment_id}_{speaker}",
                            file_path=audio_path,
                            file_size=file_size,
                            duration=duration,
                            project_id=project_id,
                            chapter_id=chapter_id,
                            chapter_number=chapter_number,
                            character_name=speaker,  # è§’è‰²å
                            speaker=speaker,  # è¯´è¯äºº
                            paragraph_index=segment_id,  # æ®µè½ç´¢å¼•
                            character_id=audio_character_id,  # ğŸš€ æ–°æ¶æ„ï¼šCharacter ID
                            voice_profile_id=audio_voice_profile_id,  # ğŸš€ æ—§æ¶æ„ï¼šVoiceProfile ID
                            text_content=text,
                            audio_type='segment',
                            processing_time=processing_time,
                            model_used='MegaTTS3',
                            status='active',
                            created_at=datetime.utcnow()
                        )
                        db.add(audio_file)
                        db.commit()
                        db.refresh(audio_file)
                        
                        # ğŸš€ æ–°æ¶æ„ï¼šå®Œå…¨åŸºäºAudioFileï¼Œä¸å†åˆ›å»ºTextSegment
                        # AudioFileå·²åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼šæ–‡æœ¬å†…å®¹ã€è¯´è¯äººã€ç« èŠ‚ç­‰
                        
                        logger.info(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} åˆæˆæˆåŠŸï¼Œè€—æ—¶ {processing_time:.2f}s")
                        
                        return {
                            "segment_id": segment_id,
                            "audio_file_id": audio_file.id,
                            "file_path": audio_path,
                            "duration": duration,
                            "speaker": speaker,
                            "character_id": audio_character_id,  # ğŸš€ æ–°æ¶æ„ï¼šè¿”å›æ­£ç¡®çš„character_id
                            "voice_profile_id": audio_voice_profile_id,  # ğŸš€ æ—§æ¶æ„ï¼šè¿”å›æ­£ç¡®çš„voice_profile_id
                            "chapter_id": chapter_id  # ğŸ”¥ æ–°å¢ï¼šè¿”å›ç« èŠ‚IDç”¨äºéŸ³é¢‘åˆå¹¶
                        }
                    else:
                        logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆ")
                        return {"error": f"æ®µè½ {segment_id} éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆ"}
                else:
                    logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {segment_id} TTSåˆæˆå¤±è´¥: {response.message}")
                    return {"error": f"æ®µè½ {segment_id} TTSåˆæˆå¤±è´¥: {response.message}"}
                    
            except Exception as e:
                logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {segment_index + 1} å¤„ç†å¼‚å¸¸: {str(e)}")
                return {"error": f"æ®µè½ {segment_index + 1} å¤„ç†å¼‚å¸¸: {str(e)}"}
        
        # åºåˆ—åŒ–å¤„ç†æ®µè½ - é˜²æ­¢GPUè¿‡è½½
        logger.info(f"[SYNTHESIS_PLAN] å¼€å§‹åºåˆ—åŒ–å¤„ç† {len(synthesis_data)} ä¸ªæ®µè½...")
        results = []
        for i, segment in enumerate(synthesis_data):
            logger.info(f"[SYNTHESIS_PLAN] å¤„ç†è¿›åº¦: {i+1}/{len(synthesis_data)}")
            
            # ğŸš¨ å…³é”®ä¿®å¤ï¼šæ¯æ¬¡å¤„ç†å‰æ£€æŸ¥é¡¹ç›®æ˜¯å¦è¢«å–æ¶ˆ
            db.refresh(project)  # åˆ·æ–°é¡¹ç›®çŠ¶æ€
            if project.status == 'cancelled':
                logger.warning(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} å·²è¢«å–æ¶ˆï¼Œåœæ­¢å¤„ç†")
                project.error_message = f"åˆæˆå·²è¢«ç”¨æˆ·å–æ¶ˆï¼Œå·²å¤„ç† {i}/{len(synthesis_data)} ä¸ªæ®µè½"
                db.commit()
                return
            
            # ğŸ”§ å®æ—¶ç»Ÿè®¡å·²å®Œæˆæ®µè½æ•°ï¼ˆåŸºäºå½“å‰projectçŠ¶æ€ï¼‰
            current_completed = db.query(AudioFile).filter(
                AudioFile.project_id == project_id,
                AudioFile.audio_type == 'segment'
            ).count()
            
            # å‘é€æ®µè½å¼€å§‹å¤„ç†çš„è¿›åº¦æ›´æ–°åˆ°å‰ç«¯
            try:
                await websocket_manager.publish_to_topic(
                    f"synthesis_{project_id}",
                    {
                        "type": "progress_update",
                        "data": {
                            "type": "synthesis",
                            "project_id": project_id,
                            "status": "running",
                            "progress": round((i / len(synthesis_data)) * 100),
                            "completed_segments": current_completed,
                            "total_segments": len(synthesis_data),
                            "failed_segments": len(failed_segments),
                            "current_processing": f"æ­£åœ¨å¤„ç†æ®µè½ {i+1} - {segment.get('speaker', 'æœªçŸ¥è§’è‰²')}: {segment.get('text', '')[:50]}...",
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    }
                )
            except Exception as ws_error:
                logger.error(f"[SYNTHESIS_PLAN] WebSocketè¿›åº¦æ¨é€å¤±è´¥: {str(ws_error)}")
            
            try:
                result = await process_segment(segment, i)
                results.append(result)
                
                # ğŸ”§ æ¯å®Œæˆä¸€ä¸ªæ®µè½å°±å®æ—¶å‘é€è¿›åº¦æ›´æ–°
                if result and not isinstance(result, Exception) and "error" not in result:
                    updated_completed = db.query(AudioFile).filter(
                        AudioFile.project_id == project_id,
                        AudioFile.audio_type == 'segment'
                    ).count()
                    
                    try:
                        await websocket_manager.publish_to_topic(
                            f"synthesis_{project_id}",
                            {
                                "type": "progress_update",
                                "data": {
                                    "type": "synthesis",
                                    "project_id": project_id,
                                    "status": "running",
                                    "progress": round(((i + 1) / len(synthesis_data)) * 100),
                                    "completed_segments": updated_completed,
                                    "total_segments": len(synthesis_data),
                                    "failed_segments": len(failed_segments),
                                    "current_processing": f"å·²å®Œæˆæ®µè½ {i+1} - {segment.get('speaker', 'æœªçŸ¥è§’è‰²')}",
                                    "timestamp": datetime.utcnow().isoformat()
                                }
                            }
                        )
                    except Exception as ws_error:
                        logger.error(f"[SYNTHESIS_PLAN] å®Œæˆè¿›åº¦æ¨é€å¤±è´¥: {str(ws_error)}")
                        
            except Exception as e:
                logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {i+1} å¤„ç†å¼‚å¸¸: {str(e)}")
                results.append(e)
        
        # ç»Ÿè®¡å¤„ç†ç»“æœ
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"[SYNTHESIS_PLAN] æ®µè½ {i + 1} å¤„ç†å¼‚å¸¸: {str(result)}")
                failed_segments.append({
                    "segment_index": i + 1,
                    "error": str(result),
                    "timestamp": datetime.utcnow().isoformat()
                })
            elif result and "error" in result:
                logger.error(f"[SYNTHESIS_PLAN] æ®µè½å¤„ç†å¤±è´¥: {result['error']}")
                failed_segments.append({
                    "segment_index": i + 1,
                    "error": result["error"],
                    "timestamp": datetime.utcnow().isoformat()
                })
            elif result:
                # é‡æ–°åˆæˆæ¨¡å¼ï¼šæ‰€æœ‰æˆåŠŸçš„ç»“æœéƒ½è®¡æ•°ï¼ˆä¸å­˜åœ¨"existing"çŠ¶æ€ï¼‰
                completed_count += 1
                output_files.append(result)
                logger.info(f"[SYNTHESIS_PLAN] æ®µè½ {result['segment_id']} åˆæˆå®Œæˆ")
        
        # ğŸš€ æ–°æ¶æ„ï¼šåªè®°å½•ç« èŠ‚çº§åˆ«çš„å¤„ç†ç»“æœ
        logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚å¤„ç†ç»“æœ: é¢„æœŸ{len(synthesis_data)}ä¸ªï¼ŒæˆåŠŸ{completed_count}ä¸ª")
        db.commit()
        
        logger.info(f"[SYNTHESIS_PLAN] å¤„ç†å®Œæˆ: æˆåŠŸ {completed_count}/{len(synthesis_data)} ä¸ªæ®µè½")
        
        # å¦‚æœæœ‰æˆåŠŸçš„æ®µè½ï¼Œå°è¯•åˆå¹¶éŸ³é¢‘
        final_audio_path = None
        if output_files:
            try:
                logger.info(f"[SYNTHESIS_PLAN] å¼€å§‹åˆå¹¶ {len(output_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶...")
                final_audio_path = await merge_audio_files_from_plan(project, output_files, db)
                logger.info(f"[SYNTHESIS_PLAN] éŸ³é¢‘åˆå¹¶å®Œæˆ: {final_audio_path}")
            except Exception as e:
                logger.error(f"[SYNTHESIS_PLAN] éŸ³é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        
        # ğŸš€ é¡¹ç›®çº§åˆ«çŠ¶æ€ç®¡ç†å·²åºŸå¼ƒ - ç°åœ¨åªå…³æ³¨ç« èŠ‚çº§åˆ«çš„å¤„ç†
        
        # ğŸš€ æœ€ç»ˆæ•°æ®ä¸€è‡´æ€§ç¡®è®¤ï¼ˆä½¿ç”¨ä¹‹å‰è®¡ç®—çš„final_totalï¼‰
        project.completed_at = datetime.utcnow()
        project.final_audio_path = final_audio_path
        
        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ›´æ–°ç« èŠ‚åˆæˆçŠ¶æ€
        logger.info(f"[SYNTHESIS_PLAN] å¼€å§‹æ›´æ–°ç« èŠ‚åˆæˆçŠ¶æ€...")
        try:
            # è·å–æ‰€æœ‰ç›¸å…³ç« èŠ‚ID
            chapter_ids = set()
            for segment in synthesis_data:
                chapter_id = segment.get('chapter_id')
                if chapter_id:
                    chapter_ids.add(chapter_id)
            
            # æ›´æ–°ç« èŠ‚çŠ¶æ€
            if chapter_ids:
                from app.models import BookChapter
                
                for chapter_id in chapter_ids:
                    # æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦æœ‰å®Œæˆçš„éŸ³é¢‘æ–‡ä»¶
                    chapter_audio_count = db.query(AudioFile).filter(
                        AudioFile.project_id == project_id,
                        AudioFile.chapter_id == chapter_id,
                        AudioFile.audio_type == 'segment'
                    ).count()
                    
                    # æ›´æ–°ç« èŠ‚çŠ¶æ€
                    chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
                    if chapter and chapter_audio_count > 0:
                        chapter.synthesis_status = 'completed'
                        logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} çŠ¶æ€æ›´æ–°ä¸º completed ({chapter_audio_count} ä¸ªéŸ³é¢‘æ–‡ä»¶)")
                    elif chapter:
                        chapter.synthesis_status = 'failed'
                        logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} çŠ¶æ€æ›´æ–°ä¸º failed (æ— éŸ³é¢‘æ–‡ä»¶)")
            
            # å¦‚æœæ²¡æœ‰chapter_idï¼Œå°è¯•ä»projectçš„bookä¸­è·å–
            elif project.book_id:
                from app.models import Book, BookChapter
                book = db.query(Book).filter(Book.id == project.book_id).first()
                if book:
                    chapters = db.query(BookChapter).filter(BookChapter.book_id == book.id).all()
                    for chapter in chapters:
                        # æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦æœ‰å®Œæˆçš„éŸ³é¢‘æ–‡ä»¶
                        chapter_audio_count = db.query(AudioFile).filter(
                            AudioFile.project_id == project_id,
                            AudioFile.chapter_number == chapter.chapter_number,
                            AudioFile.audio_type == 'segment'
                        ).count()
                        
                        if chapter_audio_count > 0:
                            chapter.synthesis_status = 'completed'
                            logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter.id} (ç¬¬{chapter.chapter_number}ç« ) çŠ¶æ€æ›´æ–°ä¸º completed")
                        else:
                            chapter.synthesis_status = 'failed'
                            logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter.id} (ç¬¬{chapter.chapter_number}ç« ) çŠ¶æ€æ›´æ–°ä¸º failed")
            
        except Exception as e:
            logger.error(f"[SYNTHESIS_PLAN] æ›´æ–°ç« èŠ‚çŠ¶æ€å¤±è´¥: {str(e)}")
        
        # ğŸš€ é¡¹ç›®çŠ¶æ€æ—¥å¿—å·²åºŸå¼ƒ - ç°åœ¨åªå…³æ³¨ç« èŠ‚çº§åˆ«çš„å¤„ç†
        
        if failed_segments:
            # ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æ‘˜è¦
            error_summary = generate_detailed_error_summary(failed_segments, len(synthesis_data))
            project.error_message = error_summary
        
        db.commit()
        
        # ğŸ”¥ æ–°å¢ï¼šæŒ‰ç« èŠ‚åˆå¹¶éŸ³é¢‘æ–‡ä»¶
        chapter_audio_files = {}
        if completed_count > 0:
            try:
                logger.info(f"[SYNTHESIS_PLAN] å¼€å§‹æŒ‰ç« èŠ‚åˆå¹¶éŸ³é¢‘æ–‡ä»¶...")
                
                # æŒ‰ç« èŠ‚ç»„ç»‡éŸ³é¢‘æ–‡ä»¶
                for result in results:
                    if isinstance(result, dict) and 'chapter_id' in result and result.get('file_path'):
                        chapter_id = result['chapter_id']
                        if chapter_id not in chapter_audio_files:
                            chapter_audio_files[chapter_id] = []
                        chapter_audio_files[chapter_id].append(result)
                
                # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆåˆå¹¶çš„éŸ³é¢‘æ–‡ä»¶
                for chapter_id, audio_files in chapter_audio_files.items():
                    if not audio_files:
                        continue
                    
                    try:
                        # æŒ‰æ®µè½é¡ºåºæ’åº
                        audio_files.sort(key=lambda x: x.get('segment_id', 0))
                        
                        # ç”Ÿæˆç« èŠ‚éŸ³é¢‘æ–‡ä»¶
                        chapter_audio_path = await merge_chapter_audio_files(
                            project_id, chapter_id, audio_files, db
                        )
                        
                        if chapter_audio_path:
                            logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} éŸ³é¢‘åˆå¹¶å®Œæˆ: {chapter_audio_path}")
                            
                            # æ›´æ–°ç« èŠ‚çŠ¶æ€ä¸ºå®Œæˆ
                            chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
                            if chapter:
                                chapter.synthesis_status = 'completed'
                                db.commit()
                        else:
                            logger.warning(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} éŸ³é¢‘åˆå¹¶å¤±è´¥")
                            
                    except Exception as e:
                        logger.error(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} éŸ³é¢‘åˆå¹¶å¼‚å¸¸: {str(e)}")
                        
            except Exception as e:
                logger.error(f"[SYNTHESIS_PLAN] ç« èŠ‚éŸ³é¢‘åˆå¹¶è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        
        # ğŸš€ å‘é€ç« èŠ‚çº§åˆ«çš„å®ŒæˆçŠ¶æ€åˆ°å‰ç«¯
        chapter_progress = round((completed_count / len(synthesis_data)) * 100) if len(synthesis_data) > 0 else 0
        await websocket_manager.publish_to_topic(
            f"synthesis_{project_id}",
            {
                "type": "progress_update",
                "data": {
                    "type": "synthesis",
                    "project_id": project_id,
                    "status": "completed" if completed_count == len(synthesis_data) else "failed",
                    "progress": chapter_progress,
                    "completed_segments": completed_count,
                    "total_segments": len(synthesis_data),
                    "failed_segments": len(failed_segments),
                    "current_processing": f"ç« èŠ‚åˆæˆ{'å®Œæˆ' if completed_count == len(synthesis_data) else 'ç»“æŸ'}",
                    "final_audio_path": None,  # ç°åœ¨ä¸å†æœ‰å…¨å±€çš„æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶
                    "chapter_audio_files": len(chapter_audio_files),  # ç”Ÿæˆçš„ç« èŠ‚éŸ³é¢‘æ–‡ä»¶æ•°é‡
                    "timestamp": datetime.utcnow().isoformat()
                }
            }
        )
        
        # ğŸš€ è®°å½•ç« èŠ‚çº§åˆ«çš„å®Œæˆæ—¥å¿—
        await log_system_event(
            db=db,
            level="info",
            message=f"ç« èŠ‚éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {project.name}",
            module="novel_reader",
            details={
                "project_id": project_id,
                "chapter_expected": len(synthesis_data),
                "chapter_actual": completed_count,
                "new_generated": completed_count,
                "failed_segments": len(failed_segments),
                "final_audio_path": final_audio_path,
                "data_source": "æ™ºèƒ½å‡†å¤‡ç»“æœ",
                "chapter_status": "completed" if completed_count == len(synthesis_data) else "failed"
            }
        )
        
        logger.info(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} éŸ³é¢‘åˆæˆä»»åŠ¡å®Œæˆ")
        
        # ğŸ”§ é¡¹ç›®å®ŒæˆçŠ¶æ€æ›´æ–°
        try:
            # æ›´æ–°ç« èŠ‚çŠ¶æ€
            chapter_ids = list(chapter_audio_files.keys())
            for chapter_id in chapter_ids:
                # æ£€æŸ¥ç« èŠ‚å®Œæ•´éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                chapter_complete_audio = db.query(AudioFile).filter(
                    AudioFile.project_id == project_id,
                    AudioFile.chapter_id == chapter_id,
                    AudioFile.audio_type == 'chapter'
                ).first()
                
                # æ›´æ–°ç« èŠ‚çŠ¶æ€
                chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
                if chapter:
                    # å¦‚æœæœ‰ç« èŠ‚å®Œæ•´éŸ³é¢‘æ–‡ä»¶ï¼ŒçŠ¶æ€ä¸ºå®Œæˆ
                    if chapter_complete_audio and os.path.exists(chapter_complete_audio.file_path):
                        chapter.synthesis_status = 'completed'
                        logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} çŠ¶æ€æ›´æ–°ä¸º completed (æœ‰å®Œæ•´éŸ³é¢‘æ–‡ä»¶)")
                    else:
                        chapter.synthesis_status = 'failed'
                        logger.info(f"[SYNTHESIS_PLAN] ç« èŠ‚ {chapter_id} çŠ¶æ€æ›´æ–°ä¸º failed (æ— éŸ³é¢‘æ–‡ä»¶)")
            
            # ğŸ”¥ æ›´æ–°é¡¹ç›®çŠ¶æ€
            if failed_segments:
                project.status = 'failed'
                # ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æ‘˜è¦
                error_summary = generate_detailed_error_summary(failed_segments, len(synthesis_data))
                project.error_message = error_summary
                logger.info(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} çŠ¶æ€æ›´æ–°ä¸º failed")
            elif len(chapter_audio_files) > 0:
                project.status = 'completed'
                project.error_message = None
                logger.info(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} çŠ¶æ€æ›´æ–°ä¸º completed")
            else:
                project.status = 'partial_completed'
                project.error_message = f"éƒ¨åˆ†å®Œæˆï¼š{completed_count}/{len(synthesis_data)} ä¸ªæ®µè½"
                logger.info(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} çŠ¶æ€æ›´æ–°ä¸º partial_completed")
            
            project.completed_at = datetime.utcnow()
            db.commit()
        
        except Exception as e:
            logger.error(f"[SYNTHESIS_PLAN] æ›´æ–°ç« èŠ‚å’Œé¡¹ç›®çŠ¶æ€å¤±è´¥: {str(e)}")
        
        db.commit()
        
    except Exception as e:
        logger.error(f"[SYNTHESIS_PLAN] é¡¹ç›® {project_id} éŸ³é¢‘åˆæˆä»»åŠ¡å¼‚å¸¸: {str(e)}", exc_info=True)
        try:
            db = next(get_db())
            project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
            if project:
                # ğŸš€ é¡¹ç›®çŠ¶æ€è®¾ç½®å·²åºŸå¼ƒï¼Œåªä¿ç•™é”™è¯¯ä¿¡æ¯è®°å½•
                # ç”Ÿæˆæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                error_details = analyze_synthesis_exception(e)
                project.error_message = error_details
                project.completed_at = datetime.utcnow()
                db.commit()
                
                # å‘é€è¯¦ç»†é”™è¯¯ä¿¡æ¯åˆ°å‰ç«¯
                await websocket_manager.publish_to_topic(
                    f"synthesis_{project_id}",
                    {
                        "type": "progress_update", 
                        "data": {
                            "type": "synthesis",
                            "project_id": project_id,
                            "status": "failed",
                            "error_message": error_details,
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    }
                )
        except Exception as inner_e:
            logger.error(f"æ›´æ–°é¡¹ç›®å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {str(inner_e)}")
    finally:
        try:
            db.close()
        except:
            pass


def generate_detailed_error_summary(failed_segments: List[Dict], total_segments: int) -> str:
    """ç”Ÿæˆè¯¦ç»†çš„é”™è¯¯æ‘˜è¦"""
    if not failed_segments:
        return "æœªçŸ¥é”™è¯¯"
    
    # ç»Ÿè®¡é”™è¯¯ç±»å‹
    error_types = {}
    for segment in failed_segments:
        error = segment.get('error', 'æœªçŸ¥é”™è¯¯')
        # ç®€åŒ–é”™è¯¯ç±»å‹åˆ†ç±»
        if 'TTS' in error or 'tts' in error.lower():
            error_type = 'TTSæœåŠ¡å¼‚å¸¸'
        elif 'GPU' in error or 'CUDA' in error or 'memory' in error.lower():
            error_type = 'GPU/æ˜¾å­˜é—®é¢˜'
        elif 'timeout' in error.lower() or 'è¶…æ—¶' in error:
            error_type = 'è¯·æ±‚è¶…æ—¶'
        elif 'voice' in error.lower() or 'å£°éŸ³' in error:
            error_type = 'å£°éŸ³é…ç½®é—®é¢˜'
        elif 'network' in error.lower() or 'ç½‘ç»œ' in error:
            error_type = 'ç½‘ç»œè¿æ¥é—®é¢˜'
        elif 'encoding' in error.lower() or 'ç¼–ç ' in error:
            error_type = 'æ–‡æœ¬ç¼–ç é—®é¢˜'
        else:
            error_type = 'å…¶ä»–é”™è¯¯'
        
        error_types[error_type] = error_types.get(error_type, 0) + 1
    
    # æ„å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
    total_failed = len(failed_segments)
    success_rate = round(((total_segments - total_failed) / total_segments) * 100, 1)
    
    error_summary = f"{total_failed}ä¸ªæ®µè½åˆæˆå¤±è´¥ (æˆåŠŸç‡: {success_rate}%)"
    
    # æ·»åŠ é”™è¯¯ç±»å‹ç»Ÿè®¡
    if error_types:
        error_details = []
        for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
            error_details.append(f"{error_type} ({count}ä¸ª)")
        error_summary += f"ï¼Œä¸»è¦åŸå› : {', '.join(error_details[:3])}"  # åªæ˜¾ç¤ºå‰3ä¸ªä¸»è¦é”™è¯¯ç±»å‹
        
        # å¦‚æœæœ‰æ›´å¤šé”™è¯¯ç±»å‹ï¼Œæ˜¾ç¤ºçœç•¥ä¿¡æ¯
        if len(error_details) > 3:
            error_summary += f" ç­‰{len(error_details)}ç§é—®é¢˜"
    
    return error_summary


def analyze_synthesis_exception(exception: Exception) -> str:
    """åˆ†æåˆæˆå¼‚å¸¸å¹¶è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯"""
    error_str = str(exception).lower()
    error_type = type(exception).__name__
    
    # æ ¹æ®å¼‚å¸¸ç±»å‹å’Œå†…å®¹æä¾›å…·ä½“çš„é”™è¯¯ä¿¡æ¯
    if 'connection' in error_str or 'timeout' in error_str:
        return f"ç½‘ç»œè¿æ¥é—®é¢˜ï¼šTTSæœåŠ¡è¿æ¥è¶…æ—¶æˆ–ä¸­æ–­ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€åé‡è¯•"
    elif 'gpu' in error_str or 'cuda' in error_str or 'memory' in error_str:
        return f"GPUèµ„æºé—®é¢˜ï¼šæ˜¾å­˜ä¸è¶³æˆ–CUDAé”™è¯¯ï¼Œå»ºè®®å‡å°‘å¹¶è¡Œä»»åŠ¡æ•°æˆ–ç­‰å¾…GPUèµ„æºé‡Šæ”¾"
    elif 'json' in error_str or 'parse' in error_str:
        return f"æ•°æ®è§£æé”™è¯¯ï¼šæ™ºèƒ½å‡†å¤‡ç»“æœæ ¼å¼å¼‚å¸¸ï¼Œè¯·é‡æ–°è¿›è¡Œæ™ºèƒ½å‡†å¤‡"
    elif 'permission' in error_str or 'access' in error_str:
        return f"æ–‡ä»¶è®¿é—®æƒé™é—®é¢˜ï¼šæ— æ³•åˆ›å»ºæˆ–å†™å…¥éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ç›®å½•æƒé™"
    elif 'disk' in error_str or 'space' in error_str:
        return f"ç£ç›˜ç©ºé—´ä¸è¶³ï¼šè¯·æ¸…ç†å­˜å‚¨ç©ºé—´åé‡è¯•"
    elif 'tts' in error_str:
        return f"TTSæœåŠ¡å¼‚å¸¸ï¼šè¯­éŸ³åˆæˆå¼•æ“å†…éƒ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥TTSæœåŠ¡çŠ¶æ€"
    elif error_type == 'KeyError':
        return f"é…ç½®ç¼ºå¤±é”™è¯¯ï¼šåˆæˆè®¡åˆ’ä¸­ç¼ºå°‘å¿…è¦çš„é…ç½®ä¿¡æ¯ï¼Œè¯·é‡æ–°è¿›è¡Œæ™ºèƒ½å‡†å¤‡"
    elif error_type == 'TypeError' or error_type == 'ValueError':
        return f"æ•°æ®ç±»å‹é”™è¯¯ï¼šåˆæˆå‚æ•°æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥è§’è‰²å£°éŸ³é…ç½®"
    elif error_type == 'FileNotFoundError':
        return f"æ–‡ä»¶ç¼ºå¤±é”™è¯¯ï¼šæ‰¾ä¸åˆ°å¿…è¦çš„éŸ³é¢‘æ–‡ä»¶æˆ–é…ç½®æ–‡ä»¶"
    else:
        # æä¾›é€šç”¨ä½†æ¯”"ç³»ç»Ÿå†…éƒ¨é”™è¯¯"æ›´æœ‰ç”¨çš„ä¿¡æ¯
        return f"åˆæˆä»»åŠ¡å¼‚å¸¸ ({error_type}): {str(exception)[:100]}{'...' if len(str(exception)) > 100 else ''}"


async def merge_audio_files_from_plan(
    project: NovelProject, 
    output_files: List[Dict], 
    db: Session
) -> str:
    """
    åŸºäºåˆæˆè®¡åˆ’ç»“æœåˆå¹¶éŸ³é¢‘æ–‡ä»¶
    """
    try:
        from pydub import AudioSegment
        import os
        
        # æŒ‰segment_idæ’åº
        sorted_files = sorted(output_files, key=lambda x: x.get('segment_id', 0))
        
        logger.info(f"[MERGE] å¼€å§‹åˆå¹¶ {len(sorted_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶...")
        
        # åˆå§‹åŒ–åˆå¹¶éŸ³é¢‘
        merged_audio = None
        silence = AudioSegment.silent(duration=500)  # 500msé—´éš”
        
        for file_info in sorted_files:
            file_path = file_info.get('file_path')
            if file_path and os.path.exists(file_path):
                try:
                    segment_audio = AudioSegment.from_wav(file_path)
                    if merged_audio is None:
                        merged_audio = segment_audio
                    else:
                        merged_audio = merged_audio + silence + segment_audio
                    logger.debug(f"[MERGE] å·²æ·»åŠ éŸ³é¢‘: {file_path}")
                except Exception as e:
                    logger.error(f"[MERGE] è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
            else:
                logger.warning(f"[MERGE] éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        if merged_audio is None:
            raise Exception("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶å¯åˆå¹¶")
        
        # å¯¼å‡ºæœ€ç»ˆéŸ³é¢‘æ–‡ä»¶
        final_filename = f"final_audio_{project.id}_{int(time.time())}.wav"
        final_path = f"outputs/projects/{project.id}/{final_filename}"
        
        merged_audio.export(final_path, format="wav")
        
        file_size = os.path.getsize(final_path)
        duration = len(merged_audio) / 1000.0  # è½¬æ¢ä¸ºç§’
        
        # ä¿å­˜æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶è®°å½•
        final_audio_file = AudioFile(
            filename=final_filename,
            original_name=f"{project.name}_å®Œæ•´éŸ³é¢‘",
            file_path=final_path,
            file_size=file_size,
            duration=duration,
            project_id=project.id,
            audio_type='final',
            model_used='MegaTTS3',
            status='active',
            created_at=datetime.utcnow()
        )
        db.add(final_audio_file)
        db.commit()
        
        logger.info(f"[MERGE] éŸ³é¢‘åˆå¹¶å®Œæˆ: {final_path} ({duration:.1f}s, {file_size} bytes)")
        
        return final_path
        
    except Exception as e:
        logger.error(f"[MERGE] éŸ³é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        raise e 

def add_chapter_info_to_synthesis_data(synthesis_data: List[Dict], analysis_results, db: Session) -> List[Dict]:
    """
    ä¸ºåˆæˆæ•°æ®æ·»åŠ ç« èŠ‚ä¿¡æ¯
    ç¡®ä¿æ¯ä¸ªsegmentéƒ½æœ‰å®Œæ•´çš„ç« èŠ‚ä¿¡æ¯
    """
    # å»ºç«‹ç« èŠ‚IDåˆ°ç« èŠ‚ä¿¡æ¯çš„æ˜ å°„
    chapter_info_map = {}
    for result in analysis_results:
        chapter_id = result.chapter_id
        if chapter_id not in chapter_info_map:
            chapter_info_map[chapter_id] = {
                'chapter_id': chapter_id,
                'chapter_number': result.chapter.chapter_number,
                'chapter_title': result.chapter.chapter_title or result.chapter.title,
                'book_id': result.chapter.book_id
            }
    
    # ä¸ºæ¯ä¸ªsegmentæ·»åŠ ç« èŠ‚ä¿¡æ¯
    for segment in synthesis_data:
        if 'chapter_id' in segment and segment['chapter_id'] in chapter_info_map:
            chapter_info = chapter_info_map[segment['chapter_id']]
            segment.update(chapter_info)
            logger.debug(f"[CHAPTER_INFO] æ®µè½ {segment.get('segment_id')} æ·»åŠ ç« èŠ‚ä¿¡æ¯: ç¬¬{chapter_info['chapter_number']}ç«  {chapter_info['chapter_title']}")
    
    return synthesis_data


async def merge_chapter_audio_files(
    project_id: int, 
    chapter_id: int, 
    audio_files: List[Dict], 
    db: Session
) -> Optional[str]:
    """
    åˆå¹¶å•ä¸ªç« èŠ‚çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ä¸ºä¸€ä¸ªå®Œæ•´çš„ç« èŠ‚éŸ³é¢‘æ–‡ä»¶
    
    Args:
        project_id: é¡¹ç›®ID
        chapter_id: ç« èŠ‚ID
        audio_files: ç« èŠ‚å†…çš„éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        åˆå¹¶åçš„ç« èŠ‚éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        from pydub import AudioSegment
        import os
        
        if not audio_files:
            logger.warning(f"[MERGE_CHAPTER] ç« èŠ‚ {chapter_id} æ²¡æœ‰éŸ³é¢‘æ–‡ä»¶éœ€è¦åˆå¹¶")
            return None
        
        # è·å–ç« èŠ‚ä¿¡æ¯
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            logger.error(f"[MERGE_CHAPTER] ç« èŠ‚ {chapter_id} ä¸å­˜åœ¨")
            return None
        
        chapter_title = chapter.chapter_title or chapter.title or f"Chapter_{chapter_id}"
        chapter_number = chapter.chapter_number or chapter_id
        
        logger.info(f"[MERGE_CHAPTER] å¼€å§‹åˆå¹¶ç« èŠ‚ {chapter_id} ({chapter_title}) çš„ {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        
        # åˆå§‹åŒ–åˆå¹¶éŸ³é¢‘
        merged_audio = None
        silence = AudioSegment.silent(duration=800)  # 800msæ®µè½é—´éš”
        total_duration = 0
        merged_segments = 0
        
        # æŒ‰æ®µè½é¡ºåºåˆå¹¶éŸ³é¢‘
        for i, audio_file in enumerate(audio_files):
            file_path = audio_file.get('file_path')
            segment_id = audio_file.get('segment_id', i + 1)
            
            if not file_path or not os.path.exists(file_path):
                logger.warning(f"[MERGE_CHAPTER] éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                continue
            
            try:
                # åŠ è½½éŸ³é¢‘æ®µè½
                segment_audio = AudioSegment.from_wav(file_path)
                
                if merged_audio is None:
                    merged_audio = segment_audio
                else:
                    # æ·»åŠ æ®µè½é—´éš”ï¼Œç„¶ååˆå¹¶
                    merged_audio = merged_audio + silence + segment_audio
                
                total_duration += len(segment_audio)
                merged_segments += 1
                
                logger.debug(f"[MERGE_CHAPTER] å·²åˆå¹¶æ®µè½ {segment_id}: {len(segment_audio)}ms")
                
            except Exception as e:
                logger.error(f"[MERGE_CHAPTER] è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {str(e)}")
                continue
        
        if merged_audio is None or merged_segments == 0:
            logger.error(f"[MERGE_CHAPTER] ç« èŠ‚ {chapter_id} æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶å¯åˆå¹¶")
            return None
        
        # ç”Ÿæˆç« èŠ‚éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        project_output_dir = f"outputs/projects/{project_id}"
        os.makedirs(project_output_dir, exist_ok=True)
        
        # æ–‡ä»¶åï¼šchapter_ç« èŠ‚å·_ç« èŠ‚æ ‡é¢˜.wav
        safe_title = "".join(c for c in chapter_title if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_title = safe_title.replace(' ', '_')
        chapter_filename = f"chapter_{chapter_number:03d}_{safe_title}.wav"
        chapter_audio_path = os.path.join(project_output_dir, chapter_filename)
        
        # å¯¼å‡ºç« èŠ‚éŸ³é¢‘æ–‡ä»¶
        merged_audio.export(chapter_audio_path, format="wav")
        
        # è®¡ç®—æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(chapter_audio_path)
        duration_seconds = len(merged_audio) / 1000.0
        
        # ä¿å­˜ç« èŠ‚éŸ³é¢‘æ–‡ä»¶è®°å½•åˆ°æ•°æ®åº“
        chapter_audio_file = AudioFile(
            filename=chapter_filename,
            original_name=f"ç¬¬{chapter_number}ç« _{chapter_title}",
            file_path=chapter_audio_path,
            file_size=file_size,
            duration=duration_seconds,
            project_id=project_id,
            chapter_id=chapter_id,
            chapter_number=chapter_number,
            character_name=None,  # ç« èŠ‚éŸ³é¢‘æ²¡æœ‰ç‰¹å®šè§’è‰²
            speaker="å¤šè§’è‰²",  # ç« èŠ‚éŸ³é¢‘åŒ…å«å¤šä¸ªè§’è‰²
            paragraph_index=None,  # ç« èŠ‚éŸ³é¢‘ä¸å¯¹åº”ç‰¹å®šæ®µè½
            character_id=None,
            voice_profile_id=None,
            text_content=f"ç¬¬{chapter_number}ç« å®Œæ•´éŸ³é¢‘",
            audio_type='chapter',  # æ ‡è®°ä¸ºç« èŠ‚éŸ³é¢‘
            processing_time=0,  # åˆå¹¶ä¸éœ€è¦å¤„ç†æ—¶é—´
            model_used='AudioMerge',
            status='active',
            created_at=datetime.utcnow(),
            metadata={
                'merged_segments': merged_segments,
                'total_segment_files': len(audio_files),
                'chapter_title': chapter_title,
                'merge_method': 'pydub_concatenate'
            }
        )
        
        db.add(chapter_audio_file)
        db.commit()
        db.refresh(chapter_audio_file)
        
        logger.info(f"[MERGE_CHAPTER] ç« èŠ‚ {chapter_id} éŸ³é¢‘åˆå¹¶å®Œæˆ: {chapter_audio_path}")
        logger.info(f"[MERGE_CHAPTER] åˆå¹¶ç»Ÿè®¡: {merged_segments}/{len(audio_files)} ä¸ªæ®µè½, æ€»æ—¶é•¿: {duration_seconds:.2f}s")
        
        return chapter_audio_path
        
    except Exception as e:
        logger.error(f"[MERGE_CHAPTER] ç« èŠ‚ {chapter_id} éŸ³é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        return None