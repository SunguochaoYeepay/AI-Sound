"""
æ—ç™½çŽ¯å¢ƒåˆ†æžå™¨
ä»Žsynthesis_planæå–æ—ç™½å†…å®¹å¹¶åˆ†æžçŽ¯å¢ƒå…³é”®è¯ä¸Žæ—¶é•¿
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class NarrationEnvironmentAnalyzer:
    """æ—ç™½çŽ¯å¢ƒåˆ†æžå™¨ - ä»Žsynthesis_planæå–æ—ç™½å†…å®¹å¹¶åˆ†æžçŽ¯å¢ƒ"""
    
    def __init__(self):
        # å¤ç”¨çŽ°æœ‰LLMåˆ†æžå™¨çš„åˆ†æžèƒ½åŠ›
        from app.services.llm_scene_analyzer import OllamaLLMSceneAnalyzer
        self.scene_analyzer = OllamaLLMSceneAnalyzer()
        
        # æ—ç™½è¯­é€Ÿé…ç½® (æ¯åˆ†é’Ÿå­—æ•°)
        self.NARRATION_SPEED_CHARS_PER_MINUTE = 300
        
    async def extract_and_analyze_narration(self, synthesis_plan: List[Dict]) -> Dict:
        """ä¸»å…¥å£ï¼šä½¿ç”¨æ‰¹é‡åˆ†æžæ¨¡å¼ï¼ŒLLMä¸å¯ç”¨æ—¶ç›´æŽ¥æŠ¥é”™"""
        logger.error("ðŸš¨ðŸš¨ðŸš¨ [NARRATION_ANALYZER] è¿™æ˜¯æ–°ç‰ˆæœ¬çš„ä»£ç ï¼ä½¿ç”¨æ‰¹é‡åˆ†æžæ¨¡å¼ï¼ŒLLMä¸å¯ç”¨æ—¶ç›´æŽ¥æŠ¥é”™ï¼ðŸš¨ðŸš¨ðŸš¨")
        return await self.extract_and_analyze_narration_batch(synthesis_plan)
    
    async def extract_and_analyze_narration_batch(self, synthesis_plan: List[Dict]) -> Dict:
        """æ‰¹é‡åˆ†æžç‰ˆæœ¬ï¼šä¸€æ¬¡åˆ†æžï¼Œæ™ºèƒ½æ˜ å°„"""
        logger.info(f"[BATCH_ANALYZER] å¼€å§‹æ‰¹é‡åˆ†æžsynthesis_planï¼Œå…±{len(synthesis_plan)}ä¸ªæ®µè½")
        
        # 1. æå–æ‰€æœ‰æ—ç™½æ®µè½ï¼Œè®°å½•æ—¶é—´è½´ä¿¡æ¯
        narration_segments = []
        cumulative_time = 0.0
        
        for segment in synthesis_plan:
            segment_duration = self._calculate_segment_duration(segment)
            
            # æ”¯æŒå¤šç§æ—ç™½æ ‡è¯†
            narration_speakers = ['æ—ç™½', 'narrator', 'å™è¿°è€…', 'narration']
            if segment.get('speaker') in narration_speakers or segment.get('character') in narration_speakers:
                narration_text = segment.get('text', '') or segment.get('content', '')
                segment_id = segment.get('segment_id') or segment.get('id', f'seg_{len(narration_segments) + 1}')
                
                narration_segments.append({
                    'segment_id': segment_id,
                    'text': narration_text,
                    'start_time': cumulative_time,
                    'duration': segment_duration,
                    'end_time': cumulative_time + segment_duration
                })
                
                logger.info(f"[BATCH_ANALYZER] æ”¶é›†æ—ç™½æ®µè½ {segment_id}: "
                           f"{cumulative_time:.1f}-{cumulative_time + segment_duration:.1f}s")
            
            cumulative_time += segment_duration
        
        if not narration_segments:
            logger.info("[BATCH_ANALYZER] æœªæ‰¾åˆ°æ—ç™½æ®µè½")
            return {
                'environment_tracks': [],
                'analysis_summary': {
                    'total_duration': cumulative_time,
                    'narration_segments': 0,
                    'environment_tracks_detected': 0,
                    'analysis_timestamp': datetime.now().isoformat()
                }
            }
        
        logger.info(f"[BATCH_ANALYZER] æ‰¾åˆ°{len(narration_segments)}ä¸ªæ—ç™½æ®µè½ï¼Œæ€»æ—¶é•¿{cumulative_time:.1f}s")
        
        # 2. æž„å»ºæ‰¹é‡åˆ†æžçš„æç¤ºè¯
        batch_prompt = self._build_batch_analysis_prompt(narration_segments)
        logger.info(f"[BATCH_ANALYZER] æž„å»ºæ‰¹é‡æç¤ºè¯ï¼Œé•¿åº¦: {len(batch_prompt)}å­—ç¬¦")
        
        # 3. ä¸€æ¬¡æ€§LLMåˆ†æž
        logger.info("[BATCH_ANALYZER] å¼€å§‹ä¸€æ¬¡æ€§LLMåˆ†æž")
        llm_result = await self.scene_analyzer.analyze_text_scenes_with_llm(batch_prompt)
        logger.info(f"[BATCH_ANALYZER] LLMåˆ†æžå®Œæˆï¼Œè¯†åˆ«åˆ°{len(llm_result.analyzed_scenes)}ä¸ªåœºæ™¯")
        
        # æ£€æŸ¥LLMæ˜¯å¦çœŸçš„æœ‰æ•ˆåˆ†æž
        if len(llm_result.analyzed_scenes) == 0 and llm_result.confidence_score == 0.0:
            raise RuntimeError("LLMåˆ†æžå™¨æ— æ³•å·¥ä½œï¼šè¿”å›žç©ºç»“æžœï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œæ­£å¸¸")
        
        # 4. æ™ºèƒ½æ˜ å°„åœºæ™¯åˆ°å…·ä½“æ®µè½
        environment_tracks = self._map_scenes_to_segments(llm_result, narration_segments)

        
        logger.info(f"[BATCH_ANALYZER] æ‰¹é‡åˆ†æžå®Œæˆ: æ€»æ—¶é•¿{cumulative_time:.1f}sï¼Œ"
                   f"æ—ç™½æ®µè½{len(narration_segments)}ä¸ªï¼ŒçŽ¯å¢ƒéŸ³è½¨é“{len(environment_tracks)}ä¸ª")
        
        return {
            'environment_tracks': environment_tracks,
            'analysis_summary': {
                'total_duration': cumulative_time,
                'narration_segments': len(narration_segments),
                'environment_tracks_detected': len(environment_tracks),
                'analysis_timestamp': datetime.now().isoformat(),
                'analysis_mode': 'batch'
            }
        }
    
    def _build_batch_analysis_prompt(self, narration_segments: List[Dict]) -> str:
        """æž„å»ºæ‰¹é‡åˆ†æžçš„æç¤ºè¯"""
        prompt_parts = ["è¯·åˆ†æžä»¥ä¸‹ç« èŠ‚çš„æ—ç™½å†…å®¹ï¼Œæå–æ¯ä¸ªæ—¶é—´æ®µçš„çŽ¯å¢ƒå£°éŸ³ï¼š"]
        
        for i, seg in enumerate(narration_segments):
            time_range = f"{seg['start_time']:.1f}-{seg['end_time']:.1f}s"
            prompt_parts.append(f"æ®µè½{i+1}({time_range}): {seg['text']}")
        
        combined_text = "\n".join(prompt_parts)
        logger.info(f"[BATCH_ANALYZER] æ‰¹é‡æç¤ºè¯ç¤ºä¾‹: {combined_text[:200]}...")
        return combined_text
    
    def _map_scenes_to_segments(self, llm_result, narration_segments: List[Dict]) -> List[Dict]:
        """å°†åœºæ™¯åˆ†æžç»“æžœæ˜ å°„åˆ°å…·ä½“æ®µè½"""
        environment_tracks = []
        
        logger.info(f"[MAPPING] å¼€å§‹æ˜ å°„{len(llm_result.analyzed_scenes)}ä¸ªåœºæ™¯åˆ°{len(narration_segments)}ä¸ªæ®µè½")
        
        # å¦‚æžœæ²¡æœ‰è¯†åˆ«åˆ°åœºæ™¯ï¼Œè¿”å›žç©º
        if not llm_result.analyzed_scenes:
            logger.info("[MAPPING] æœªè¯†åˆ«åˆ°ä»»ä½•åœºæ™¯")
            return environment_tracks
        
        # ç­–ç•¥1: å¦‚æžœåœºæ™¯æ•°é‡ä¸Žæ®µè½æ•°é‡åŒ¹é…ï¼Œä¸€å¯¹ä¸€æ˜ å°„
        if len(llm_result.analyzed_scenes) == len(narration_segments):
            logger.info("[MAPPING] åœºæ™¯ä¸Žæ®µè½æ•°é‡åŒ¹é…ï¼Œä½¿ç”¨ä¸€å¯¹ä¸€æ˜ å°„")
            for i, segment in enumerate(narration_segments):
                scene = llm_result.analyzed_scenes[i]
                if scene.keywords:
                    environment_tracks.append({
                        'segment_id': segment['segment_id'],
                        'start_time': segment['start_time'],
                        'duration': segment['duration'],
                        'narration_text': segment['text'],
                        'environment_keywords': scene.keywords,
                        'scene_description': scene.location if scene.location != "detected_environment" else "ã€".join(scene.keywords[:3]),
                        'confidence': scene.confidence,
                        'analysis_timestamp': datetime.now().isoformat(),
                        'mapping_strategy': 'one_to_one'
                    })
                    logger.info(f"[MAPPING] æ®µè½{i+1}æ˜ å°„åˆ°åœºæ™¯: {scene.keywords}")
        
        # ç­–ç•¥2: åœºæ™¯æ•°é‡ä¸åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½ä½ç½®æ˜ å°„
        else:
            logger.info(f"[MAPPING] åœºæ™¯æ•°é‡({len(llm_result.analyzed_scenes)})ä¸Žæ®µè½æ•°é‡({len(narration_segments)})ä¸åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½ä½ç½®æ˜ å°„")
            
            # æ™ºèƒ½æ˜ å°„ï¼šä¸ºæ¯ä¸ªåœºæ™¯æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ®µè½
            used_segments = set()
            
            for scene_idx, scene in enumerate(llm_result.analyzed_scenes):
                if not scene.keywords:
                    continue
                    
                best_segment = None
                best_score = 0.0
                
                # ä¸ºå½“å‰åœºæ™¯æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ®µè½
                for segment in narration_segments:
                    if segment['segment_id'] in used_segments:
                        continue
                        
                    # è®¡ç®—åŒ¹é…åˆ†æ•°
                    score = self._calculate_scene_segment_match_score(scene, segment)
                    
                    if score > best_score:
                        best_score = score
                        best_segment = segment
                
                # å¦‚æžœæ‰¾åˆ°äº†åˆé€‚çš„åŒ¹é…
                if best_segment and best_score > 0.1:
                    used_segments.add(best_segment['segment_id'])
                    
                    environment_tracks.append({
                        'segment_id': best_segment['segment_id'],
                        'start_time': best_segment['start_time'],
                        'duration': best_segment['duration'],
                        'narration_text': best_segment['text'],
                        'environment_keywords': scene.keywords,
                        'scene_description': scene.location if scene.location != "detected_environment" else "ã€".join(scene.keywords[:3]),
                        'confidence': scene.confidence * (0.8 + 0.2 * best_score),  # æ ¹æ®åŒ¹é…åº¦è°ƒæ•´ç½®ä¿¡åº¦
                        'analysis_timestamp': datetime.now().isoformat(),
                        'mapping_strategy': 'intelligent_position_mapping'
                    })
                    logger.info(f"[MAPPING] åœºæ™¯{scene_idx+1}({scene.keywords}) æ™ºèƒ½æ˜ å°„åˆ°æ®µè½ {best_segment['segment_id']} (åˆ†æ•°: {best_score:.2f})")
                else:
                    logger.info(f"[MAPPING] åœºæ™¯{scene_idx+1}({scene.keywords}) æœªæ‰¾åˆ°åˆé€‚çš„æ®µè½åŒ¹é…")
        
        logger.info(f"[MAPPING] æ˜ å°„å®Œæˆï¼Œç”Ÿæˆ{len(environment_tracks)}ä¸ªçŽ¯å¢ƒéŸ³è½¨é“")
        return environment_tracks
    
    def _find_best_matching_scene(self, text: str, scenes: List) -> Optional[Any]:
        """ä¸ºæ–‡æœ¬æ‰¾åˆ°æœ€åŒ¹é…çš„åœºæ™¯"""
        if not scenes:
            return None
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ç­–ç•¥
        text_lower = text.lower()
        best_scene = None
        best_score = 0.0
        
        for scene in scenes:
            score = 0.0
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            for keyword in scene.keywords:
                if keyword.lower() in text_lower:
                    score += 1.0
            
            # æ£€æŸ¥åœºæ™¯ä½ç½®åŒ¹é…
            if hasattr(scene, 'location') and scene.location and scene.location.lower() in text_lower:
                score += 0.5
            
            # å½’ä¸€åŒ–åˆ†æ•°
            if len(scene.keywords) > 0:
                score = score / len(scene.keywords)
            
            if score > best_score:
                best_score = score
                best_scene = scene
        
        # åªè¿”å›žæœ‰ä¸€å®šåŒ¹é…åº¦çš„åœºæ™¯
        if best_score > 0.2:
            logger.info(f"[MATCHING] æ–‡æœ¬ç‰‡æ®µåŒ¹é…åˆ°åœºæ™¯ï¼Œåˆ†æ•°: {best_score:.2f}")
            return best_scene
        
        # å¦‚æžœæ²¡æœ‰å¥½çš„åŒ¹é…ï¼Œä¸è¦ä½¿ç”¨é»˜è®¤åœºæ™¯ï¼Œç›´æŽ¥è¿”å›žNone
        # è¿™æ ·å¯ä»¥é¿å…å°†ä¸ç›¸å…³çš„å…³é”®è¯åˆ†é…ç»™æ— æ³•åŒ¹é…çš„æ®µè½
        logger.info("[MATCHING] æœªæ‰¾åˆ°åˆé€‚çš„åŒ¹é…åœºæ™¯ï¼Œè·³è¿‡è¯¥æ®µè½")
        return None

    def _calculate_scene_segment_match_score(self, scene, segment) -> float:
        """è®¡ç®—åœºæ™¯ä¸Žæ®µè½çš„åŒ¹é…åˆ†æ•°"""
        text = segment['text'].lower()
        score = 0.0
        
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        for keyword in scene.keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in text:
                score += 1.0
            # æ£€æŸ¥ç›¸å…³è¯æ±‡åŒ¹é…
            elif self._check_related_keywords(keyword_lower, text):
                score += 0.5
        
        # æ ¹æ®å…³é”®è¯æ•°é‡å½’ä¸€åŒ–
        if len(scene.keywords) > 0:
            score = score / len(scene.keywords)
        
        return min(score, 1.0)  # æœ€å¤§åˆ†æ•°ä¸º1.0
    
    def _check_related_keywords(self, keyword: str, text: str) -> bool:
        """æ£€æŸ¥ç›¸å…³å…³é”®è¯åŒ¹é…"""
        # å®šä¹‰ç›¸å…³è¯æ±‡æ˜ å°„
        related_words = {
            'è„šæ­¥å£°': ['èµ°', 'è·‘', 'è·³', 'è¸', 'è¿›', 'å‡º'],
            'ç¿»ä¹¦å£°': ['ä¹¦', 'ç¿»', 'çœ‹', 'è¯»', 'é¡µ'],
            'é›·å£°': ['é›·', 'æ‰“é›·', 'é›·é¸£', 'é—ªç”µ'],
            'é›¨å£°': ['é›¨', 'ä¸‹é›¨', 'é›¨ç‚¹', 'é›¨æ°´'],
            'é£Žå£°': ['é£Ž', 'å¹', 'å¾®é£Ž', 'å¤§é£Ž'],
            'è™«é¸£': ['è™«', 'è‰', 'è›è›', 'æ˜†è™«'],
            'é¸Ÿå«': ['é¸Ÿ', 'é¸Ÿå„¿', 'æ­Œå”±', 'å•å•¾'],
            'æ°´å£°': ['æ°´', 'æµæ°´', 'æºªæ°´', 'æ²³æ°´']
        }
        
        if keyword in related_words:
            for related_word in related_words[keyword]:
                if related_word in text:
                    return True
        
        return False

    async def extract_and_analyze_narration_individual(self, synthesis_plan: List[Dict]) -> Dict:
        """åŽŸæœ‰çš„é€ä¸€åˆ†æžæ–¹æ³•ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰"""
        logger.info(f"[INDIVIDUAL_ANALYZER] å¼€å§‹é€ä¸€åˆ†æžsynthesis_planï¼Œå…±{len(synthesis_plan)}ä¸ªæ®µè½")
        
        environment_tracks = []
        cumulative_time = 0.0
        narration_count = 0
        
        for segment in synthesis_plan:
            # åªå¤„ç†æ—ç™½segments (æ—ç™½æ‰ä¼šè¯´çŽ¯å¢ƒå†…å®¹)
            narration_speakers = ['æ—ç™½', 'narrator', 'å™è¿°è€…', 'narration']
            if segment.get('speaker') in narration_speakers or segment.get('character') in narration_speakers:
                narration_count += 1
                
                # è®¡ç®—æ—ç™½æ—¶é•¿ (æ—ç™½è¯­é€Ÿå›ºå®šï¼Œå†…å®¹å·²åœ¨JSON)
                narration_text = segment.get('text', '') or segment.get('content', '')
                estimated_duration = self._calculate_narration_duration(narration_text)
                
                segment_id = segment.get('segment_id') or segment.get('id', f'seg_{narration_count}')
                logger.info(f"[INDIVIDUAL_ANALYZER] å¤„ç†æ—ç™½æ®µè½ {segment_id}: "
                           f"æ—¶é•¿{estimated_duration:.1f}sï¼Œå†…å®¹: {narration_text[:50]}...")
                
                # ä½¿ç”¨LLMæå–å£°éŸ³å…³é”®è¯
                try:
                    logger.info("[INDIVIDUAL_ANALYZER] ä½¿ç”¨LLMæå–å£°éŸ³å…³é”®è¯")
                    llm_result = await self.scene_analyzer.analyze_text_scenes_with_llm(narration_text)
                    
                    # è½¬æ¢ä¸ºæˆ‘ä»¬éœ€è¦çš„æ ¼å¼
                    environment_analysis = {
                        'environment_detected': len(llm_result.analyzed_scenes) > 0,
                        'scene_keywords': [],
                        'scene_description': '',
                        'confidence': llm_result.confidence_score
                    }
                    
                    # æå–å…³é”®è¯å’Œåœºæ™¯æè¿°
                    if llm_result.analyzed_scenes:
                        for scene in llm_result.analyzed_scenes:
                            environment_analysis['scene_keywords'].extend(scene.keywords)
                            if scene.location and scene.location != "detected_environment":
                                environment_analysis['scene_description'] += f"{scene.location} "
                        
                        # åŽ»é‡å…³é”®è¯
                        environment_analysis['scene_keywords'] = list(set(environment_analysis['scene_keywords']))
                        environment_analysis['scene_description'] = environment_analysis['scene_description'].strip()
                        
                        # å¦‚æžœæ²¡æœ‰å…·ä½“åœºæ™¯æè¿°ï¼Œç”¨å…³é”®è¯ç»„åˆ
                        if not environment_analysis['scene_description']:
                            environment_analysis['scene_description'] = "ã€".join(environment_analysis['scene_keywords'][:3])
                    
                    # æ£€æŸ¥LLMæ˜¯å¦çœŸçš„æœ‰æ•ˆåˆ†æž
                    if len(llm_result.analyzed_scenes) == 0 and llm_result.confidence_score == 0.0:
                        raise RuntimeError(f"LLMåˆ†æžå™¨æ— æ³•å·¥ä½œï¼šæ®µè½ {segment_id} è¿”å›žç©ºç»“æžœï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œæ­£å¸¸")
                    
                    if environment_analysis.get('environment_detected'):
                        environment_tracks.append({
                            'segment_id': segment_id,
                            'start_time': cumulative_time,
                            'duration': estimated_duration,
                            'narration_text': narration_text,
                            'environment_keywords': environment_analysis.get('scene_keywords', []),
                            'scene_description': environment_analysis.get('scene_description', ''),
                            'confidence': environment_analysis.get('confidence', 0.0),
                            'analysis_timestamp': datetime.now().isoformat(),
                            'mapping_strategy': 'individual'
                        })
                        
                        logger.info(f"[INDIVIDUAL_ANALYZER] æ£€æµ‹åˆ°çŽ¯å¢ƒ: {environment_analysis.get('scene_keywords', [])}")
                    else:
                        logger.info(f"[INDIVIDUAL_ANALYZER] LLMæœªæ£€æµ‹åˆ°çŽ¯å¢ƒå£°éŸ³")
                        
                except Exception as e:
                    logger.error(f"[INDIVIDUAL_ANALYZER] LLMåˆ†æžå¤±è´¥: {str(e)}")
                    raise RuntimeError(f"LLMåˆ†æžå™¨å¼‚å¸¸ï¼šæ®µè½ {segment_id} åˆ†æžå¤±è´¥ - {str(e)}")
                
                cumulative_time += estimated_duration
            else:
                # éžæ—ç™½æ®µè½ï¼Œç´¯åŠ æ—¶é•¿ä½†ä¸åˆ†æžçŽ¯å¢ƒ
                segment_duration = self._calculate_segment_duration(segment)
                cumulative_time += segment_duration
                
        logger.info(f"[INDIVIDUAL_ANALYZER] åˆ†æžå®Œæˆ: æ€»æ—¶é•¿{cumulative_time:.1f}sï¼Œ"
                   f"æ—ç™½æ®µè½{narration_count}ä¸ªï¼ŒçŽ¯å¢ƒéŸ³è½¨é“{len(environment_tracks)}ä¸ª")
                
        return {
            'environment_tracks': environment_tracks,
            'analysis_summary': {
                'total_duration': cumulative_time,
                'narration_segments': narration_count,
                'environment_tracks_detected': len(environment_tracks),
                'analysis_timestamp': datetime.now().isoformat(),
                'analysis_mode': 'individual'
            }
        }
        
    def _calculate_narration_duration(self, text: str) -> float:
        """è®¡ç®—æ—ç™½æ—¶é•¿ (è¯­é€Ÿå›ºå®š)"""
        if not text or not text.strip():
            return 0.0
            
        # åŽ»é™¤ç©ºç™½å­—ç¬¦ï¼Œè®¡ç®—æœ‰æ•ˆå­—ç¬¦æ•°
        char_count = len(text.replace(' ', '').replace('\n', '').replace('\t', ''))
        
        # æ ¹æ®å›ºå®šè¯­é€Ÿè®¡ç®—æ—¶é•¿
        duration_minutes = char_count / self.NARRATION_SPEED_CHARS_PER_MINUTE
        duration_seconds = duration_minutes * 60.0
        
        # æœ€å°‘1ç§’ï¼Œæœ€å¤š60ç§’
        return max(1.0, min(duration_seconds, 60.0))
        
    def _calculate_segment_duration(self, segment: Dict) -> float:
        """è®¡ç®—å…¶ä»–æ®µè½æ—¶é•¿"""
        # å°è¯•ä»Žsegmentä¸­èŽ·å–é¢„ä¼°æ—¶é•¿
        if 'estimated_duration' in segment:
            return float(segment['estimated_duration'])
            
        # å¦‚æžœæ²¡æœ‰é¢„ä¼°æ—¶é•¿ï¼Œæ ¹æ®æ–‡æœ¬é•¿åº¦è®¡ç®—
        text = segment.get('text', '') or segment.get('content', '')
        if text:
            # å¯¹è¯é€šå¸¸æ¯”æ—ç™½è¯­é€Ÿå¿«ä¸€äº›
            char_count = len(text.replace(' ', '').replace('\n', ''))
            duration_minutes = char_count / 400  # å¯¹è¯è¯­é€Ÿæ›´å¿«
            return max(0.5, duration_minutes * 60.0)
            
        return 1.0  # é»˜è®¤1ç§’
        
    def get_analysis_stats(self, analysis_result: Dict) -> Dict:
        """èŽ·å–åˆ†æžç»Ÿè®¡ä¿¡æ¯"""
        environment_tracks = analysis_result.get('environment_tracks', [])
        
        if not environment_tracks:
            return {
                'total_tracks': 0,
                'total_duration': 0.0,
                'avg_duration': 0.0,
                'keyword_distribution': {},
                'confidence_distribution': {}
            }
            
        total_duration = sum(track['duration'] for track in environment_tracks)
        avg_duration = total_duration / len(environment_tracks)
        
        # å…³é”®è¯åˆ†å¸ƒç»Ÿè®¡
        keyword_count = {}
        for track in environment_tracks:
            for keyword in track.get('environment_keywords', []):
                keyword_count[keyword] = keyword_count.get(keyword, 0) + 1
                
        # ç½®ä¿¡åº¦åˆ†å¸ƒç»Ÿè®¡
        confidence_ranges = {'é«˜(>0.8)': 0, 'ä¸­(0.5-0.8)': 0, 'ä½Ž(<0.5)': 0}
        for track in environment_tracks:
            confidence = track.get('confidence', 0.0)
            if confidence > 0.8:
                confidence_ranges['é«˜(>0.8)'] += 1
            elif confidence > 0.5:
                confidence_ranges['ä¸­(0.5-0.8)'] += 1
            else:
                confidence_ranges['ä½Ž(<0.5)'] += 1
                
        return {
            'total_tracks': len(environment_tracks),
            'total_duration': round(total_duration, 1),
            'avg_duration': round(avg_duration, 1),
            'keyword_distribution': dict(sorted(keyword_count.items(), key=lambda x: x[1], reverse=True)),
            'confidence_distribution': confidence_ranges
        }
