"""
æ—ç™½çŽ¯å¢ƒåˆ†æžå™¨
ä»Žsynthesis_planæå–æ—ç™½å†…å®¹å¹¶åˆ†æžçŽ¯å¢ƒå…³é”®è¯ä¸Žæ—¶é•¿
é›†æˆæ™ºèƒ½æ—¶é—´è½´ä¿®æ­£å™¨ï¼Œç¡®ä¿çŽ¯å¢ƒéŸ³ä¸Žæ—ç™½æè¿°åŒæ­¥
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)

class NarrationEnvironmentAnalyzer:
    """æ—ç™½çŽ¯å¢ƒåˆ†æžå™¨ - ä»Žsynthesis_planæå–æ—ç™½å†…å®¹å¹¶åˆ†æžçŽ¯å¢ƒ"""
    
    def __init__(self, db: Optional[Session] = None):
        # å¤ç”¨çŽ°æœ‰LLMåˆ†æžå™¨çš„åˆ†æžèƒ½åŠ›
        from app.services.llm_scene_analyzer import OllamaLLMSceneAnalyzer
        self.scene_analyzer = OllamaLLMSceneAnalyzer()
        
        # æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£å™¨
        from app.services.intelligent_timeline_corrector import IntelligentTimelineCorrector
        self.timeline_corrector = IntelligentTimelineCorrector()
        
        # æ•°æ®åº“ä¼šè¯ï¼ˆç”¨äºŽèŽ·å–å®žé™…éŸ³é¢‘æ—¶é•¿ï¼‰
        self.db = db
        
        # æ—ç™½è¯­é€Ÿé…ç½® (æ¯åˆ†é’Ÿå­—æ•°) - ä»…ä½œä¸ºåŽå¤‡æ–¹æ¡ˆ
        self.NARRATION_SPEED_CHARS_PER_MINUTE = 300
        
    async def extract_and_analyze_narration(self, synthesis_plan: List[Dict]) -> Dict:
        """ä¸»å…¥å£ï¼šä½¿ç”¨æ‰¹é‡åˆ†æžæ¨¡å¼ï¼ŒLLMä¸å¯ç”¨æ—¶ç›´æŽ¥æŠ¥é”™"""
        logger.error("ðŸš¨ðŸš¨ðŸš¨ [NARRATION_ANALYZER] è¿™æ˜¯æ–°ç‰ˆæœ¬çš„ä»£ç ï¼ä½¿ç”¨æ‰¹é‡åˆ†æžæ¨¡å¼ï¼ŒLLMä¸å¯ç”¨æ—¶ç›´æŽ¥æŠ¥é”™ï¼ðŸš¨ðŸš¨ðŸš¨")
        return await self.extract_and_analyze_narration_batch(synthesis_plan)
    
    async def extract_and_analyze_narration_batch(self, synthesis_plan: List[Dict]) -> Dict:
        """æ‰¹é‡åˆ†æžç‰ˆæœ¬ï¼šä¸€æ¬¡åˆ†æžï¼Œæ™ºèƒ½æ˜ å°„"""
        logger.info(f"[BATCH_ANALYZER] å¼€å§‹æ‰¹é‡åˆ†æžsynthesis_planï¼Œå…±{len(synthesis_plan)}ä¸ªæ®µè½")
        
        # 1. æå–æ‰€æœ‰æ—ç™½æ®µè½ï¼Œè®°å½•æ—¶é—´è½´ä¿¡æ¯
        narration_segments = []
        cumulative_time = 0.0
        
        for segment in synthesis_plan:
            segment_duration = self._calculate_segment_duration(segment)
            
            # æ”¯æŒå¤šç§æ—ç™½æ ‡è¯†
            narration_speakers = ['æ—ç™½', 'narrator', 'å™è¿°è€…', 'narration']
            if segment.get('speaker') in narration_speakers or segment.get('character') in narration_speakers:
                narration_text = segment.get('text', '') or segment.get('content', '')
                segment_id = segment.get('segment_id') or segment.get('id', f'seg_{len(narration_segments) + 1}')
                
                narration_segments.append({
                    'segment_id': segment_id,
                    'text': narration_text,
                    'start_time': cumulative_time,
                    'duration': segment_duration,
                    'end_time': cumulative_time + segment_duration
                })
                
                logger.info(f"[BATCH_ANALYZER] æ”¶é›†æ—ç™½æ®µè½ {segment_id}: "
                           f"{cumulative_time:.1f}-{cumulative_time + segment_duration:.1f}s")
            
            cumulative_time += segment_duration
        
        if not narration_segments:
            logger.info("[BATCH_ANALYZER] æœªæ‰¾åˆ°æ—ç™½æ®µè½")
            return {
                'environment_tracks': [],
                'analysis_summary': {
                    'total_duration': cumulative_time,
                    'narration_segments': 0,
                    'environment_tracks_detected': 0,
                    'analysis_timestamp': datetime.now().isoformat()
                }
            }
        
        logger.info(f"[BATCH_ANALYZER] æ‰¾åˆ°{len(narration_segments)}ä¸ªæ—ç™½æ®µè½ï¼Œæ€»æ—¶é•¿{cumulative_time:.1f}s")
        
        # 2. æž„å»ºæ‰¹é‡åˆ†æžçš„æç¤ºè¯
        batch_prompt = self._build_batch_analysis_prompt(narration_segments)
        logger.info(f"[BATCH_ANALYZER] æž„å»ºæ‰¹é‡æç¤ºè¯ï¼Œé•¿åº¦: {len(batch_prompt)}å­—ç¬¦")
        
        # 3. ä¸€æ¬¡æ€§LLMåˆ†æž
        logger.info("[BATCH_ANALYZER] å¼€å§‹ä¸€æ¬¡æ€§LLMåˆ†æž")
        llm_result = await self.scene_analyzer.analyze_text_scenes_with_llm(batch_prompt)
        logger.info(f"[BATCH_ANALYZER] LLMåˆ†æžå®Œæˆï¼Œè¯†åˆ«åˆ°{len(llm_result.analyzed_scenes)}ä¸ªåœºæ™¯")
        
        # æ£€æŸ¥LLMæ˜¯å¦çœŸçš„æœ‰æ•ˆåˆ†æž
        if len(llm_result.analyzed_scenes) == 0 and llm_result.confidence_score == 0.0:
            raise RuntimeError("LLMåˆ†æžå™¨æ— æ³•å·¥ä½œï¼šè¿”å›žç©ºç»“æžœï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œæ­£å¸¸")
        
        # 4. æ™ºèƒ½æ˜ å°„åœºæ™¯åˆ°å…·ä½“æ®µè½
        environment_tracks = self._map_scenes_to_segments(llm_result, narration_segments)
        
        # 5. ðŸ• åº”ç”¨æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£å™¨
        if environment_tracks:
            logger.info("[BATCH_ANALYZER] å¼€å§‹åº”ç”¨æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£")
            original_tracks = [track.copy() for track in environment_tracks]  # ä¿å­˜åŽŸå§‹æ•°æ®
            corrected_tracks = self.timeline_corrector.correct_environment_tracks_timeline(
                environment_tracks, narration_segments
            )
            
            # èŽ·å–ä¿®æ­£ç»Ÿè®¡
            correction_summary = self.timeline_corrector.get_correction_summary(
                original_tracks, corrected_tracks
            )
            
            logger.info(f"[BATCH_ANALYZER] æ—¶é—´è½´ä¿®æ­£å®Œæˆ: {correction_summary['summary']}")
            environment_tracks = corrected_tracks
        
        logger.info(f"[BATCH_ANALYZER] æ‰¹é‡åˆ†æžå®Œæˆ: æ€»æ—¶é•¿{cumulative_time:.1f}sï¼Œ"
                   f"æ—ç™½æ®µè½{len(narration_segments)}ä¸ªï¼ŒçŽ¯å¢ƒéŸ³è½¨é“{len(environment_tracks)}ä¸ª")
        
        return {
            'environment_tracks': environment_tracks,
            'analysis_summary': {
                'total_duration': cumulative_time,
                'narration_segments': len(narration_segments),
                'environment_tracks_detected': len(environment_tracks),
                'analysis_timestamp': datetime.now().isoformat(),
                'analysis_mode': 'batch',
                'timeline_correction_applied': True if environment_tracks else False
            }
        }
    
    def _build_batch_analysis_prompt(self, narration_segments: List[Dict]) -> str:
        """æž„å»ºæ‰¹é‡åˆ†æžçš„æç¤ºè¯"""
        
        # æž„å»ºæ›´è¯¦ç»†çš„æç¤ºè¯ï¼ŒåŒ…å«å…·ä½“çš„çŽ¯å¢ƒéŸ³ç±»åž‹æŒ‡å¯¼
        prompt_parts = [
            "è¯·ä»”ç»†åˆ†æžä»¥ä¸‹å°è¯´ç« èŠ‚çš„æ—ç™½å†…å®¹ï¼Œè¯†åˆ«æ¯ä¸ªæ—¶é—´æ®µä¸­æè¿°çš„çŽ¯å¢ƒå£°éŸ³ã€‚",
            "",
            "éœ€è¦è¯†åˆ«çš„çŽ¯å¢ƒéŸ³ç±»åž‹åŒ…æ‹¬ä½†ä¸é™äºŽï¼š",
            "â€¢ è‡ªç„¶çŽ¯å¢ƒï¼šé›¨å£°ã€é›·å£°ã€é£Žå£°ã€é¸Ÿé¸£ã€è™«é¸£ã€æµ·æµªå£°ã€æµæ°´å£°ã€å¶å­æ‘©æ“¦å£°",
            "â€¢ äººä¸ºæ´»åŠ¨ï¼šè„šæ­¥å£°ã€å¼€é—¨å£°ã€å…³é—¨å£°ã€ç¿»ä¹¦å£°ã€å†™å­—å£°ã€æ•²å‡»å£°ã€æœºæ¢°å£°",
            "â€¢ å®¤å†…çŽ¯å¢ƒï¼šæ—¶é’Ÿæ»´ç­”å£°ã€ç©ºè°ƒå£°ã€ç«ç„°ç‡ƒçƒ§å£°ã€ç”µå™¨è¿è½¬å£°ã€åŽ¨æˆ¿å£°éŸ³",
            "â€¢ äº¤é€šçŽ¯å¢ƒï¼šæ±½è½¦å£°ã€ç«è½¦å£°ã€é£žæœºå£°ã€è½®èˆ¹å£°ã€é©¬è¹„å£°",
            "â€¢ ç¤¾äº¤åœºæ™¯ï¼šäººç¾¤å–§å“—ã€æŽŒå£°ã€éŸ³ä¹å£°ã€ä¹å™¨å£°ã€æ­Œå£°",
            "",
            "åˆ†æžè¦æ±‚ï¼š",
            "1. åªåˆ†æžæ˜Žç¡®æè¿°æˆ–æš—ç¤ºæœ‰å…·ä½“å£°éŸ³çš„å†…å®¹",
            "2. ä¼˜å…ˆè¯†åˆ«ç›´æŽ¥æè¿°çš„å£°éŸ³ï¼ˆå¦‚'é›¨å£°''è„šæ­¥å£°'ï¼‰",
            "3. ä»ŽçŽ¯å¢ƒæè¿°ä¸­æŽ¨æ–­å¯èƒ½çš„çŽ¯å¢ƒéŸ³ï¼ˆå¦‚'é›¨å¤œ'â†’é›¨å£°ï¼Œ'èµ°è¿‡èµ°å»Š'â†’è„šæ­¥å£°ï¼‰",
            "4. è€ƒè™‘åœºæ™¯çš„æ—¶é—´ã€åœ°ç‚¹ã€å¤©æ°”å¯¹çŽ¯å¢ƒéŸ³çš„å½±å“",
            "5. å¿½ç•¥çº¯ç²¹çš„å¯¹è¯ã€å¿ƒç†æè¿°å’Œæƒ…æ„Ÿè¡¨è¾¾",
            "",
            "ä»¥ä¸‹æ˜¯éœ€è¦åˆ†æžçš„æ—ç™½å†…å®¹ï¼š",
            ""
        ]
        
        for i, seg in enumerate(narration_segments):
            time_range = f"{seg['start_time']:.1f}-{seg['end_time']:.1f}s"
            # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ
            clean_text = ' '.join(seg['text'].split())
            prompt_parts.append(f"ã€æ®µè½{i+1}ã€‘æ—¶é—´è½´ï¼š{time_range}")
            prompt_parts.append(f"å†…å®¹ï¼š{clean_text}")
            prompt_parts.append("")
        
        prompt_parts.extend([
            "è¯·ä¸ºæ¯ä¸ªæ®µè½æä¾›åˆ†æžç»“æžœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š",
            "æ®µè½Xï¼š[è¯†åˆ«åˆ°çš„çŽ¯å¢ƒéŸ³å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”]",
            "å¦‚æžœæŸæ®µè½æ²¡æœ‰æ˜Žç¡®çš„çŽ¯å¢ƒéŸ³ï¼Œè¯·æ ‡æ³¨ï¼šæ®µè½Xï¼šæ— çŽ¯å¢ƒéŸ³"
        ])
        
        combined_text = "\n".join(prompt_parts)
        logger.info(f"[BATCH_ANALYZER] ä¼˜åŒ–åŽçš„æ‰¹é‡æç¤ºè¯é•¿åº¦: {len(combined_text)}å­—ç¬¦")
        logger.info(f"[BATCH_ANALYZER] æç¤ºè¯å‰200å­—ç¬¦: {combined_text[:200]}...")
        return combined_text
    
    def _map_scenes_to_segments(self, llm_result, narration_segments: List[Dict]) -> List[Dict]:
        """å°†åœºæ™¯åˆ†æžç»“æžœæ˜ å°„åˆ°å…·ä½“æ®µè½"""
        environment_tracks = []
        
        logger.info(f"[MAPPING] å¼€å§‹æ˜ å°„{len(llm_result.analyzed_scenes)}ä¸ªåœºæ™¯åˆ°{len(narration_segments)}ä¸ªæ®µè½")
        
        # å¦‚æžœæ²¡æœ‰è¯†åˆ«åˆ°åœºæ™¯ï¼Œè¿”å›žç©º
        if not llm_result.analyzed_scenes:
            logger.info("[MAPPING] æœªè¯†åˆ«åˆ°ä»»ä½•åœºæ™¯")
            return environment_tracks
        
        # ç­–ç•¥1: å¦‚æžœåœºæ™¯æ•°é‡ä¸Žæ®µè½æ•°é‡åŒ¹é…ï¼Œä¸€å¯¹ä¸€æ˜ å°„
        if len(llm_result.analyzed_scenes) == len(narration_segments):
            logger.info("[MAPPING] åœºæ™¯ä¸Žæ®µè½æ•°é‡åŒ¹é…ï¼Œä½¿ç”¨ä¸€å¯¹ä¸€æ˜ å°„")
            for i, segment in enumerate(narration_segments):
                scene = llm_result.analyzed_scenes[i]
                if scene.keywords:
                    environment_tracks.append({
                        'segment_id': segment['segment_id'],
                        'start_time': segment['start_time'],
                        'duration': segment['duration'],
                        'narration_text': segment['text'],
                        'environment_keywords': scene.keywords,
                        'scene_description': scene.location if scene.location != "detected_environment" else "ã€".join(scene.keywords[:3]),
                        'confidence': scene.confidence,
                        'analysis_timestamp': datetime.now().isoformat(),
                        'mapping_strategy': 'one_to_one'
                    })
                    logger.info(f"[MAPPING] æ®µè½{i+1}æ˜ å°„åˆ°åœºæ™¯: {scene.keywords}")
        
        # ç­–ç•¥2: åœºæ™¯æ•°é‡ä¸åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½ä½ç½®æ˜ å°„
        else:
            logger.info(f"[MAPPING] åœºæ™¯æ•°é‡({len(llm_result.analyzed_scenes)})ä¸Žæ®µè½æ•°é‡({len(narration_segments)})ä¸åŒ¹é…ï¼Œä½¿ç”¨æ™ºèƒ½ä½ç½®æ˜ å°„")
            
            # æ™ºèƒ½æ˜ å°„ï¼šä¸ºæ¯ä¸ªåœºæ™¯æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ®µè½
            used_segments = set()
            
            for scene_idx, scene in enumerate(llm_result.analyzed_scenes):
                if not scene.keywords:
                    continue
                    
                best_segment = None
                best_score = 0.0
                
                # ä¸ºå½“å‰åœºæ™¯æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„æ®µè½
                for segment in narration_segments:
                    if segment['segment_id'] in used_segments:
                        continue
                        
                    # è®¡ç®—åŒ¹é…åˆ†æ•°
                    score = self._calculate_scene_segment_match_score(scene, segment)
                    
                    if score > best_score:
                        best_score = score
                        best_segment = segment
                
                # å¦‚æžœæ‰¾åˆ°äº†åˆé€‚çš„åŒ¹é…
                if best_segment and best_score > 0.1:
                    used_segments.add(best_segment['segment_id'])
                    
                    environment_tracks.append({
                        'segment_id': best_segment['segment_id'],
                        'start_time': best_segment['start_time'],
                        'duration': best_segment['duration'],
                        'narration_text': best_segment['text'],
                        'environment_keywords': scene.keywords,
                        'scene_description': scene.location if scene.location != "detected_environment" else "ã€".join(scene.keywords[:3]),
                        'confidence': scene.confidence * (0.8 + 0.2 * best_score),  # æ ¹æ®åŒ¹é…åº¦è°ƒæ•´ç½®ä¿¡åº¦
                        'analysis_timestamp': datetime.now().isoformat(),
                        'mapping_strategy': 'intelligent_position_mapping'
                    })
                    logger.info(f"[MAPPING] åœºæ™¯{scene_idx+1}({scene.keywords}) æ™ºèƒ½æ˜ å°„åˆ°æ®µè½ {best_segment['segment_id']} (åˆ†æ•°: {best_score:.2f})")
                else:
                    logger.info(f"[MAPPING] åœºæ™¯{scene_idx+1}({scene.keywords}) æœªæ‰¾åˆ°åˆé€‚çš„æ®µè½åŒ¹é…")
        
        logger.info(f"[MAPPING] æ˜ å°„å®Œæˆï¼Œç”Ÿæˆ{len(environment_tracks)}ä¸ªçŽ¯å¢ƒéŸ³è½¨é“")
        return environment_tracks
    
    def _find_best_matching_scene(self, text: str, scenes: List) -> Optional[Any]:
        """ä¸ºæ–‡æœ¬æ‰¾åˆ°æœ€åŒ¹é…çš„åœºæ™¯"""
        if not scenes:
            return None
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ç­–ç•¥
        text_lower = text.lower()
        best_scene = None
        best_score = 0.0
        
        for scene in scenes:
            score = 0.0
            
            # æ£€æŸ¥å…³é”®è¯åŒ¹é…
            for keyword in scene.keywords:
                if keyword.lower() in text_lower:
                    score += 1.0
            
            # æ£€æŸ¥åœºæ™¯ä½ç½®åŒ¹é…
            if hasattr(scene, 'location') and scene.location and scene.location.lower() in text_lower:
                score += 0.5
            
            # å½’ä¸€åŒ–åˆ†æ•°
            if len(scene.keywords) > 0:
                score = score / len(scene.keywords)
            
            if score > best_score:
                best_score = score
                best_scene = scene
        
        # åªè¿”å›žæœ‰ä¸€å®šåŒ¹é…åº¦çš„åœºæ™¯
        if best_score > 0.2:
            logger.info(f"[MATCHING] æ–‡æœ¬ç‰‡æ®µåŒ¹é…åˆ°åœºæ™¯ï¼Œåˆ†æ•°: {best_score:.2f}")
            return best_scene
        
        # å¦‚æžœæ²¡æœ‰å¥½çš„åŒ¹é…ï¼Œä¸è¦ä½¿ç”¨é»˜è®¤åœºæ™¯ï¼Œç›´æŽ¥è¿”å›žNone
        # è¿™æ ·å¯ä»¥é¿å…å°†ä¸ç›¸å…³çš„å…³é”®è¯åˆ†é…ç»™æ— æ³•åŒ¹é…çš„æ®µè½
        logger.info("[MATCHING] æœªæ‰¾åˆ°åˆé€‚çš„åŒ¹é…åœºæ™¯ï¼Œè·³è¿‡è¯¥æ®µè½")
        return None

    def _calculate_scene_segment_match_score(self, scene, segment) -> float:
        """è®¡ç®—åœºæ™¯ä¸Žæ®µè½çš„åŒ¹é…åˆ†æ•°"""
        text = segment['text'].lower()
        score = 0.0
        
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        for keyword in scene.keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in text:
                score += 1.0
            # æ£€æŸ¥ç›¸å…³è¯æ±‡åŒ¹é…
            elif self._check_related_keywords(keyword_lower, text):
                score += 0.5
        
        # æ ¹æ®å…³é”®è¯æ•°é‡å½’ä¸€åŒ–
        if len(scene.keywords) > 0:
            score = score / len(scene.keywords)
        
        return min(score, 1.0)  # æœ€å¤§åˆ†æ•°ä¸º1.0
    
    def _check_related_keywords(self, keyword: str, text: str) -> bool:
        """æ£€æŸ¥ç›¸å…³å…³é”®è¯åŒ¹é…"""
        # æ‰©å±•çš„ç›¸å…³è¯æ±‡æ˜ å°„ - æ›´å…¨é¢çš„çŽ¯å¢ƒéŸ³è¯†åˆ«
        related_words = {
            # è‡ªç„¶çŽ¯å¢ƒéŸ³
            'è„šæ­¥å£°': ['èµ°', 'è·‘', 'è·³', 'è¸', 'è¿›', 'å‡º', 'è¸±æ­¥', 'å¥”è·‘', 'ç–¾èµ°', 'ç¼“æ­¥', 'è¿ˆæ­¥', 'è·¨æ­¥', 'è¸å…¥', 'èµ°å‘', 'æœç€', 'æ­¥å…¥', 'èµ¶è·¯'],
            'ç¿»ä¹¦å£°': ['ä¹¦', 'ç¿»', 'çœ‹', 'è¯»', 'é¡µ', 'ä¹¦é¡µ', 'ç¿»é˜…', 'é˜…è¯»', 'æŸ¥çœ‹', 'ç¿»åŠ¨', 'ä¹¦æœ¬', 'å…¸ç±', 'å†Œå­'],
            'é›·å£°': ['é›·', 'æ‰“é›·', 'é›·é¸£', 'é—ªç”µ', 'é›·ç”µ', 'éœ¹é›³', 'è½°éš†', 'é›·å£°éš†éš†', 'ç”µé—ªé›·é¸£', 'é›·é›¨', 'é›·æš´'],
            'é›¨å£°': ['é›¨', 'ä¸‹é›¨', 'é›¨ç‚¹', 'é›¨æ°´', 'é™é›¨', 'ç»†é›¨', 'å¤§é›¨', 'æš´é›¨', 'é›¨æ»´', 'é›¨å¤œ', 'é›¨å£°', 'é›¨æ‰“', 'é›¨æ·‹'],
            'é£Žå£°': ['é£Ž', 'å¹', 'å¾®é£Ž', 'å¤§é£Ž', 'æ¸…é£Ž', 'ç‹‚é£Ž', 'åŠ²é£Ž', 'é£Žèµ·', 'é£Žå£°', 'å‘¼å•¸', 'å¹æ‹‚', 'é£Žå¹', 'åˆ®é£Ž'],
            'è™«é¸£': ['è™«', 'è‰', 'è›è›', 'æ˜†è™«', 'è™«å­', 'è‰é¸£', 'èŸ‹èŸ€', 'é¸£è™«', 'å¤è™«', 'ç§‹è™«', 'è™«å”±', 'è™«å£°'],
            'é¸Ÿå«': ['é¸Ÿ', 'é¸Ÿå„¿', 'æ­Œå”±', 'å•å•¾', 'é¸Ÿé¸£', 'é¸Ÿå£°', 'é£žé¸Ÿ', 'ç™¾é¸Ÿ', 'é¸Ÿå•¼', 'é›€é¸Ÿ', 'é¸£ç¦½', 'é¸Ÿè¯­'],
            'æ°´å£°': ['æ°´', 'æµæ°´', 'æºªæ°´', 'æ²³æ°´', 'æ¹–æ°´', 'æ³‰æ°´', 'æ°´æµ', 'æ½ºæ½º', 'æ¶“æ¶“', 'æ±©æ±©', 'æºªæµ', 'æ±Ÿæ²³', 'å–·æ³‰'],
            
            # å®¤å†…çŽ¯å¢ƒéŸ³
            'å¼€é—¨å£°': ['å¼€é—¨', 'æŽ¨é—¨', 'æ‹‰é—¨', 'é—¨å¼€', 'å¼€å¯', 'æˆ¿é—¨', 'å¤§é—¨', 'æœ¨é—¨', 'æŽ¨å¼€', 'æ‹‰å¼€'],
            'å…³é—¨å£°': ['å…³é—¨', 'å…³ä¸Š', 'é—¨å…³', 'åˆé—¨', 'æŽ©é—¨', 'é—­é—¨', 'ç °', 'é—¨å“'],
            'æ•²é—¨å£°': ['æ•²é—¨', 'æ•²å‡»', 'å©é—¨', 'æ‹é—¨', 'é—¨å“', 'æ•²æ‰“', 'æ‰£é—¨'],
            'æ—¶é’Ÿå£°': ['æ—¶é’Ÿ', 'é’Ÿè¡¨', 'æ»´ç­”', 'é’Ÿå£°', 'è¡¨å£°', 'è®¡æ—¶', 'é’Ÿæ‘†', 'ç§’é’ˆ'],
            'ç«ç„°å£°': ['ç«', 'ç«ç„°', 'ç‡ƒçƒ§', 'ç¯ç«', 'ç‚‰ç«', 'ç«è‹—', 'çƒ›ç«', 'åŠˆå•ª', 'å™¼å•ª'],
            
            # äººä¸ºæ´»åŠ¨éŸ³
            'å†™å­—å£°': ['å†™', 'ä¹¦å†™', 'è®°å½•', 'ç¬”', 'çº¸', 'å†™å­—', 'æ‰§ç¬”', 'è½ç¬”', 'ä¹¦å†™'],
            'ç¿»é¡µå£°': ['ç¿»é¡µ', 'ç¿»åŠ¨', 'çº¸å¼ ', 'ä¹¦é¡µ', 'é¡µé¢', 'ç¿»çœ‹'],
            'å’³å—½å£°': ['å’³å—½', 'å’³', 'æ¸…å’³', 'è½»å’³'],
            'å‘¼å¸å£°': ['å‘¼å¸', 'å–˜æ¯', 'å‘¼æ°”', 'å¸æ°”', 'å–˜æ°”', 'æ°”æ¯'],
            'å¿ƒè·³å£°': ['å¿ƒè·³', 'å¿ƒè„', 'å¿ƒå¾‹', 'è„‰æ', 'è·³åŠ¨'],
            
            # äº¤é€šçŽ¯å¢ƒéŸ³
            'æ±½è½¦å£°': ['æ±½è½¦', 'è½¦è¾†', 'è½¿è½¦', 'è´§è½¦', 'å¡è½¦', 'è½¦å­', 'è½¦å£°', 'å¼•æ“Ž', 'å‘åŠ¨æœº', 'é©¬è¾¾'],
            'é©¬è¹„å£°': ['é©¬', 'é©¬åŒ¹', 'æˆ˜é©¬', 'éªé©¬', 'é©¬è¹„', 'å¥”é©¬', 'éª‘é©¬'],
            'ç«è½¦å£°': ['ç«è½¦', 'åˆ—è½¦', 'è½¦åŽ¢', 'é“è·¯', 'è½¨é“', 'æ±½ç¬›'],
            
            # ç¤¾äº¤åœºæ™¯éŸ³
            'äººç¾¤å£°': ['äººç¾¤', 'ä¼—äºº', 'äººä»¬', 'äººå£°', 'å˜ˆæ‚', 'å–§å“—', 'å˜ˆå˜ˆ', 'è®®è®º', 'äº¤è°ˆ'],
            'æŽŒå£°': ['æŽŒå£°', 'é¼“æŽŒ', 'å–å½©', 'å«å¥½', 'æ¬¢å‘¼'],
            'éŸ³ä¹å£°': ['éŸ³ä¹', 'ä¹å£°', 'æ—‹å¾‹', 'ä¹æ›²', 'æ¼”å¥', 'å¼¹å¥'],
            'æ­Œå£°': ['æ­Œå£°', 'æ­Œå”±', 'åŸå”±', 'å”±æ­Œ', 'æ­Œè°£', 'åŸè¯µ'],
            
            # åŽ¨æˆ¿çŽ¯å¢ƒéŸ³
            'åˆ‡èœå£°': ['åˆ‡èœ', 'åˆ‡', 'åˆ€', 'èœæ¿', 'æ–™ç†', 'çƒ¹é¥ª'],
            'ç‚’èœå£°': ['ç‚’èœ', 'ç‚’', 'çƒ¹é¥ª', 'ä¸‹é”…', 'çˆ†ç‚’'],
            'ç…®æ°´å£°': ['ç…®æ°´', 'çƒ§æ°´', 'å¼€æ°´', 'æ°´å¼€', 'æ²¸è…¾'],
            
            # æˆ˜æ–—/æ­¦å™¨éŸ³
            'åˆ€å‰‘å£°': ['åˆ€', 'å‰‘', 'å…µå™¨', 'åˆ€å‰‘', 'å…µåˆƒ', 'åˆ©åˆƒ', 'å®å‰‘', 'é•¿åˆ€'],
            'æ’žå‡»å£°': ['æ’žå‡»', 'ç¢°æ’ž', 'æ’ž', 'å‡»', 'ç¢°', 'æ’žå‡»'],
            'ç ´ç¢Žå£°': ['ç ´ç¢Ž', 'ç¢Žè£‚', 'ç ´', 'ç¢Ž', 'ç²‰ç¢Ž', 'æ‰“ç¢Ž'],
            
            # å¤©æ°”ç›¸å…³
            'é›ªå£°': ['é›ª', 'ä¸‹é›ª', 'é›ªèŠ±', 'é£˜é›ª', 'é›ªå¤œ', 'é£Žé›ª'],
            'å†°å£°': ['å†°', 'ç»“å†°', 'å†°å—', 'å†°éœœ', 'å†°å†·'],
            
            # åŠ¨ç‰©å£°éŸ³
            'çŒ«å£°': ['çŒ«', 'çŒ«å’ª', 'å°çŒ«', 'å–µ', 'çŒ«å«'],
            'ç‹—å£°': ['ç‹—', 'çŠ¬', 'å°ç‹—', 'æ±ª', 'ç‹—å«', 'çŠ¬å '],
            'é©¬å£°': ['é©¬', 'é©¬åŒ¹', 'é©¬å˜¶', 'å˜¶é¸£'],
            'é¸¡å£°': ['é¸¡', 'å…¬é¸¡', 'é¸¡é¸£', 'é¸¡å«', 'å•¼é¸£']
        }
        
        if keyword in related_words:
            for related_word in related_words[keyword]:
                if related_word in text:
                    return True
        
        return False

    async def extract_and_analyze_narration_individual(self, synthesis_plan: List[Dict]) -> Dict:
        """åŽŸæœ‰çš„é€ä¸€åˆ†æžæ–¹æ³•ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰"""
        logger.info(f"[INDIVIDUAL_ANALYZER] å¼€å§‹é€ä¸€åˆ†æžsynthesis_planï¼Œå…±{len(synthesis_plan)}ä¸ªæ®µè½")
        
        environment_tracks = []
        cumulative_time = 0.0
        narration_count = 0
        
        for segment in synthesis_plan:
            # åªå¤„ç†æ—ç™½segments (æ—ç™½æ‰ä¼šè¯´çŽ¯å¢ƒå†…å®¹)
            narration_speakers = ['æ—ç™½', 'narrator', 'å™è¿°è€…', 'narration']
            if segment.get('speaker') in narration_speakers or segment.get('character') in narration_speakers:
                narration_count += 1
                
                # è®¡ç®—æ—ç™½æ—¶é•¿ (æ—ç™½è¯­é€Ÿå›ºå®šï¼Œå†…å®¹å·²åœ¨JSON)
                narration_text = segment.get('text', '') or segment.get('content', '')
                estimated_duration = self._calculate_narration_duration(narration_text)
                
                segment_id = segment.get('segment_id') or segment.get('id', f'seg_{narration_count}')
                logger.info(f"[INDIVIDUAL_ANALYZER] å¤„ç†æ—ç™½æ®µè½ {segment_id}: "
                           f"æ—¶é•¿{estimated_duration:.1f}sï¼Œå†…å®¹: {narration_text[:50]}...")
                
                # ä½¿ç”¨LLMæå–å£°éŸ³å…³é”®è¯
                try:
                    logger.info("[INDIVIDUAL_ANALYZER] ä½¿ç”¨LLMæå–å£°éŸ³å…³é”®è¯")
                    llm_result = await self.scene_analyzer.analyze_text_scenes_with_llm(narration_text)
                    
                    # è½¬æ¢ä¸ºæˆ‘ä»¬éœ€è¦çš„æ ¼å¼
                    environment_analysis = {
                        'environment_detected': len(llm_result.analyzed_scenes) > 0,
                        'scene_keywords': [],
                        'scene_description': '',
                        'confidence': llm_result.confidence_score
                    }
                    
                    # æå–å…³é”®è¯å’Œåœºæ™¯æè¿°
                    if llm_result.analyzed_scenes:
                        for scene in llm_result.analyzed_scenes:
                            environment_analysis['scene_keywords'].extend(scene.keywords)
                            if scene.location and scene.location != "detected_environment":
                                environment_analysis['scene_description'] += f"{scene.location} "
                        
                        # åŽ»é‡å…³é”®è¯
                        environment_analysis['scene_keywords'] = list(set(environment_analysis['scene_keywords']))
                        environment_analysis['scene_description'] = environment_analysis['scene_description'].strip()
                        
                        # å¦‚æžœæ²¡æœ‰å…·ä½“åœºæ™¯æè¿°ï¼Œç”¨å…³é”®è¯ç»„åˆ
                        if not environment_analysis['scene_description']:
                            environment_analysis['scene_description'] = "ã€".join(environment_analysis['scene_keywords'][:3])
                    
                    # æ£€æŸ¥LLMæ˜¯å¦çœŸçš„æœ‰æ•ˆåˆ†æž
                    if len(llm_result.analyzed_scenes) == 0 and llm_result.confidence_score == 0.0:
                        raise RuntimeError(f"LLMåˆ†æžå™¨æ— æ³•å·¥ä½œï¼šæ®µè½ {segment_id} è¿”å›žç©ºç»“æžœï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œæ­£å¸¸")
                    
                    if environment_analysis.get('environment_detected'):
                        environment_tracks.append({
                            'segment_id': segment_id,
                            'start_time': cumulative_time,
                            'duration': estimated_duration,
                            'narration_text': narration_text,
                            'environment_keywords': environment_analysis.get('scene_keywords', []),
                            'scene_description': environment_analysis.get('scene_description', ''),
                            'confidence': environment_analysis.get('confidence', 0.0),
                            'analysis_timestamp': datetime.now().isoformat(),
                            'mapping_strategy': 'individual'
                        })
                        
                        logger.info(f"[INDIVIDUAL_ANALYZER] æ£€æµ‹åˆ°çŽ¯å¢ƒ: {environment_analysis.get('scene_keywords', [])}")
                    else:
                        logger.info(f"[INDIVIDUAL_ANALYZER] LLMæœªæ£€æµ‹åˆ°çŽ¯å¢ƒå£°éŸ³")
                        
                except Exception as e:
                    logger.error(f"[INDIVIDUAL_ANALYZER] LLMåˆ†æžå¤±è´¥: {str(e)}")
                    raise RuntimeError(f"LLMåˆ†æžå™¨å¼‚å¸¸ï¼šæ®µè½ {segment_id} åˆ†æžå¤±è´¥ - {str(e)}")
                
                cumulative_time += estimated_duration
            else:
                # éžæ—ç™½æ®µè½ï¼Œç´¯åŠ æ—¶é•¿ä½†ä¸åˆ†æžçŽ¯å¢ƒ
                segment_duration = self._calculate_segment_duration(segment)
                cumulative_time += segment_duration
        
        # ðŸ• åº”ç”¨æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£å™¨
        if environment_tracks:
            logger.info("[INDIVIDUAL_ANALYZER] å¼€å§‹åº”ç”¨æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£")
            # æž„å»ºæ®µè½ä¿¡æ¯ä¾›ä¿®æ­£å™¨ä½¿ç”¨
            narration_segments = []
            current_time = 0.0
            for segment in synthesis_plan:
                segment_duration = self._calculate_segment_duration(segment)
                narration_speakers = ['æ—ç™½', 'narrator', 'å™è¿°è€…', 'narration']
                if segment.get('speaker') in narration_speakers or segment.get('character') in narration_speakers:
                    narration_segments.append({
                        'segment_id': segment.get('segment_id') or segment.get('id'),
                        'text': segment.get('text', '') or segment.get('content', ''),
                        'start_time': current_time,
                        'duration': segment_duration
                    })
                current_time += segment_duration
            
            original_tracks = [track.copy() for track in environment_tracks]
            corrected_tracks = self.timeline_corrector.correct_environment_tracks_timeline(
                environment_tracks, narration_segments
            )
            
            correction_summary = self.timeline_corrector.get_correction_summary(
                original_tracks, corrected_tracks
            )
            
            logger.info(f"[INDIVIDUAL_ANALYZER] æ—¶é—´è½´ä¿®æ­£å®Œæˆ: {correction_summary['summary']}")
            environment_tracks = corrected_tracks
                
        logger.info(f"[INDIVIDUAL_ANALYZER] åˆ†æžå®Œæˆ: æ€»æ—¶é•¿{cumulative_time:.1f}sï¼Œ"
                   f"æ—ç™½æ®µè½{narration_count}ä¸ªï¼ŒçŽ¯å¢ƒéŸ³è½¨é“{len(environment_tracks)}ä¸ª")
                
        return {
            'environment_tracks': environment_tracks,
            'analysis_summary': {
                'total_duration': cumulative_time,
                'narration_segments': narration_count,
                'environment_tracks_detected': len(environment_tracks),
                'analysis_timestamp': datetime.now().isoformat(),
                'analysis_mode': 'individual',
                'timeline_correction_applied': True if environment_tracks else False
            }
        }
        
    def _calculate_narration_duration(self, text: str) -> float:
        """è®¡ç®—æ—ç™½æ—¶é•¿ (è¯­é€Ÿå›ºå®š)"""
        if not text or not text.strip():
            return 0.0
            
        # åŽ»é™¤ç©ºç™½å­—ç¬¦ï¼Œè®¡ç®—æœ‰æ•ˆå­—ç¬¦æ•°
        char_count = len(text.replace(' ', '').replace('\n', '').replace('\t', ''))
        
        # æ ¹æ®å›ºå®šè¯­é€Ÿè®¡ç®—æ—¶é•¿
        duration_minutes = char_count / self.NARRATION_SPEED_CHARS_PER_MINUTE
        duration_seconds = duration_minutes * 60.0
        
        # æœ€å°‘1ç§’ï¼Œæœ€å¤š60ç§’
        return max(1.0, min(duration_seconds, 60.0))
        
    def _calculate_segment_duration(self, segment: Dict) -> float:
        """è®¡ç®—æ®µè½æ—¶é•¿ - ä¼˜å…ˆä½¿ç”¨å®žé™…éŸ³é¢‘æ—¶é•¿"""
        
        # 1. ä¼˜å…ˆä»Žsegmentä¸­èŽ·å–é¢„ä¼°æ—¶é•¿
        if 'estimated_duration' in segment:
            return float(segment['estimated_duration'])
        
        # 2. å°è¯•ä»Žæ•°æ®åº“èŽ·å–å®žé™…éŸ³é¢‘æ—¶é•¿
        if self.db and 'segment_id' in segment:
            try:
                from app.models.audio import AudioFile
                
                # æ ¹æ®segment_idæŸ¥æ‰¾å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶
                audio_file = self.db.query(AudioFile).filter(
                    AudioFile.segment_id == segment['segment_id'],
                    AudioFile.audio_type == 'segment',
                    AudioFile.status == 'active'
                ).first()
                
                if audio_file and audio_file.duration:
                    logger.info(f"[DURATION] æ®µè½{segment['segment_id']}ä½¿ç”¨å®žé™…éŸ³é¢‘æ—¶é•¿: {audio_file.duration:.1f}s")
                    return float(audio_file.duration)
                else:
                    logger.debug(f"[DURATION] æ®µè½{segment['segment_id']}æœªæ‰¾åˆ°å®žé™…éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨ä¼°ç®—æ—¶é•¿")
                    
            except Exception as e:
                logger.warning(f"[DURATION] èŽ·å–å®žé™…éŸ³é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
        
        # 3. å¦‚æžœæ²¡æœ‰æ•°æ®åº“è¿žæŽ¥æˆ–æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œæ ¹æ®æ–‡æœ¬é•¿åº¦è®¡ç®—
        text = segment.get('text', '') or segment.get('content', '')
        if text:
            # å¯¹è¯é€šå¸¸æ¯”æ—ç™½è¯­é€Ÿå¿«ä¸€äº›
            char_count = len(text.replace(' ', '').replace('\n', ''))
            duration_minutes = char_count / 400  # å¯¹è¯è¯­é€Ÿæ›´å¿«
            estimated_duration = max(0.5, duration_minutes * 60.0)
            logger.debug(f"[DURATION] æ®µè½ä¼°ç®—æ—¶é•¿: {estimated_duration:.1f}s (å­—ç¬¦æ•°: {char_count})")
            return estimated_duration
            
        return 1.0  # é»˜è®¤1ç§’
        
    def get_analysis_stats(self, analysis_result: Dict) -> Dict:
        """èŽ·å–åˆ†æžç»Ÿè®¡ä¿¡æ¯"""
        environment_tracks = analysis_result.get('environment_tracks', [])
        
        if not environment_tracks:
            return {
                'total_tracks': 0,
                'total_duration': 0.0,
                'avg_duration': 0.0,
                'keyword_distribution': {},
                'confidence_distribution': {}
            }
            
        total_duration = sum(track['duration'] for track in environment_tracks)
        avg_duration = total_duration / len(environment_tracks)
        
        # å…³é”®è¯åˆ†å¸ƒç»Ÿè®¡
        keyword_count = {}
        for track in environment_tracks:
            for keyword in track.get('environment_keywords', []):
                keyword_count[keyword] = keyword_count.get(keyword, 0) + 1
                
        # ç½®ä¿¡åº¦åˆ†å¸ƒç»Ÿè®¡
        confidence_ranges = {'é«˜(>0.8)': 0, 'ä¸­(0.5-0.8)': 0, 'ä½Ž(<0.5)': 0}
        for track in environment_tracks:
            confidence = track.get('confidence', 0.0)
            if confidence > 0.8:
                confidence_ranges['é«˜(>0.8)'] += 1
            elif confidence > 0.5:
                confidence_ranges['ä¸­(0.5-0.8)'] += 1
            else:
                confidence_ranges['ä½Ž(<0.5)'] += 1
                
        return {
            'total_tracks': len(environment_tracks),
            'total_duration': round(total_duration, 1),
            'avg_duration': round(avg_duration, 1),
            'keyword_distribution': dict(sorted(keyword_count.items(), key=lambda x: x[1], reverse=True)),
            'confidence_distribution': confidence_ranges
        }
