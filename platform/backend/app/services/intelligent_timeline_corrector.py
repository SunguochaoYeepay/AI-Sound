#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£å™¨
æ ¹æ®æ—ç™½æ–‡æœ¬ä¸­ç¯å¢ƒéŸ³å…³é”®è¯çš„å…·ä½“ä½ç½®ï¼Œç²¾ç¡®è®¡ç®—ç¯å¢ƒéŸ³çš„å¼€å§‹æ—¶é—´
è§£å†³ç¯å¢ƒéŸ³æ’­æ”¾æ—¶é—´ä¸æ—ç™½æè¿°ä¸åŒæ­¥çš„é—®é¢˜
"""

import re
import logging
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class KeywordPosition:
    """å…³é”®è¯ä½ç½®ä¿¡æ¯"""
    keyword: str
    start_pos: int        # åœ¨æ–‡æœ¬ä¸­çš„å­—ç¬¦ä½ç½®
    end_pos: int
    relative_time: float  # åœ¨æ®µè½ä¸­çš„ç›¸å¯¹æ—¶é—´ï¼ˆç§’ï¼‰

@dataclass
class CorrectedTrack:
    """ä¿®æ­£åçš„è½¨é“æ—¶é—´ä¿¡æ¯"""
    original_start_time: float
    corrected_start_time: float
    duration: float
    keyword_position: KeywordPosition
    confidence: float

class IntelligentTimelineCorrector:
    """æ™ºèƒ½æ—¶é—´è½´ä¿®æ­£å™¨"""
    
    def __init__(self):
        # ä¸­æ–‡è¯­éŸ³æœ—è¯»é€Ÿåº¦ (å­—ç¬¦/åˆ†é’Ÿ)
        self.CHINESE_SPEECH_RATE = 300  # æ¯åˆ†é’Ÿ300ä¸ªæ±‰å­—ï¼Œé€‚ä¸­è¯­é€Ÿ
        
        # ç¯å¢ƒéŸ³å…³é”®è¯çš„å¸¸è§åˆ«åå’Œå˜ä½“
        self.keyword_variants = {
            'é›·': ['é›·å£°', 'é›·é¸£', 'ç”µé—ªé›·é¸£', 'è½°é›·', 'ç‚¸é›·'],
            'é›¨': ['é›¨å£°', 'ä¸‹é›¨', 'é›¨æ°´', 'é›¨æ»´', 'ç»†é›¨', 'æš´é›¨'],
            'é£': ['é£å£°', 'åˆ®é£', 'å¾®é£', 'ç‹‚é£', 'é£å¹'],
            'è„šæ­¥': ['è„šæ­¥å£°', 'èµ°è·¯', 'è¸æ­¥', 'è¡Œèµ°', 'è„šæ­¥'],
            'é¸Ÿ': ['é¸Ÿé¸£', 'é¸Ÿå«', 'é¸Ÿå£°', 'å•å•¾'],
            'æ°´': ['æ°´å£°', 'æµæ°´', 'æºªæ°´', 'æ²³æ°´', 'æ½ºæ½º'],
            'é©¬è¹„': ['é©¬è¹„å£°', 'é©¬è¸', 'éªé©¬', 'é©¬è¹„è¸åœ°'],
            'èœ‚é¸£': ['èœ‚é¸£å£°', 'å˜Ÿå˜Ÿå£°', 'è­¦æŠ¥', 'æç¤ºéŸ³']
        }
    
    def correct_environment_tracks_timeline(self, 
                                          environment_tracks: List[Dict], 
                                          narration_segments: List[Dict]) -> List[Dict]:
        """ä¿®æ­£ç¯å¢ƒè½¨é“çš„æ—¶é—´è½´"""
        corrected_tracks = []
        
        # å»ºç«‹æ®µè½IDåˆ°æ®µè½ä¿¡æ¯çš„æ˜ å°„
        segment_map = {seg.get('segment_id'): seg for seg in narration_segments}
        
        for track in environment_tracks:
            segment_id = track.get('segment_id')
            segment = segment_map.get(segment_id)
            
            if not segment:
                logger.warning(f"æ‰¾ä¸åˆ°æ®µè½ {segment_id}ï¼Œä¿æŒåŸå§‹æ—¶é—´")
                corrected_tracks.append(track)
                continue
            
            # åˆ†æå¹¶ä¿®æ­£æ—¶é—´è½´
            corrected_track = self._correct_single_track_timeline(track, segment)
            corrected_tracks.append(corrected_track)
        
        return corrected_tracks
    
    def _correct_single_track_timeline(self, track: Dict, segment: Dict) -> Dict:
        """ä¿®æ­£å•ä¸ªè½¨é“çš„æ—¶é—´è½´"""
        narration_text = segment.get('text', '') or segment.get('content', '')
        keywords = track.get('environment_keywords', [])
        
        if not narration_text or not keywords:
            logger.debug(f"æ®µè½ {track.get('segment_id')} ç¼ºå°‘æ–‡æœ¬æˆ–å…³é”®è¯ï¼Œä¿æŒåŸå§‹æ—¶é—´")
            return track
        
        # æŸ¥æ‰¾å…³é”®è¯åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®
        keyword_positions = self._find_keywords_in_text(narration_text, keywords)
        
        if not keyword_positions:
            logger.debug(f"æ®µè½ {track.get('segment_id')} æœªæ‰¾åˆ°å…³é”®è¯ä½ç½®ï¼Œä¿æŒåŸå§‹æ—¶é—´")
            return track
        
        # é€‰æ‹©æœ€æ—©å‡ºç°çš„å…³é”®è¯ä½œä¸ºç¯å¢ƒéŸ³å¼€å§‹ç‚¹
        earliest_position = min(keyword_positions, key=lambda x: x.start_pos)
        
        # è®¡ç®—ä¿®æ­£åçš„å¼€å§‹æ—¶é—´
        segment_start_time = track.get('start_time', 0.0)
        relative_time_offset = earliest_position.relative_time
        corrected_start_time = segment_start_time + relative_time_offset
        
        # åˆ›å»ºä¿®æ­£åçš„è½¨é“
        corrected_track = track.copy()
        corrected_track.update({
            'original_start_time': segment_start_time,
            'start_time': corrected_start_time,
            'timeline_correction': {
                'applied': True,
                'offset_seconds': relative_time_offset,
                'keyword_found': earliest_position.keyword,
                'keyword_position': earliest_position.start_pos,
                'total_text_length': len(narration_text),
                'correction_confidence': earliest_position.relative_time / (track.get('duration', 10.0))
            }
        })
        
        logger.info(f"ğŸ• è½¨é“æ—¶é—´ä¿®æ­£: '{earliest_position.keyword}' "
                   f"ä» {segment_start_time:.1f}s è°ƒæ•´ä¸º {corrected_start_time:.1f}s "
                   f"(åç§» +{relative_time_offset:.1f}s)")
        
        return corrected_track
    
    def _find_keywords_in_text(self, text: str, keywords: List[str]) -> List[KeywordPosition]:
        """æŸ¥æ‰¾å…³é”®è¯åœ¨æ–‡æœ¬ä¸­çš„ä½ç½®"""
        positions = []
        
        for keyword in keywords:
            # è·å–å…³é”®è¯çš„æ‰€æœ‰å˜ä½“
            variants = self._get_keyword_variants(keyword)
            
            for variant in variants:
                # æŸ¥æ‰¾å˜ä½“åœ¨æ–‡æœ¬ä¸­çš„æ‰€æœ‰å‡ºç°ä½ç½®
                matches = list(re.finditer(re.escape(variant), text))
                
                for match in matches:
                    start_pos = match.start()
                    end_pos = match.end()
                    
                    # è®¡ç®—ç›¸å¯¹æ—¶é—´ï¼ˆåŸºäºå­—ç¬¦ä½ç½®å’Œè¯­é€Ÿï¼‰
                    relative_time = self._calculate_relative_time_from_position(
                        start_pos, len(text)
                    )
                    
                    positions.append(KeywordPosition(
                        keyword=variant,
                        start_pos=start_pos,
                        end_pos=end_pos,
                        relative_time=relative_time
                    ))
        
        return positions
    
    def _get_keyword_variants(self, keyword: str) -> List[str]:
        """è·å–å…³é”®è¯çš„æ‰€æœ‰å˜ä½“"""
        # é¦–å…ˆåŒ…å«åŸå…³é”®è¯
        variants = [keyword]
        
        # æ·»åŠ é¢„å®šä¹‰çš„å˜ä½“
        for base_keyword, variant_list in self.keyword_variants.items():
            if base_keyword in keyword or keyword in base_keyword:
                variants.extend(variant_list)
        
        # å»é‡å¹¶æŒ‰é•¿åº¦æ’åºï¼ˆä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„è¯ï¼‰
        variants = list(set(variants))
        variants.sort(key=len, reverse=True)
        
        return variants
    
    def _calculate_relative_time_from_position(self, char_position: int, total_length: int) -> float:
        """æ ¹æ®å­—ç¬¦ä½ç½®è®¡ç®—åœ¨æ®µè½ä¸­çš„ç›¸å¯¹æ—¶é—´"""
        if total_length == 0:
            return 0.0
        
        # è®¡ç®—å­—ç¬¦ä½ç½®åœ¨æ–‡æœ¬ä¸­çš„æ¯”ä¾‹
        position_ratio = char_position / total_length
        
        # æ ¹æ®è¯­é€Ÿè®¡ç®—æ€»æ®µè½æ—¶é•¿
        total_duration_minutes = total_length / self.CHINESE_SPEECH_RATE
        total_duration_seconds = total_duration_minutes * 60.0
        
        # è®¡ç®—ç›¸å¯¹æ—¶é—´
        relative_time = position_ratio * total_duration_seconds
        
        # ç¡®ä¿ç›¸å¯¹æ—¶é—´åˆç† (ä¸è¶…è¿‡æ®µè½æ€»æ—¶é•¿)
        max_duration = min(total_duration_seconds, 60.0)  # æœ€å¤§60ç§’
        relative_time = min(relative_time, max_duration * 0.9)  # æœ€å¤š90%çš„ä½ç½®
        
        return relative_time
    
    def get_correction_summary(self, original_tracks: List[Dict], 
                             corrected_tracks: List[Dict]) -> Dict:
        """è·å–ä¿®æ­£æ€»ç»“"""
        corrections_applied = 0
        total_offset = 0.0
        max_offset = 0.0
        
        for original, corrected in zip(original_tracks, corrected_tracks):
            if corrected.get('timeline_correction', {}).get('applied', False):
                corrections_applied += 1
                offset = corrected['timeline_correction']['offset_seconds']
                total_offset += offset
                max_offset = max(max_offset, offset)
        
        return {
            'total_tracks': len(original_tracks),
            'corrections_applied': corrections_applied,
            'correction_rate': corrections_applied / len(original_tracks) if original_tracks else 0,
            'average_offset': total_offset / corrections_applied if corrections_applied else 0,
            'max_offset': max_offset,
            'summary': f"ä¿®æ­£äº† {corrections_applied}/{len(original_tracks)} ä¸ªè½¨é“çš„æ—¶é—´è½´"
        } 