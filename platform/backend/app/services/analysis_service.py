"""
æ™ºèƒ½åˆ†ææœåŠ¡
å¤„ç†ä¹¦ç±å†…å®¹çš„AIæ™ºèƒ½åˆ†æåŠŸèƒ½
"""

import asyncio
import json
import hashlib
from typing import List, Dict, Any, Optional, AsyncGenerator
from datetime import datetime, timedelta
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from ..models import Book, BookChapter, NovelProject, AnalysisSession, AnalysisResult
# from .dify_client import DifyClient  # ğŸš€ å·²åˆ é™¤ - æ–‡ä»¶ä¸å­˜åœ¨
from ..exceptions import ServiceException, DifyAPIException
from ..utils.websocket_manager import ProgressWebSocketManager


class AnalysisSessionManager:
    """åˆ†æä¼šè¯ç®¡ç†å™¨"""
    
    def __init__(self, db: Session, websocket_manager: ProgressWebSocketManager):
        self.db = db
        self.websocket_manager = websocket_manager
        # self.dify_client = DifyClient()  # ğŸš€ å·²åˆ é™¤ - æ–‡ä»¶ä¸å­˜åœ¨
        
    async def create_session(
        self, 
        project_id: int, 
        target_type: str,
        target_ids: List[int] = None,
        config: Dict[str, Any] = None
    ) -> AnalysisSession:
        """åˆ›å»ºæ–°çš„åˆ†æä¼šè¯"""
        
        # éªŒè¯é¡¹ç›®å­˜åœ¨
        project = self.db.query(NovelProject).filter(NovelProject.id == project_id).first()
        if not project:
            raise ServiceException("é¡¹ç›®ä¸å­˜åœ¨")
        
        # è®¡ç®—ä»»åŠ¡æ€»æ•°
        total_tasks = 0
        if target_type == "full_book":
            total_tasks = self.db.query(BookChapter).filter(BookChapter.book_id == project.book_id).count()
        elif target_type == "chapters":
            total_tasks = len(target_ids or [])
        else:
            raise ServiceException(f"ä¸æ”¯æŒçš„ç›®æ ‡ç±»å‹: {target_type}")
        
        # åˆ›å»ºä¼šè¯
        session = AnalysisSession(
            project_id=project_id,
            book_id=project.book_id,
            target_type=target_type,
            target_ids=json.dumps(target_ids or []),
            llm_provider=config.get("llm_provider", "dify"),
            llm_model=config.get("llm_model"),
            llm_workflow_id=config.get("llm_workflow_id"),
            status="pending",
            total_tasks=total_tasks
        )
        
        self.db.add(session)
        self.db.commit()
        self.db.refresh(session)
        
        return session
    
    async def start_session(self, session_id: int) -> bool:
        """å¯åŠ¨åˆ†æä¼šè¯"""
        session = self.db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        if not session:
            raise ServiceException("ä¼šè¯ä¸å­˜åœ¨")
        
        if session.status != "pending":
            raise ServiceException(f"ä¼šè¯çŠ¶æ€ä¸æ­£ç¡®: {session.status}")
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        session.status = "running"
        session.started_at = datetime.utcnow()
        self.db.commit()
        
        # å¼‚æ­¥å¯åŠ¨åˆ†æä»»åŠ¡
        asyncio.create_task(self._run_analysis_tasks(session))
        
        return True
    
    async def _run_analysis_tasks(self, session: AnalysisSession):
        """æ‰§è¡Œåˆ†æä»»åŠ¡ä¸»é€»è¾‘"""
        try:
            # è·å–ç›®æ ‡ç« èŠ‚
            target_ids = json.loads(session.target_ids)
            
            if session.target_type == "full_book":
                chapters = self.db.query(BookChapter).filter(
                    BookChapter.book_id == session.book_id
                ).order_by(BookChapter.chapter_number).all()
            else:
                chapters = self.db.query(BookChapter).filter(
                    BookChapter.id.in_(target_ids)
                ).order_by(BookChapter.chapter_number).all()
            
            # æ‰¹é‡å¤„ç†ç« èŠ‚
            batch_size = 3  # å¹¶å‘å¤„ç†æ•°é‡
            completed = 0
            
            for i in range(0, len(chapters), batch_size):
                batch_chapters = chapters[i:i + batch_size]
                
                # å¹¶å‘å¤„ç†æœ¬æ‰¹æ¬¡ç« èŠ‚
                tasks = [
                    self._analyze_chapter(session, chapter) 
                    for chapter in batch_chapters
                ]
                
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # å¤„ç†ç»“æœ
                for j, result in enumerate(batch_results):
                    chapter = batch_chapters[j]
                    completed += 1
                    
                    if isinstance(result, Exception):
                        session.failed_tasks += 1
                        await self._send_progress_update(session, completed, f"ç« èŠ‚ {chapter.chapter_title} åˆ†æå¤±è´¥: {str(result)}")
                    else:
                        session.completed_tasks += 1
                        await self._send_progress_update(session, completed, f"ç« èŠ‚ {chapter.chapter_title} åˆ†æå®Œæˆ")
                    
                    # æ›´æ–°æ•°æ®åº“
                    self.db.commit()
                
                # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼Œé¿å…APIé™æµ
                if i + batch_size < len(chapters):
                    await asyncio.sleep(2)
            
            # å®Œæˆä¼šè¯
            session.status = "completed"
            session.completed_at = datetime.utcnow()
            session.progress = 100
            
            await self._send_progress_update(session, completed, "æ‰€æœ‰ç« èŠ‚åˆ†æå®Œæˆ")
            
        except Exception as e:
            # å¤„ç†å…¨å±€é”™è¯¯
            session.status = "failed"
            session.error_message = str(e)
            await self._send_progress_update(session, session.completed_tasks, f"åˆ†æå¤±è´¥: {str(e)}")
        
        finally:
            self.db.commit()
    
    async def _analyze_chapter(self, session: AnalysisSession, chapter: BookChapter) -> AnalysisResult:
        """åˆ†æå•ä¸ªç« èŠ‚"""
        try:
            # è®¡ç®—å†…å®¹å“ˆå¸Œ
            input_hash = hashlib.md5(chapter.content.encode('utf-8')).hexdigest()
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒå†…å®¹çš„åˆ†æç»“æœ
            existing_result = self.db.query(AnalysisResult).filter(
                and_(
                    AnalysisResult.input_hash == input_hash,
                    AnalysisResult.status == "active"
                )
            ).first()
            
            if existing_result:
                # å¤åˆ¶ç°æœ‰ç»“æœ
                new_result = AnalysisResult(
                    session_id=session.id,
                    chapter_id=chapter.id,
                    input_text=chapter.content,
                    input_hash=input_hash,
                    raw_response=existing_result.raw_response,
                    project_info=existing_result.project_info,
                    synthesis_plan=existing_result.synthesis_plan,
                    characters=existing_result.characters,
                    final_config=existing_result.final_config,
                    llm_response_time=0  # ç¼“å­˜å‘½ä¸­ï¼Œå“åº”æ—¶é—´ä¸º0
                )
            else:
                # è°ƒç”¨LLMåˆ†æ
                start_time = datetime.utcnow()
                # llm_response = await self.dify_client.analyze_text(  # ğŸš€ å·²åˆ é™¤ - DifyClientä¸å­˜åœ¨
                # ä½¿ç”¨æ¨¡æ‹Ÿå“åº”æˆ–å…¶ä»–åˆ†ææ–¹æ³•
                llm_response = await self._fallback_analysis(
                    text=chapter.content,
                    workflow_id=session.llm_workflow_id
                )
                end_time = datetime.utcnow()
                response_time = int((end_time - start_time).total_seconds() * 1000)
                
                # è§£æå“åº”
                parsed_result = self._parse_llm_response(llm_response)
                
                new_result = AnalysisResult(
                    session_id=session.id,
                    chapter_id=chapter.id,
                    input_text=chapter.content,
                    input_hash=input_hash,
                    llm_request_id=llm_response.get("request_id"),
                    llm_response_time=response_time,
                    raw_response=llm_response,
                    project_info=parsed_result.get("project_info"),
                    synthesis_plan=parsed_result["synthesis_plan"],
                    characters=parsed_result["characters"],
                    final_config=parsed_result["synthesis_plan"]  # åˆå§‹æ—¶final_configç­‰äºsynthesis_plan
                )
            
            self.db.add(new_result)
            self.db.commit()
            self.db.refresh(new_result)
            
            return new_result
            
        except Exception as e:
            raise ServiceException(f"ç« èŠ‚åˆ†æå¤±è´¥: {str(e)}")
    
    def _parse_llm_response(self, llm_response: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æLLMå“åº”ç»“æœ"""
        try:
            # ä»Difyå“åº”ä¸­æå–ç»“æ„åŒ–æ•°æ®
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„Difyå·¥ä½œæµè¾“å‡ºæ ¼å¼è¿›è¡Œè°ƒæ•´
            output_data = llm_response.get("data", {})
            
            # è§£æé¡¹ç›®ä¿¡æ¯
            project_info = output_data.get("project_info", {})
            
            # è§£æåˆæˆè®¡åˆ’
            synthesis_plan = output_data.get("synthesis_plan", {})
            if not synthesis_plan:
                raise ServiceException("LLMå“åº”ä¸­ç¼ºå°‘synthesis_plan")
            
            # è§£æè§’è‰²åˆ—è¡¨
            characters = output_data.get("characters", [])
            if not characters:
                raise ServiceException("LLMå“åº”ä¸­ç¼ºå°‘characters")
            
            return {
                "project_info": project_info,
                "synthesis_plan": synthesis_plan,
                "characters": characters
            }
            
        except (KeyError, TypeError, json.JSONDecodeError) as e:
            raise ServiceException(f"LLMå“åº”è§£æå¤±è´¥: {str(e)}")
    
    async def _send_progress_update(self, session: AnalysisSession, completed: int, message: str):
        """å‘é€è¿›åº¦æ›´æ–°"""
        progress = min(100, round((completed / session.total_tasks) * 100)) if session.total_tasks > 0 else 0
        session.progress = progress
        session.current_processing = message
        
        # é€šè¿‡WebSocketå‘é€æ›´æ–°
        await self.websocket_manager.send_progress_update(
            session_id=f"analysis_{session.id}",
            data={
                "session_id": session.id,
                "status": session.status,
                "progress": progress,
                "completed_tasks": completed,
                "total_tasks": session.total_tasks,
                "failed_tasks": session.failed_tasks,
                "current_processing": message,
                "timestamp": datetime.utcnow().isoformat()
            }
        )

    async def _fallback_analysis(self, text: str, workflow_id: str = None) -> Dict[str, Any]:
        """é™çº§åˆ†ææ–¹æ³• - å½“DifyClientä¸å¯ç”¨æ—¶ä½¿ç”¨"""
        import re
        
        # ç®€å•çš„æ–‡æœ¬åˆ†æé€»è¾‘
        lines = text.split('\n')
        dialogues = []
        
        # æ£€æµ‹å¯¹è¯
        dialogue_patterns = [r'"([^"]*)"', r'"([^"]*)"', r'ã€Œ([^ã€]*)ã€']
        
        for line in lines:
            for pattern in dialogue_patterns:
                matches = re.findall(pattern, line)
                dialogues.extend(matches)
        
        # ç”Ÿæˆç®€åŒ–çš„åˆ†æç»“æœ
        characters = []
        if dialogues:
            # åŸºäºå¯¹è¯æ•°é‡ä¼°ç®—è§’è‰²
            char_count = min(len(set(dialogues[:10])), 5)
            for i in range(char_count):
                characters.append({
                    "name": f"è§’è‰²{i+1}",
                    "voice_id": i + 1
                })
        
        # æ·»åŠ æ—ç™½
        characters.append({
            "name": "æ—ç™½",
            "voice_id": len(characters) + 1
        })
        
        # ç”Ÿæˆåˆæˆè®¡åˆ’
        synthesis_plan = {
            "segments": []
        }
        
        segment_id = 1
        for line in lines[:20]:  # åªå¤„ç†å‰20è¡Œ
            if line.strip():
                is_dialogue = any(re.search(pattern, line) for pattern in dialogue_patterns)
                synthesis_plan["segments"].append({
                    "id": segment_id,
                    "text": line.strip(),
                    "speaker": "è§’è‰²1" if is_dialogue else "æ—ç™½",
                    "voice_id": 1 if is_dialogue else len(characters)
                })
                segment_id += 1
        
        return {
            "request_id": f"fallback_{hash(text) % 10000}",
            "data": {
                "project_info": {
                    "analysis_method": "fallback",
                    "total_segments": len(synthesis_plan["segments"])
                },
                "synthesis_plan": synthesis_plan,
                "characters": characters
            }
        }


class AnalysisService:
    """æ™ºèƒ½åˆ†ææœåŠ¡ä¸»ç±»"""
    
    def __init__(self, db: Session, websocket_manager: ProgressWebSocketManager = None):
        self.db = db
        self.websocket_manager = websocket_manager or ProgressWebSocketManager()
        self.session_manager = AnalysisSessionManager(db, self.websocket_manager)
    
    async def start_analysis(
        self, 
        project_id: int, 
        target_type: str = "full_book",
        target_ids: List[int] = None,
        config: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """å¯åŠ¨æ™ºèƒ½åˆ†æ"""
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„ä¼šè¯
        active_session = self.db.query(AnalysisSession).filter(
            and_(
                AnalysisSession.project_id == project_id,
                AnalysisSession.status.in_(["pending", "running"])
            )
        ).first()
        
        if active_session:
            raise ServiceException("è¯¥é¡¹ç›®å·²æœ‰æ­£åœ¨è¿›è¡Œçš„åˆ†æä¼šè¯")
        
        # åˆ›å»ºæ–°ä¼šè¯
        session = await self.session_manager.create_session(
            project_id=project_id,
            target_type=target_type,
            target_ids=target_ids,
            config=config or {}
        )
        
        # å¯åŠ¨ä¼šè¯
        await self.session_manager.start_session(session.id)
        
        return {
            "session_id": session.id,
            "status": session.status,
            "total_tasks": session.total_tasks,
            "message": "åˆ†æå·²å¯åŠ¨"
        }
    
    async def get_session_status(self, session_id: int) -> Dict[str, Any]:
        """è·å–ä¼šè¯çŠ¶æ€"""
        session = self.db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        if not session:
            raise ServiceException("ä¼šè¯ä¸å­˜åœ¨")
        
        return {
            "session_id": session.id,
            "project_id": session.project_id,
            "status": session.status,
            "progress": session.progress,
            "total_tasks": session.total_tasks,
            "completed_tasks": session.completed_tasks,
            "failed_tasks": session.failed_tasks,
            "current_processing": session.current_processing,
            "started_at": session.started_at.isoformat() if session.started_at else None,
            "completed_at": session.completed_at.isoformat() if session.completed_at else None,
            "error_message": session.error_message
        }
    
    async def cancel_session(self, session_id: int) -> bool:
        """å–æ¶ˆåˆ†æä¼šè¯"""
        session = self.db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        if not session:
            raise ServiceException("ä¼šè¯ä¸å­˜åœ¨")
        
        if session.status not in ["pending", "running"]:
            raise ServiceException(f"æ— æ³•å–æ¶ˆçŠ¶æ€ä¸º {session.status} çš„ä¼šè¯")
        
        session.status = "cancelled"
        self.db.commit()
        
        return True
    
    async def get_analysis_results(self, session_id: int) -> List[Dict[str, Any]]:
        """è·å–åˆ†æç»“æœ"""
        results = self.db.query(AnalysisResult).filter(
            and_(
                AnalysisResult.session_id == session_id,
                AnalysisResult.status == "active"
            )
        ).order_by(AnalysisResult.created_at).all()
        
        return [result.to_dict() for result in results]
    
    async def update_analysis_result(
        self, 
        result_id: int, 
        user_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ›´æ–°åˆ†æç»“æœï¼ˆç”¨æˆ·ä¿®æ”¹é…ç½®ï¼‰"""
        result = self.db.query(AnalysisResult).filter(AnalysisResult.id == result_id).first()
        if not result:
            raise ServiceException("åˆ†æç»“æœä¸å­˜åœ¨")
        
        # è®°å½•ç”¨æˆ·ä¿®æ”¹
        result.user_modified = True
        result.user_config = user_config
        
        # åˆå¹¶æœ€ç»ˆé…ç½®
        final_config = result.synthesis_plan.copy()
        final_config.update(user_config)
        result.final_config = final_config
        
        result.applied_at = datetime.utcnow()
        
        self.db.commit()
        
        return result.to_dict()
    
    async def get_project_analysis_history(self, project_id: int) -> List[Dict[str, Any]]:
        """è·å–é¡¹ç›®çš„åˆ†æå†å²"""
        sessions = self.db.query(AnalysisSession).filter(
            AnalysisSession.project_id == project_id
        ).order_by(AnalysisSession.created_at.desc()).all()
        
        return [session.to_dict() for session in sessions]
    
    async def delete_session(self, session_id: int) -> bool:
        """åˆ é™¤åˆ†æä¼šè¯åŠå…¶ç»“æœ"""
        session = self.db.query(AnalysisSession).filter(AnalysisSession.id == session_id).first()
        if not session:
            raise ServiceException("ä¼šè¯ä¸å­˜åœ¨")
        
        if session.status == "running":
            raise ServiceException("æ— æ³•åˆ é™¤æ­£åœ¨è¿è¡Œçš„ä¼šè¯")
        
        # åˆ é™¤ç›¸å…³çš„åˆ†æç»“æœ
        self.db.query(AnalysisResult).filter(AnalysisResult.session_id == session_id).delete()
        
        # åˆ é™¤ä¼šè¯
        self.db.delete(session)
        self.db.commit()
        
        return True 