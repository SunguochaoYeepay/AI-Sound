"""
ç« èŠ‚åˆ†ææœåŠ¡
ç”¨äºèšåˆå’Œè½¬æ¢ç« èŠ‚åˆ†æç»“æœï¼Œä¸ºåˆæˆä¸­å¿ƒæä¾›æ™ºèƒ½åˆ†æèƒ½åŠ›
"""

import json
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_

from ..models import NovelProject, BookChapter, AnalysisResult, VoiceProfile
from ..exceptions import ServiceException

logger = logging.getLogger(__name__)


class ChapterAnalysisService:
    """ç« èŠ‚åˆ†ææœåŠ¡ - å¤ç”¨ä¹¦ç±ç®¡ç†çš„ç« èŠ‚åˆ†æèƒ½åŠ›"""
    
    def __init__(self, db: Session):
        self.db = db
    
    def validate_analysis_result(self, analysis_data: Dict[str, Any]) -> bool:
        """éªŒè¯åˆ†æç»“æœæ ¼å¼"""
        try:
            required_fields = ['detected_characters', 'segments']
            for field in required_fields:
                if field not in analysis_data:
                    logger.warning(f"åˆ†æç»“æœç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return False
            
            # æ£€æŸ¥è§’è‰²æ•°æ®æ ¼å¼
            characters = analysis_data.get('detected_characters', [])
            if not isinstance(characters, list):
                return False
            
            for char in characters:
                if not isinstance(char, dict) or 'name' not in char:
                    return False
            
            # æ£€æŸ¥æ®µè½æ•°æ®æ ¼å¼
            segments = analysis_data.get('segments', [])
            if not isinstance(segments, list):
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"éªŒè¯åˆ†æç»“æœå¤±è´¥: {str(e)}")
            return False
    
    def get_existing_analysis(self, chapter_id: int) -> Optional[Dict[str, Any]]:
        """è·å–å•ç« èŠ‚åˆ†æç»“æœ"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„å·²å®Œæˆåˆ†æç»“æœ
            analysis_result = self.db.query(AnalysisResult).filter(
                and_(
                    AnalysisResult.chapter_id == chapter_id,
                    AnalysisResult.status == 'completed'
                )
            ).order_by(AnalysisResult.created_at.desc()).first()
            
            if not analysis_result:
                return None
            
            # ä¼˜å…ˆä½¿ç”¨original_analysisä¸­çš„æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç›´æ¥å­—æ®µ
            if analysis_result.original_analysis:
                # ä½¿ç”¨åŸå§‹åˆ†ææ•°æ®
                original_data = analysis_result.original_analysis
                if isinstance(original_data, str):
                    original_data = json.loads(original_data)
                
                analysis_data = {
                    'detected_characters': original_data.get('detected_characters', []),
                    'segments': original_data.get('segments', []),
                    'synthesis_plan': original_data.get('synthesis_plan', {}),
                    'final_config': analysis_result.final_config or {},
                    'processing_stats': {
                        'confidence_score': analysis_result.confidence_score or 0,
                        'processing_time': analysis_result.processing_time or 0,
                        'analysis_id': analysis_result.id,
                        'created_at': analysis_result.created_at.isoformat() if analysis_result.created_at else None
                    }
                }
            else:
                # å›é€€åˆ°ç›´æ¥å­—æ®µ
                analysis_data = {
                    'detected_characters': analysis_result.detected_characters or [],
                    'segments': analysis_result.dialogue_segments or [],
                    'synthesis_plan': analysis_result.synthesis_plan or {},
                    'final_config': analysis_result.final_config or {},
                    'processing_stats': {
                        'confidence_score': analysis_result.confidence_score or 0,
                        'processing_time': analysis_result.processing_time or 0,
                        'analysis_id': analysis_result.id,
                        'created_at': analysis_result.created_at.isoformat() if analysis_result.created_at else None
                    }
                }
            
            # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
            if not self.validate_analysis_result(analysis_data):
                logger.warning(f"ç« èŠ‚ {chapter_id} çš„åˆ†æç»“æœæ ¼å¼æ— æ•ˆ")
                return None
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"è·å–ç« èŠ‚ {chapter_id} åˆ†æç»“æœå¤±è´¥: {str(e)}")
            return None
    
    def batch_get_existing_analysis(self, chapter_ids: List[int]) -> Dict[int, Dict[str, Any]]:
        """æ‰¹é‡è·å–ç« èŠ‚åˆ†æç»“æœ"""
        try:
            results = {}
            
            # æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰ç« èŠ‚çš„åˆ†æç»“æœ
            analysis_results = self.db.query(AnalysisResult).filter(
                and_(
                    AnalysisResult.chapter_id.in_(chapter_ids),
                    AnalysisResult.status == 'completed'
                )
            ).order_by(AnalysisResult.chapter_id, AnalysisResult.created_at.desc()).all()
            
            # æŒ‰ç« èŠ‚åˆ†ç»„ï¼Œå–æœ€æ–°çš„ç»“æœ
            chapter_results = {}
            for result in analysis_results:
                if result.chapter_id not in chapter_results:
                    chapter_results[result.chapter_id] = result
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            for chapter_id, analysis_result in chapter_results.items():
                # ä¼˜å…ˆä½¿ç”¨original_analysisä¸­çš„æ•°æ®
                if analysis_result.original_analysis:
                    original_data = analysis_result.original_analysis
                    if isinstance(original_data, str):
                        original_data = json.loads(original_data)
                    
                    analysis_data = {
                        'detected_characters': original_data.get('detected_characters', []),
                        'segments': original_data.get('segments', []),
                        'synthesis_plan': original_data.get('synthesis_plan', {}),
                        'final_config': analysis_result.final_config or {},
                        'processing_stats': {
                            'confidence_score': analysis_result.confidence_score or 0,
                            'processing_time': analysis_result.processing_time or 0,
                            'analysis_id': analysis_result.id,
                            'created_at': analysis_result.created_at.isoformat() if analysis_result.created_at else None
                        }
                    }
                else:
                    # å›é€€åˆ°ç›´æ¥å­—æ®µ
                    analysis_data = {
                        'detected_characters': analysis_result.detected_characters or [],
                        'segments': analysis_result.dialogue_segments or [],
                        'synthesis_plan': analysis_result.synthesis_plan or {},
                        'final_config': analysis_result.final_config or {},
                        'processing_stats': {
                            'confidence_score': analysis_result.confidence_score or 0,
                            'processing_time': analysis_result.processing_time or 0,
                            'analysis_id': analysis_result.id,
                            'created_at': analysis_result.created_at.isoformat() if analysis_result.created_at else None
                        }
                    }
                
                if self.validate_analysis_result(analysis_data):
                    results[chapter_id] = analysis_data
                else:
                    logger.warning(f"è·³è¿‡ç« èŠ‚ {chapter_id} çš„æ— æ•ˆåˆ†æç»“æœ")
            
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡è·å–ç« èŠ‚åˆ†æç»“æœå¤±è´¥: {str(e)}")
            return {}
    
    def get_project_chapters(self, project_id: int) -> List[Dict[str, Any]]:
        """è·å–é¡¹ç›®å…³è”ç« èŠ‚åˆ—è¡¨"""
        try:
            project = self.db.query(NovelProject).filter(NovelProject.id == project_id).first()
            if not project:
                raise ServiceException("é¡¹ç›®ä¸å­˜åœ¨")
            
            if not project.book_id:
                raise ServiceException("é¡¹ç›®æ²¡æœ‰å…³è”ä¹¦ç±")
            
            # è·å–ä¹¦ç±çš„æ‰€æœ‰ç« èŠ‚
            chapters = self.db.query(BookChapter).filter(
                BookChapter.book_id == project.book_id
            ).order_by(BookChapter.chapter_number).all()
            
            if not chapters:
                raise ServiceException("é¡¹ç›®å…³è”çš„ä¹¦ç±æ²¡æœ‰ç« èŠ‚")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            chapter_list = []
            for chapter in chapters:
                chapter_list.append({
                    'id': chapter.id,
                    'chapter_number': chapter.chapter_number,
                    'chapter_title': chapter.chapter_title,
                    'word_count': chapter.word_count or 0,
                    'analysis_status': chapter.analysis_status,
                    'synthesis_status': chapter.synthesis_status
                })
            
            return chapter_list
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›® {project_id} ç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}")
            raise ServiceException(f"è·å–é¡¹ç›®ç« èŠ‚å¤±è´¥: {str(e)}")
    
    def get_project_chapters_with_status(self, project_id: int, selected_chapter_ids: Optional[List[int]] = None) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """è·å–ç« èŠ‚åŠåˆ†æçŠ¶æ€"""
        try:
            chapters = self.get_project_chapters(project_id)
            
            # å¦‚æœæŒ‡å®šäº†é€‰ä¸­çš„ç« èŠ‚IDï¼Œåˆ™åªå¤„ç†è¿™äº›ç« èŠ‚
            if selected_chapter_ids:
                chapters = [ch for ch in chapters if ch['id'] in selected_chapter_ids]
                logger.info(f"è¿‡æ»¤åçš„ç« èŠ‚æ•°é‡: {len(chapters)}, åŸå§‹æ•°é‡: {len(self.get_project_chapters(project_id))}")
            
            chapter_ids = [ch['id'] for ch in chapters]
            
            # è·å–åˆ†æç»“æœ
            analysis_results = self.batch_get_existing_analysis(chapter_ids)
            
            # ç»Ÿè®¡çŠ¶æ€
            status_summary = {
                'total_chapters': len(chapters),
                'analyzed_chapters': len(analysis_results),
                'pending_chapters': len(chapters) - len(analysis_results),
                'analyzed_chapter_ids': list(analysis_results.keys()),
                'pending_chapter_ids': [ch['id'] for ch in chapters if ch['id'] not in analysis_results]
            }
            
            # ä¸ºç« èŠ‚æ·»åŠ åˆ†æçŠ¶æ€
            for chapter in chapters:
                chapter['has_analysis'] = chapter['id'] in analysis_results
                chapter['analysis_result'] = analysis_results.get(chapter['id'])
            
            return chapters, status_summary
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›® {project_id} ç« èŠ‚çŠ¶æ€å¤±è´¥: {str(e)}")
            raise ServiceException(f"è·å–ç« èŠ‚çŠ¶æ€å¤±è´¥: {str(e)}")
    
    def convert_chapter_analysis_to_synthesis_format(self, analysis_data: Dict[str, Any], chapter_info: Dict[str, Any]) -> Dict[str, Any]:
        """å•ç« èŠ‚æ ¼å¼è½¬æ¢"""
        try:
            # æå–è§’è‰²ä¿¡æ¯
            characters = analysis_data.get('detected_characters', [])
            segments = analysis_data.get('segments', [])
            
            # è½¬æ¢è§’è‰²æ ¼å¼
            converted_characters = []
            for char in characters:
                char_info = {
                    'name': char.get('name', ''),
                    'frequency': char.get('frequency', 1),
                    'gender': char.get('recommended_config', {}).get('gender', 'unknown'),
                    'personality': char.get('recommended_config', {}).get('personality', 'calm'),
                    'personality_description': char.get('recommended_config', {}).get('personality_description', ''),
                    'is_main_character': char.get('is_main_character', False),
                    'chapter_source': chapter_info.get('chapter_number', 0),
                    'first_appearance_chapter': chapter_info.get('chapter_number', 0)
                }
                converted_characters.append(char_info)
            
            # è½¬æ¢æ®µè½æ ¼å¼ä¸ºåˆæˆè®¡åˆ’
            synthesis_plan = []
            for i, segment in enumerate(segments):
                plan_item = {
                    'segment_id': i + 1,
                    'text': segment.get('text', ''),
                    'speaker': segment.get('speaker', 'æ—ç™½'),
                    'text_type': segment.get('text_type', 'narration'),
                    'confidence': segment.get('confidence', 0.8),
                    'chapter_id': chapter_info.get('id'),
                    'chapter_number': chapter_info.get('chapter_number'),
                    'parameters': {
                        'timeStep': 20,
                        'pWeight': 1.0,
                        'tWeight': 1.0
                    }
                }
                synthesis_plan.append(plan_item)
            
            return {
                'characters': converted_characters,
                'synthesis_plan': synthesis_plan,
                'chapter_info': chapter_info,
                'processing_stats': analysis_data.get('processing_stats', {})
            }
            
        except Exception as e:
            logger.error(f"è½¬æ¢ç« èŠ‚åˆ†ææ ¼å¼å¤±è´¥: {str(e)}")
            raise ServiceException(f"æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")
    
    def aggregate_chapter_results(self, project_id: int, selected_chapter_ids: Optional[List[int]] = None) -> Dict[str, Any]:
        """å¤šç« èŠ‚ç»“æœèšåˆ"""
        try:
            # è·å–ç« èŠ‚åŠçŠ¶æ€
            chapters, status_summary = self.get_project_chapters_with_status(project_id, selected_chapter_ids)
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç« èŠ‚éƒ½å·²åˆ†æ
            if status_summary['pending_chapters'] > 0:
                pending_titles = []
                for chapter in chapters:
                    if not chapter['has_analysis']:
                        pending_titles.append(f"ç¬¬{chapter['chapter_number']}ç« : {chapter['chapter_title']}")
                
                raise ServiceException(
                    f"é¡¹ç›®è¿˜æœ‰ {status_summary['pending_chapters']} ä¸ªç« èŠ‚æœªå®Œæˆåˆ†æï¼Œ"
                    f"è¯·å…ˆå®Œæˆä»¥ä¸‹ç« èŠ‚çš„æ™ºèƒ½å‡†å¤‡ï¼š\n" + "\n".join(pending_titles[:5]) + 
                    ("..." if len(pending_titles) > 5 else "")
                )
            
            # èšåˆæ‰€æœ‰ç« èŠ‚çš„åˆ†æç»“æœ
            all_characters = {}  # è§’è‰²å -> è§’è‰²ä¿¡æ¯ï¼ˆåˆå¹¶åï¼‰
            all_synthesis_plan = []
            chapter_mapping = {}  # ç« èŠ‚ID -> ç« èŠ‚ä¿¡æ¯
            
            for chapter in chapters:
                analysis_data = chapter['analysis_result']
                if not analysis_data:
                    continue
                
                chapter_info = {
                    'id': chapter['id'],
                    'chapter_number': chapter['chapter_number'],
                    'chapter_title': chapter['chapter_title'],
                    'word_count': chapter['word_count']
                }
                
                # è½¬æ¢å•ç« èŠ‚æ ¼å¼
                converted = self.convert_chapter_analysis_to_synthesis_format(analysis_data, chapter_info)
                
                # åˆå¹¶è§’è‰²ä¿¡æ¯
                for char in converted['characters']:
                    char_name = char['name']
                    if char_name in all_characters:
                        # åˆå¹¶å·²å­˜åœ¨çš„è§’è‰²
                        existing = all_characters[char_name]
                        existing['frequency'] += char['frequency']
                        existing['appearances'] = existing.get('appearances', []) + [chapter['chapter_number']]
                        
                        # æ›´æ–°ä¸»è§’è‰²æ ‡è¯†
                        if char['is_main_character']:
                            existing['is_main_character'] = True
                    else:
                        # æ–°è§’è‰²
                        char['appearances'] = [chapter['chapter_number']]
                        all_characters[char_name] = char
                
                # æ·»åŠ åˆæˆè®¡åˆ’
                all_synthesis_plan.extend(converted['synthesis_plan'])
                
                # è®°å½•ç« èŠ‚æ˜ å°„
                chapter_mapping[chapter['id']] = chapter_info
            
            # è½¬æ¢è§’è‰²å­—å…¸ä¸ºåˆ—è¡¨
            characters_list = list(all_characters.values())
            
            # æŒ‰é¢‘æ¬¡æ’åºè§’è‰²
            characters_list.sort(key=lambda x: x['frequency'], reverse=True)
            
            # æ„å»ºèšåˆç»“æœ
            aggregated_result = {
                'project_info': {
                    'project_id': project_id,
                    'total_chapters': status_summary['total_chapters'],
                    'total_characters': len(characters_list),
                    'total_segments': len(all_synthesis_plan),
                    'analysis_time': datetime.now().isoformat(),
                    'ai_model': 'ollama-gemma3-27b',
                    'source': 'chapter_analysis_aggregation'
                },
                'characters': characters_list,
                'synthesis_plan': all_synthesis_plan,
                'chapter_mapping': chapter_mapping,
                'status_summary': status_summary
            }
            
            logger.info(f"é¡¹ç›® {project_id} ç« èŠ‚èšåˆå®Œæˆ: {len(characters_list)} ä¸ªè§’è‰², {len(all_synthesis_plan)} ä¸ªæ®µè½")
            
            return aggregated_result
            
        except Exception as e:
            logger.error(f"èšåˆé¡¹ç›® {project_id} ç« èŠ‚ç»“æœå¤±è´¥: {str(e)}")
            if isinstance(e, ServiceException):
                raise
            else:
                raise ServiceException(f"ç« èŠ‚ç»“æœèšåˆå¤±è´¥: {str(e)}")
    
    def assign_voices_to_characters(self, characters: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ä¸ºè§’è‰²åˆ†é…è¯­éŸ³ - å·²ç¦ç”¨è‡ªåŠ¨åˆ†é…ï¼Œä¿æŒvoice_idä¸ºNone"""
        try:
            logger.info(f"ğŸ­ æ£€æµ‹åˆ° {len(characters)} ä¸ªè§’è‰²ï¼Œä½†ä¸è‡ªåŠ¨åˆ†é…voice_id")
            
            # ğŸ”§ ä¸å†è‡ªåŠ¨åˆ†é…ä»»ä½•voice_idï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨åˆ†é…
            assigned_characters = []
            
            for char in characters:
                char_name = char.get('name', '')
                
                # æ›´æ–°è§’è‰²ä¿¡æ¯ï¼Œä½†ä¸åˆ†é…voice_id
                char_with_voice = char.copy()
                char_with_voice['voice_id'] = None
                char_with_voice['voice_name'] = 'æœªåˆ†é…'
                char_with_voice['voice_type'] = 'unknown'
                char_with_voice['voice_description'] = ''
                
                logger.info(f"âš ï¸ è§’è‰² '{char_name}' æœªåˆ†é…voice_idï¼Œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®")
                assigned_characters.append(char_with_voice)
            
            logger.info(f"å®Œæˆè§’è‰²å¤„ç†: {len(assigned_characters)} ä¸ªè§’è‰²ï¼Œå…¨éƒ¨éœ€è¦ç”¨æˆ·æ‰‹åŠ¨åˆ†é…voice_id")
            
            return assigned_characters
            
        except Exception as e:
            logger.error(f"è§’è‰²å¤„ç†å¤±è´¥: {str(e)}")
            # å›é€€ï¼šè¿”å›åŸå§‹è§’è‰²åˆ—è¡¨ï¼Œä¸åˆ†é…å£°éŸ³
            for char in characters:
                char['voice_id'] = None
                char['voice_name'] = 'å¤„ç†å¤±è´¥'
            return characters
    
    def _infer_gender_from_name(self, name: str) -> str:
        """ä»è§’è‰²åç§°æ¨æ–­æ€§åˆ« - å·²ç¦ç”¨è‡ªåŠ¨æ¨æ–­"""
        logger.info(f"âŒ æ€§åˆ«è‡ªåŠ¨æ¨æ–­å·²ç¦ç”¨ï¼Œè§’è‰² '{name}' æ€§åˆ«ä¿æŒä¸º unknown")
        return 'unknown'
    
    def convert_to_synthesis_format(self, aggregated_data: Dict[str, Any]) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºåˆæˆæ ¼å¼"""
        try:
            # ä¸ºè§’è‰²åˆ†é…å£°éŸ³
            characters_with_voices = self.assign_voices_to_characters(aggregated_data['characters'])
            
            # æ›´æ–°åˆæˆè®¡åˆ’ä¸­çš„å£°éŸ³ä¿¡æ¯
            synthesis_plan = aggregated_data['synthesis_plan']
            character_voice_mapping = {char['name']: char for char in characters_with_voices}
            
            for plan_item in synthesis_plan:
                speaker = plan_item.get('speaker', 'æ—ç™½')
                if speaker in character_voice_mapping:
                    char_info = character_voice_mapping[speaker]
                    plan_item['voice_id'] = char_info.get('voice_id')
                    plan_item['voice_name'] = char_info.get('voice_name', '')
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”è§’è‰²ï¼Œä½¿ç”¨é»˜è®¤å£°éŸ³
                    plan_item['voice_id'] = None
                    plan_item['voice_name'] = 'æœªåˆ†é…'
            
            # ğŸ”§ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å’Œä¿®å¤
            character_names = {char['name'] for char in characters_with_voices}
            synthesis_speakers = {item.get('speaker') for item in synthesis_plan}
            
            # æ‰¾å‡ºåœ¨synthesis_planä¸­ä½†ä¸åœ¨charactersä¸­çš„è§’è‰²
            missing_characters = synthesis_speakers - character_names
            if missing_characters:
                logger.warning(f"å‘ç°ä¸ä¸€è‡´ï¼šsynthesis_planä¸­æœ‰è§’è‰²ä½†charactersä¸­ç¼ºå¤±: {missing_characters}")
                
                # è‡ªåŠ¨æ·»åŠ ç¼ºå¤±çš„è§’è‰²åˆ°charactersåˆ—è¡¨ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
                for missing_char in missing_characters:
                    if missing_char and missing_char.strip():  # è¿‡æ»¤ç©ºå€¼
                        default_char = {
                            'name': missing_char,
                            'voice_id': None,
                            'voice_name': 'æœªåˆ†é…',
                            'voice_type': 'unknown',
                            'frequency': 1,
                            'gender': 'unknown',
                            'personality': 'calm',
                            'is_main_character': False
                        }
                        characters_with_voices.append(default_char)
                        logger.info(f"è‡ªåŠ¨æ·»åŠ ç¼ºå¤±è§’è‰²: {missing_char}")
            
            # æ„å»ºæœ€ç»ˆçš„åˆæˆæ ¼å¼
            synthesis_format = {
                'project_info': aggregated_data['project_info'],
                'synthesis_plan': synthesis_plan,
                'characters': characters_with_voices,
                'chapter_mapping': aggregated_data.get('chapter_mapping', {}),
                'voice_assignment_summary': {
                    'total_characters': len(characters_with_voices),
                    'assigned_voices': len([c for c in characters_with_voices if c.get('voice_id')]),
                    'unassigned_characters': len([c for c in characters_with_voices if not c.get('voice_id')])
                },
                'data_consistency_check': {
                    'characters_count': len(character_names),
                    'synthesis_speakers_count': len(synthesis_speakers),
                    'missing_characters_found': len(missing_characters),
                    'missing_characters': list(missing_characters) if missing_characters else []
                }
            }
            
            return synthesis_format
            
        except Exception as e:
            logger.error(f"è½¬æ¢ä¸ºåˆæˆæ ¼å¼å¤±è´¥: {str(e)}")
            raise ServiceException(f"åˆæˆæ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}") 