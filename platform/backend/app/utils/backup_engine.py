#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“å¤‡ä»½å¼•æ“
"""

import os
import asyncio
import subprocess
import time
import gzip
import shutil
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any
from sqlalchemy.orm import Session

from app.models.backup import BackupTask, TaskStatus
from app.config import settings
from app.utils.logger import log_system_event

# é…ç½®å¸¸é‡ - ä½¿ç”¨æœ¬åœ°å¼€å‘ç¯å¢ƒè·¯å¾„
import os
from pathlib import Path

# å¤‡ä»½å­˜å‚¨é…ç½®
from app.utils.path_manager import get_storage_path

# ä½¿ç”¨get_storage_pathè·å–æ­£ç¡®çš„è·¯å¾„
BACKUP_DIR = get_storage_path("data", "backups")
AUDIO_DIR = get_storage_path("audio")

# ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
os.makedirs(BACKUP_DIR, exist_ok=True)
MAX_BACKUP_SIZE = 10 * 1024 * 1024 * 1024  # 10GB


class BackupEngine:
    """æ•°æ®åº“å¤‡ä»½å¼•æ“"""
    
    def __init__(self, db: Session):
        self.db = db
        self.settings = settings
        self._ensure_backup_directory()
    
    def _ensure_backup_directory(self):
        """ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨"""
        Path(BACKUP_DIR).mkdir(parents=True, exist_ok=True)
        log_system_event(f"å¤‡ä»½ç›®å½•æ£€æŸ¥å®Œæˆ: {BACKUP_DIR}", "debug")
    
    async def create_database_backup(
        self, 
        task_id: int, 
        backup_type: str = "full",
        include_audio: bool = False
    ) -> bool:
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        
        task = self.db.query(BackupTask).filter(BackupTask.id == task_id).first()
        if not task:
            log_system_event(f"å¤‡ä»½ä»»åŠ¡ {task_id} ä¸å­˜åœ¨", "error")
            return False
        
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
            task.status = "running"
            task.start_time = datetime.utcnow()
            task.progress_percentage = 0
            self.db.commit()
            
            log_system_event(f"ğŸš€ å¼€å§‹æ‰§è¡Œå¤‡ä»½ä»»åŠ¡: {task.task_name} (ID: {task_id})", "info")
            log_system_event(f"ğŸ“ å¤‡ä»½ç±»å‹: {backup_type}, åŒ…å«éŸ³é¢‘: {include_audio}", "info")
            
            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"backup_{backup_type}_{timestamp}.sql"
            backup_path = os.path.join(BACKUP_DIR, backup_filename)
            
            log_system_event(f"ğŸ“ å¤‡ä»½æ–‡ä»¶è·¯å¾„: {backup_path}", "info")
            
            # æ‰§è¡Œæ•°æ®åº“å¤‡ä»½
            log_system_event(f"â³ å¼€å§‹æ•°æ®åº“å¤‡ä»½...", "info")
            success = await self._execute_pg_dump(task, backup_path)
            
            if not success:
                return False
            

            
            # å‹ç¼©å¤‡ä»½æ–‡ä»¶
            log_system_event(f"ğŸ—œï¸ å¼€å§‹å‹ç¼©å¤‡ä»½æ–‡ä»¶...", "info")
            task.progress_percentage = 70
            self.db.commit()
            
            compressed_path = await self._compress_backup_file(backup_path)
            if compressed_path:
                backup_path = compressed_path
                log_system_event(f"âœ… å‹ç¼©å®Œæˆ: {compressed_path}", "info")
            
            # åŒ…å«éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if include_audio:
                task.progress_percentage = 80
                self.db.commit()
                
                audio_backup_path = await self._backup_audio_files(task_id, timestamp)
                if audio_backup_path:
                    log_system_event(f"éŸ³é¢‘æ–‡ä»¶å¤‡ä»½å®Œæˆ: {audio_backup_path}", "info")
            
            # è®¡ç®—æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(backup_path)
            
            # æ›´æ–°ä»»åŠ¡å®ŒæˆçŠ¶æ€
            task.status = "success"
            task.end_time = datetime.utcnow()
            task.duration_seconds = int((task.end_time - task.start_time).total_seconds())
            task.file_path = backup_path
            task.file_size = file_size
            task.compressed_size = file_size if compressed_path else None
            task.progress_percentage = 100
            
            self.db.commit()
            
            log_system_event(
                f"ğŸ‰ å¤‡ä»½ä»»åŠ¡å®Œæˆ: {task.task_name}", "info"
            )
            log_system_event(
                f"ğŸ“Š å¤‡ä»½ç»Ÿè®¡: æ–‡ä»¶å¤§å° {file_size / 1024 / 1024:.2f} MB, è€—æ—¶ {task.duration_seconds}ç§’", "info"
            )
            
            # æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶
            await self._cleanup_old_backups(task.retention_days)
            
            return True
            
        except Exception as e:
            # æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€
            task.status = "failed"
            task.end_time = datetime.utcnow()
            task.error_message = str(e)
            self.db.commit()
            
            log_system_event(f"å¤‡ä»½ä»»åŠ¡å¤±è´¥: {task.task_name}, é”™è¯¯: {str(e)}", "error")
            return False
    
    async def _execute_pg_dump(self, task: BackupTask, backup_path: str) -> bool:
        """æ‰§è¡Œ pg_dump å‘½ä»¤"""
        try:
            # æ£€æŸ¥ pg_dump æ˜¯å¦å¯ç”¨
            import shutil
            pg_dump_path = shutil.which('pg_dump')
            
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å®‰è£…è·¯å¾„
            if not pg_dump_path:
                potential_paths = [
                    r"C:\Program Files\PostgreSQL\16\bin\pg_dump.exe",
                    r"C:\Program Files\PostgreSQL\15\bin\pg_dump.exe",
                    r"C:\Program Files (x86)\PostgreSQL\16\bin\pg_dump.exe",
                ]
                
                for path in potential_paths:
                    if os.path.exists(path):
                        pg_dump_path = path
                        log_system_event(f"âœ… ä½¿ç”¨å®Œæ•´è·¯å¾„æ‰¾åˆ° pg_dump: {pg_dump_path}", "info")
                        break
            
            if not pg_dump_path:
                error_msg = """pg_dump å·¥å…·æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… PostgreSQL å®¢æˆ·ç«¯å·¥å…·

ğŸ“¥ å®‰è£…æ–¹æ³•ï¼š
1. è®¿é—® https://www.postgresql.org/download/windows/
2. ä¸‹è½½ PostgreSQL å®‰è£…åŒ…ï¼ˆæ¨èç‰ˆæœ¬ 15 æˆ– 16ï¼‰
3. å®‰è£…æ—¶ç¡®ä¿é€‰æ‹© "Command Line Tools"
4. å®‰è£…å®Œæˆåé‡å¯AI-Soundåç«¯

ğŸ’¡ æˆ–è€…ä½¿ç”¨ Chocolateyï¼š
   choco install postgresql

âš ï¸ æ³¨æ„ï¼šå®‰è£…åéœ€è¦å°† PostgreSQL/bin ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿ PATH ç¯å¢ƒå˜é‡ä¸­
   å…¸å‹è·¯å¾„ï¼šC:\\Program Files\\PostgreSQL\\15\\bin

ğŸ”§ ä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼šå¦‚æœåªéœ€è¦é…ç½®å¤‡ä»½è€Œä¸ç«‹å³æ‰§è¡Œï¼Œå¯ä»¥å…ˆåˆ›å»ºå¤‡ä»½é…ç½®"""
                
                log_system_event("âŒ pg_dump å·¥å…·æ£€æŸ¥å¤±è´¥", "error")
                log_system_event("ğŸ“‹ æä¾›PostgreSQLå®¢æˆ·ç«¯å·¥å…·å®‰è£…æŒ‡å¯¼", "info")
                task.error_message = error_msg
                self.db.commit()
                return False
            
            log_system_event(f"âœ… æ‰¾åˆ° pg_dump å·¥å…·: {pg_dump_path}", "info")
            
            # ä» database_url è§£ææ•°æ®åº“è¿æ¥å‚æ•°
            import re
            
            # è§£æ database_url
            # æ ¼å¼: postgresql://username:password@host:port/database
            db_url = self.settings.database_url
            log_system_event(f"ğŸ”§ ä½¿ç”¨æ•°æ®åº“è¿æ¥: {db_url}", "info")
            print(f"DATABASE URL: {db_url}")
            match = re.match(r'postgresql://([^:]+):([^@]+)@([^:]+):(\d+)/(.+)', db_url)
            
            if not match:
                raise Exception(f"æ— æ•ˆçš„ database_url æ ¼å¼: {db_url}")
            
            username, password, host, port, database = match.groups()
            
            print(f"HOST: {host}, PORT: {port}, USER: {username}, DB: {database}")
            log_system_event(f"ğŸ”— è¿æ¥å‚æ•°: {host}:{port}/{database} (ç”¨æˆ·: {username})", "info")
            
            # æ„å»º pg_dump å‘½ä»¤
            cmd = [
                pg_dump_path,
                "--host", host,
                "--port", port,
                "--username", username,
                "--dbname", database,
                "--no-password",
                "--verbose",
                "--clean",
                "--if-exists",
                "--format=custom",
                "--file", backup_path
            ]
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env["PGPASSWORD"] = password
            
            log_system_event(f"ğŸ”§ æ‰§è¡Œ pg_dump å‘½ä»¤: {' '.join(cmd[:-1])} [file]", "info")
            log_system_event(f"ğŸ”— è¿æ¥æ•°æ®åº“: {host}:{port}/{database}", "info")
            
            # Windowså¹³å°ä½¿ç”¨åŒæ­¥subprocessï¼Œé¿å…asyncioé—®é¢˜
            import subprocess
            import threading
            import time
            
            result_container = {"process": None, "stdout": None, "stderr": None, "returncode": None}
            
            def run_pg_dump():
                """åœ¨çº¿ç¨‹ä¸­è¿è¡Œpg_dump"""
                try:
                    log_system_event("ğŸ”„ å¼€å§‹æ‰§è¡Œpg_dumpè¿›ç¨‹...", "info")
                    process = subprocess.Popen(
                        cmd,
                        env=env,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True
                    )
                    result_container["process"] = process
                    
                    # ç­‰å¾…è¿›ç¨‹å®Œæˆ
                    stdout, stderr = process.communicate()
                    result_container["stdout"] = stdout
                    result_container["stderr"] = stderr
                    result_container["returncode"] = process.returncode
                    
                    log_system_event(f"âœ… pg_dumpè¿›ç¨‹å®Œæˆï¼Œé€€å‡ºç : {process.returncode}", "info")
                    
                except Exception as e:
                    log_system_event(f"âŒ pg_dumpè¿›ç¨‹å¼‚å¸¸: {str(e)}", "error")
                    result_container["returncode"] = -1
                    result_container["stderr"] = str(e)
            
            # å¯åŠ¨çº¿ç¨‹æ‰§è¡Œpg_dump
            dump_thread = threading.Thread(target=run_pg_dump)
            dump_thread.start()
            
            # ç›‘æ§è¿›åº¦ï¼Œæ¯2ç§’æ›´æ–°ä¸€æ¬¡
            progress = 10
            while dump_thread.is_alive():
                await asyncio.sleep(2)
                if progress < 60:
                    progress += 5
                    task.progress_percentage = progress
                    self.db.commit()
                    log_system_event(f"ğŸ“Š å¤‡ä»½è¿›åº¦: {progress}%", "debug")
            
            # ç­‰å¾…çº¿ç¨‹å®Œæˆ
            dump_thread.join()
            
            # è·å–ç»“æœ
            stdout = result_container["stdout"] or ""
            stderr = result_container["stderr"] or ""
            returncode = result_container["returncode"]
            
            if returncode == 0:
                log_system_event(f"âœ… pg_dump æ‰§è¡ŒæˆåŠŸï¼Œé€€å‡ºç : {returncode}", "info")
                
                # æ£€æŸ¥å¤‡ä»½æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
                if os.path.exists(backup_path):
                    file_size = os.path.getsize(backup_path)
                    log_system_event(f"ğŸ“ å¤‡ä»½æ–‡ä»¶å·²ç”Ÿæˆ: {backup_path} ({file_size / 1024 / 1024:.2f} MB)", "info")
                else:
                    log_system_event(f"âŒ å¤‡ä»½æ–‡ä»¶æœªç”Ÿæˆ: {backup_path}", "error")
                    return False
                    
                return True
            else:
                error_msg = stderr if stderr else "pg_dump æ‰§è¡Œå¤±è´¥"
                log_system_event(f"âŒ pg_dump æ‰§è¡Œå¤±è´¥ (é€€å‡ºç : {returncode}): {error_msg}", "error")
                task.error_message = error_msg
                self.db.commit()
                return False
                
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            error_msg = f"pg_dump æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            
            # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
            log_system_event(f"âŒ {error_msg}", "error")
            log_system_event(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {error_details}", "error")
            print(f"BACKUP ERROR: {error_msg}")
            print(f"BACKUP ERROR DETAILS: {error_details}")
            
            # æ£€æŸ¥å…·ä½“é”™è¯¯ç±»å‹
            error_str = str(e).lower()
            if "connection" in error_str or "connect" in error_str:
                log_system_event("ğŸ”— å¯èƒ½æ˜¯æ•°æ®åº“è¿æ¥é—®é¢˜", "error")
            elif "permission" in error_str or "access" in error_str:
                log_system_event("ğŸ” å¯èƒ½æ˜¯æƒé™é—®é¢˜", "error")
            elif "no such file" in error_str or "not found" in error_str:
                log_system_event("ğŸ“ å¯èƒ½æ˜¯æ–‡ä»¶è·¯å¾„é—®é¢˜", "error")
            
            # æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®
            if "No such file or directory" in str(e) or "not found" in str(e).lower():
                fix_msg = """
ğŸ”§ PostgreSQLå·¥å…·è·¯å¾„é—®é¢˜ä¿®å¤å»ºè®®:
1. é‡å¯AI-Soundåç«¯ç¨‹åº (è®©ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ)
2. æ£€æŸ¥PATHç¯å¢ƒå˜é‡æ˜¯å¦åŒ…å«: C:\\Program Files\\PostgreSQL\\16\\bin
3. éªŒè¯pg_dump.exeæ˜¯å¦å­˜åœ¨äºè¯¥è·¯å¾„
4. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·é‡å¯æ•´ä¸ªç³»ç»Ÿ
"""
                log_system_event(fix_msg, "info")
                task.error_message = f"{error_msg}\n{fix_msg}"
            else:
                task.error_message = error_msg
            
            self.db.commit()
            return False
    

    

    
    async def _compress_backup_file(self, backup_path: str) -> Optional[str]:
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶"""
        try:
            compressed_path = f"{backup_path}.gz"
            
            # è®°å½•åŸå§‹æ–‡ä»¶å¤§å°
            original_size = os.path.getsize(backup_path)
            
            with open(backup_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # è®°å½•å‹ç¼©åæ–‡ä»¶å¤§å°
            compressed_size = os.path.getsize(compressed_path)
            
            # åˆ é™¤åŸå§‹æ–‡ä»¶
            os.remove(backup_path)
            compression_ratio = (1 - compressed_size / original_size) * 100
            
            log_system_event(
                f"ğŸ—œï¸ å¤‡ä»½æ–‡ä»¶å‹ç¼©å®Œæˆ: {compressed_path}", "info"
            )
            log_system_event(
                f"ğŸ“Š å‹ç¼©ç»Ÿè®¡: {original_size / 1024 / 1024:.2f} MB â†’ {compressed_size / 1024 / 1024:.2f} MB (å‹ç¼©ç‡: {compression_ratio:.1f}%)", 
                "info"
            )
            return compressed_path
            
        except Exception as e:
            log_system_event(f"å‹ç¼©å¤‡ä»½æ–‡ä»¶å¤±è´¥: {str(e)}", "warning")
            return None
    
    async def _backup_audio_files(self, task_id: int, timestamp: str) -> Optional[str]:
        """å¤‡ä»½éŸ³é¢‘æ–‡ä»¶"""
        try:
            if not os.path.exists(AUDIO_DIR):
                log_system_event("éŸ³é¢‘ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡éŸ³é¢‘å¤‡ä»½", "warning")
                return None
            
            audio_backup_name = f"audio_backup_{task_id}_{timestamp}.tar.gz"
            audio_backup_path = os.path.join(BACKUP_DIR, audio_backup_name)
            
            # ä½¿ç”¨ tar å‘½ä»¤å‹ç¼©éŸ³é¢‘ç›®å½•
            cmd = [
                "tar", "-czf", audio_backup_path,
                "-C", os.path.dirname(AUDIO_DIR),
                os.path.basename(AUDIO_DIR)
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                log_system_event(f"éŸ³é¢‘æ–‡ä»¶å¤‡ä»½å®Œæˆ: {audio_backup_path}", "info")
                return audio_backup_path
            else:
                error_msg = stderr.decode() if stderr else "éŸ³é¢‘å¤‡ä»½å¤±è´¥"
                log_system_event(f"éŸ³é¢‘æ–‡ä»¶å¤‡ä»½å¤±è´¥: {error_msg}", "warning")
                return None
                
        except Exception as e:
            log_system_event(f"å¤‡ä»½éŸ³é¢‘æ–‡ä»¶å¼‚å¸¸: {str(e)}", "warning")
            return None
    
    async def _cleanup_old_backups(self, retention_days: int):
        """æ¸…ç†è¿‡æœŸçš„å¤‡ä»½æ–‡ä»¶"""
        try:
            cutoff_time = time.time() - (retention_days * 24 * 60 * 60)
            deleted_count = 0
            
            for filename in os.listdir(BACKUP_DIR):
                file_path = os.path.join(BACKUP_DIR, filename)
                if os.path.isfile(file_path):
                    if os.path.getmtime(file_path) < cutoff_time:
                        try:
                            os.remove(file_path)
                            deleted_count += 1
                            log_system_event(f"åˆ é™¤è¿‡æœŸå¤‡ä»½æ–‡ä»¶: {filename}", "debug")
                        except Exception as e:
                            log_system_event(f"åˆ é™¤å¤‡ä»½æ–‡ä»¶å¤±è´¥: {filename}, {str(e)}", "warning")
            
            if deleted_count > 0:
                log_system_event(f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªè¿‡æœŸå¤‡ä»½æ–‡ä»¶", "info")
                
        except Exception as e:
            log_system_event(f"æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶å¤±è´¥: {str(e)}", "warning")
    
    async def get_backup_file_info(self, backup_path: str) -> Dict[str, Any]:
        """è·å–å¤‡ä»½æ–‡ä»¶ä¿¡æ¯"""
        try:
            if not os.path.exists(backup_path):
                return {"exists": False}
            
            stat = os.stat(backup_path)
            
            return {
                "exists": True,
                "size": stat.st_size,
                "created_time": datetime.fromtimestamp(stat.st_ctime),
                "modified_time": datetime.fromtimestamp(stat.st_mtime),
                "readable": os.access(backup_path, os.R_OK)
            }
            
        except Exception as e:
            log_system_event(f"è·å–å¤‡ä»½æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}", "warning")
            return {"exists": False, "error": str(e)}
    
    async def validate_backup_file(self, backup_path: str) -> bool:
        """éªŒè¯å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(backup_path):
                return False
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(backup_path)
            if file_size == 0:
                return False
            
            # å¦‚æœæ˜¯å‹ç¼©æ–‡ä»¶ï¼Œå°è¯•è§£å‹éªŒè¯
            if backup_path.endswith('.gz'):
                try:
                    with gzip.open(backup_path, 'rb') as f:
                        # è¯»å–æ–‡ä»¶å¤´éªŒè¯æ ¼å¼
                        header = f.read(100)
                        if len(header) == 0:
                            return False
                except Exception:
                    return False
            
            return True
            
        except Exception as e:
            log_system_event(f"éªŒè¯å¤‡ä»½æ–‡ä»¶å¤±è´¥: {str(e)}", "warning")
            return False

    def check_backup_environment(self) -> Dict[str, Any]:
        """æ£€æŸ¥å¤‡ä»½ç¯å¢ƒçŠ¶æ€"""
        import shutil
        
        result = {
            "pg_dump_available": False,
            "pg_dump_path": None,
            "backup_directory": False,
            "database_connection": False,
            "environment": "unknown",
            "recommendations": []
        }
        
        # æ£€æµ‹è¿è¡Œç¯å¢ƒ
        is_docker = os.path.exists('/.dockerenv') or os.getenv('DOCKER_CONTAINER', False)
        result["environment"] = "docker" if is_docker else "host"
        
        # æ£€æŸ¥ pg_dump
        pg_dump_path = shutil.which('pg_dump')
        if pg_dump_path:
            result["pg_dump_available"] = True
            result["pg_dump_path"] = pg_dump_path
            log_system_event(f"âœ… pg_dump å·¥å…·å¯ç”¨: {pg_dump_path} (ç¯å¢ƒ: {result['environment']})", "info")
        else:
            if is_docker:
                result["recommendations"].append({
                    "type": "critical",
                    "message": "Dockerå®¹å™¨ä¸­ç¼ºå°‘ PostgreSQL å®¢æˆ·ç«¯å·¥å…·",
                    "action": "é‡æ–°æ„å»ºDockeré•œåƒï¼Œç¡®ä¿å®‰è£…äº† postgresql-client åŒ…"
                })
                log_system_event("âŒ Dockerå®¹å™¨ä¸­pg_dumpå·¥å…·ä¸å¯ç”¨", "warning")
            else:
                result["recommendations"].append({
                    "type": "critical",
                    "message": "éœ€è¦å®‰è£… PostgreSQL å®¢æˆ·ç«¯å·¥å…·",
                    "action": "è®¿é—® https://www.postgresql.org/download/windows/ ä¸‹è½½å®‰è£…"
                })
                log_system_event("âŒ ä¸»æœºç¯å¢ƒä¸­pg_dumpå·¥å…·ä¸å¯ç”¨", "warning")
        
        # æ£€æŸ¥å¤‡ä»½ç›®å½•
        try:
            self._ensure_backup_directory()
            result["backup_directory"] = True
            log_system_event(f"âœ… å¤‡ä»½ç›®å½•å¯ç”¨: {BACKUP_DIR}", "info")
        except Exception as e:
            result["recommendations"].append({
                "type": "error", 
                "message": f"å¤‡ä»½ç›®å½•åˆ›å»ºå¤±è´¥: {str(e)}",
                "action": "æ£€æŸ¥ç£ç›˜ç©ºé—´å’Œæƒé™"
            })
            log_system_event(f"âŒ å¤‡ä»½ç›®å½•æ£€æŸ¥å¤±è´¥: {str(e)}", "error")
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥ï¼ˆç®€å•æ£€æŸ¥ï¼‰
        try:
            # è¿™é‡Œåªæ˜¯æ£€æŸ¥æ•°æ®åº“ä¼šè¯æ˜¯å¦æœ‰æ•ˆ
            self.db.execute("SELECT 1")
            result["database_connection"] = True
            log_system_event("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸", "info")
        except Exception as e:
            result["recommendations"].append({
                "type": "error",
                "message": f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}",
                "action": "æ£€æŸ¥æ•°æ®åº“æœåŠ¡çŠ¶æ€"
            })
            log_system_event(f"âŒ æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥: {str(e)}", "error")
        
        # æ€»ä½“çŠ¶æ€
        result["ready"] = all([
            result["pg_dump_available"],
            result["backup_directory"], 
            result["database_connection"]
        ])
        
        if result["ready"]:
            log_system_event("ğŸ‰ å¤‡ä»½ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥æ‰§è¡Œå¤‡ä»½æ“ä½œ", "info")
        else:
            log_system_event("âš ï¸ å¤‡ä»½ç¯å¢ƒæ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·å…ˆè§£å†³ç›¸å…³é—®é¢˜", "warning")
        
        return result