"""
ç¯å¢ƒæ··éŸ³API
æä¾›ç¯å¢ƒæ··éŸ³ä½œå“çš„ç®¡ç†ã€ç”Ÿæˆå’Œä¸‹è½½åŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Any
import logging
from datetime import datetime
import json

from app.database import get_db
from app.models import NovelProject, EnvironmentAudioMixingJob, EnvironmentGenerationSession
from pydantic import BaseModel
from app.clients.tangoflux_client import TangoFluxClient
import requests
import io
import numpy as np
from pydub import AudioSegment

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/environment/mixing", tags=["ç¯å¢ƒæ··éŸ³"])

def _build_tangoflux_prompt(keywords: List[str], duration: float) -> str:
    """æ„å»ºTangoFluxæç¤ºè¯"""
    # å…³é”®è¯æ˜ å°„åˆ°è‹±æ–‡æç¤ºè¯
    keyword_mapping = {
        'è„šæ­¥': 'footsteps walking on wooden floor',
        'ç¿»ä¹¦': 'pages turning in a book, paper rustling',
        'é›·': 'thunder rumbling in the distance',
        'é›¨': 'gentle rain falling, water droplets',
        'æ°´': 'water flowing, stream sound',
        'é£': 'wind blowing through trees',
        'é¸Ÿ': 'birds chirping in nature',
        'è™«': 'insects buzzing at night',
        'ç«': 'fire crackling in fireplace',
        'æµ·': 'ocean waves crashing on shore',
        'é—¨': 'door opening and closing',
        'è½¦': 'car driving on road',
        'äºº': 'people talking in background',
        'å¨‡å–': 'person shouting in distance',
        'å–': 'person drinking'
    }
    
    # è½¬æ¢å…³é”®è¯ä¸ºè‹±æ–‡æç¤ºè¯
    english_prompts = []
    for keyword in keywords:
        found = False
        for key, prompt in keyword_mapping.items():
            if key in keyword:
                english_prompts.append(prompt)
                found = True
                break
        if not found:
            english_prompts.append(f"ambient {keyword} sound")
    
    # æ„å»ºæœ€ç»ˆæç¤ºè¯
    base_prompt = ", ".join(english_prompts[:3])  # æœ€å¤š3ä¸ªå…³é”®è¯
    
    # æ·»åŠ è´¨é‡æè¿°
    quality_suffix = "high quality, clear, natural environmental sound"
    
    # æ ¹æ®æ—¶é•¿è°ƒæ•´æè¿°
    if duration < 5:
        duration_desc = "short duration"
    elif duration < 15:
        duration_desc = "medium duration"
    else:
        duration_desc = "long duration ambient"
    
    final_prompt = f"{base_prompt}, {duration_desc}, {quality_suffix}"
    
    return final_prompt

# è¯·æ±‚æ¨¡å‹
class MixingConfigRequest(BaseModel):
    """ç¯å¢ƒæ··éŸ³é…ç½®è¯·æ±‚"""
    environment_config: Dict[str, Any]
    chapter_ids: Optional[List[int]] = None
    mixing_options: Optional[Dict[str, Any]] = None

# å“åº”æ¨¡å‹
class MixingResultResponse(BaseModel):
    """æ··éŸ³ç»“æœå“åº”"""
    id: int
    project_id: int
    name: Optional[str]
    status: str
    file_path: Optional[str]
    file_url: Optional[str]
    duration: Optional[float]
    environment_tracks_count: Optional[int]
    created_at: str
    updated_at: Optional[str]

class MixingStatsResponse(BaseModel):
    """æ··éŸ³ç»Ÿè®¡å“åº”"""
    total_mixings: int
    completed_mixings: int
    processing_mixings: int
    failed_mixings: int
    total_tracks: int

@router.get("/results")
async def get_mixing_results(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    project_id: Optional[int] = Query(None, description="é¡¹ç›®ID"),
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰"),
    db: Session = Depends(get_db)
):
    """
    è·å–ç¯å¢ƒæ··éŸ³ç»“æœåˆ—è¡¨
    """
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢çœŸå®æ•°æ®
        query = db.query(EnvironmentAudioMixingJob)
        
        # åº”ç”¨ç­›é€‰
        if project_id:
            query = query.filter(EnvironmentAudioMixingJob.project_id == project_id)
            
        if status:
            # çŠ¶æ€æ˜ å°„
            status_mapping = {
                'completed': 'completed',
                'processing': 'running', 
                'pending': 'pending',
                'failed': 'failed'
            }
            db_status = status_mapping.get(status, status)
            query = query.filter(EnvironmentAudioMixingJob.job_status == db_status)
        
        # æœç´¢åŠŸèƒ½ - åŸºäºç« èŠ‚IDæˆ–é¡¹ç›®ID
        if search:
            search_pattern = f"%{search}%"
            try:
                # å°è¯•å°†æœç´¢è¯è½¬æ¢ä¸ºæ•´æ•°ï¼Œç”¨äºé¡¹ç›®IDæœç´¢
                search_int = int(search)
                query = query.filter(
                    (EnvironmentAudioMixingJob.chapter_id.like(search_pattern)) |
                    (EnvironmentAudioMixingJob.project_id == search_int)
                )
            except ValueError:
                # å¦‚æœä¸æ˜¯æ•°å­—ï¼Œåªæœç´¢ç« èŠ‚ID
                query = query.filter(
                    EnvironmentAudioMixingJob.chapter_id.like(search_pattern)
                )
        
        # è·å–æ€»æ•°
        total = query.count()
        
        # åˆ†é¡µå’Œæ’åº
        query = query.order_by(EnvironmentAudioMixingJob.created_at.desc())
        query = query.offset((page - 1) * page_size).limit(page_size)
        
        mixing_jobs = query.all()
        
        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        results = []
        for job in mixing_jobs:
            # ç”Ÿæˆåç§°
            name = f"é¡¹ç›®{job.project_id}ç« èŠ‚{job.chapter_id}ç¯å¢ƒæ··éŸ³"
            if job.output_file_path:
                import os
                name = os.path.splitext(os.path.basename(job.output_file_path))[0]
            
            # çŠ¶æ€æ˜ å°„
            status_mapping = {
                'pending': 'pending',
                'running': 'processing',
                'completed': 'completed',
                'failed': 'failed'
            }
            display_status = status_mapping.get(job.job_status, job.job_status)
            
            result = {
                "id": job.id,
                "project_id": job.project_id,
                "name": name,
                "status": display_status,
                "file_path": job.output_file_path,
                "file_url": f"/api/v1/environment/mixing/{job.id}/audio" if job.output_file_path else None,
                "duration": job.output_duration,
                "environment_tracks_count": job.total_tracks,
                "progress": job.progress,
                "created_at": job.created_at.isoformat() if job.created_at else None,
                "updated_at": job.updated_at.isoformat() if job.updated_at else None
            }
            results.append(result)
        
        return {
            "success": True,
            "data": results,
            "total": total,
            "page": page,
            "page_size": page_size,
            "message": "ç¯å¢ƒæ··éŸ³ç»“æœè·å–æˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"è·å–ç¯å¢ƒæ··éŸ³ç»“æœå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¯å¢ƒæ··éŸ³ç»“æœå¤±è´¥: {str(e)}")

@router.get("/stats")
async def get_mixing_stats(
    db: Session = Depends(get_db)
):
    """
    è·å–ç¯å¢ƒæ··éŸ³ç»Ÿè®¡æ•°æ®
    """
    try:
        # ä»æ•°æ®åº“æŸ¥è¯¢çœŸå®ç»Ÿè®¡æ•°æ®
        total_mixings = db.query(EnvironmentAudioMixingJob).count()
        completed_mixings = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.job_status == 'completed'
        ).count()
        processing_mixings = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.job_status == 'running'
        ).count()
        failed_mixings = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.job_status == 'failed'
        ).count()
        
        # è®¡ç®—æ€»éŸ³è½¨æ•°
        from sqlalchemy import func
        total_tracks_result = db.query(func.sum(EnvironmentAudioMixingJob.total_tracks)).scalar()
        total_tracks = total_tracks_result or 0
        
        stats = {
            "total_mixings": total_mixings,
            "completed_mixings": completed_mixings,
            "processing_mixings": processing_mixings,
            "failed_mixings": failed_mixings,
            "total_tracks": total_tracks
        }
        
        return {
            "success": True,
            "data": stats,
            "message": "ç¯å¢ƒæ··éŸ³ç»Ÿè®¡æ•°æ®è·å–æˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"è·å–ç¯å¢ƒæ··éŸ³ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¯å¢ƒæ··éŸ³ç»Ÿè®¡å¤±è´¥: {str(e)}")

@router.post("/{project_id}/start")
async def start_environment_mixing(
    project_id: int,
    config: MixingConfigRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    å¼€å§‹ç¯å¢ƒæ··éŸ³
    """
    try:
        # éªŒè¯é¡¹ç›®æ˜¯å¦å­˜åœ¨
        project = db.query(NovelProject).filter(NovelProject.id == project_id).first()
        if not project:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        logger.info(f"å¼€å§‹ä¸ºé¡¹ç›® {project_id} ç”Ÿæˆç¯å¢ƒæ··éŸ³")
        logger.info(f"ç¯å¢ƒé…ç½®: {config.environment_config}")
        
        # ä»ç¯å¢ƒé…ç½®ä¸­æå–ç« èŠ‚ID
        chapter_ids = config.chapter_ids or []
        chapter_id = ",".join(map(str, chapter_ids)) if chapter_ids else f"project_{project_id}"
        
        # åˆ›å»ºç¯å¢ƒæ··éŸ³ä»»åŠ¡è®°å½•
        mixing_job = EnvironmentAudioMixingJob(
            project_id=project_id,
            chapter_id=chapter_id,
            job_status='pending',
            progress=0.0,
            mixing_config=config.dict(),
            total_tracks=len(config.environment_config.get('analysis_result', {}).get('tracks', [])) if config.environment_config.get('analysis_result') else 0,
            completed_tracks=0,
            failed_tracks=0,
            started_at=datetime.now()
        )
        
        # ğŸ”§ å¤„ç†ä¸»é”®å†²çªï¼šä¿®å¤PostgreSQLåºåˆ—
        try:
            db.add(mixing_job)
            db.commit()
            db.refresh(mixing_job)
        except Exception as e:
            db.rollback()  # å›æ»šäº‹åŠ¡
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸»é”®å†²çªé”™è¯¯
            if "duplicate key value violates unique constraint" in str(e) or "UniqueViolation" in str(e):
                logger.warning(f"æ£€æµ‹åˆ°ä¸»é”®å†²çªï¼Œå°è¯•ä¿®å¤PostgreSQLåºåˆ—: {str(e)}")
                
                try:
                    # è·å–å½“å‰è¡¨ä¸­çš„æœ€å¤§ID
                    max_id_result = db.execute("SELECT MAX(id) FROM environment_audio_mixing_jobs").fetchone()
                    max_id = max_id_result[0] if max_id_result and max_id_result[0] else 0
                    
                    # ä¿®å¤åºåˆ—å€¼
                    new_seq_value = max_id + 1
                    db.execute(f"SELECT setval('environment_audio_mixing_jobs_id_seq', {new_seq_value})")
                    db.commit()
                    
                    logger.info(f"PostgreSQLåºåˆ—å·²ä¿®å¤ï¼Œè®¾ç½®ä¸º: {new_seq_value}")
                    
                    # é‡æ–°å°è¯•åˆ›å»ºä»»åŠ¡
                    mixing_job = EnvironmentAudioMixingJob(
                        project_id=project_id,
                        chapter_id=chapter_id,
                        job_status='pending',
                        progress=0.0,
                        mixing_config=config.dict(),
                        total_tracks=len(config.environment_config.get('analysis_result', {}).get('tracks', [])) if config.environment_config.get('analysis_result') else 0,
                        completed_tracks=0,
                        failed_tracks=0,
                        started_at=datetime.now()
                    )
                    
                    db.add(mixing_job)
                    db.commit()
                    db.refresh(mixing_job)
                    
                    logger.info(f"åºåˆ—ä¿®å¤åæˆåŠŸåˆ›å»ºç¯å¢ƒæ··éŸ³ä»»åŠ¡: ID={mixing_job.id}")
                    
                except Exception as fix_error:
                    logger.error(f"ä¿®å¤åºåˆ—æ—¶å‡ºé”™: {str(fix_error)}")
                    raise HTTPException(status_code=500, detail=f"æ•°æ®åº“åºåˆ—ä¿®å¤å¤±è´¥: {str(fix_error)}")
            else:
                # å…¶ä»–ç±»å‹çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                raise
        
        logger.info(f"åˆ›å»ºç¯å¢ƒæ··éŸ³ä»»åŠ¡è®°å½•: ID={mixing_job.id}")
        
        # å¯åŠ¨åå°æ··éŸ³ä»»åŠ¡
        background_tasks.add_task(process_environment_mixing, mixing_job.id)
        
        return {
            "success": True,
            "data": {
                "mixing_id": mixing_job.id,
                "project_id": project_id,
                "status": "started",
                "estimated_duration": "5-10åˆ†é’Ÿ",
                "message": "ç¯å¢ƒæ··éŸ³ä»»åŠ¡å·²å¯åŠ¨"
            },
            "message": "ç¯å¢ƒæ··éŸ³ä»»åŠ¡å¯åŠ¨æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯åŠ¨ç¯å¢ƒæ··éŸ³å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨ç¯å¢ƒæ··éŸ³å¤±è´¥: {str(e)}")

@router.get("/{mixing_id}/download")
async def download_mixing(
    mixing_id: int,
    db: Session = Depends(get_db)
):
    """
    ä¸‹è½½ç¯å¢ƒæ··éŸ³ä½œå“
    """
    try:
        from fastapi.responses import FileResponse
        import os
        
        # ä»æ•°æ®åº“æŸ¥è¯¢çœŸå®çš„æ–‡ä»¶è·¯å¾„
        mixing_job = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.id == mixing_id
        ).first()
        
        if not mixing_job:
            raise HTTPException(status_code=404, detail="æ··éŸ³ä»»åŠ¡ä¸å­˜åœ¨")
        
        if not mixing_job.output_file_path:
            raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶å°šæœªç”Ÿæˆ")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(mixing_job.output_file_path):
            logger.warning(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {mixing_job.output_file_path}")
            raise HTTPException(status_code=404, detail="æ··éŸ³æ–‡ä»¶ä¸å­˜åœ¨")
        
        # ç”Ÿæˆå‹å¥½çš„ä¸‹è½½æ–‡ä»¶å
        download_filename = f"ç¯å¢ƒæ··éŸ³_é¡¹ç›®{mixing_job.project_id}_{mixing_job.id}.wav"
        
        return FileResponse(
            mixing_job.output_file_path,
            media_type="audio/wav",
            filename=download_filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä¸‹è½½ç¯å¢ƒæ··éŸ³å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ä¸‹è½½ç¯å¢ƒæ··éŸ³å¤±è´¥: {str(e)}")

@router.delete("/{mixing_id}")
async def delete_mixing(
    mixing_id: int,
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤ç¯å¢ƒæ··éŸ³ä½œå“
    """
    try:
        import os
        
        # ä»æ•°æ®åº“æŸ¥è¯¢æ··éŸ³ä»»åŠ¡
        mixing_job = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.id == mixing_id
        ).first()
        
        if not mixing_job:
            raise HTTPException(status_code=404, detail="æ··éŸ³ä»»åŠ¡ä¸å­˜åœ¨")
        
        logger.info(f"åˆ é™¤ç¯å¢ƒæ··éŸ³ {mixing_id}")
        
        # åˆ é™¤ç›¸å…³çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if mixing_job.output_file_path and os.path.exists(mixing_job.output_file_path):
            try:
                os.remove(mixing_job.output_file_path)
                logger.info(f"å·²åˆ é™¤éŸ³é¢‘æ–‡ä»¶: {mixing_job.output_file_path}")
            except Exception as e:
                logger.warning(f"åˆ é™¤éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
        
        # ä»æ•°æ®åº“åˆ é™¤è®°å½•
        db.delete(mixing_job)
        db.commit()
        
        logger.info(f"ç¯å¢ƒæ··éŸ³ä»»åŠ¡ {mixing_id} åˆ é™¤æˆåŠŸ")
        
        return {
            "success": True,
            "data": {
                "mixing_id": mixing_id,
                "deleted_at": datetime.now().isoformat()
            },
            "message": "ç¯å¢ƒæ··éŸ³ä½œå“åˆ é™¤æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤ç¯å¢ƒæ··éŸ³å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ç¯å¢ƒæ··éŸ³å¤±è´¥: {str(e)}")

@router.get("/{mixing_id}")
async def get_mixing_detail(
    mixing_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç¯å¢ƒæ··éŸ³è¯¦æƒ…
    """
    try:
        # æ¨¡æ‹Ÿæ··éŸ³è¯¦æƒ…
        mixing_detail = {
            "id": mixing_id,
            "project_id": 42,
            "name": f"ç¯å¢ƒæ··éŸ³ {mixing_id}",
            "status": "completed",
            "file_path": f"/storage/mixings/mixing_{mixing_id}.wav",
            "file_url": f"/api/v1/environment/mixing/{mixing_id}/audio",
            "duration": 1800.5,
            "environment_tracks_count": 8,
            "config": {
                "environment_volume": 0.3,
                "fade_duration": 2.0,
                "crossfade_enabled": True
            },
            "tracks": [
                {"name": "æ£®æ—é¸Ÿé¸£", "volume": 0.4, "start_time": 0, "duration": 1800},
                {"name": "æºªæµå£°", "volume": 0.3, "start_time": 300, "duration": 1200},
                {"name": "é£å£°", "volume": 0.2, "start_time": 0, "duration": 1800}
            ],
            "created_at": "2025-06-23T08:30:00",
            "updated_at": "2025-06-23T09:15:00"
        }
        
        return {
            "success": True,
            "data": mixing_detail,
            "message": "ç¯å¢ƒæ··éŸ³è¯¦æƒ…è·å–æˆåŠŸ"
        }
        
    except Exception as e:
        logger.error(f"è·å–ç¯å¢ƒæ··éŸ³è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¯å¢ƒæ··éŸ³è¯¦æƒ…å¤±è´¥: {str(e)}")

@router.get("/{mixing_id}/audio")
async def get_mixing_audio(
    mixing_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç¯å¢ƒæ··éŸ³éŸ³é¢‘æ–‡ä»¶
    ç”¨äºå‰ç«¯æ’­æ”¾
    """
    try:
        from fastapi.responses import FileResponse
        import os
        import wave
        import numpy as np
        
        # ä»æ•°æ®åº“æŸ¥è¯¢çœŸå®çš„æ–‡ä»¶è·¯å¾„
        mixing_job = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.id == mixing_id
        ).first()
        
        if not mixing_job:
            raise HTTPException(status_code=404, detail="æ··éŸ³ä»»åŠ¡ä¸å­˜åœ¨")
        
        if not mixing_job.output_file_path:
            raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶å°šæœªç”Ÿæˆ")
        
        # ğŸ”§ æ™ºèƒ½æ–‡ä»¶æ£€æŸ¥å’Œä¿®å¤
        file_needs_generation = False
        
        if not os.path.exists(mixing_job.output_file_path):
            logger.warning(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ: {mixing_job.output_file_path}")
            file_needs_generation = True
        elif os.path.getsize(mixing_job.output_file_path) < 1000:  # å°äº1KBè®¤ä¸ºæ˜¯æ— æ•ˆæ–‡ä»¶
            logger.warning(f"éŸ³é¢‘æ–‡ä»¶è¿‡å°({os.path.getsize(mixing_job.output_file_path)} bytes)ï¼Œå°†é‡æ–°ç”Ÿæˆ: {mixing_job.output_file_path}")
            file_needs_generation = True
        
        # ğŸµ æ™ºèƒ½ç”ŸæˆéŸ³é¢‘æ–‡ä»¶ï¼ˆæ ¹æ®é…ç½®æ•°æ®ç”Ÿæˆå¯¹åº”éŸ³æ•ˆï¼‰
        if file_needs_generation:
            try:
                import json
                
                os.makedirs(os.path.dirname(mixing_job.output_file_path), exist_ok=True)
                
                # éŸ³é¢‘å‚æ•°
                sample_rate = 44100
                channels = 2
                bit_depth = 16
                duration_seconds = mixing_job.output_duration or 120.0
                
                # è®¡ç®—æ ·æœ¬æ•°
                num_samples = int(sample_rate * duration_seconds)
                
                # åˆå§‹åŒ–ç«‹ä½“å£°éŸ³é¢‘æ•°ç»„
                left_channel = np.zeros(num_samples)
                right_channel = np.zeros(num_samples)
                
                # è§£ææ··éŸ³ä»»åŠ¡çš„é…ç½®æ•°æ®ï¼Œç”Ÿæˆæ™ºèƒ½éŸ³é¢‘
                try:
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šmixing_job.mixing_config åŸå§‹æ•°æ®ç±»å‹: {type(mixing_job.mixing_config)}")
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šmixing_config å‰100å­—ç¬¦: {str(mixing_job.mixing_config)[:100] if mixing_job.mixing_config else 'None'}")
                    
                    # å¤„ç†æ··éŸ³é…ç½®æ•°æ®ï¼šå¯èƒ½æ˜¯å­—å…¸æˆ–JSONå­—ç¬¦ä¸²
                    if isinstance(mixing_job.mixing_config, dict):
                        config_data = mixing_job.mixing_config
                        logger.info("ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šmixing_config æ˜¯å­—å…¸å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨")
                    elif isinstance(mixing_job.mixing_config, str):
                        config_data = json.loads(mixing_job.mixing_config)
                        logger.info("ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šmixing_config æ˜¯JSONå­—ç¬¦ä¸²ï¼Œè§£ææˆåŠŸ")
                    else:
                        config_data = {}
                        logger.warning(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šmixing_config ç±»å‹æœªçŸ¥: {type(mixing_job.mixing_config)}")
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šè§£æåçš„ config_data é”®: {list(config_data.keys())}")
                    
                    environment_config = config_data.get('environment_config', {})
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šenvironment_config é”®: {list(environment_config.keys())}")
                    
                    analysis_result = environment_config.get('analysis_result', {})
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šanalysis_result é”®: {list(analysis_result.keys())}")
                    
                    chapters = analysis_result.get('chapters', [])
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šchapters æ•°é‡: {len(chapters)}")
                    
                    # æå–æ‰€æœ‰ç¯å¢ƒè½¨é“
                    all_tracks = []
                    for i, chapter in enumerate(chapters):
                        logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šç« èŠ‚ {i} é”®: {list(chapter.keys())}")
                        chapter_result = chapter.get('analysis_result', {})
                        logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šç« èŠ‚ {i} analysis_result é”®: {list(chapter_result.keys())}")
                        environment_tracks = chapter_result.get('environment_tracks', [])
                        logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šç« èŠ‚ {i} environment_tracks æ•°é‡: {len(environment_tracks)}")
                        if environment_tracks:
                            logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šç« èŠ‚ {i} ç¬¬ä¸€ä¸ªtrack: {environment_tracks[0]}")
                        all_tracks.extend(environment_tracks)
                    
                    logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šæ€»å…±æ‰¾åˆ° {len(all_tracks)} ä¸ªç¯å¢ƒè½¨é“")
                    for i, track in enumerate(all_tracks):
                        logger.info(f"ğŸ” [æ’­æ”¾] è°ƒè¯•ï¼šè½¨é“ {i} å…³é”®è¯: {track.get('environment_keywords', [])}")
                    
                    logger.info(f"æ™ºèƒ½éŸ³é¢‘ç”Ÿæˆ: æ‰¾åˆ° {len(all_tracks)} ä¸ªç¯å¢ƒè½¨é“")
                    
                    # ä¸ºæ¯ä¸ªè½¨é“ç”Ÿæˆå¯¹åº”çš„éŸ³é¢‘æ•ˆæœ
                    for track in all_tracks:
                        start_time = float(track.get('start_time', 0))
                        track_duration = float(track.get('duration', 5.0))
                        volume = float(track.get('volume', 0.4))
                        keywords = track.get('environment_keywords', [])
                        
                        # è®¡ç®—æ ·æœ¬èŒƒå›´
                        start_sample = int(start_time * sample_rate)
                        end_sample = min(start_sample + int(track_duration * sample_rate), num_samples)
                        
                        if start_sample >= num_samples:
                            continue
                        
                        track_samples = end_sample - start_sample
                        track_time = np.linspace(0, track_duration, track_samples)
                        
                        # ğŸ¨ æ ¹æ®å…³é”®è¯ç”Ÿæˆæ™ºèƒ½éŸ³æ•ˆ
                        track_left = np.zeros(track_samples)
                        track_right = np.zeros(track_samples)
                        
                        # ğŸ¯ ä½¿ç”¨TangoFlux AIç”ŸæˆçœŸå®ç¯å¢ƒéŸ³ï¼ˆæ’­æ”¾æ¨¡å¼ï¼‰
                        logger.info(f"ğŸµ [æ’­æ”¾] è°ƒç”¨TangoFluxç”ŸæˆéŸ³æ•ˆ: {keywords} (æ—¶é•¿: {track_duration:.1f}s)")
                        
                        # æ„å»ºTangoFluxæç¤ºè¯
                        tango_prompt = _build_tangoflux_prompt(keywords, track_duration)
                        
                        # è°ƒç”¨TangoFluxç”ŸæˆéŸ³æ•ˆ
                        try:
                            tangoflux_client = TangoFluxClient()
                            generation_result = tangoflux_client.generate_environment_sound(
                                prompt=tango_prompt,
                                duration=track_duration,
                                steps=50,
                                cfg_scale=3.5,
                                return_type='file'
                            )
                            
                            if generation_result['success']:
                                # æˆåŠŸç”ŸæˆéŸ³æ•ˆ
                                logger.info(f"âœ… [æ’­æ”¾] TangoFluxç”ŸæˆæˆåŠŸ: {tango_prompt[:50]}...")
                                
                                # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºAudioSegment
                                audio_bytes = generation_result['audio_data']
                                generated_audio = AudioSegment.from_wav(io.BytesIO(audio_bytes))
                                
                                # ç¡®ä¿éŸ³é¢‘é•¿åº¦ç¬¦åˆè¦æ±‚
                                if len(generated_audio) > track_duration * 1000:
                                    generated_audio = generated_audio[:int(track_duration * 1000)]
                                elif len(generated_audio) < track_duration * 1000:
                                    # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œå¾ªç¯æ’­æ”¾
                                    loops_needed = int((track_duration * 1000) / len(generated_audio)) + 1
                                    generated_audio = generated_audio * loops_needed
                                    generated_audio = generated_audio[:int(track_duration * 1000)]
                                
                                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                                audio_array = np.array(generated_audio.get_array_of_samples())
                                
                                # å¤„ç†ç«‹ä½“å£°
                                if generated_audio.channels == 2:
                                    # å·²ç»æ˜¯ç«‹ä½“å£°
                                    track_left = audio_array[::2].astype(np.float32) / 32768.0
                                    track_right = audio_array[1::2].astype(np.float32) / 32768.0
                                else:
                                    # å•å£°é“è½¬ç«‹ä½“å£°
                                    audio_mono = audio_array.astype(np.float32) / 32768.0
                                    track_left = audio_mono
                                    track_right = audio_mono * 0.95  # å³å£°é“ç¨å¼±
                                
                                logger.info(f"ğŸ§ [æ’­æ”¾] éŸ³æ•ˆå¤„ç†å®Œæˆ: {len(track_left)} é‡‡æ ·ç‚¹")
                                
                            else:
                                # TangoFluxç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™éŸ³
                                logger.warning(f"âŒ [æ’­æ”¾] TangoFluxç”Ÿæˆå¤±è´¥: {generation_result.get('error', 'Unknown error')}")
                                track_left = np.zeros(track_samples)
                                track_right = np.zeros(track_samples)
                                
                        except Exception as e:
                            logger.error(f"ğŸ”¥ [æ’­æ”¾] TangoFluxè°ƒç”¨å¼‚å¸¸: {str(e)}")
                            # å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨é™éŸ³
                            track_left = np.zeros(track_samples)
                            track_right = np.zeros(track_samples)
                        
                        # åº”ç”¨æ¸å˜å’ŒéŸ³é‡
                        fade_in_samples = int(track.get('fade_in', 1.0) * sample_rate)
                        fade_out_samples = int(track.get('fade_out', 1.0) * sample_rate)
                        
                        if fade_in_samples > 0 and track_samples > fade_in_samples:
                            fade_in_curve = np.linspace(0, 1, min(fade_in_samples, track_samples))
                            track_left[:len(fade_in_curve)] *= fade_in_curve
                            track_right[:len(fade_in_curve)] *= fade_in_curve
                        
                        if fade_out_samples > 0 and track_samples > fade_out_samples:
                            fade_out_curve = np.linspace(1, 0, min(fade_out_samples, track_samples))
                            track_left[-len(fade_out_curve):] *= fade_out_curve
                            track_right[-len(fade_out_curve):] *= fade_out_curve
                        
                        # æ··åˆåˆ°ä¸»è½¨é“
                        track_left *= volume
                        track_right *= volume
                        
                        left_channel[start_sample:end_sample] += track_left
                        right_channel[start_sample:end_sample] += track_right
                        
                        logger.info(f"ç”Ÿæˆæ™ºèƒ½éŸ³æ•ˆ: {keywords} ({start_time:.1f}s-{start_time+track_duration:.1f}s)")
                
                except Exception as parse_error:
                    logger.warning(f"è§£æé…ç½®å¤±è´¥ï¼Œç”Ÿæˆé™éŸ³æ–‡ä»¶: {str(parse_error)}")
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç”Ÿæˆé™éŸ³
                    left_channel = np.zeros(num_samples)
                    right_channel = np.zeros(num_samples)
                
                # æ ‡å‡†åŒ–éŸ³é¢‘
                max_amplitude = max(np.max(np.abs(left_channel)), np.max(np.abs(right_channel)))
                if max_amplitude > 0.8:
                    normalize_factor = 0.8 / max_amplitude
                    left_channel *= normalize_factor
                    right_channel *= normalize_factor
                
                # ç»„åˆåŒå£°é“éŸ³é¢‘
                audio_data = np.column_stack((left_channel, right_channel))
                
                # è½¬æ¢ä¸º16ä½æ•´æ•°
                audio_data = (audio_data * 32767).astype(np.int16)
                
                # ä¿å­˜ä¸ºWAVæ–‡ä»¶
                with wave.open(mixing_job.output_file_path, 'wb') as wav_file:
                    wav_file.setnchannels(channels)
                    wav_file.setsampwidth(bit_depth // 8)
                    wav_file.setframerate(sample_rate)
                    wav_file.writeframes(audio_data.tobytes())
                
                # æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(mixing_job.output_file_path)
                mixing_job.file_size = file_size
                db.commit()
                
                logger.info(f"âœ… æ™ºèƒ½ç¯å¢ƒæ··éŸ³éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {mixing_job.output_file_path} ({file_size:,} bytes, {duration_seconds}ç§’)")
                
            except Exception as gen_error:
                logger.error(f"ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(gen_error)}")
                raise HTTPException(status_code=500, detail=f"ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(gen_error)}")
        
        # è·å–æ–‡ä»¶åç”¨äºä¸‹è½½
        filename = os.path.basename(mixing_job.output_file_path)
        
        return FileResponse(
            mixing_job.output_file_path,
            media_type="audio/wav",
            headers={
                "Accept-Ranges": "bytes",
                "Content-Disposition": f"inline; filename={filename}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ç¯å¢ƒæ··éŸ³éŸ³é¢‘å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¯å¢ƒæ··éŸ³éŸ³é¢‘å¤±è´¥: {str(e)}") 


async def process_environment_mixing(mixing_job_id: int):
    """
    åå°å¤„ç†ç¯å¢ƒæ··éŸ³ä»»åŠ¡
    """
    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
    from app.database import SessionLocal
    db = SessionLocal()
    
    try:
        # è·å–ä»»åŠ¡
        mixing_job = db.query(EnvironmentAudioMixingJob).filter(
            EnvironmentAudioMixingJob.id == mixing_job_id
        ).first()
        
        if not mixing_job:
            logger.error(f"æ··éŸ³ä»»åŠ¡ä¸å­˜åœ¨: {mixing_job_id}")
            return
        
        # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
        mixing_job.job_status = 'running'
        mixing_job.progress = 10.0
        db.commit()
        
        logger.info(f"å¼€å§‹å¤„ç†ç¯å¢ƒæ··éŸ³ä»»åŠ¡: {mixing_job_id}")
        
        # æ¨¡æ‹Ÿæ··éŸ³è¿‡ç¨‹
        import asyncio
        import os
        
        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
        for progress in [20, 40, 60, 80, 95]:
            await asyncio.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            mixing_job.progress = progress
            db.commit()
            logger.info(f"æ··éŸ³ä»»åŠ¡ {mixing_job_id} è¿›åº¦: {progress}%")
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_dir = "storage/audio/environment_mixings"
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"mixing_{mixing_job.project_id}_{mixing_job.id}.wav"
        output_file_path = os.path.join(output_dir, output_filename)
        
        # ğŸµ æ ¹æ®åˆ†æç»“æœç”Ÿæˆæ™ºèƒ½ç¯å¢ƒæ··éŸ³éŸ³é¢‘æ–‡ä»¶
        try:
            import wave
            import numpy as np
            import json
            
            # éŸ³é¢‘å‚æ•°
            sample_rate = 44100
            channels = 2
            bit_depth = 16
            duration_seconds = float(mixing_job.output_duration or 120.0)
            
            logger.info(f"ç”Ÿæˆç¯å¢ƒæ··éŸ³éŸ³é¢‘æ–‡ä»¶: {output_file_path} ({duration_seconds}ç§’)")
            
            # è®¡ç®—æ ·æœ¬æ•°
            num_samples = int(sample_rate * duration_seconds)
            
            # åˆå§‹åŒ–ç«‹ä½“å£°éŸ³é¢‘æ•°ç»„
            left_channel = np.zeros(num_samples)
            right_channel = np.zeros(num_samples)
            
            # è§£ææ··éŸ³ä»»åŠ¡çš„é…ç½®æ•°æ®ï¼Œè·å–ç¯å¢ƒè½¨é“ä¿¡æ¯
            try:
                logger.info(f"ğŸ” è°ƒè¯•ï¼šmixing_job.mixing_config åŸå§‹æ•°æ®ç±»å‹: {type(mixing_job.mixing_config)}")
                logger.info(f"ğŸ” è°ƒè¯•ï¼šmixing_config å‰100å­—ç¬¦: {str(mixing_job.mixing_config)[:100] if mixing_job.mixing_config else 'None'}")
                
                # å¤„ç†æ··éŸ³é…ç½®æ•°æ®ï¼šå¯èƒ½æ˜¯å­—å…¸æˆ–JSONå­—ç¬¦ä¸²
                if isinstance(mixing_job.mixing_config, dict):
                    config_data = mixing_job.mixing_config
                    logger.info("ğŸ” è°ƒè¯•ï¼šmixing_config æ˜¯å­—å…¸å¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨")
                elif isinstance(mixing_job.mixing_config, str):
                    config_data = json.loads(mixing_job.mixing_config)
                    logger.info("ğŸ” è°ƒè¯•ï¼šmixing_config æ˜¯JSONå­—ç¬¦ä¸²ï¼Œè§£ææˆåŠŸ")
                else:
                    config_data = {}
                    logger.warning(f"ğŸ” è°ƒè¯•ï¼šmixing_config ç±»å‹æœªçŸ¥: {type(mixing_job.mixing_config)}")
                logger.info(f"ğŸ” è°ƒè¯•ï¼šè§£æåçš„ config_data é”®: {list(config_data.keys())}")
                
                environment_config = config_data.get('environment_config', {})
                logger.info(f"ğŸ” è°ƒè¯•ï¼šenvironment_config é”®: {list(environment_config.keys())}")
                
                analysis_result = environment_config.get('analysis_result', {})
                logger.info(f"ğŸ” è°ƒè¯•ï¼šanalysis_result é”®: {list(analysis_result.keys())}")
                
                chapters = analysis_result.get('chapters', [])
                logger.info(f"ğŸ” è°ƒè¯•ï¼šchapters æ•°é‡: {len(chapters)}")
                
                # æå–æ‰€æœ‰ç¯å¢ƒè½¨é“
                all_tracks = []
                for i, chapter in enumerate(chapters):
                    logger.info(f"ğŸ” è°ƒè¯•ï¼šç« èŠ‚ {i} é”®: {list(chapter.keys())}")
                    chapter_result = chapter.get('analysis_result', {})
                    logger.info(f"ğŸ” è°ƒè¯•ï¼šç« èŠ‚ {i} analysis_result é”®: {list(chapter_result.keys())}")
                    environment_tracks = chapter_result.get('environment_tracks', [])
                    logger.info(f"ğŸ” è°ƒè¯•ï¼šç« èŠ‚ {i} environment_tracks æ•°é‡: {len(environment_tracks)}")
                    if environment_tracks:
                        logger.info(f"ğŸ” è°ƒè¯•ï¼šç« èŠ‚ {i} ç¬¬ä¸€ä¸ªtrack: {environment_tracks[0]}")
                    all_tracks.extend(environment_tracks)
                
                logger.info(f"ğŸ” è°ƒè¯•ï¼šæ€»å…±æ‰¾åˆ° {len(all_tracks)} ä¸ªç¯å¢ƒè½¨é“")
                for i, track in enumerate(all_tracks):
                    logger.info(f"ğŸ” è°ƒè¯•ï¼šè½¨é“ {i} å…³é”®è¯: {track.get('environment_keywords', [])}")
                
                logger.info(f"æ‰¾åˆ° {len(all_tracks)} ä¸ªç¯å¢ƒè½¨é“è¿›è¡ŒéŸ³é¢‘ç”Ÿæˆ")
                
                # ä¸ºæ¯ä¸ªè½¨é“ç”Ÿæˆå¯¹åº”çš„éŸ³é¢‘æ•ˆæœ
                for track_idx, track in enumerate(all_tracks):
                    try:
                        start_time = float(track.get('start_time', 0))
                        track_duration = float(track.get('duration', 5.0))
                        volume = float(track.get('volume', 0.4))
                        keywords = track.get('environment_keywords', [])
                        scene_desc = track.get('scene_description', '')
                        
                        # è®¡ç®—æ ·æœ¬èŒƒå›´
                        start_sample = int(start_time * sample_rate)
                        end_sample = min(start_sample + int(track_duration * sample_rate), num_samples)
                        
                        if start_sample >= num_samples:
                            logger.info(f"â­ï¸ è·³è¿‡è½¨é“ {track_idx}: å¼€å§‹æ—¶é—´è¶…å‡ºèŒƒå›´")
                            continue
                        
                        track_samples = end_sample - start_sample
                        track_time = np.linspace(0, track_duration, track_samples)
                        
                        # ğŸ¨ æ ¹æ®å…³é”®è¯ç”Ÿæˆä¸åŒçš„éŸ³é¢‘æ•ˆæœ
                        track_left = np.zeros(track_samples)
                        track_right = np.zeros(track_samples)
                        
                        logger.info(f"ğŸµ å¤„ç†è½¨é“ {track_idx}: {keywords} ({start_time:.1f}s-{start_time+track_duration:.1f}s)")
                    except Exception as track_prep_error:
                        logger.error(f"ğŸ”¥ è½¨é“ {track_idx} å‡†å¤‡å¤±è´¥: {str(track_prep_error)}")
                        continue
                    
                    # ğŸ¯ ä½¿ç”¨TangoFlux AIç”ŸæˆçœŸå®ç¯å¢ƒéŸ³
                    try:
                        logger.info(f"ğŸµ è°ƒç”¨TangoFluxç”ŸæˆéŸ³æ•ˆ: {keywords} (æ—¶é•¿: {track_duration:.1f}s)")
                        
                        # æ„å»ºTangoFluxæç¤ºè¯
                        tango_prompt = _build_tangoflux_prompt(keywords, track_duration)
                        
                        # è°ƒç”¨TangoFluxç”ŸæˆéŸ³æ•ˆ
                        try:
                            tangoflux_client = TangoFluxClient()
                            generation_result = tangoflux_client.generate_environment_sound(
                                prompt=tango_prompt,
                                duration=track_duration,
                                steps=50,
                                cfg_scale=3.5,
                                return_type='file'
                            )
                            
                            if generation_result['success']:
                                # æˆåŠŸç”ŸæˆéŸ³æ•ˆ
                                logger.info(f"âœ… TangoFluxç”ŸæˆæˆåŠŸ: {tango_prompt[:50]}...")
                                
                                # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºAudioSegment
                                audio_bytes = generation_result['audio_data']
                                generated_audio = AudioSegment.from_wav(io.BytesIO(audio_bytes))
                                
                                # ç¡®ä¿éŸ³é¢‘é•¿åº¦ç¬¦åˆè¦æ±‚
                                if len(generated_audio) > track_duration * 1000:
                                    generated_audio = generated_audio[:int(track_duration * 1000)]
                                elif len(generated_audio) < track_duration * 1000:
                                    # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œå¾ªç¯æ’­æ”¾
                                    loops_needed = int((track_duration * 1000) / len(generated_audio)) + 1
                                    generated_audio = generated_audio * loops_needed
                                    generated_audio = generated_audio[:int(track_duration * 1000)]
                                
                                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                                audio_array = np.array(generated_audio.get_array_of_samples())
                                
                                # å¤„ç†ç«‹ä½“å£°
                                if generated_audio.channels == 2:
                                    # å·²ç»æ˜¯ç«‹ä½“å£°
                                    track_left = audio_array[::2].astype(np.float32) / 32768.0
                                    track_right = audio_array[1::2].astype(np.float32) / 32768.0
                                else:
                                    # å•å£°é“è½¬ç«‹ä½“å£°
                                    audio_mono = audio_array.astype(np.float32) / 32768.0
                                    track_left = audio_mono
                                    track_right = audio_mono * 0.95  # å³å£°é“ç¨å¼±
                                
                                # ğŸ”§ ç¡®ä¿éŸ³é¢‘é•¿åº¦å®Œå…¨åŒ¹é…é¢„æœŸçš„è½¨é“é•¿åº¦
                                if len(track_left) > track_samples:
                                    # éŸ³é¢‘å¤ªé•¿ï¼Œæˆªå–åˆ°æ­£ç¡®é•¿åº¦
                                    track_left = track_left[:track_samples]
                                    track_right = track_right[:track_samples]
                                    logger.info(f"ğŸ”§ éŸ³é¢‘æˆªå–: {len(track_left)} -> {track_samples} é‡‡æ ·ç‚¹")
                                elif len(track_left) < track_samples:
                                    # éŸ³é¢‘å¤ªçŸ­ï¼Œç”¨é™éŸ³å¡«å……
                                    padding_left = np.zeros(track_samples - len(track_left))
                                    padding_right = np.zeros(track_samples - len(track_right))
                                    track_left = np.concatenate([track_left, padding_left])
                                    track_right = np.concatenate([track_right, padding_right])
                                    logger.info(f"ğŸ”§ éŸ³é¢‘å¡«å……: {len(track_left) - len(padding_left)} -> {track_samples} é‡‡æ ·ç‚¹")
                                
                                logger.info(f"ğŸ§ éŸ³æ•ˆå¤„ç†å®Œæˆ: {len(track_left)} é‡‡æ ·ç‚¹ (åŒ¹é… {track_samples})")
                                
                            else:
                                # TangoFluxç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é™éŸ³
                                logger.warning(f"âŒ TangoFluxç”Ÿæˆå¤±è´¥: {generation_result.get('error', 'Unknown error')}")
                                track_left = np.zeros(track_samples)
                                track_right = np.zeros(track_samples)
                                
                        except Exception as e:
                            logger.error(f"ğŸ”¥ TangoFluxè°ƒç”¨å¼‚å¸¸: {str(e)}")
                            # å¼‚å¸¸æƒ…å†µä¸‹ä½¿ç”¨é™éŸ³
                            track_left = np.zeros(track_samples)
                            track_right = np.zeros(track_samples)
                        
                        # ğŸšï¸ åº”ç”¨éŸ³é‡å’Œæ¸å˜æ•ˆæœï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥éƒ½è¦å¤„ç†ï¼‰
                        fade_in_samples = int(track.get('fade_in', 1.0) * sample_rate)
                        fade_out_samples = int(track.get('fade_out', 1.0) * sample_rate)
                        
                        # æ¸å…¥æ•ˆæœ
                        if fade_in_samples > 0 and track_samples > fade_in_samples:
                            fade_in_curve = np.linspace(0, 1, min(fade_in_samples, track_samples))
                            track_left[:len(fade_in_curve)] *= fade_in_curve
                            track_right[:len(fade_in_curve)] *= fade_in_curve
                        
                        # æ¸å‡ºæ•ˆæœ
                        if fade_out_samples > 0 and track_samples > fade_out_samples:
                            fade_out_curve = np.linspace(1, 0, min(fade_out_samples, track_samples))
                            track_left[-len(fade_out_curve):] *= fade_out_curve
                            track_right[-len(fade_out_curve):] *= fade_out_curve
                        
                        # åº”ç”¨éŸ³é‡å¹¶æ··åˆåˆ°ä¸»è½¨é“
                        track_left *= volume
                        track_right *= volume
                        
                        # ğŸ”§ ç¡®ä¿æ•°ç»„é•¿åº¦åŒ¹é…ï¼Œè¿›è¡Œæœ€ç»ˆæ··åˆ
                        if len(track_left) == len(left_channel[start_sample:end_sample]):
                            left_channel[start_sample:end_sample] += track_left
                            right_channel[start_sample:end_sample] += track_right
                            logger.info(f"âœ… è½¨é“ {track_idx} æ··åˆæˆåŠŸ: {keywords} ({start_time:.1f}s-{start_time+track_duration:.1f}s, éŸ³é‡:{volume})")
                        else:
                            logger.warning(f"âš ï¸ è½¨é“ {track_idx} é•¿åº¦ä¸åŒ¹é…: {len(track_left)} vs {len(left_channel[start_sample:end_sample])}")
                            
                    except Exception as track_error:
                        logger.error(f"ğŸ”¥ è½¨é“ {track_idx} éŸ³é¢‘å¤„ç†å¤±è´¥: {str(track_error)}")
                        continue
                
                logger.info(f"ğŸµ æ‰€æœ‰è½¨é“å¤„ç†å®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆæœ€ç»ˆéŸ³é¢‘æ–‡ä»¶")
            
            except Exception as parse_error:
                logger.warning(f"è§£ææ··éŸ³é…ç½®å¤±è´¥ï¼Œå°†ç”Ÿæˆé™éŸ³æ–‡ä»¶: {str(parse_error)}")
                # å¦‚æœè§£æå¤±è´¥ï¼Œç”Ÿæˆé™éŸ³
                left_channel = np.zeros(num_samples)
                right_channel = np.zeros(num_samples)
            
            # æ ‡å‡†åŒ–éŸ³é¢‘é˜²æ­¢å‰Šæ³¢
            max_amplitude = max(np.max(np.abs(left_channel)), np.max(np.abs(right_channel)))
            if max_amplitude > 0.8:
                normalize_factor = 0.8 / max_amplitude
                left_channel *= normalize_factor
                right_channel *= normalize_factor
                logger.info(f"éŸ³é¢‘æ ‡å‡†åŒ–ï¼Œç¼©æ”¾å› å­: {normalize_factor:.3f}")
            
            # ç»„åˆåŒå£°é“éŸ³é¢‘
            audio_data = np.column_stack((left_channel, right_channel))
            
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            audio_data = (audio_data * 32767).astype(np.int16)
            
            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            with wave.open(output_file_path, 'wb') as wav_file:
                wav_file.setnchannels(channels)
                wav_file.setsampwidth(bit_depth // 8)
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(audio_data.tobytes())
            
            logger.info(f"âœ… æ™ºèƒ½ç¯å¢ƒæ··éŸ³éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {output_file_path}")
            
        except Exception as audio_error:
            logger.error(f"ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(audio_error)}")
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„é™éŸ³æ–‡ä»¶
            import wave
            with wave.open(output_file_path, 'wb') as wav_file:
                wav_file.setnchannels(2)
                wav_file.setsampwidth(2)
                wav_file.setframerate(44100)
                # å†™å…¥é™éŸ³
                silent_data = b'\x00' * (44100 * 2 * 2 * int(duration_seconds))
                wav_file.writeframes(silent_data)
            logger.info(f"å·²ç”Ÿæˆé™éŸ³æ›¿ä»£æ–‡ä»¶: {output_file_path}")
        
        # æ›´æ–°ä»»åŠ¡å®ŒæˆçŠ¶æ€
        mixing_job.job_status = 'completed'
        mixing_job.progress = 100.0
        mixing_job.output_file_path = output_file_path
        mixing_job.output_duration = 120.0  # æ¨¡æ‹Ÿ2åˆ†é’ŸéŸ³é¢‘
        mixing_job.file_size = os.path.getsize(output_file_path)
        mixing_job.completed_at = datetime.now()
        mixing_job.completed_tracks = mixing_job.total_tracks
        
        db.commit()
        logger.info(f"ç¯å¢ƒæ··éŸ³ä»»åŠ¡å®Œæˆ: {mixing_job_id}, æ–‡ä»¶: {output_file_path}")
        
    except Exception as e:
        logger.error(f"å¤„ç†ç¯å¢ƒæ··éŸ³ä»»åŠ¡å¤±è´¥: {mixing_job_id}, é”™è¯¯: {str(e)}")
        
        # æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€
        try:
            mixing_job = db.query(EnvironmentAudioMixingJob).filter(
                EnvironmentAudioMixingJob.id == mixing_job_id
            ).first()
            if mixing_job:
                mixing_job.job_status = 'failed'
                mixing_job.error_message = str(e)
                mixing_job.completed_at = datetime.now()
                db.commit()
        except Exception as inner_e:
            logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {inner_e}")
    
    finally:
        db.close()