"""
ä¹¦ç±ç®¡ç†API
æä¾›ä¹¦ç±ä¸Šä¼ ã€ç« èŠ‚æ£€æµ‹ã€ç»“æ„åŒ–å¤„ç†ç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, Query
from sqlalchemy.orm import Session
from sqlalchemy.orm.attributes import flag_modified
from sqlalchemy import desc, asc, func, or_, and_
from typing import List, Optional, Dict, Any
import asyncio
import logging
import json
import re
from datetime import datetime
from pydantic import BaseModel

from app.database import get_db
from app.models import Book, BookChapter, AnalysisResult

# æ³¨æ„ï¼šPUTç«¯ç‚¹ç°åœ¨ä½¿ç”¨Formå‚æ•°è€Œä¸æ˜¯JSONè¯·æ±‚

router = APIRouter(prefix="/books")

logger = logging.getLogger(__name__)


def detect_chapters_from_content(content: str) -> List[dict]:
    """
    ä»ä¹¦ç±å†…å®¹ä¸­æ£€æµ‹ç« èŠ‚
    è¿”å›ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å«ï¼štitle, content, word_count
    """
    if not content or not content.strip():
        return []
    
    chapters = []
    lines = content.split('\n')
    current_chapter = None
    chapter_content = []
    chapter_number = 0
    
    # ç« èŠ‚æ ‡é¢˜æ£€æµ‹æ¨¡å¼
    chapter_patterns = [
        r'^#{1,6}\s+',  # Markdownæ ‡é¢˜ # ## ### ç­‰
        r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ç« èŠ‚å›]',  # ç¬¬ä¸€ç« ã€ç¬¬1ç« ã€ç¬¬ä¸€èŠ‚ç­‰
        r'^Chapter\s+\d+',  # Chapter 1
        r'^\d+\.',  # 1.
        r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',  # ä¸€ã€äºŒã€ä¸‰ã€
        r'^ã€.*?ã€‘',  # ã€ç« èŠ‚æ ‡é¢˜ã€‘
        r'^ï¼ˆç¬¬.*?ï¼‰',  # ï¼ˆç¬¬ä¸€ç« ï¼‰
    ]
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ£€æµ‹æ˜¯å¦ä¸ºç« èŠ‚æ ‡é¢˜
        is_chapter_title = False
        for pattern in chapter_patterns:
            if re.match(pattern, line):
                is_chapter_title = True
                break
        
        if is_chapter_title:
            # ä¿å­˜ä¸Šä¸€ç« èŠ‚
            if current_chapter and chapter_content:
                chapter_text = '\n'.join(chapter_content)
                if chapter_text.strip():  # ç¡®ä¿ç« èŠ‚å†…å®¹ä¸ä¸ºç©º
                    chapters.append({
                        'number': chapter_number,
                        'title': current_chapter,
                        'content': chapter_text,
                        'word_count': len(chapter_text.replace(' ', '').replace('\n', ''))
                    })
            
            # å¼€å§‹æ–°ç« èŠ‚
            chapter_number += 1
            current_chapter = line
            chapter_content = []
        else:
            chapter_content.append(line)
    
    # ä¿å­˜æœ€åä¸€ç« 
    if current_chapter and chapter_content:
        chapter_text = '\n'.join(chapter_content)
        if chapter_text.strip():
            chapters.append({
                'number': chapter_number,
                'title': current_chapter,
                'content': chapter_text,
                'word_count': len(chapter_text.replace(' ', '').replace('\n', ''))
            })
    
    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç« èŠ‚ï¼Œå°†æ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªç« èŠ‚
    if not chapters and content.strip():
        chapters.append({
            'number': 1,
            'title': 'å…¨æ–‡',
            'content': content.strip(),
            'word_count': len(content.replace(' ', '').replace('\n', ''))
        })
    
    return chapters


@router.post("")
async def upload_book(
    title: str = Form(...),
    author: Optional[str] = Form(""),
    description: Optional[str] = Form(""),
    content: Optional[str] = Form(""),
    tags: Optional[str] = Form("[]"),
    text_file: Optional[UploadFile] = File(None),
    auto_detect_chapters: bool = Form(True),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºä¹¦ç±è®°å½•
    - æ”¯æŒç›´æ¥æ–‡æœ¬å†…å®¹æˆ–æ–‡ä»¶ä¸Šä¼ 
    - æ”¯æŒtxtã€docxç­‰æ ¼å¼æ–‡ä»¶
    - å¯é€‰æ‹©è‡ªåŠ¨æ£€æµ‹ç« èŠ‚
    """
    try:
        # è§£ææ ‡ç­¾
        try:
            import json
            parsed_tags = json.loads(tags) if tags else []
        except json.JSONDecodeError:
            parsed_tags = []
        
        # è·å–ä¹¦ç±å†…å®¹
        book_content = ""
        if text_file and text_file.filename:
            # ä»æ–‡ä»¶è¯»å–å†…å®¹
            file_content = await text_file.read()
            try:
                book_content = file_content.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    book_content = file_content.decode('gbk')
                except UnicodeDecodeError:
                    raise HTTPException(status_code=400, detail="æ–‡ä»¶ç¼–ç æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨UTF-8æˆ–GBKç¼–ç ")
        elif content:
            # ä½¿ç”¨ç›´æ¥ä¼ å…¥çš„æ–‡æœ¬å†…å®¹
            book_content = content
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›æ–‡æœ¬å†…å®¹æˆ–ä¸Šä¼ æ–‡ä»¶")
        
        # åˆ›å»ºä¹¦ç±è®°å½•
        new_book = Book(
            title=title,
            author=author or "",
            description=description or "",
            content=book_content,
            tags=json.dumps(parsed_tags, ensure_ascii=False),
            status='draft',
            word_count=len(book_content),
            chapter_count=0
        )
        
        db.add(new_book)
        db.commit()
        db.refresh(new_book)
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨ç« èŠ‚æ£€æµ‹ä¸”å†…å®¹ä¸ä¸ºç©º
        if auto_detect_chapters and book_content.strip():
            try:
                # æ£€æµ‹ç« èŠ‚
                chapters_data = detect_chapters_from_content(book_content)
                
                # ä¿å­˜ç« èŠ‚åˆ°æ•°æ®åº“
                for chapter_data in chapters_data:
                    chapter = BookChapter(
                        book_id=new_book.id,
                        chapter_number=chapter_data['number'],
                        chapter_title=chapter_data['title'],
                        content=chapter_data['content'],
                        word_count=chapter_data['word_count'],
                        analysis_status='pending',
                        synthesis_status='pending',
                        created_at=datetime.utcnow(),
                        updated_at=datetime.utcnow()
                    )
                    db.add(chapter)
                
                # æ›´æ–°ä¹¦ç±çš„ç« èŠ‚æ•°
                new_book.chapter_count = len(chapters_data)
                db.commit()
                
                logger.info(f"ä¹¦ç± '{title}' è‡ªåŠ¨æ£€æµ‹åˆ° {len(chapters_data)} ä¸ªç« èŠ‚")
                
            except Exception as e:
                logger.error(f"ç« èŠ‚æ£€æµ‹å¤±è´¥: {str(e)}")
                # ç« èŠ‚æ£€æµ‹å¤±è´¥ä¸å½±å“ä¹¦ç±åˆ›å»º
        
        return {
            "success": True,
            "data": new_book.to_dict(),
            "message": f"ä¹¦ç±åˆ›å»ºæˆåŠŸï¼Œæ£€æµ‹åˆ° {new_book.chapter_count} ä¸ªç« èŠ‚"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ›å»ºä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¹¦ç±å¤±è´¥: {str(e)}")


@router.get("")
async def get_books(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    search: str = Query("", description="æœç´¢å…³é”®è¯"),
    author: str = Query("", description="ä½œè€…è¿‡æ»¤"),
    status: str = Query("", description="çŠ¶æ€è¿‡æ»¤"),
    sort_by: str = Query("created_at", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘"),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±åˆ—è¡¨
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    - æ”¯æŒæ ‡é¢˜å’Œä½œè€…æœç´¢
    """
    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(Book)
        
        # æœç´¢è¿‡æ»¤
        if search:
            search_pattern = f"%{search}%"
            query = query.filter(
                or_(
                    Book.title.like(search_pattern),
                    Book.author.like(search_pattern),
                    Book.description.like(search_pattern)
                )
            )
        
        # ä½œè€…è¿‡æ»¤
        if author:
            query = query.filter(Book.author.like(f"%{author}%"))
        
        # çŠ¶æ€è¿‡æ»¤
        if status:
            query = query.filter(Book.status == status)
        
        # æ’åº
        sort_field = getattr(Book, sort_by, Book.created_at)
        if sort_order == "asc":
            query = query.order_by(asc(sort_field))
        else:
            query = query.order_by(desc(sort_field))
        
        # ç»Ÿè®¡æ€»æ•°
        total = query.count()
        
        # åˆ†é¡µ
        offset = (page - 1) * page_size
        books = query.offset(offset).limit(page_size).all()
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        book_list = [book.to_dict() for book in books]
        
        # åˆ†é¡µä¿¡æ¯
        total_pages = (total + page_size - 1) // page_size
        
        return {
            "success": True,
            "data": book_list,
            "pagination": {
                "page": page,
                "pageSize": page_size,
                "total": total,
                "totalPages": total_pages,
                "hasMore": page < total_pages
            },
            "filters": {
                "search": search,
                "author": author,
                "status": status
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¹¦ç±åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/{book_id}")
async def get_book(book_id: int, db: Session = Depends(get_db)):
    """è·å–ä¹¦ç±è¯¦æƒ…"""
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": book.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¹¦ç±è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.post("/{book_id}/detect-chapters")
async def detect_chapters(
    book_id: int,
    force_reprocess: bool = False,
    detection_config: Optional[dict] = None,
    db: Session = Depends(get_db)
):
    """
    æ£€æµ‹ä¹¦ç±ç« èŠ‚ç»“æ„
    - æ”¯æŒå¼ºåˆ¶é‡æ–°å¤„ç†
    - æ”¯æŒè‡ªå®šä¹‰æ£€æµ‹é…ç½®
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail=f"ä¹¦ç± ID {book_id} ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç« èŠ‚æ•°æ®
        existing_chapters = db.query(BookChapter).filter(BookChapter.book_id == book_id).count()
        if existing_chapters > 0 and not force_reprocess:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¹¦ç±å·²æœ‰ {existing_chapters} ä¸ªç« èŠ‚ï¼Œä½¿ç”¨ force_reprocess=true å¼ºåˆ¶é‡æ–°å¤„ç†"
            )
        
        # å¦‚æœå¼ºåˆ¶é‡æ–°å¤„ç†ï¼Œåˆ é™¤ç°æœ‰ç« èŠ‚
        if force_reprocess and existing_chapters > 0:
            db.query(BookChapter).filter(BookChapter.book_id == book_id).delete()
            db.commit()
        
        # æ£€æµ‹ç« èŠ‚
        chapters_data = detect_chapters_from_content(book.content or "")
        
        if not chapters_data:
            raise HTTPException(status_code=400, detail="æœªæ£€æµ‹åˆ°æœ‰æ•ˆç« èŠ‚")
        
        # ä¿å­˜ç« èŠ‚åˆ°æ•°æ®åº“
        for chapter_data in chapters_data:
            chapter = BookChapter(
                book_id=book_id,
                chapter_number=chapter_data['number'],
                chapter_title=chapter_data['title'],
                content=chapter_data['content'],
                word_count=chapter_data['word_count'],
                analysis_status='pending',
                synthesis_status='pending',
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow()
            )
            db.add(chapter)
        
        # æ›´æ–°ä¹¦ç±ä¿¡æ¯
        book.chapter_count = len(chapters_data)
        db.commit()
        
        return {
            "success": True,
            "message": f"ç« èŠ‚æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(chapters_data)} ä¸ªç« èŠ‚",
            "chapters_found": len(chapters_data),
            "book_id": book_id,
            "chapters": [
                {
                    "number": ch['number'],
                    "title": ch['title'],
                    "word_count": ch['word_count']
                }
                for ch in chapters_data
            ]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç« èŠ‚æ£€æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç« èŠ‚æ£€æµ‹å¤±è´¥: {str(e)}")


@router.get("/{book_id}/chapters")
def get_book_chapters(
    book_id: int,
    skip: int = 0,
    limit: int = 50,
    status_filter: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±ç« èŠ‚åˆ—è¡¨
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    - æ”¯æŒçŠ¶æ€ç­›é€‰
    """
    # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    query = db.query(BookChapter).filter(BookChapter.book_id == book_id)
    
    if status_filter:
        query = query.filter(BookChapter.analysis_status == status_filter)
    
    chapters = query.order_by(BookChapter.chapter_number).offset(skip).limit(limit).all()
    
    return {
        "success": True,
        "data": [chapter.to_dict() for chapter in chapters]
    }


@router.get("/{book_id}/structure-status")
def get_structure_status(book_id: int, db: Session = Depends(get_db)):
    """
    è·å–ä¹¦ç±ç»“æ„åŒ–å¤„ç†çŠ¶æ€
    """
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    # ç»Ÿè®¡ç« èŠ‚çŠ¶æ€
    chapter_stats = db.query(BookChapter.analysis_status, 
                           db.func.count(BookChapter.id).label('count')) \
                     .filter(BookChapter.book_id == book_id) \
                     .group_by(BookChapter.analysis_status) \
                     .all()
    
    status_counts = {stat.analysis_status: stat.count for stat in chapter_stats}
    
    return {
        "book_id": book_id,
        "structure_detected": book.structure_detected,
        "total_chapters": book.total_chapters,
        "total_words": book.total_words,
        "chapter_status_counts": status_counts,
        "detection_config": book.chapter_detection_config
    }


@router.delete("/{book_id}")
def delete_book(book_id: int, db: Session = Depends(get_db)):
    """åˆ é™¤ä¹¦ç±åŠå…¶æ‰€æœ‰ç›¸å…³æ•°æ®"""
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    # åˆ é™¤ä¹¦ç±ï¼ˆçº§è”åˆ é™¤ç« èŠ‚ï¼‰
    db.delete(book)
    db.commit()
    
    return {"message": f"ä¹¦ç± '{book.title}' å·²åˆ é™¤"}


@router.put("/{book_id}")
async def update_book_put(
    book_id: int,
    title: Optional[str] = Form(None),
    author: Optional[str] = Form(None),
    description: Optional[str] = Form(None),
    content: Optional[str] = Form(None),
    tags: Optional[str] = Form(None),
    status: Optional[str] = Form(None),
    db: Session = Depends(get_db)
):
    """å®Œæ•´æ›´æ–°ä¹¦ç±ä¿¡æ¯ (PUTæ–¹æ³•) - æ”¯æŒFormæ ¼å¼"""
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ›´æ–°æä¾›çš„å­—æ®µ
        if title is not None:
            if not title.strip():
                raise HTTPException(status_code=400, detail="ä¹¦ç±æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
            book.title = title.strip()
        
        if author is not None:
            book.author = author.strip()
        
        if description is not None:
            book.description = description.strip()
        
        if content is not None:
            book.content = content
            book.word_count = len(content)
        
        if tags is not None:
            try:
                parsed_tags = json.loads(tags) if tags else []
                book.tags = json.dumps(parsed_tags, ensure_ascii=False)
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="æ ‡ç­¾æ ¼å¼é”™è¯¯")
        
        if status is not None:
            if status not in ['draft', 'published', 'archived']:
                raise HTTPException(status_code=400, detail="æ— æ•ˆçš„çŠ¶æ€å€¼")
            book.status = status
        
        db.commit()
        db.refresh(book)
        
        return {
            "success": True,
            "data": book.to_dict()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°ä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ä¹¦ç±å¤±è´¥: {str(e)}")


@router.patch("/{book_id}")
def update_book_patch(
    book_id: int,
    title: Optional[str] = None,
    author: Optional[str] = None,
    description: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """éƒ¨åˆ†æ›´æ–°ä¹¦ç±ä¿¡æ¯ (PATCHæ–¹æ³•)"""
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    if title is not None:
        book.title = title
    if author is not None:
        book.author = author
    if description is not None:
        book.description = description
    
    db.commit()
    db.refresh(book)
    
    return {
        "success": True,
        "data": book.to_dict()
    } 


@router.get("/{book_id}/analysis-results")
async def get_book_analysis_results(
    book_id: int,
    chapter_ids: Optional[str] = Query(None, description="é€—å·åˆ†éš”çš„ç« èŠ‚IDåˆ—è¡¨"),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±çš„æ‰€æœ‰æ™ºèƒ½å‡†å¤‡ç»“æœ
    ç”¨äºåˆæˆä¸­å¿ƒåŠ è½½å·²å®Œæˆçš„åˆ†ææ•°æ®
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = db.query(BookChapter, AnalysisResult).join(
            AnalysisResult, BookChapter.id == AnalysisResult.chapter_id, isouter=True
        ).filter(
            BookChapter.book_id == book_id
        )
        
        # å¦‚æœæŒ‡å®šäº†ç« èŠ‚IDï¼Œåˆ™åªæŸ¥è¯¢è¿™äº›ç« èŠ‚
        if chapter_ids:
            try:
                chapter_id_list = [int(id.strip()) for id in chapter_ids.split(',') if id.strip()]
                if chapter_id_list:
                    query = query.filter(BookChapter.id.in_(chapter_id_list))
                    logger.info(f"è¿‡æ»¤ç« èŠ‚ID: {chapter_id_list}")
            except ValueError:
                raise HTTPException(status_code=400, detail="ç« èŠ‚IDæ ¼å¼é”™è¯¯")
        
        chapters_with_analysis = query.order_by(BookChapter.chapter_number).all()
        
        analysis_results = []
        
        for chapter, analysis in chapters_with_analysis:
            if analysis and analysis.synthesis_plan:
                # æ„å»ºåˆ†æç»“æœæ•°æ®
                result_data = {
                    "chapter_id": chapter.id,
                    "chapter_number": chapter.chapter_number,
                    "chapter_title": chapter.chapter_title,
                    "word_count": chapter.word_count,
                    "analysis_id": analysis.id,
                    "synthesis_json": analysis.synthesis_plan,
                    "confidence_score": analysis.confidence_score,
                    "processing_time": analysis.processing_time,
                    "created_at": analysis.created_at.isoformat() if analysis.created_at else None,
                    "updated_at": analysis.updated_at.isoformat() if analysis.updated_at else None
                }
                analysis_results.append(result_data)
        
        logger.info(f"è·å–ä¹¦ç± {book_id} çš„åˆ†æç»“æœ: æ‰¾åˆ° {len(analysis_results)} ä¸ªå·²åˆ†æç« èŠ‚")
        
        return {
            "success": True,
            "data": analysis_results,
            "book_info": {
                "id": book.id,
                "title": book.title,
                "author": book.author,
                "total_chapters": len(chapters_with_analysis),
                "analyzed_chapters": len(analysis_results)
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±åˆ†æç»“æœå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ†æç»“æœå¤±è´¥: {str(e)}") 


# ============= è§’è‰²ç®¡ç†ç›¸å…³API =============

@router.get("/{book_id}/characters")
async def get_book_characters(
    book_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±è§’è‰²æ±‡æ€»ä¿¡æ¯
    é«˜æ€§èƒ½ï¼šä¸éå†æ‰€æœ‰ç« èŠ‚ï¼Œç›´æ¥ä»book.character_summaryè¯»å–
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        character_summary = book.get_character_summary()
        
        # ğŸ”§ æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.info(f"[è°ƒè¯•] è·å–ä¹¦ç±{book_id}è§’è‰²æ±‡æ€»:")
        logger.info(f"  character_summaryåŸå§‹ç±»å‹: {type(book.character_summary)}")
        logger.info(f"  character_summaryåŸå§‹æ•°æ®: {book.character_summary}")
        logger.info(f"  get_character_summary()è¿”å›ç±»å‹: {type(character_summary)}")
        logger.info(f"  get_character_summary()è¿”å›æ•°æ®: {character_summary}")
        logger.info(f"  voice_mappings: {character_summary.get('voice_mappings', {})}")
        
        return {
            "success": True,
            "data": {
                "book_id": book_id,
                "book_title": book.title,
                "characters": character_summary.get('characters', []),
                "voice_mappings": character_summary.get('voice_mappings', {}),
                "last_updated": character_summary.get('last_updated'),
                "total_chapters_analyzed": character_summary.get('total_chapters_analyzed', 0),
                "character_count": len(character_summary.get('characters', [])),
                "configured_count": len(character_summary.get('voice_mappings', {}))
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±è§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}")


@router.post("/{book_id}/characters/{character_name}/voice-mapping")
async def set_character_voice_mapping(
    book_id: int,
    character_name: str,
    voice_id: str = Form(...),
    db: Session = Depends(get_db)
):
    """
    è®¾ç½®å•ä¸ªè§’è‰²çš„è¯­éŸ³æ˜ å°„
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ£€æŸ¥è§’è‰²æ˜¯å¦å­˜åœ¨
        character_names = book.get_all_character_names()
        if character_name not in character_names:
            raise HTTPException(status_code=404, detail=f"è§’è‰² '{character_name}' ä¸å­˜åœ¨")
        
        # è®¾ç½®è¯­éŸ³æ˜ å°„
        book.set_character_voice_mapping(character_name, voice_id)
        db.commit()
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ­¥æ›´æ–°ç›¸å…³ç« èŠ‚çš„synthesis_plan
        # è·å–å®Œæ•´çš„è§’è‰²è¯­éŸ³æ˜ å°„ï¼ˆè€Œä¸æ˜¯åªä¼ é€’å•ä¸ªè§’è‰²æ˜ å°„ï¼‰
        db.refresh(book)  # ç¡®ä¿è·å–æœ€æ–°æ•°æ®
        complete_voice_mappings = book.get_character_summary().get('voice_mappings', {})
        
        if complete_voice_mappings:
            updated_chapters = await _sync_character_voice_to_synthesis_plans(
                book_id, complete_voice_mappings, db
            )
        else:
            updated_chapters = 0
        
        logger.info(f"è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„: ä¹¦ç±{book_id} - {character_name} -> {voice_id}ï¼ŒåŒæ­¥æ›´æ–°äº† {updated_chapters} ä¸ªç« èŠ‚")
        
        return {
            "success": True,
            "message": f"å·²è®¾ç½®è§’è‰² '{character_name}' çš„è¯­éŸ³é…ç½®ï¼ŒåŒæ­¥æ›´æ–°äº† {updated_chapters} ä¸ªç« èŠ‚çš„åˆæˆè®¡åˆ’",
            "data": {
                "character_name": character_name,
                "voice_id": voice_id,
                "updated_chapters": updated_chapters,
                "updated_at": datetime.utcnow().isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è®¾ç½®è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")


@router.post("/{book_id}/characters/batch-voice-mappings")
async def batch_set_character_voice_mappings(
    book_id: int,
    mappings: str = Form(..., description="è§’è‰²è¯­éŸ³æ˜ å°„JSONå­—ç¬¦ä¸²ï¼Œæ ¼å¼: {è§’è‰²å: voice_id}"),
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # è§£ææ˜ å°„æ•°æ®
        if isinstance(mappings, str):
            try:
                mappings = json.loads(mappings)
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="æ˜ å°„æ•°æ®æ ¼å¼é”™è¯¯")
        
        if not isinstance(mappings, dict):
            raise HTTPException(status_code=400, detail="æ˜ å°„æ•°æ®å¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
        
        # æ£€æŸ¥æ‰€æœ‰è§’è‰²æ˜¯å¦å­˜åœ¨
        character_names = book.get_all_character_names()
        invalid_characters = [char for char in mappings.keys() if char not in character_names]
        if invalid_characters:
            raise HTTPException(
                status_code=400, 
                detail=f"ä»¥ä¸‹è§’è‰²ä¸å­˜åœ¨: {', '.join(invalid_characters)}"
            )
        
        # æ‰¹é‡è®¾ç½®è¯­éŸ³æ˜ å°„
        success_count = 0
        updated_mappings = {}
        for character_name, voice_id in mappings.items():
            if voice_id:  # åªè®¾ç½®éç©ºçš„voice_id
                logger.info(f"[è°ƒè¯•] è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„: {character_name} -> {voice_id}")
                book.set_character_voice_mapping(character_name, voice_id)
                updated_mappings[character_name] = voice_id
                success_count += 1
        
        # ğŸ”¥ è°ƒè¯•ï¼šæäº¤å‰æ£€æŸ¥æ•°æ®
        logger.info(f"[è°ƒè¯•] æäº¤å‰æ£€æŸ¥ character_summary: {book.character_summary}")
        db.commit()
        
        # ğŸ”¥ è°ƒè¯•ï¼šæäº¤åé‡æ–°æŸ¥è¯¢éªŒè¯
        db.refresh(book)
        post_commit_summary = book.get_character_summary()
        # ğŸ”¥ å®‰å…¨ç±»å‹æ£€æŸ¥
        if isinstance(post_commit_summary, dict):
            logger.info(f"[è°ƒè¯•] æäº¤åé‡æ–°æŸ¥è¯¢ voice_mappings: {post_commit_summary.get('voice_mappings', {})}")
        else:
            logger.warning(f"[è°ƒè¯•] æäº¤åæ•°æ®æ ¼å¼å¼‚å¸¸: {type(post_commit_summary)} - {post_commit_summary}")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ­¥æ›´æ–°æ‰€æœ‰ç›¸å…³ç« èŠ‚çš„synthesis_plan
        # è·å–å®Œæ•´çš„è§’è‰²è¯­éŸ³æ˜ å°„ï¼ˆè€Œä¸æ˜¯åªä¼ é€’æœ¬æ¬¡æ›´æ–°çš„éƒ¨åˆ†æ˜ å°„ï¼‰
        db.refresh(book)  # ç¡®ä¿è·å–æœ€æ–°æ•°æ®
        complete_voice_mappings = book.get_character_summary().get('voice_mappings', {})
        
        if complete_voice_mappings:
            # ğŸ”¥ ä¿®å¤ï¼šä¼ é€’å®Œæ•´çš„è§’è‰²æ˜ å°„ï¼Œç¡®ä¿æ‰€æœ‰è§’è‰²éƒ½èƒ½è¢«æ­£ç¡®åŒæ­¥
            updated_chapters = await _sync_character_voice_to_synthesis_plans(
                book_id, complete_voice_mappings, db
            )
            logger.info(f"åŒæ­¥æ›´æ–°äº† {updated_chapters} ä¸ªç« èŠ‚çš„synthesis_planï¼Œå®Œæ•´æ˜ å°„: {complete_voice_mappings}")
        else:
            updated_chapters = 0
            logger.warning(f"ä¹¦ç± {book_id} æ²¡æœ‰ä»»ä½•è§’è‰²è¯­éŸ³æ˜ å°„ï¼Œè·³è¿‡åŒæ­¥")
        
        logger.info(f"æ‰¹é‡è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„: ä¹¦ç±{book_id} - æˆåŠŸè®¾ç½® {success_count} ä¸ªè§’è‰²")
        
        return {
            "success": True,
            "message": f"æˆåŠŸè®¾ç½® {success_count} ä¸ªè§’è‰²çš„è¯­éŸ³é…ç½®ï¼Œå·²åŒæ­¥æ›´æ–° {updated_chapters} ä¸ªç« èŠ‚çš„åˆæˆè®¡åˆ’",
            "data": {
                "book_id": book_id,
                "updated_mappings": updated_mappings,
                "success_count": success_count,
                "updated_chapters": updated_chapters,
                "updated_at": datetime.utcnow().isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è®¾ç½®å¤±è´¥: {str(e)}")


@router.post("/{book_id}/characters/rebuild-summary")
async def rebuild_character_summary(
    book_id: int,
    db: Session = Depends(get_db)
):
    """
    é‡å»ºä¹¦ç±è§’è‰²æ±‡æ€»ï¼ˆä»æ‰€æœ‰ç« èŠ‚åˆ†æç»“æœé‡æ–°æ±‡æ€»ï¼‰
    ç”¨äºä¿®å¤æˆ–æ›´æ–°æ±‡æ€»æ•°æ®
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # è·å–æ‰€æœ‰å·²åˆ†æçš„ç« èŠ‚
        chapters_with_analysis = db.query(BookChapter, AnalysisResult).join(
            AnalysisResult, BookChapter.id == AnalysisResult.chapter_id
        ).filter(
            BookChapter.book_id == book_id,
            AnalysisResult.detected_characters.isnot(None)
        ).all()
        
        if not chapters_with_analysis:
            return {
                "success": True,
                "message": "æš‚æ— ç« èŠ‚åˆ†ææ•°æ®ï¼Œè§’è‰²æ±‡æ€»ä¸ºç©º",
                "data": book.get_character_summary()
            }
        
        # ä¿å­˜å½“å‰çš„è¯­éŸ³æ˜ å°„é…ç½®
        try:
            current_summary = book.get_character_summary()
            # ğŸ”¥ ç¡®ä¿current_summaryæ˜¯å­—å…¸æ ¼å¼
            if isinstance(current_summary, dict):
                current_mappings = current_summary.get('voice_mappings', {})
            else:
                logger.warning(f"è§’è‰²æ±‡æ€»æ•°æ®æ ¼å¼å¼‚å¸¸: {type(current_summary)} - {current_summary}")
                current_mappings = {}
        except Exception as e:
            logger.warning(f"è·å–å½“å‰è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ç©ºæ˜ å°„")
            current_mappings = {}
        
        # æ¸…ç©ºè§’è‰²æ±‡æ€»ï¼Œé‡æ–°æ„å»º
        book.character_summary = None
        
        # é€ç« èŠ‚æ›´æ–°è§’è‰²æ±‡æ€»
        total_rebuilt = 0
        for chapter, analysis in chapters_with_analysis:
            detected_characters = analysis.detected_characters or []
            if detected_characters:
                book.update_character_summary(detected_characters, chapter.id)
                total_rebuilt += 1
        
        # æ¢å¤ä¹‹å‰çš„è¯­éŸ³æ˜ å°„é…ç½®
        try:
            current_summary = book.get_character_summary()
            # ğŸ”¥ å¢å¼ºå®‰å…¨æ£€æŸ¥
            if isinstance(current_summary, dict):
                current_summary['voice_mappings'] = current_mappings
                book.character_summary = current_summary
                flag_modified(book, 'character_summary')  # ç¡®ä¿SQLAlchemyæ£€æµ‹åˆ°ä¿®æ”¹
            else:
                logger.warning(f"è§’è‰²æ±‡æ€»æ•°æ®æ ¼å¼å¼‚å¸¸: {type(current_summary)}, è·³è¿‡è¯­éŸ³æ˜ å°„æ¢å¤")
        except Exception as e:
            logger.warning(f"æ¢å¤è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")
        
        db.commit()
        
        logger.info(f"é‡å»ºä¹¦ç±è§’è‰²æ±‡æ€»: ä¹¦ç±{book_id} - å¤„ç†äº† {total_rebuilt} ä¸ªç« èŠ‚")
        
        return {
            "success": True,
            "message": f"æˆåŠŸé‡å»ºè§’è‰²æ±‡æ€»ï¼Œå¤„ç†äº† {total_rebuilt} ä¸ªç« èŠ‚",
            "data": book.get_character_summary()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡å»ºè§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é‡å»ºæ±‡æ€»å¤±è´¥: {str(e)}")


# ========== å†…éƒ¨è¾…åŠ©å‡½æ•° ==========

async def _sync_character_voice_to_synthesis_plans(
    book_id: int, 
    character_voice_mappings: Dict[str, Any], 
    db: Session
) -> int:
    """
    åŒæ­¥è§’è‰²è¯­éŸ³é…ç½®åˆ°æ‰€æœ‰ç›¸å…³ç« èŠ‚çš„synthesis_plan
    
    Args:
        book_id: ä¹¦ç±ID
        character_voice_mappings: è§’è‰²è¯­éŸ³æ˜ å°„ {è§’è‰²å: voice_id}
        db: æ•°æ®åº“ä¼šè¯
    
    Returns:
        æ›´æ–°çš„ç« èŠ‚æ•°é‡
    """
    try:
        # ğŸ”¥ å¢å¼ºè°ƒè¯•ï¼šè®°å½•ä¼ å…¥çš„æ˜ å°„ä¿¡æ¯
        logger.info(f"ğŸš€ [å¼€å§‹åŒæ­¥] ä¹¦ç± {book_id}, ä¼ å…¥æ˜ å°„: {character_voice_mappings}")
        
        # è·å–è¿™æœ¬ä¹¦æ‰€æœ‰å·²å®Œæˆåˆ†æçš„ç« èŠ‚
        # æ³¨æ„ï¼šBookChapter, AnalysisResult å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
        chapters_with_analysis = db.query(BookChapter, AnalysisResult).join(
            AnalysisResult, BookChapter.id == AnalysisResult.chapter_id
        ).filter(
            BookChapter.book_id == book_id,
            AnalysisResult.status == 'completed',
            AnalysisResult.synthesis_plan.isnot(None)
        ).all()
        
        if not chapters_with_analysis:
            logger.info(f"ä¹¦ç± {book_id} æš‚æ— éœ€è¦åŒæ­¥çš„ç« èŠ‚åˆ†æç»“æœ")
            return 0
        
        updated_count = 0
        
        for chapter, analysis in chapters_with_analysis:
            try:
                synthesis_plan = analysis.synthesis_plan
                if not synthesis_plan:
                    continue
                
                # ğŸ”¥ ä¿®å¤ï¼šæ”¯æŒä¸¤ç§æ•°æ®ç»“æ„
                # ç»“æ„1: {'segments': [...]}  (æ—§ç‰ˆæœ¬)
                # ç»“æ„2: {'synthesis_plan': [...], 'project_info': {...}, 'characters': [...]}  (æ–°ç‰ˆæœ¬)
                segments = None
                if 'segments' in synthesis_plan:
                    segments = synthesis_plan.get('segments', [])
                elif 'synthesis_plan' in synthesis_plan:
                    segments = synthesis_plan.get('synthesis_plan', [])
                
                if not segments or not isinstance(segments, list):
                    logger.debug(f"ç« èŠ‚ {chapter.id} synthesis_planæ ¼å¼ä¸åŒ¹é…æˆ–ä¸ºç©ºï¼Œè·³è¿‡åŒæ­¥")
                    continue
                plan_updated = False
                
                # ğŸ”¥ è·å–voice_idåˆ°voice_nameçš„æ˜ å°„
                voice_id_to_name = {}
                try:
                    from ...models import VoiceProfile
                    voices = db.query(VoiceProfile).filter(VoiceProfile.status == 'active').all()
                    voice_id_to_name = {str(v.id): v.name for v in voices}
                    logger.info(f"ğŸ“‹ [è¯­éŸ³æ˜ å°„] åŠ è½½äº† {len(voice_id_to_name)} ä¸ªè¯­éŸ³æ¡£æ¡ˆ")
                except Exception as e:
                    logger.warning(f"è·å–è¯­éŸ³æ¡£æ¡ˆå¤±è´¥: {str(e)}")
                
                # éå†æ¯ä¸ªæ®µè½ï¼Œæ›´æ–°åŒ¹é…è§’è‰²çš„voice_idå’Œvoice_name
                for segment in segments:
                    speaker = segment.get('speaker', '')
                    
                    # æ£€æŸ¥è¿™ä¸ªè§’è‰²æ˜¯å¦åœ¨è¦æ›´æ–°çš„æ˜ å°„ä¸­
                    if speaker in character_voice_mappings:
                        old_voice_id = segment.get('voice_id')
                        old_voice_name = segment.get('voice_name', 'æœªåˆ†é…')
                        new_voice_id = character_voice_mappings[speaker]
                        
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ—¶æ›´æ–°voice_name
                        new_voice_name = voice_id_to_name.get(str(new_voice_id), f"Voice_{new_voice_id}")
                        
                        # ğŸ”¥ å¢å¼ºè°ƒè¯•ï¼šè®°å½•åŒæ­¥è¿‡ç¨‹
                        logger.info(f"ğŸ“ [åŒæ­¥è°ƒè¯•] ç« èŠ‚ {chapter.id} è§’è‰² '{speaker}': old_voice_id='{old_voice_id}', new_voice_id='{new_voice_id}', old_voice_name='{old_voice_name}', new_voice_name='{new_voice_name}'")
                        
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ— è®ºvoice_idæ˜¯å¦æ”¹å˜ï¼Œéƒ½è¦ç¡®ä¿voice_nameæ­£ç¡®
                        voice_id_changed = str(old_voice_id) != str(new_voice_id)
                        voice_name_wrong = old_voice_name != new_voice_name
                        
                        if voice_id_changed or voice_name_wrong:
                            # ğŸ”¥ ç¡®ä¿è®¾ç½®ä¸ºæ­£ç¡®çš„ç±»å‹ï¼ˆæ ¹æ®åŸæ•°æ®ç±»å‹å†³å®šï¼‰
                            if isinstance(old_voice_id, int) or (isinstance(old_voice_id, str) and old_voice_id.isdigit()):
                                segment['voice_id'] = int(new_voice_id) if str(new_voice_id).isdigit() else new_voice_id
                            else:
                                segment['voice_id'] = str(new_voice_id)
                            
                            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ—¶æ›´æ–°voice_name
                            segment['voice_name'] = new_voice_name
                            
                            plan_updated = True
                            logger.info(f"âœ… [åŒæ­¥æˆåŠŸ] {speaker}: voice_id {old_voice_id} â†’ {segment['voice_id']}, voice_name '{old_voice_name}' â†’ '{new_voice_name}'")
                        else:
                            logger.info(f"â„¹ï¸ [è·³è¿‡åŒæ­¥] è§’è‰² '{speaker}' é…ç½®å·²æ˜¯æœ€æ–°: voice_id={old_voice_id}, voice_name={old_voice_name}")
                
                # å¦‚æœæœ‰æ›´æ–°ï¼Œä¿å­˜åˆ°æ•°æ®åº“
                if plan_updated:
                    # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®æ•°æ®ç»“æ„ä¿å­˜å›æ­£ç¡®çš„ä½ç½®
                    if 'segments' in synthesis_plan:
                        synthesis_plan['segments'] = segments
                    elif 'synthesis_plan' in synthesis_plan:
                        synthesis_plan['synthesis_plan'] = segments
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶SQLAlchemyæ£€æµ‹JSONå­—æ®µä¿®æ”¹
                    from sqlalchemy.orm.attributes import flag_modified
                    analysis.synthesis_plan = synthesis_plan
                    flag_modified(analysis, 'synthesis_plan')
                    
                    # ğŸ”¥ CRITICAL FIX: æ¸…ç©ºfinal_configé¿å…APIè¿”å›æ—§æ•°æ®
                    # å½“synthesis_planæ›´æ–°æ—¶ï¼Œè‡ªåŠ¨æ¸…ç©ºfinal_configï¼Œç¡®ä¿APIè¿”å›æœ€æ–°åŒæ­¥çš„æ•°æ®
                    if analysis.final_config:
                        logger.info(f"ğŸ—‘ï¸ [æ¸…ç©ºç¼“å­˜] ç« èŠ‚ {chapter.id} æ¸…ç©ºfinal_configï¼Œé¿å…APIè¿”å›è¿‡æœŸæ•°æ®")
                        analysis.final_config = None
                        flag_modified(analysis, 'final_config')
                    
                    analysis.updated_at = datetime.utcnow()
                    updated_count += 1
                    logger.info(f"å·²æ›´æ–°ç« èŠ‚ {chapter.id} ({chapter.chapter_title}) çš„åˆæˆè®¡åˆ’")
                
            except Exception as e:
                logger.error(f"æ›´æ–°ç« èŠ‚ {chapter.id} çš„synthesis_planå¤±è´¥: {str(e)}")
                continue
        
        # æ‰¹é‡æäº¤æ•°æ®åº“æ›´æ”¹
        if updated_count > 0:
            db.commit()
            logger.info(f"æˆåŠŸåŒæ­¥æ›´æ–°äº† {updated_count} ä¸ªç« èŠ‚çš„synthesis_plan")
        
        return updated_count
        
    except Exception as e:
        logger.error(f"åŒæ­¥è§’è‰²è¯­éŸ³é…ç½®åˆ°synthesis_planå¤±è´¥: {str(e)}")
        return 0 