"""
ä¹¦ç±ç®¡ç†API
æä¾›ä¹¦ç±ä¸Šä¼ ã€ç« èŠ‚æ£€æµ‹ã€ç»“æ„åŒ–å¤„ç†ç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, Query
from sqlalchemy.orm import Session
from sqlalchemy.orm.attributes import flag_modified
from sqlalchemy import desc, asc, func, or_, and_
from typing import List, Optional, Dict, Any
import asyncio
import logging
import json
import re
from datetime import datetime
from pydantic import BaseModel

from app.database import get_db
from app.models import Book, BookChapter, AnalysisResult

# é…ç½®æ–‡ä»¶ä¸Šä¼ å¤§å°é™åˆ¶
from fastapi import File
from typing import BinaryIO

router = APIRouter(prefix="/books")

logger = logging.getLogger(__name__)


def detect_chapters_from_content(content: str) -> List[dict]:
    """
    ä»ä¹¦ç±å†…å®¹ä¸­æ£€æµ‹ç« èŠ‚
    è¿”å›ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å«ï¼štitle, content, word_count
    """
    if not content or not content.strip():
        return []
    
    chapters = []
    lines = content.split('\n')
    current_chapter = None
    chapter_content = []
    chapter_number = 0
    
    # ç« èŠ‚æ ‡é¢˜æ£€æµ‹æ¨¡å¼
    chapter_patterns = [
        r'^#{1,6}\s+',  # Markdownæ ‡é¢˜ # ## ### ç­‰
        r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ç« èŠ‚å›]',  # ç¬¬ä¸€ç« ã€ç¬¬1ç« ã€ç¬¬ä¸€èŠ‚ç­‰
        r'^Chapter\s+\d+',  # Chapter 1
        r'^\d+\.',  # 1.
        r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',  # ä¸€ã€äºŒã€ä¸‰ã€
        r'^ã€.*?ã€‘',  # ã€ç« èŠ‚æ ‡é¢˜ã€‘
        r'^ï¼ˆç¬¬.*?ï¼‰',  # ï¼ˆç¬¬ä¸€ç« ï¼‰
    ]
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # æ£€æµ‹æ˜¯å¦ä¸ºç« èŠ‚æ ‡é¢˜
        is_chapter_title = False
        for pattern in chapter_patterns:
            if re.match(pattern, line):
                is_chapter_title = True
                break
        
        if is_chapter_title:
            # ä¿å­˜ä¸Šä¸€ç« èŠ‚
            if current_chapter and chapter_content:
                chapter_text = '\n'.join(chapter_content)
                if chapter_text.strip():  # ç¡®ä¿ç« èŠ‚å†…å®¹ä¸ä¸ºç©º
                    chapters.append({
                        'number': chapter_number,
                        'title': current_chapter,
                        'content': chapter_text,
                        'word_count': len(chapter_text.replace(' ', '').replace('\n', ''))
                    })
            
            # å¼€å§‹æ–°ç« èŠ‚
            chapter_number += 1
            current_chapter = line
            chapter_content = []
        else:
            chapter_content.append(line)
    
    # ä¿å­˜æœ€åä¸€ç« 
    if current_chapter and chapter_content:
        chapter_text = '\n'.join(chapter_content)
        if chapter_text.strip():
            chapters.append({
                'number': chapter_number,
                'title': current_chapter,
                'content': chapter_text,
                'word_count': len(chapter_text.replace(' ', '').replace('\n', ''))
            })
    
    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç« èŠ‚ï¼Œå°†æ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªç« èŠ‚
    if not chapters and content.strip():
        chapters.append({
            'number': 1,
            'title': 'å…¨æ–‡',
            'content': content.strip(),
            'word_count': len(content.replace(' ', '').replace('\n', ''))
        })
    
    return chapters


@router.post("")
async def upload_book(
    title: str = Form(...),
    author: Optional[str] = Form(""),
    description: Optional[str] = Form(""),
    content: Optional[str] = Form(""),
    tags: Optional[str] = Form("[]"),
    text_file: Optional[UploadFile] = File(None, description="ä¸Šä¼ çš„æ–‡æœ¬æ–‡ä»¶"),
    auto_detect_chapters: bool = Form(True),
    db: Session = Depends(get_db)
):
    """
    åˆ›å»ºä¹¦ç±è®°å½•
    - æ”¯æŒç›´æ¥æ–‡æœ¬å†…å®¹æˆ–æ–‡ä»¶ä¸Šä¼ 
    - æ”¯æŒtxtã€docxç­‰æ ¼å¼æ–‡ä»¶
    - å¯é€‰æ‹©è‡ªåŠ¨æ£€æµ‹ç« èŠ‚
    """
    try:
        # è§£ææ ‡ç­¾
        try:
            parsed_tags = json.loads(tags) if tags else []
        except json.JSONDecodeError:
            parsed_tags = []
        
        # è·å–ä¹¦ç±å†…å®¹
        book_content = ""
        if text_file and text_file.filename:
            # ä»æ–‡ä»¶è¯»å–å†…å®¹
            file_content = await text_file.read()
            try:
                book_content = file_content.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    book_content = file_content.decode('gbk')
                except UnicodeDecodeError:
                    raise HTTPException(status_code=400, detail="æ–‡ä»¶ç¼–ç æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä½¿ç”¨UTF-8æˆ–GBKç¼–ç ")
        elif content:
            # ä½¿ç”¨ç›´æ¥ä¼ å…¥çš„æ–‡æœ¬å†…å®¹
            book_content = content
        else:
            raise HTTPException(status_code=400, detail="å¿…é¡»æä¾›æ–‡æœ¬å†…å®¹æˆ–ä¸Šä¼ æ–‡ä»¶")
        
        # åˆ›å»ºä¹¦ç±è®°å½•
        new_book = Book(
            title=title,
            author=author or "",
            description=description or "",
            content=book_content,
            tags=json.dumps(parsed_tags, ensure_ascii=False),
            status='draft',
            word_count=len(book_content),
            chapter_count=0
        )
        
        db.add(new_book)
        db.commit()
        db.refresh(new_book)
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨ç« èŠ‚æ£€æµ‹ä¸”å†…å®¹ä¸ä¸ºç©º
        if auto_detect_chapters and book_content.strip():
            try:
                # æ£€æµ‹ç« èŠ‚
                chapters_data = detect_chapters_from_content(book_content)
                
                # ä¿å­˜ç« èŠ‚åˆ°æ•°æ®åº“
                for chapter_data in chapters_data:
                    chapter = BookChapter(
                        book_id=new_book.id,
                        chapter_number=chapter_data['number'],
                        chapter_title=chapter_data['title'],
                        content=chapter_data['content'],
                        word_count=chapter_data['word_count'],
                        analysis_status='pending',
                        synthesis_status='pending',
                        created_at=datetime.utcnow(),
                        updated_at=datetime.utcnow()
                    )
                    db.add(chapter)
                
                # æ›´æ–°ä¹¦ç±çš„ç« èŠ‚æ•°
                new_book.chapter_count = len(chapters_data)
                db.commit()
                
                logger.info(f"ä¹¦ç± '{title}' è‡ªåŠ¨æ£€æµ‹åˆ° {len(chapters_data)} ä¸ªç« èŠ‚")
                
            except Exception as e:
                logger.error(f"ç« èŠ‚æ£€æµ‹å¤±è´¥: {str(e)}")
                # ç« èŠ‚æ£€æµ‹å¤±è´¥ä¸å½±å“ä¹¦ç±åˆ›å»º
        
        return {
            "success": True,
            "data": new_book.to_dict(),
            "message": f"ä¹¦ç±åˆ›å»ºæˆåŠŸï¼Œæ£€æµ‹åˆ° {new_book.chapter_count} ä¸ªç« èŠ‚"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ›å»ºä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¹¦ç±å¤±è´¥: {str(e)}")


@router.get("")
async def get_books(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    search: str = Query("", description="æœç´¢å…³é”®è¯"),
    author: str = Query("", description="ä½œè€…è¿‡æ»¤"),
    status: str = Query("", description="çŠ¶æ€è¿‡æ»¤"),
    sort_by: str = Query("created_at", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºæ–¹å‘"),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±åˆ—è¡¨
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    - æ”¯æŒæ ‡é¢˜å’Œä½œè€…æœç´¢
    """
    try:
        # æ„å»ºæŸ¥è¯¢
        query = db.query(Book)
        
        # æœç´¢è¿‡æ»¤
        if search:
            search_pattern = f"%{search}%"
            query = query.filter(
                or_(
                    Book.title.like(search_pattern),
                    Book.author.like(search_pattern),
                    Book.description.like(search_pattern)
                )
            )
        
        # ä½œè€…è¿‡æ»¤
        if author:
            query = query.filter(Book.author.like(f"%{author}%"))
        
        # çŠ¶æ€è¿‡æ»¤
        if status:
            query = query.filter(Book.status == status)
        
        # æ’åº
        sort_field = getattr(Book, sort_by, Book.created_at)
        if sort_order == "asc":
            query = query.order_by(asc(sort_field))
        else:
            query = query.order_by(desc(sort_field))
        
        # ç»Ÿè®¡æ€»æ•°
        total = query.count()
        
        # åˆ†é¡µ
        offset = (page - 1) * page_size
        books = query.offset(offset).limit(page_size).all()
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        book_list = [book.to_dict() for book in books]
        
        # åˆ†é¡µä¿¡æ¯
        total_pages = (total + page_size - 1) // page_size
        
        return {
            "success": True,
            "data": book_list,
            "pagination": {
                "page": page,
                "pageSize": page_size,
                "total": total,
                "totalPages": total_pages,
                "hasMore": page < total_pages
            },
            "filters": {
                "search": search,
                "author": author,
                "status": status
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¹¦ç±åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/{book_id}")
async def get_book(book_id: int, db: Session = Depends(get_db)):
    """è·å–ä¹¦ç±è¯¦æƒ…"""
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": book.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±è¯¦æƒ…å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¹¦ç±è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.post("/{book_id}/detect-chapters")
async def detect_chapters(
    book_id: int,
    force_reprocess: bool = False,
    detection_config: Optional[dict] = None,
    db: Session = Depends(get_db)
):
    """
    æ£€æµ‹ä¹¦ç±ç« èŠ‚ç»“æ„
    - æ”¯æŒå¼ºåˆ¶é‡æ–°å¤„ç†
    - æ”¯æŒè‡ªå®šä¹‰æ£€æµ‹é…ç½®
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail=f"ä¹¦ç± ID {book_id} ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç« èŠ‚æ•°æ®
        existing_chapters = db.query(BookChapter).filter(BookChapter.book_id == book_id).count()
        if existing_chapters > 0 and not force_reprocess:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¹¦ç±å·²æœ‰ {existing_chapters} ä¸ªç« èŠ‚ï¼Œä½¿ç”¨ force_reprocess=true å¼ºåˆ¶é‡æ–°å¤„ç†"
            )
        
        # å¦‚æœå¼ºåˆ¶é‡æ–°å¤„ç†ï¼Œåˆ é™¤ç°æœ‰ç« èŠ‚
        if force_reprocess and existing_chapters > 0:
            db.query(BookChapter).filter(BookChapter.book_id == book_id).delete()
            db.commit()
        
        # æ£€æµ‹ç« èŠ‚
        chapters_data = detect_chapters_from_content(book.content or "")
        
        if not chapters_data:
            raise HTTPException(status_code=400, detail="æœªæ£€æµ‹åˆ°æœ‰æ•ˆç« èŠ‚")
        
        # ä¿å­˜ç« èŠ‚åˆ°æ•°æ®åº“
        for chapter_data in chapters_data:
            chapter = BookChapter(
                book_id=book_id,
                chapter_number=chapter_data['number'],
                chapter_title=chapter_data['title'],
                content=chapter_data['content'],
                word_count=chapter_data['word_count'],
                analysis_status='pending',
                synthesis_status='pending',
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow()
            )
            db.add(chapter)
        
        # æ›´æ–°ä¹¦ç±ä¿¡æ¯
        book.chapter_count = len(chapters_data)
        db.commit()
        
        return {
            "success": True,
            "message": f"ç« èŠ‚æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(chapters_data)} ä¸ªç« èŠ‚",
            "chapters_found": len(chapters_data),
            "book_id": book_id,
            "chapters": [
                {
                    "number": ch['number'],
                    "title": ch['title'],
                    "word_count": ch['word_count']
                }
                for ch in chapters_data
            ]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç« èŠ‚æ£€æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç« èŠ‚æ£€æµ‹å¤±è´¥: {str(e)}")


@router.get("/{book_id}/chapters")
async def get_chapters(
    book_id: int,
    skip: int = Query(0, description="è·³è¿‡çš„è®°å½•æ•°"),
    limit: int = Query(100, description="è¿”å›çš„è®°å½•æ•°"),
    status_filter: str = Query("", description="çŠ¶æ€è¿‡æ»¤"),
    fields: str = Query("", description="æŒ‡å®šè¿”å›å­—æ®µï¼Œé€—å·åˆ†éš”ï¼Œå¦‚'id,chapter_number,chapter_title,word_count'"),
    exclude_content: bool = Query(True, description="æ˜¯å¦æ’é™¤å†…å®¹å­—æ®µä»¥ä¼˜åŒ–æ€§èƒ½"),
    db: Session = Depends(get_db)
):
    """è·å–ä¹¦ç±çš„ç« èŠ‚åˆ—è¡¨
    
    æ€§èƒ½ä¼˜åŒ–ï¼š
    - æ”¯æŒå­—æ®µé€‰æ‹©ï¼Œé¿å…è¿”å›å¤§å­—æ®µ
    - é»˜è®¤æ’é™¤contentå­—æ®µä»¥å‡å°‘æ•°æ®ä¼ è¾“
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ„å»ºæŸ¥è¯¢
        query = db.query(BookChapter).filter(BookChapter.book_id == book_id)
        
        # åº”ç”¨çŠ¶æ€è¿‡æ»¤
        if status_filter:
            query = query.filter(BookChapter.analysis_status == status_filter)
        
        # è·å–æ€»æ•°
        total = query.count()
        
        # åº”ç”¨åˆ†é¡µ
        chapters = query.order_by(BookChapter.chapter_number).offset(skip).limit(limit).all()
        
        # å¤„ç†å­—æ®µé€‰æ‹©
        if fields:
            requested_fields = [f.strip() for f in fields.split(',') if f.strip()]
        else:
            # é»˜è®¤å­—æ®µï¼Œæ’é™¤å¤§å†…å®¹å­—æ®µ
            requested_fields = [
                'id', 'book_id', 'chapter_number', 'chapter_title', 
                'word_count', 'character_count', 'analysis_status', 
                'synthesis_status', 'created_at', 'updated_at'
            ]
            if not exclude_content:
                requested_fields.append('content')
        
        # è½¬æ¢ä¸ºç²¾ç®€å­—å…¸
        chapters_data = []
        for chapter in chapters:
            chapter_dict = chapter.to_dict()
            
            # æ ¹æ®å­—æ®µé€‰æ‹©è¿‡æ»¤
            if fields or exclude_content:
                filtered_dict = {}
                for field in requested_fields:
                    if field in chapter_dict:
                        filtered_dict[field] = chapter_dict[field]
                chapters_data.append(filtered_dict)
            else:
                chapters_data.append(chapter_dict)
        
        return {
            "success": True,
            "data": chapters_data,
            "total": total,
            "skip": skip,
            "limit": limit,
            "pagination": {
                "page": (skip // limit) + 1 if limit > 0 else 1,
                "page_size": limit,
                "total": total,
                "total_pages": (total + limit - 1) // limit if limit > 0 else 1,
                "has_next": skip + limit < total,
                "has_prev": skip > 0
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/{book_id}/structure-status")
def get_structure_status(book_id: int, db: Session = Depends(get_db)):
    """
    è·å–ä¹¦ç±ç»“æ„åŒ–å¤„ç†çŠ¶æ€
    """
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    # ç»Ÿè®¡ç« èŠ‚çŠ¶æ€
    chapter_stats = db.query(BookChapter.analysis_status, 
                           db.func.count(BookChapter.id).label('count')) \
                     .filter(BookChapter.book_id == book_id) \
                     .group_by(BookChapter.analysis_status) \
                     .all()
    
    status_counts = {stat.analysis_status: stat.count for stat in chapter_stats}
    
    return {
        "book_id": book_id,
        "structure_detected": book.structure_detected,
        "total_chapters": book.total_chapters,
        "total_words": book.total_words,
        "chapter_status_counts": status_counts,
        "detection_config": book.chapter_detection_config
    }


@router.delete("/{book_id}")
def delete_book(book_id: int, db: Session = Depends(get_db)):
    """åˆ é™¤ä¹¦ç±åŠå…¶æ‰€æœ‰ç›¸å…³æ•°æ®"""
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    # åˆ é™¤ä¹¦ç±ï¼ˆçº§è”åˆ é™¤ç« èŠ‚ï¼‰
    db.delete(book)
    db.commit()
    
    return {"message": f"ä¹¦ç± '{book.title}' å·²åˆ é™¤"}


@router.put("/{book_id}")
async def update_book_put(
    book_id: int,
    title: Optional[str] = Form(None),
    author: Optional[str] = Form(None),
    description: Optional[str] = Form(None),
    content: Optional[str] = Form(None),
    tags: Optional[str] = Form(None),
    status: Optional[str] = Form(None),
    db: Session = Depends(get_db)
):
    """å®Œæ•´æ›´æ–°ä¹¦ç±ä¿¡æ¯ (PUTæ–¹æ³•) - æ”¯æŒFormæ ¼å¼"""
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ›´æ–°æä¾›çš„å­—æ®µ
        if title is not None:
            if not title.strip():
                raise HTTPException(status_code=400, detail="ä¹¦ç±æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
            book.title = title.strip()
        
        if author is not None:
            book.author = author.strip()
        
        if description is not None:
            book.description = description.strip()
        
        if content is not None:
            book.content = content
            book.word_count = len(content)
        
        if tags is not None:
            try:
                parsed_tags = json.loads(tags) if tags else []
                book.tags = json.dumps(parsed_tags, ensure_ascii=False)
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="æ ‡ç­¾æ ¼å¼é”™è¯¯")
        
        if status is not None:
            if status not in ['draft', 'published', 'archived']:
                raise HTTPException(status_code=400, detail="æ— æ•ˆçš„çŠ¶æ€å€¼")
            book.status = status
        
        db.commit()
        db.refresh(book)
        
        return {
            "success": True,
            "data": book.to_dict()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°ä¹¦ç±å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ä¹¦ç±å¤±è´¥: {str(e)}")


@router.patch("/{book_id}")
def update_book_patch(
    book_id: int,
    title: Optional[str] = None,
    author: Optional[str] = None,
    description: Optional[str] = None,
    db: Session = Depends(get_db)
):
    """éƒ¨åˆ†æ›´æ–°ä¹¦ç±ä¿¡æ¯ (PATCHæ–¹æ³•)"""
    book = db.query(Book).filter(Book.id == book_id).first()
    if not book:
        raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
    
    if title is not None:
        book.title = title
    if author is not None:
        book.author = author
    if description is not None:
        book.description = description
    
    db.commit()
    db.refresh(book)
    
    return {
        "success": True,
        "data": book.to_dict()
    } 


@router.get("/{book_id}/analysis-results")
async def get_book_analysis_results(
    book_id: int,
    chapter_ids: Optional[str] = Query(None, description="é€—å·åˆ†éš”çš„ç« èŠ‚IDåˆ—è¡¨"),
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±çš„æ‰€æœ‰æ™ºèƒ½å‡†å¤‡ç»“æœ
    ç”¨äºåˆæˆä¸­å¿ƒåŠ è½½å·²å®Œæˆçš„åˆ†ææ•°æ®
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = db.query(BookChapter, AnalysisResult).join(
            AnalysisResult, BookChapter.id == AnalysisResult.chapter_id, isouter=True
        ).filter(
            BookChapter.book_id == book_id
        )
        
        # å¦‚æœæŒ‡å®šäº†ç« èŠ‚IDï¼Œåˆ™åªæŸ¥è¯¢è¿™äº›ç« èŠ‚
        if chapter_ids:
            try:
                chapter_id_list = [int(id.strip()) for id in chapter_ids.split(',') if id.strip()]
                if chapter_id_list:
                    query = query.filter(BookChapter.id.in_(chapter_id_list))
                    logger.info(f"è¿‡æ»¤ç« èŠ‚ID: {chapter_id_list}")
            except ValueError:
                raise HTTPException(status_code=400, detail="ç« èŠ‚IDæ ¼å¼é”™è¯¯")
        
        chapters_with_analysis = query.order_by(BookChapter.chapter_number).all()
        
        analysis_results = []
        
        for chapter, analysis in chapters_with_analysis:
            if analysis and analysis.synthesis_plan:
                # æ„å»ºåˆ†æç»“æœæ•°æ®
                result_data = {
                    "chapter_id": chapter.id,
                    "chapter_number": chapter.chapter_number,
                    "chapter_title": chapter.chapter_title,
                    "word_count": chapter.word_count,
                    "analysis_id": analysis.id,
                    "synthesis_json": analysis.synthesis_plan,
                    "confidence_score": analysis.confidence_score,
                    "processing_time": analysis.processing_time,
                    "created_at": analysis.created_at.isoformat() if analysis.created_at else None,
                    "updated_at": analysis.updated_at.isoformat() if analysis.updated_at else None
                }
                analysis_results.append(result_data)
        
        logger.info(f"è·å–ä¹¦ç± {book_id} çš„åˆ†æç»“æœ: æ‰¾åˆ° {len(analysis_results)} ä¸ªå·²åˆ†æç« èŠ‚")
        
        return {
            "success": True,
            "data": analysis_results,
            "book_info": {
                "id": book.id,
                "title": book.title,
                "author": book.author,
                "total_chapters": len(chapters_with_analysis),
                "analyzed_chapters": len(analysis_results)
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±åˆ†æç»“æœå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ†æç»“æœå¤±è´¥: {str(e)}") 


# ============= è§’è‰²ç®¡ç†ç›¸å…³API =============

@router.get("/{book_id}/characters")
async def get_book_characters(
    book_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ä¹¦ç±è§’è‰²æ±‡æ€»ä¿¡æ¯
    é«˜æ€§èƒ½ï¼šä¸éå†æ‰€æœ‰ç« èŠ‚ï¼Œç›´æ¥ä»book.character_summaryè¯»å–
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        character_summary = book.get_character_summary()
        voice_mappings = character_summary.get('voice_mappings', {})
        
        # ğŸ”§ æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.info(f"[è°ƒè¯•] è·å–ä¹¦ç±{book_id}è§’è‰²æ±‡æ€»:")
        logger.info(f"  voice_mappings: {voice_mappings}")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå°†é…éŸ³ä¿¡æ¯åˆå¹¶åˆ°è§’è‰²å¯¹è±¡ä¸­
        enhanced_characters = []
        raw_characters = character_summary.get('characters', [])
        
        # åŠ è½½è§’è‰²é…éŸ³åº“æ•°æ®
        character_library = {}
        try:
            from ..models import Character
            library_chars = db.query(Character).filter(Character.book_id == book_id).all()
            character_library = {char.name: char for char in library_chars}
            logger.info(f"ğŸ“š [è§’è‰²é…éŸ³åº“] åŠ è½½äº† {len(character_library)} ä¸ªè§’è‰²")
        except Exception as e:
            logger.warning(f"åŠ è½½è§’è‰²é…éŸ³åº“å¤±è´¥: {e}")
        
        # åŠ è½½VoiceProfileæ•°æ®
        voice_profiles = {}
        try:
            from ..models import VoiceProfile
            profiles = db.query(VoiceProfile).filter(VoiceProfile.status == 'active').all()
            voice_profiles = {profile.id: profile for profile in profiles}
            logger.info(f"ğŸ“‹ [è¯­éŸ³æ¡£æ¡ˆ] åŠ è½½äº† {len(voice_profiles)} ä¸ªè¯­éŸ³æ¡£æ¡ˆ")
        except Exception as e:
            logger.warning(f"åŠ è½½è¯­éŸ³æ¡£æ¡ˆå¤±è´¥: {e}")
        
        for character in raw_characters:
            enhanced_char = dict(character)  # å¤åˆ¶åŸå§‹è§’è‰²æ•°æ®
            char_name = character.get('name', '')
            
            # ğŸ”¥ é‡è¦ï¼šä»voice_mappingsè·å–é…éŸ³ID
            voice_id_str = voice_mappings.get(char_name)
            character_id = None
            voice_id = None
            voice_name = "æœªåˆ†é…"
            in_character_library = False
            is_voice_configured = False
            
            if voice_id_str:
                try:
                    voice_id_int = int(voice_id_str)
                    
                    # ğŸ”¥ æ™ºèƒ½åˆ¤æ–­IDç±»å‹ï¼šä¼˜å…ˆæ£€æŸ¥è§’è‰²é…éŸ³åº“
                    if char_name in character_library:
                        library_char = character_library[char_name]
                        if library_char.id == voice_id_int:
                            # åŒ¹é…è§’è‰²é…éŸ³åº“
                            character_id = library_char.id
                            voice_name = library_char.name
                            in_character_library = True
                            # ğŸ”¥ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æ–‡ä»¶é…ç½®ï¼Œè€Œä¸æ˜¯ç®€å•æ£€æŸ¥status
                            is_voice_configured = bool(library_char.reference_audio_path)
                            logger.info(f"ğŸ­ [é…éŸ³ä¿¡æ¯] {char_name} -> è§’è‰²é…éŸ³åº“ ID:{character_id} (é…éŸ³çŠ¶æ€: {is_voice_configured})")
                        else:
                            logger.warning(f"âš ï¸ [é…éŸ³ä¿¡æ¯] {char_name} åœ¨é…éŸ³åº“ä¸­ä½†IDä¸åŒ¹é…: åº“ä¸­ID={library_char.id}, æ˜ å°„ID={voice_id_int}")
                    
                    # å¦‚æœä¸æ˜¯è§’è‰²é…éŸ³åº“ï¼Œæ£€æŸ¥VoiceProfile
                    if not character_id and voice_id_int in voice_profiles:
                        voice_profile = voice_profiles[voice_id_int]
                        voice_id = voice_profile.id
                        voice_name = voice_profile.name
                        is_voice_configured = True
                        logger.info(f"ğŸ¤ [é…éŸ³ä¿¡æ¯] {char_name} -> VoiceProfile ID:{voice_id}")
                    
                    if not character_id and not voice_id:
                        logger.warning(f"âš ï¸ [é…éŸ³ä¿¡æ¯] {char_name} çš„é…éŸ³ID {voice_id_int} æ— æ³•æ‰¾åˆ°å¯¹åº”é…ç½®")
                        
                except ValueError:
                    logger.warning(f"âš ï¸ [é…éŸ³ä¿¡æ¯] {char_name} çš„é…éŸ³IDæ ¼å¼é”™è¯¯: {voice_id_str}")
            else:
                # æ£€æŸ¥æ˜¯å¦åœ¨è§’è‰²é…éŸ³åº“ä¸­ä½†æœªé…éŸ³
                if char_name in character_library:
                    library_char = character_library[char_name]
                    character_id = library_char.id
                    voice_name = library_char.name
                    in_character_library = True
                    # ğŸ”¥ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æ–‡ä»¶é…ç½®ï¼Œè€Œä¸æ˜¯ç®€å•æ£€æŸ¥status
                    is_voice_configured = bool(library_char.reference_audio_path)
                    logger.info(f"ğŸ­ [é…éŸ³ä¿¡æ¯] {char_name} -> è§’è‰²é…éŸ³åº“ ID:{character_id} (æœªé…ç½®voice_mappings, é…éŸ³çŠ¶æ€: {is_voice_configured})")
            
            # ğŸ”¥ å…³é”®ï¼šæ·»åŠ é…éŸ³ç›¸å…³å­—æ®µåˆ°è§’è‰²å¯¹è±¡
            enhanced_char.update({
                'character_id': character_id,
                'voice_id': voice_id,
                'voice_name': voice_name,
                'in_character_library': in_character_library,
                'is_voice_configured': is_voice_configured
            })
            
            enhanced_characters.append(enhanced_char)
        
        logger.info(f"âœ… [æ•°æ®å¢å¼º] æˆåŠŸå¢å¼º {len(enhanced_characters)} ä¸ªè§’è‰²çš„é…éŸ³ä¿¡æ¯")
        
        return {
            "success": True,
            "data": {
                "book_id": book_id,
                "book_title": book.title,
                "characters": enhanced_characters,  # ğŸ”¥ ä½¿ç”¨å¢å¼ºåçš„è§’è‰²æ•°æ®
                "voice_mappings": voice_mappings,
                "last_updated": character_summary.get('last_updated'),
                "total_chapters_analyzed": character_summary.get('total_chapters_analyzed', 0),
                "character_count": len(enhanced_characters),
                "configured_count": len([c for c in enhanced_characters if c.get('is_voice_configured')])
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¹¦ç±è§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}")


@router.post("/{book_id}/characters/{character_name}/voice-mapping")
async def set_character_voice_mapping(
    book_id: int,
    character_name: str,
    voice_id: str = Form(...),
    db: Session = Depends(get_db)
):
    """
    è®¾ç½®å•ä¸ªè§’è‰²çš„è¯­éŸ³æ˜ å°„
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ£€æŸ¥è§’è‰²æ˜¯å¦å­˜åœ¨
        character_names = book.get_all_character_names()
        if character_name not in character_names:
            raise HTTPException(status_code=404, detail=f"è§’è‰² '{character_name}' ä¸å­˜åœ¨")
        
        # è®¾ç½®è¯­éŸ³æ˜ å°„
        book.set_character_voice_mapping(character_name, voice_id)
        db.commit()
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ­¥æ›´æ–°ç›¸å…³ç« èŠ‚çš„synthesis_plan
        # è·å–å®Œæ•´çš„è§’è‰²è¯­éŸ³æ˜ å°„ï¼ˆè€Œä¸æ˜¯åªä¼ é€’å•ä¸ªè§’è‰²æ˜ å°„ï¼‰
        db.refresh(book)  # ç¡®ä¿è·å–æœ€æ–°æ•°æ®
        complete_voice_mappings = book.get_character_summary().get('voice_mappings', {})
        
        if complete_voice_mappings:
            updated_chapters = await _sync_character_voice_to_synthesis_plans(
                book_id, complete_voice_mappings, db
            )
        else:
            updated_chapters = 0
        
        logger.info(f"è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„: ä¹¦ç±{book_id} - {character_name} -> {voice_id}ï¼ŒåŒæ­¥æ›´æ–°äº† {updated_chapters} ä¸ªç« èŠ‚")
        
        return {
            "success": True,
            "message": f"å·²è®¾ç½®è§’è‰² '{character_name}' çš„è¯­éŸ³é…ç½®ï¼ŒåŒæ­¥æ›´æ–°äº† {updated_chapters} ä¸ªç« èŠ‚çš„åˆæˆè®¡åˆ’",
            "data": {
                "character_name": character_name,
                "voice_id": voice_id,
                "updated_chapters": updated_chapters,
                "updated_at": datetime.utcnow().isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è®¾ç½®è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")


@router.post("/{book_id}/characters/batch-voice-mappings")
async def batch_set_character_voice_mappings(
    book_id: int,
    mappings: str = Form(..., description="è§’è‰²è¯­éŸ³æ˜ å°„JSONå­—ç¬¦ä¸²ï¼Œæ ¼å¼: {è§’è‰²å: voice_id}"),
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # è§£ææ˜ å°„æ•°æ®
        if isinstance(mappings, str):
            try:
                mappings = json.loads(mappings)
            except json.JSONDecodeError:
                raise HTTPException(status_code=400, detail="æ˜ å°„æ•°æ®æ ¼å¼é”™è¯¯")
        
        if not isinstance(mappings, dict):
            raise HTTPException(status_code=400, detail="æ˜ å°„æ•°æ®å¿…é¡»æ˜¯å­—å…¸æ ¼å¼")
        
        # æ£€æŸ¥æ‰€æœ‰è§’è‰²æ˜¯å¦å­˜åœ¨
        character_names = book.get_all_character_names()
        invalid_characters = [char for char in mappings.keys() if char not in character_names]
        if invalid_characters:
            raise HTTPException(
                status_code=400, 
                detail=f"ä»¥ä¸‹è§’è‰²ä¸å­˜åœ¨: {', '.join(invalid_characters)}"
            )
        
        # æ‰¹é‡è®¾ç½®è¯­éŸ³æ˜ å°„
        success_count = 0
        updated_mappings = {}
        for character_name, voice_id in mappings.items():
            if voice_id:  # åªè®¾ç½®éç©ºçš„voice_id
                logger.info(f"[è°ƒè¯•] è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„: {character_name} -> {voice_id}")
                book.set_character_voice_mapping(character_name, voice_id)
                updated_mappings[character_name] = voice_id
                success_count += 1
        
        # ğŸ”¥ è°ƒè¯•ï¼šæäº¤å‰æ£€æŸ¥æ•°æ®
        logger.info(f"[è°ƒè¯•] æäº¤å‰æ£€æŸ¥ character_summary: {book.character_summary}")
        db.commit()
        
        # ğŸ”¥ è°ƒè¯•ï¼šæäº¤åé‡æ–°æŸ¥è¯¢éªŒè¯
        db.refresh(book)
        post_commit_summary = book.get_character_summary()
        # ğŸ”¥ å®‰å…¨ç±»å‹æ£€æŸ¥
        if isinstance(post_commit_summary, dict):
            logger.info(f"[è°ƒè¯•] æäº¤åé‡æ–°æŸ¥è¯¢ voice_mappings: {post_commit_summary.get('voice_mappings', {})}")
        else:
            logger.warning(f"[è°ƒè¯•] æäº¤åæ•°æ®æ ¼å¼å¼‚å¸¸: {type(post_commit_summary)} - {post_commit_summary}")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ­¥æ›´æ–°æ‰€æœ‰ç›¸å…³ç« èŠ‚çš„synthesis_plan
        # è·å–å®Œæ•´çš„è§’è‰²è¯­éŸ³æ˜ å°„ï¼ˆè€Œä¸æ˜¯åªä¼ é€’æœ¬æ¬¡æ›´æ–°çš„éƒ¨åˆ†æ˜ å°„ï¼‰
        db.refresh(book)  # ç¡®ä¿è·å–æœ€æ–°æ•°æ®
        complete_voice_mappings = book.get_character_summary().get('voice_mappings', {})
        
        if complete_voice_mappings:
            # ğŸ”¥ ä¿®å¤ï¼šä¼ é€’å®Œæ•´çš„è§’è‰²æ˜ å°„ï¼Œç¡®ä¿æ‰€æœ‰è§’è‰²éƒ½èƒ½è¢«æ­£ç¡®åŒæ­¥
            updated_chapters = await _sync_character_voice_to_synthesis_plans(
                book_id, complete_voice_mappings, db
            )
            logger.info(f"åŒæ­¥æ›´æ–°äº† {updated_chapters} ä¸ªç« èŠ‚çš„synthesis_planï¼Œå®Œæ•´æ˜ å°„: {complete_voice_mappings}")
        else:
            updated_chapters = 0
            logger.warning(f"ä¹¦ç± {book_id} æ²¡æœ‰ä»»ä½•è§’è‰²è¯­éŸ³æ˜ å°„ï¼Œè·³è¿‡åŒæ­¥")
        
        logger.info(f"æ‰¹é‡è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„: ä¹¦ç±{book_id} - æˆåŠŸè®¾ç½® {success_count} ä¸ªè§’è‰²")
        
        return {
            "success": True,
            "message": f"æˆåŠŸè®¾ç½® {success_count} ä¸ªè§’è‰²çš„è¯­éŸ³é…ç½®ï¼Œå·²åŒæ­¥æ›´æ–° {updated_chapters} ä¸ªç« èŠ‚çš„åˆæˆè®¡åˆ’",
            "data": {
                "book_id": book_id,
                "updated_mappings": updated_mappings,
                "success_count": success_count,
                "updated_chapters": updated_chapters,
                "updated_at": datetime.utcnow().isoformat()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡è®¾ç½®è§’è‰²è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è®¾ç½®å¤±è´¥: {str(e)}")


@router.post("/{book_id}/chapters/batch-status")
async def get_chapters_batch_status(
    book_id: int,
    chapter_ids: List[int] = Query(None, description="ç« èŠ‚IDåˆ—è¡¨ï¼Œä¸ä¼ åˆ™è¿”å›æ‰€æœ‰ç« èŠ‚"),
    include_analysis: bool = Query(False, description="æ˜¯å¦åŒ…å«åˆ†æç»“æœæ‘˜è¦"),
    include_synthesis: bool = Query(False, description="æ˜¯å¦åŒ…å«åˆæˆçŠ¶æ€"),
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡è·å–ç« èŠ‚çŠ¶æ€ä¿¡æ¯
    
    æ€§èƒ½ä¼˜åŒ–ï¼š
    - å•æ¬¡è¯·æ±‚è·å–å¤šä¸ªç« èŠ‚çš„çŠ¶æ€ï¼Œé¿å…8000+æ¬¡å•ç‹¬è¯·æ±‚
    - æ”¯æŒé€‰æ‹©æ€§åŒ…å«åˆ†æç»“æœå’ŒåˆæˆçŠ¶æ€
    - è¿”å›è½»é‡çº§çŠ¶æ€æ•°æ®
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ„å»ºæŸ¥è¯¢
        query = db.query(BookChapter).filter(BookChapter.book_id == book_id)
        
        # å¦‚æœæŒ‡å®šäº†ç« èŠ‚IDï¼Œåˆ™åªæŸ¥è¯¢è¿™äº›ç« èŠ‚
        if chapter_ids:
            query = query.filter(BookChapter.id.in_(chapter_ids))
        
        chapters = query.order_by(BookChapter.chapter_number).all()
        
        if not chapters:
            return {
                "success": True,
                "data": [],
                "total": 0,
                "message": "æœªæ‰¾åˆ°ç« èŠ‚"
            }
        
        # å‡†å¤‡ç»“æœ
        results = []
        
        # å¦‚æœéœ€è¦åˆ†æç»“æœï¼Œæ‰¹é‡æŸ¥è¯¢
        analysis_map = {}
        if include_analysis:
            chapter_ids_list = [c.id for c in chapters]
            analysis_results = db.query(AnalysisResult).filter(
                AnalysisResult.chapter_id.in_(chapter_ids_list)
            ).all()
            analysis_map = {a.chapter_id: a for a in analysis_results}
        
        # åˆæˆä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
        synthesis_map = {}
        if include_synthesis:
            from ..models import SynthesisTask
            chapter_ids_list = [c.id for c in chapters]
            synthesis_tasks = db.query(SynthesisTask).filter(
                SynthesisTask.chapter_id.in_(chapter_ids_list)
            ).all()
            synthesis_map = {t.chapter_id: t for t in synthesis_tasks}
        
        # æ„å»ºå“åº”æ•°æ®
        for chapter in chapters:
            chapter_data = {
                "id": chapter.id,
                "chapter_number": chapter.chapter_number,
                "chapter_title": chapter.chapter_title,
                "word_count": chapter.word_count,
                "analysis_status": chapter.analysis_status,
                "synthesis_status": chapter.synthesis_status,
                "updated_at": chapter.updated_at.isoformat() if chapter.updated_at else None
            }
            
            # æ·»åŠ åˆ†æç»“æœæ‘˜è¦
            if include_analysis and chapter.id in analysis_map:
                analysis = analysis_map[chapter.id]
                chapter_data["analysis_summary"] = {
                    "id": analysis.id,
                    "status": analysis.status,
                    "confidence_score": analysis.confidence_score,
                    "character_count": len(analysis.detected_characters or []),
                    "segment_count": len(analysis.synthesis_plan.get('segments', [])) if analysis.synthesis_plan else 0,
                    "created_at": analysis.created_at.isoformat() if analysis.created_at else None
                }
            
            # æ·»åŠ åˆæˆçŠ¶æ€
            if include_synthesis and chapter.id in synthesis_map:
                synthesis = synthesis_map[chapter.id]
                chapter_data["synthesis_summary"] = {
                    "task_id": synthesis.id,
                    "status": synthesis.status,
                    "progress": synthesis.progress,
                    "duration": synthesis.duration,
                    "created_at": synthesis.created_at.isoformat() if synthesis.created_at else None
                }
            
            results.append(chapter_data)
        
        return {
            "success": True,
            "data": results,
            "total": len(results),
            "book_info": {
                "id": book.id,
                "title": book.title,
                "total_chapters": book.chapter_count
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡è·å–ç« èŠ‚çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡è·å–ç« èŠ‚çŠ¶æ€å¤±è´¥: {str(e)}")


@router.post("/{book_id}/characters/rebuild-summary")
async def rebuild_character_summary(
    book_id: int,
    db: Session = Depends(get_db)
):
    """
    é‡å»ºä¹¦ç±è§’è‰²æ±‡æ€»ï¼ˆä»æ‰€æœ‰ç« èŠ‚åˆ†æç»“æœé‡æ–°æ±‡æ€»ï¼‰
    ç”¨äºä¿®å¤æˆ–æ›´æ–°æ±‡æ€»æ•°æ®
    """
    try:
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # è·å–æ‰€æœ‰å·²åˆ†æçš„ç« èŠ‚
        chapters_with_analysis = db.query(BookChapter, AnalysisResult).join(
            AnalysisResult, BookChapter.id == AnalysisResult.chapter_id
        ).filter(
            BookChapter.book_id == book_id,
            AnalysisResult.detected_characters.isnot(None)
        ).all()
        
        if not chapters_with_analysis:
            return {
                "success": True,
                "message": "æš‚æ— ç« èŠ‚åˆ†ææ•°æ®ï¼Œè§’è‰²æ±‡æ€»ä¸ºç©º",
                "data": book.get_character_summary()
            }
        
        # ä¿å­˜å½“å‰çš„è¯­éŸ³æ˜ å°„é…ç½®
        try:
            current_summary = book.get_character_summary()
            # ğŸ”¥ ç¡®ä¿current_summaryæ˜¯å­—å…¸æ ¼å¼
            if isinstance(current_summary, dict):
                current_mappings = current_summary.get('voice_mappings', {})
            else:
                logger.warning(f"è§’è‰²æ±‡æ€»æ•°æ®æ ¼å¼å¼‚å¸¸: {type(current_summary)} - {current_summary}")
                current_mappings = {}
        except Exception as e:
            logger.warning(f"è·å–å½“å‰è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ç©ºæ˜ å°„")
            current_mappings = {}
        
        # æ¸…ç©ºè§’è‰²æ±‡æ€»ï¼Œé‡æ–°æ„å»º
        book.character_summary = None
        
        # é€ç« èŠ‚æ›´æ–°è§’è‰²æ±‡æ€»
        total_rebuilt = 0
        for chapter, analysis in chapters_with_analysis:
            detected_characters = analysis.detected_characters or []
            if detected_characters:
                book.update_character_summary(detected_characters, chapter.id)
                total_rebuilt += 1
        
        # æ¢å¤ä¹‹å‰çš„è¯­éŸ³æ˜ å°„é…ç½®
        try:
            current_summary = book.get_character_summary()
            # ğŸ”¥ å¢å¼ºå®‰å…¨æ£€æŸ¥
            if isinstance(current_summary, dict):
                current_summary['voice_mappings'] = current_mappings
                book.character_summary = current_summary
                flag_modified(book, 'character_summary')  # ç¡®ä¿SQLAlchemyæ£€æµ‹åˆ°ä¿®æ”¹
            else:
                logger.warning(f"è§’è‰²æ±‡æ€»æ•°æ®æ ¼å¼å¼‚å¸¸: {type(current_summary)}, è·³è¿‡è¯­éŸ³æ˜ å°„æ¢å¤")
        except Exception as e:
            logger.warning(f"æ¢å¤è¯­éŸ³æ˜ å°„å¤±è´¥: {str(e)}")
        
        db.commit()
        
        logger.info(f"é‡å»ºä¹¦ç±è§’è‰²æ±‡æ€»: ä¹¦ç±{book_id} - å¤„ç†äº† {total_rebuilt} ä¸ªç« èŠ‚")
        
        return {
            "success": True,
            "message": f"æˆåŠŸé‡å»ºè§’è‰²æ±‡æ€»ï¼Œå¤„ç†äº† {total_rebuilt} ä¸ªç« èŠ‚",
            "data": book.get_character_summary()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡å»ºè§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é‡å»ºæ±‡æ€»å¤±è´¥: {str(e)}")


@router.get("/{book_id}/chapters/search")
async def search_chapters(
    book_id: int,
    query: str = Query("", description="æœç´¢å…³é”®è¯ï¼Œæ”¯æŒç« èŠ‚æ ‡é¢˜æ¨¡ç³Šæœç´¢"),
    chapter_number: int = Query(None, description="æŒ‰ç« èŠ‚å·ç²¾ç¡®æœç´¢"),
    status_filter: str = Query("", description="çŠ¶æ€è¿‡æ»¤"),
    skip: int = Query(0, description="è·³è¿‡çš„è®°å½•æ•°"),
    limit: int = Query(50, description="è¿”å›çš„è®°å½•æ•°"),
    db: Session = Depends(get_db)
):
    """
    æœç´¢ç« èŠ‚
    
    æ”¯æŒï¼š
    - æŒ‰ç« èŠ‚æ ‡é¢˜æ¨¡ç³Šæœç´¢
    - æŒ‰ç« èŠ‚å·ç²¾ç¡®æœç´¢
    - çŠ¶æ€è¿‡æ»¤
    - åˆ†é¡µè¿”å›
    """
    try:
        # æ£€æŸ¥ä¹¦ç±æ˜¯å¦å­˜åœ¨
        book = db.query(Book).filter(Book.id == book_id).first()
        if not book:
            raise HTTPException(status_code=404, detail="ä¹¦ç±ä¸å­˜åœ¨")
        
        # æ„å»ºæŸ¥è¯¢
        query_obj = db.query(BookChapter).filter(BookChapter.book_id == book_id)
        
        # åº”ç”¨æœç´¢æ¡ä»¶
        if query:
            search_pattern = f"%{query}%"
            query_obj = query_obj.filter(BookChapter.chapter_title.like(search_pattern))
        
        if chapter_number:
            query_obj = query_obj.filter(BookChapter.chapter_number == chapter_number)
        
        if status_filter:
            query_obj = query_obj.filter(BookChapter.analysis_status == status_filter)
        
        # è·å–æ€»æ•°
        total = query_obj.count()
        
        # åº”ç”¨åˆ†é¡µ
        chapters = query_obj.order_by(BookChapter.chapter_number).offset(skip).limit(limit).all()
        
        # è¿”å›ç²¾ç®€æ•°æ®
        chapters_data = []
        for chapter in chapters:
            chapters_data.append({
                "id": chapter.id,
                "chapter_number": chapter.chapter_number,
                "chapter_title": chapter.chapter_title,
                "word_count": chapter.word_count,
                "analysis_status": chapter.analysis_status,
                "synthesis_status": chapter.synthesis_status,
                "created_at": chapter.created_at.isoformat() if chapter.created_at else None,
                "updated_at": chapter.updated_at.isoformat() if chapter.updated_at else None
            })
        
        return {
            "success": True,
            "data": chapters_data,
            "total": total,
            "skip": skip,
            "limit": limit,
            "query": query,
            "pagination": {
                "page": (skip // limit) + 1 if limit > 0 else 1,
                "page_size": limit,
                "total": total,
                "total_pages": (total + limit - 1) // limit if limit > 0 else 1,
                "has_next": skip + limit < total,
                "has_prev": skip > 0
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æœç´¢ç« èŠ‚å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æœç´¢ç« èŠ‚å¤±è´¥: {str(e)}")


# ========== å†…éƒ¨è¾…åŠ©å‡½æ•° ==========

async def _sync_character_voice_to_synthesis_plans(
    book_id: int, 
    character_voice_mappings: Dict[str, Any], 
    db: Session
) -> int:
    """
    åŒæ­¥è§’è‰²è¯­éŸ³é…ç½®åˆ°æ‰€æœ‰ç›¸å…³ç« èŠ‚çš„synthesis_plan
    
    ğŸš€ æ–°æ¶æ„è¯´æ˜ï¼š
    åœ¨æ–°æ¶æ„ä¸­ï¼Œsynthesis_planå­˜å‚¨character_idè€Œä¸æ˜¯voice_idï¼Œ
    åˆæˆæ—¶ä¼šåŠ¨æ€æŸ¥æ‰¾Characterè¡¨è·å–æœ€æ–°é…éŸ³ï¼Œå› æ­¤ä¸å†éœ€è¦æ‰‹åŠ¨åŒæ­¥ã€‚
    
    ğŸ”„ å‘åå…¼å®¹ï¼š
    æ­¤å‡½æ•°ä¿ç•™ç”¨äºå¤„ç†ä½¿ç”¨æ—§æ¶æ„çš„å†å²æ•°æ®ï¼Œ
    æ–°çš„æ™ºèƒ½å‡†å¤‡å°†ç›´æ¥ç”Ÿæˆä½¿ç”¨character_idçš„synthesis_planã€‚
    
    Args:
        book_id: ä¹¦ç±ID
        character_voice_mappings: è§’è‰²è¯­éŸ³æ˜ å°„ {è§’è‰²å: id_value}
        db: æ•°æ®åº“ä¼šè¯
    
    Returns:
        æ›´æ–°çš„ç« èŠ‚æ•°é‡
    """
    try:
        # ğŸ”¥ å¢å¼ºè°ƒè¯•ï¼šè®°å½•ä¼ å…¥çš„æ˜ å°„ä¿¡æ¯
        logger.info(f"ğŸš€ [å¼€å§‹åŒæ­¥] ä¹¦ç± {book_id}, ä¼ å…¥æ˜ å°„: {character_voice_mappings}")
        
        # ğŸ”¥ CRITICAL FIX: æ ¹æ®ä¼ å…¥IDçš„å®é™…ç±»å‹å»ºç«‹æ­£ç¡®æ˜ å°„
        # Step 1: åˆ†æä¼ å…¥çš„IDï¼ŒåŒºåˆ†Character IDå’ŒVoiceProfile ID
        character_mappings = {}  # {è§’è‰²å: Characterå¯¹è±¡}
        voice_profile_mappings = {}  # {è§’è‰²å: VoiceProfileå¯¹è±¡}
        id_to_name_mapping = {}  # ç”¨äºæ—¥å¿—æ˜¾ç¤º
        
        # åŠ è½½è§’è‰²é…éŸ³åº“æ•°æ®
        try:
            from ...models import Character
            characters = db.query(Character).filter(
                Character.book_id == book_id
            ).all()
            character_id_map = {char.id: char for char in characters}
            logger.info(f"ğŸ“š [è§’è‰²é…éŸ³åº“] åŠ è½½äº† {len(character_id_map)} ä¸ªè§’è‰²é…éŸ³åº“è®°å½•")
        except Exception as e:
            logger.warning(f"è·å–è§’è‰²é…éŸ³åº“å¤±è´¥: {str(e)}")
            character_id_map = {}

        # åŠ è½½VoiceProfileæ•°æ®  
        try:
            from ...models import VoiceProfile
            voices = db.query(VoiceProfile).filter(VoiceProfile.status == 'active').all()
            voice_profile_id_map = {voice.id: voice for voice in voices}
            logger.info(f"ğŸ“‹ [è¯­éŸ³æ¡£æ¡ˆ] åŠ è½½äº† {len(voice_profile_id_map)} ä¸ªè¯­éŸ³æ¡£æ¡ˆè®°å½•")
        except Exception as e:
            logger.warning(f"è·å–è¯­éŸ³æ¡£æ¡ˆå¤±è´¥: {str(e)}")
            voice_profile_id_map = {}

        # Step 2: åˆ†æä¼ å…¥æ˜ å°„ï¼Œåˆ¤æ–­æ¯ä¸ªIDçš„çœŸå®ç±»å‹
        for character_name, id_value in character_voice_mappings.items():
            try:
                id_int = int(id_value)
                
                # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºCharacter ID
                if id_int in character_id_map:
                    character_mappings[character_name] = character_id_map[id_int]
                    id_to_name_mapping[str(id_int)] = f"{character_id_map[id_int].name}(è§’è‰²é…éŸ³åº“)"
                    logger.info(f"ğŸ­ [IDç±»å‹è¯†åˆ«] è§’è‰²'{character_name}' -> Character ID {id_int} ({character_id_map[id_int].name})")
                
                # å¦‚æœä¸æ˜¯Character IDï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºVoiceProfile ID
                elif id_int in voice_profile_id_map:
                    voice_profile_mappings[character_name] = voice_profile_id_map[id_int]
                    id_to_name_mapping[str(id_int)] = f"{voice_profile_id_map[id_int].name}(è¯­éŸ³æ¡£æ¡ˆ)"
                    logger.info(f"ğŸ¤ [IDç±»å‹è¯†åˆ«] è§’è‰²'{character_name}' -> VoiceProfile ID {id_int} ({voice_profile_id_map[id_int].name})")
                
                else:
                    logger.warning(f"âš ï¸ [IDç±»å‹è¯†åˆ«] è§’è‰²'{character_name}' -> ID {id_int} åœ¨ä¸¤ä¸ªè¡¨ä¸­éƒ½ä¸å­˜åœ¨")
                    id_to_name_mapping[str(id_int)] = f"ID_{id_int}(æœªçŸ¥)"
                    
            except (ValueError, TypeError):
                logger.warning(f"âš ï¸ [IDç±»å‹è¯†åˆ«] è§’è‰²'{character_name}' -> æ— æ•ˆIDæ ¼å¼: {id_value}")

        logger.info(f"ğŸ¯ [æ˜ å°„æ±‡æ€»] Characteræ˜ å°„: {len(character_mappings)}, VoiceProfileæ˜ å°„: {len(voice_profile_mappings)}")
        
        # è·å–è¿™æœ¬ä¹¦æ‰€æœ‰å·²å®Œæˆåˆ†æçš„ç« èŠ‚
        chapters_with_analysis = db.query(BookChapter, AnalysisResult).join(
            AnalysisResult, BookChapter.id == AnalysisResult.chapter_id
        ).filter(
            BookChapter.book_id == book_id,
            AnalysisResult.status == 'completed',
            AnalysisResult.synthesis_plan.isnot(None)
        ).all()
        
        if not chapters_with_analysis:
            logger.info(f"ä¹¦ç± {book_id} æš‚æ— éœ€è¦åŒæ­¥çš„ç« èŠ‚åˆ†æç»“æœ")
            return 0
        
        updated_count = 0
        
        for chapter, analysis in chapters_with_analysis:
            try:
                synthesis_plan = analysis.synthesis_plan
                if not synthesis_plan:
                    continue
                
                # ğŸ”¥ ä¿®å¤ï¼šæ”¯æŒä¸¤ç§æ•°æ®ç»“æ„
                # ç»“æ„1: {'segments': [...]}  (æ—§ç‰ˆæœ¬)
                # ç»“æ„2: {'synthesis_plan': [...], 'project_info': {...}, 'characters': [...]}  (æ–°ç‰ˆæœ¬)
                segments = None
                if 'segments' in synthesis_plan:
                    segments = synthesis_plan.get('segments', [])
                elif 'synthesis_plan' in synthesis_plan:
                    segments = synthesis_plan.get('synthesis_plan', [])
                
                if not segments or not isinstance(segments, list):
                    logger.debug(f"ç« èŠ‚ {chapter.id} synthesis_planæ ¼å¼ä¸åŒ¹é…æˆ–ä¸ºç©ºï¼Œè·³è¿‡åŒæ­¥")
                    continue
                plan_updated = False
                
                # éå†æ¯ä¸ªæ®µè½ï¼Œæ›´æ–°åŒ¹é…è§’è‰²çš„IDé…ç½®
                for segment in segments:
                    speaker = segment.get('speaker', '')
                    
                    # ğŸ”¥ æ™ºèƒ½è§’è‰²åŒ¹é…ï¼šæ”¯æŒç²¾ç¡®åŒ¹é…å’Œæ¨¡ç³ŠåŒ¹é…
                    matched_character = None
                    matched_voice_profile = None
                    matched_character_name = None
                    
                    # 1. ç²¾ç¡®åŒ¹é…
                    if speaker in character_mappings:
                        matched_character = character_mappings[speaker]
                        matched_character_name = speaker
                        logger.debug(f"ğŸ¯ [ç²¾ç¡®åŒ¹é…-è§’è‰²] è§’è‰² '{speaker}' æ‰¾åˆ°Characteré…ç½®: ID={matched_character.id}")
                    elif speaker in voice_profile_mappings:
                        matched_voice_profile = voice_profile_mappings[speaker]
                        matched_character_name = speaker
                        logger.debug(f"ğŸ¯ [ç²¾ç¡®åŒ¹é…-è¯­éŸ³] è§’è‰² '{speaker}' æ‰¾åˆ°VoiceProfileé…ç½®: ID={matched_voice_profile.id}")
                    
                    # 2. æ¨¡ç³ŠåŒ¹é…ï¼ˆå¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼‰
                    elif speaker:
                        # å…ˆåœ¨è§’è‰²é…éŸ³åº“ä¸­æ¨¡ç³ŠåŒ¹é…
                        for config_name, character in character_mappings.items():
                            if (speaker in config_name) or (config_name in speaker):
                                matched_character = character
                                matched_character_name = config_name
                                logger.debug(f"ğŸ” [æ¨¡ç³ŠåŒ¹é…-è§’è‰²] è§’è‰² '{speaker}' åŒ¹é…åˆ°é…ç½®è§’è‰² '{config_name}': Character ID={character.id}")
                                break
                            
                            # æ£€æŸ¥å»é™¤å¸¸è§åç¼€åæ˜¯å¦åŒ¹é…
                            clean_speaker = speaker.rstrip('å‡ä¸´æ—¶å¤‡ç”¨')
                            clean_config = config_name.rstrip('å‡ä¸´æ—¶å¤‡ç”¨')
                            if clean_speaker == clean_config and len(clean_speaker) > 1:
                                matched_character = character
                                matched_character_name = config_name
                                logger.debug(f"ğŸ§¹ [åç¼€åŒ¹é…-è§’è‰²] è§’è‰² '{speaker}' é€šè¿‡å»é™¤åç¼€åŒ¹é…åˆ° '{config_name}': Character ID={character.id}")
                                break
                        
                        # å¦‚æœè§’è‰²é…éŸ³åº“æ²¡æ‰¾åˆ°ï¼Œå†åœ¨VoiceProfileä¸­æ¨¡ç³ŠåŒ¹é…
                        if not matched_character:
                            for config_name, voice_profile in voice_profile_mappings.items():
                                if (speaker in config_name) or (config_name in speaker):
                                    matched_voice_profile = voice_profile
                                    matched_character_name = config_name
                                    logger.debug(f"ğŸ” [æ¨¡ç³ŠåŒ¹é…-è¯­éŸ³] è§’è‰² '{speaker}' åŒ¹é…åˆ°é…ç½®è§’è‰² '{config_name}': VoiceProfile ID={voice_profile.id}")
                                    break
                    
                    # æ£€æŸ¥è¿™ä¸ªè§’è‰²æ˜¯å¦æ‰¾åˆ°äº†åŒ¹é…çš„é…ç½®
                    if matched_character or matched_voice_profile:
                        old_character_id = segment.get('character_id')
                        old_voice_id = segment.get('voice_id')
                        old_voice_name = segment.get('voice_name', 'æœªåˆ†é…')
                        
                        # ğŸš€ æ ¹æ®åŒ¹é…ç±»å‹è®¾ç½®æ­£ç¡®çš„IDå­—æ®µ
                        if matched_character:
                            # è§’è‰²é…éŸ³åº“ï¼šè®¾ç½®character_idï¼Œæ¸…é™¤voice_id
                            new_character_id = matched_character.id
                            new_voice_name = matched_character.name
                            
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                            character_id_changed = old_character_id != new_character_id
                            voice_id_exists = old_voice_id is not None
                            voice_name_wrong = old_voice_name != new_voice_name
                            
                            if character_id_changed or voice_id_exists or voice_name_wrong:
                                segment['character_id'] = new_character_id
                                segment['voice_name'] = new_voice_name
                                
                                # ğŸ”¥ å…³é”®ï¼šæ¸…é™¤voice_idé¿å…IDç©ºé—´å†²çª
                                if 'voice_id' in segment:
                                    del segment['voice_id']
                                
                                plan_updated = True
                                logger.info(f"âœ… [è§’è‰²åŒæ­¥] {speaker} (é€šè¿‡{matched_character_name}é…ç½®): character_id={new_character_id}, voice_name='{new_voice_name}' (æ¸…é™¤voice_id)")
                        
                        elif matched_voice_profile:
                            # VoiceProfileï¼šè®¾ç½®voice_idï¼Œæ¸…é™¤character_id  
                            new_voice_id = matched_voice_profile.id
                            new_voice_name = matched_voice_profile.name
                            
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                            voice_id_changed = old_voice_id != new_voice_id
                            character_id_exists = old_character_id is not None
                            voice_name_wrong = old_voice_name != new_voice_name
                            
                            if voice_id_changed or character_id_exists or voice_name_wrong:
                                segment['voice_id'] = new_voice_id
                                segment['voice_name'] = new_voice_name
                                
                                # ğŸ”¥ å…³é”®ï¼šæ¸…é™¤character_idé¿å…IDç©ºé—´å†²çª
                                if 'character_id' in segment:
                                    del segment['character_id']
                                
                                plan_updated = True
                                logger.info(f"âœ… [è¯­éŸ³åŒæ­¥] {speaker} (é€šè¿‡{matched_character_name}é…ç½®): voice_id={new_voice_id}, voice_name='{new_voice_name}' (æ¸…é™¤character_id)")
                
                # å¦‚æœæœ‰æ›´æ–°ï¼Œä¿å­˜åˆ°æ•°æ®åº“
                if plan_updated:
                    # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®æ•°æ®ç»“æ„ä¿å­˜å›æ­£ç¡®çš„ä½ç½®
                    if 'segments' in synthesis_plan:
                        synthesis_plan['segments'] = segments
                    elif 'synthesis_plan' in synthesis_plan:
                        synthesis_plan['synthesis_plan'] = segments
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶SQLAlchemyæ£€æµ‹JSONå­—æ®µä¿®æ”¹
                    from sqlalchemy.orm.attributes import flag_modified
                    analysis.synthesis_plan = synthesis_plan
                    flag_modified(analysis, 'synthesis_plan')
                    
                    # ğŸ”¥ CRITICAL FIX: æ¸…ç©ºfinal_configé¿å…APIè¿”å›æ—§æ•°æ®
                    # å½“synthesis_planæ›´æ–°æ—¶ï¼Œè‡ªåŠ¨æ¸…ç©ºfinal_configï¼Œç¡®ä¿APIè¿”å›æœ€æ–°åŒæ­¥çš„æ•°æ®
                    if analysis.final_config:
                        logger.info(f"ğŸ—‘ï¸ [æ¸…ç©ºç¼“å­˜] ç« èŠ‚ {chapter.id} æ¸…ç©ºfinal_configï¼Œé¿å…APIè¿”å›è¿‡æœŸæ•°æ®")
                        analysis.final_config = None
                        flag_modified(analysis, 'final_config')
                    
                    updated_count += 1
                    logger.info(f"âœ… [ç« èŠ‚åŒæ­¥] ç« èŠ‚ {chapter.id} '{chapter.title}' åŒæ­¥å®Œæˆ")
                
            except Exception as e:
                logger.error(f"åŒæ­¥ç« èŠ‚ {chapter.id} å¤±è´¥: {str(e)}")
                continue
        
        # æäº¤æ‰€æœ‰æ›´æ”¹
        db.commit()
        logger.info(f"ğŸ‰ [åŒæ­¥å®Œæˆ] ä¹¦ç± {book_id} å…±åŒæ­¥äº† {updated_count} ä¸ªç« èŠ‚çš„synthesis_plan")
        
        return updated_count
        
    except Exception as e:
        logger.error(f"åŒæ­¥è§’è‰²è¯­éŸ³é…ç½®å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        db.rollback()
        return 0 