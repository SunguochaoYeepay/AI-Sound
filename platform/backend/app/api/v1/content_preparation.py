"""
å†…å®¹å‡†å¤‡API
æä¾›å°è¯´ç« èŠ‚è¯­éŸ³åˆæˆå‰çš„æ™ºèƒ½å†…å®¹å‡†å¤‡åŠŸèƒ½
"""

from fastapi import APIRouter, Depends, HTTPException, Query, Body
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional, Dict, Any
import logging

from app.database import get_db
from app.models import BookChapter, Book
from app.services.content_preparation_service import ContentPreparationService

router = APIRouter(prefix="/content-preparation")
logger = logging.getLogger(__name__)

# æœåŠ¡å®ä¾‹å°†åœ¨æ¯ä¸ªè¯·æ±‚ä¸­åˆ›å»º

class PreparationRequest(BaseModel):
    """æ™ºèƒ½å‡†å¤‡è¯·æ±‚æ¨¡å‹"""
    auto_add_narrator: bool = True
    processing_mode: str = "auto"
    tts_optimization: str = "balanced"  # fast, balanced, quality


@router.get("/content-stats/{chapter_id}")
async def get_content_stats(
    chapter_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç« èŠ‚å†…å®¹ç»Ÿè®¡ä¿¡æ¯
    ç”¨äºå¿«é€Ÿäº†è§£ç« èŠ‚åŸºæœ¬ä¿¡æ¯å’Œå¤„ç†å»ºè®®
    """
    try:
        # è·å–ç« èŠ‚
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹å¹¶è·å–ç»Ÿè®¡ä¿¡æ¯
        content_prep_service = ContentPreparationService(db)
        stats = await content_prep_service.get_content_stats(chapter_id, db)
        
        return {
            "success": True,
            "data": stats,
            "message": "å†…å®¹ç»Ÿè®¡è·å–æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å†…å®¹ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å†…å®¹ç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.get("/synthesis-preview/{chapter_id}")
async def get_synthesis_preview(
    chapter_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç« èŠ‚è¯­éŸ³åˆæˆé¢„è§ˆ
    å¿«é€Ÿåˆ†æç« èŠ‚å†…å®¹ï¼Œæä¾›è§’è‰²æ£€æµ‹å’Œåˆ†æ®µé¢„è§ˆ
    """
    try:
        # è·å–ç« èŠ‚
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹å¹¶è·å–é¢„è§ˆä¿¡æ¯
        content_prep_service = ContentPreparationService(db)
        preview = await content_prep_service.get_synthesis_preview(chapter_id, db)
        
        return {
            "success": True,
            "data": preview,
            "message": "åˆæˆé¢„è§ˆè·å–æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–åˆæˆé¢„è§ˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆæˆé¢„è§ˆå¤±è´¥: {str(e)}")


@router.post("/prepare-synthesis/{chapter_id}")
async def prepare_chapter_for_synthesis(
    chapter_id: int,
    request: PreparationRequest = Body(default=PreparationRequest()),
    db: Session = Depends(get_db)
):
    """
    æ™ºèƒ½å‡†å¤‡ç« èŠ‚ç”¨äºè¯­éŸ³åˆæˆï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ™ºèƒ½æ–‡æœ¬åˆ†å—ï¼ˆæœ€å¤§3000 tokensï¼‰
    2. è§’è‰²å¯¹è¯æ£€æµ‹å’Œåˆ†ç¦»
    3. è‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²
    4. ç”Ÿæˆè¯­éŸ³åˆæˆé…ç½®ï¼ˆæ”¯æŒTTSä¼˜åŒ–æ¨¡å¼ï¼‰
    5. è¾“å‡ºJSONæ ¼å¼æ•°æ®
    
    å‚æ•°ï¼š
    - auto_add_narrator: æ˜¯å¦è‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²
    - processing_mode: å¤„ç†æ¨¡å¼ï¼ˆauto/single/distributedï¼‰
      * auto: è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å¼
      * single: å•å—åˆ†ææ¨¡å¼ï¼ˆé€‚åˆè¾ƒçŸ­ç« èŠ‚ï¼‰
      * distributed: åˆ†å¸ƒå¼åˆ†ææ¨¡å¼ï¼ˆé€‚åˆé•¿ç« èŠ‚ï¼‰
    - tts_optimization: TTSä¼˜åŒ–æ¨¡å¼ï¼ˆfast/balanced/qualityï¼‰
      * fast: å¿«é€Ÿæ¨¡å¼ï¼Œä¼˜åŒ–æ€§èƒ½
      * balanced: å¹³è¡¡æ¨¡å¼ï¼Œæ€§èƒ½ä¸è´¨é‡å…¼é¡¾
      * quality: è´¨é‡æ¨¡å¼ï¼Œæœ€é«˜è´¨é‡åˆ†æ
    """
    try:
        # è·å–ç« èŠ‚
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹å¹¶æ‰§è¡Œæ™ºèƒ½å‡†å¤‡
        content_prep_service = ContentPreparationService(db)
        
        # ğŸ”§ ä¼˜åŒ–ï¼šæ„å»ºç”¨æˆ·åå¥½é…ç½®ï¼ŒåŒ…å«TTSä¼˜åŒ–æ¨¡å¼
        user_preferences = {
            "auto_add_narrator": request.auto_add_narrator,
            "processing_mode": request.processing_mode,
            "tts_optimization": request.tts_optimization
        }
        
        logger.info(f"ğŸ“‹ ç« èŠ‚{chapter_id}æ™ºèƒ½å‡†å¤‡è¯·æ±‚: {user_preferences}")
        
        result = await content_prep_service.prepare_chapter_for_synthesis(
            chapter_id=chapter_id,
            user_preferences=user_preferences
        )
        
        return {
            "success": True,
            "data": result,
            "message": "ç« èŠ‚æ™ºèƒ½å‡†å¤‡å®Œæˆ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = str(e)
        logger.error(f"ç« èŠ‚æ™ºèƒ½å‡†å¤‡å¤±è´¥: {error_msg}")
        
        # æä¾›ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
        user_friendly_msg = "ç« èŠ‚æ™ºèƒ½å‡†å¤‡å¤±è´¥"
        
        if "timeout" in error_msg.lower() or "è¶…æ—¶" in error_msg:
            user_friendly_msg = "æ™ºèƒ½å‡†å¤‡è¶…æ—¶ï¼Œè¯¥ç« èŠ‚å†…å®¹å¯èƒ½è¾ƒé•¿ï¼Œè¯·ç¨åé‡è¯•"
        elif "ollama" in error_msg.lower():
            user_friendly_msg = "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
        elif "network" in error_msg.lower() or "connection" in error_msg.lower():
            user_friendly_msg = "ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•"
        elif "analysis" in error_msg.lower():
            user_friendly_msg = "æ–‡æœ¬åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç« èŠ‚å†…å®¹æ ¼å¼"
        elif "character" in error_msg.lower():
            user_friendly_msg = "è§’è‰²è¯†åˆ«å¤±è´¥ï¼Œè¯·ç¡®ä¿ç« èŠ‚åŒ…å«å¯¹è¯å†…å®¹"
        else:
            user_friendly_msg = f"æ™ºèƒ½å‡†å¤‡è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{error_msg}"
        
        raise HTTPException(status_code=500, detail=user_friendly_msg)


@router.get("/preparation-status/{chapter_id}")
async def get_preparation_status(
    chapter_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç« èŠ‚å‡†å¤‡çŠ¶æ€
    æ£€æŸ¥ç« èŠ‚æ˜¯å¦å·²ç»å®Œæˆæ™ºèƒ½å‡†å¤‡
    """
    try:
        # è·å–ç« èŠ‚
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹å¹¶æ£€æŸ¥å‡†å¤‡çŠ¶æ€
        content_prep_service = ContentPreparationService(db)
        status = await content_prep_service.get_preparation_status(chapter_id, db)
        
        return {
            "success": True,
            "data": status,
            "message": "å‡†å¤‡çŠ¶æ€è·å–æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å‡†å¤‡çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å‡†å¤‡çŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/result/{chapter_id}")
async def get_preparation_result(
    chapter_id: int,
    db: Session = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„å·²æœ‰æ™ºèƒ½å‡†å¤‡ç»“æœ
    ä¸é‡æ–°æ‰§è¡Œæ™ºèƒ½å‡†å¤‡ï¼Œåªè¿”å›å·²å­˜å‚¨çš„ç»“æœ
    """
    try:
        # è·å–ç« èŠ‚
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ™ºèƒ½å‡†å¤‡ç»“æœ
        try:
            from app.models import AnalysisResult
            
            # æŸ¥æ‰¾æœ€æ–°çš„æ™ºèƒ½å‡†å¤‡ç»“æœ
            latest_result = db.query(AnalysisResult).filter(
                AnalysisResult.chapter_id == chapter_id,
                AnalysisResult.status == 'completed'
            ).order_by(AnalysisResult.created_at.desc()).first()
            
            if not latest_result:
                raise HTTPException(status_code=404, detail="è¯¥ç« èŠ‚å°šæœªå®Œæˆæ™ºèƒ½å‡†å¤‡")
            
            # ç›´æ¥ä½¿ç”¨å­˜å‚¨çš„æ™ºèƒ½å‡†å¤‡ç»“æœï¼Œä¸å†è¿›è¡ŒåŠ¨æ€ç¼“å­˜åŒæ­¥
            synthesis_plan = latest_result.synthesis_plan or {}
            logger.info("ğŸ“‹ [ç»“æœè·å–] ä½¿ç”¨å­˜å‚¨çš„æ™ºèƒ½å‡†å¤‡ç»“æœï¼Œå·²åŒ…å«æ­£ç¡®çš„è§’è‰²é…ç½®")
            
            # æ„å»ºè¿”å›æ•°æ®
            result_data = {
                "synthesis_json": synthesis_plan,
                "processing_info": {
                    "mode": "stored",
                    "total_segments": len(synthesis_plan.get('synthesis_plan', [])) if synthesis_plan else 0,
                    "characters_found": len(latest_result.detected_characters) if latest_result.detected_characters else 0,
                    "saved_to_database": True,
                    "result_id": latest_result.id,
                    "created_at": latest_result.created_at.isoformat() if latest_result.created_at else None,
                    "completed_at": latest_result.completed_at.isoformat() if latest_result.completed_at else None,
                    "voice_sync_applied": False  # ä¸å†è¿›è¡ŒåŠ¨æ€è¯­éŸ³åŒæ­¥
                },
                "last_updated": latest_result.updated_at.isoformat() if latest_result.updated_at else latest_result.created_at.isoformat()
            }
            
            # ğŸ”¥ CRITICAL FIX: æ™ºèƒ½å¤„ç†final_configï¼Œä¼˜å…ˆè¿”å›æœ€æ–°æ•°æ®
            if latest_result.final_config:
                try:
                    final_config = latest_result.final_config
                    if isinstance(final_config, str):
                        import json
                        final_config = json.loads(final_config)
                    
                    # ğŸ”¥ ç®€åŒ–é€»è¾‘ï¼šåªæœ‰final_configåŒ…å«æ˜ç¡®çš„æ›´æ–°æ—¶é—´æˆ³æ—¶æ‰ä½¿ç”¨
                    # å¦åˆ™ä¼˜å…ˆä½¿ç”¨synthesis_planï¼ˆè§’è‰²åŒæ­¥åçš„æœ€æ–°æ•°æ®ï¼‰
                    if (final_config.get('synthesis_json') and 
                        final_config.get('last_updated')):
                        
                        # æœ‰æ˜ç¡®æ›´æ–°æ—¶é—´çš„final_configï¼Œè®¤ä¸ºæ˜¯ç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘çš„æœ€æ–°æ•°æ®
                        result_data["synthesis_json"] = final_config['synthesis_json']
                        logger.info(f"ä½¿ç”¨final_configæ•°æ® (æ‰‹åŠ¨ç¼–è¾‘äº: {final_config.get('last_updated')})")
                    else:
                        # æ²¡æœ‰æ—¶é—´æˆ³çš„final_configè®¤ä¸ºæ˜¯è¿‡æœŸæ•°æ®ï¼Œä½¿ç”¨synthesis_plan
                        logger.info("final_configç¼ºå°‘æ—¶é—´æˆ³ï¼Œä½¿ç”¨synthesis_planæ•°æ®ï¼ˆè§’è‰²åŒæ­¥åçš„æœ€æ–°æ•°æ®ï¼‰")
                    
                    if final_config.get('processing_info'):
                        result_data["processing_info"].update(final_config['processing_info'])
                        
                except Exception as e:
                    logger.warning(f"è§£æfinal_configå¤±è´¥ï¼Œä½¿ç”¨synthesis_planæ•°æ®: {str(e)}")
            
            return {
                "success": True,
                "data": result_data,
                "message": "æ™ºèƒ½å‡†å¤‡ç»“æœè·å–æˆåŠŸ"
            }
            
        except ImportError:
            # å¦‚æœæ²¡æœ‰AnalysisResultæ¨¡å‹ï¼Œå°è¯•ä»ç« èŠ‚å­—æ®µè·å–
            analysis_result = getattr(chapter, 'character_analysis_result', None)
            if not analysis_result:
                raise HTTPException(status_code=404, detail="è¯¥ç« èŠ‚å°šæœªå®Œæˆæ™ºèƒ½å‡†å¤‡")
            
            try:
                import json
                if isinstance(analysis_result, str):
                    result_data = json.loads(analysis_result)
                else:
                    result_data = analysis_result
                
                return {
                    "success": True,
                    "data": result_data,
                    "message": "æ™ºèƒ½å‡†å¤‡ç»“æœè·å–æˆåŠŸ"
                }
            except Exception as e:
                logger.error(f"è§£æç« èŠ‚åˆ†æç»“æœå¤±è´¥: {str(e)}")
                raise HTTPException(status_code=500, detail="æ™ºèƒ½å‡†å¤‡ç»“æœæ•°æ®æ ¼å¼é”™è¯¯")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ™ºèƒ½å‡†å¤‡ç»“æœå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ™ºèƒ½å‡†å¤‡ç»“æœå¤±è´¥: {str(e)}")


@router.put("/result/{chapter_id}")
async def update_preparation_result(
    chapter_id: int,
    update_data: Dict[str, Any],
    db: Session = Depends(get_db)
):
    """
    æ›´æ–°ç« èŠ‚çš„æ™ºèƒ½å‡†å¤‡ç»“æœ
    å…è®¸ç”¨æˆ·ç¼–è¾‘å’Œä¿®æ­£AIåˆ†æçš„ç»“æœ
    """
    try:
        # è·å–ç« èŠ‚
        chapter = db.query(BookChapter).filter(BookChapter.id == chapter_id).first()
        if not chapter:
            raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
        
        # ğŸ”¥ æ–°å¢ï¼šè·å–ä¹¦ç±IDç”¨äºåç»­è§’è‰²è¯­éŸ³åŒæ­¥
        book_id = chapter.book_id
        
        # å°è¯•æ‰¾åˆ°ç°æœ‰çš„åˆ†æç»“æœ
        try:
            from app.models import AnalysisResult
            
            # æŸ¥æ‰¾æœ€æ–°çš„æ™ºèƒ½å‡†å¤‡ç»“æœ
            latest_result = db.query(AnalysisResult).filter(
                AnalysisResult.chapter_id == chapter_id,
                AnalysisResult.status == 'completed'
            ).order_by(AnalysisResult.created_at.desc()).first()
            
            if not latest_result:
                raise HTTPException(status_code=404, detail="è¯¥ç« èŠ‚å°šæœªå®Œæˆæ™ºèƒ½å‡†å¤‡ï¼Œæ— æ³•æ›´æ–°")
            
            # æ›´æ–°ç»“æœæ•°æ®
            if 'synthesis_json' in update_data:
                latest_result.synthesis_plan = update_data['synthesis_json']
            
            # æ›´æ–°final_configä»¥ä¿å­˜å®Œæ•´çš„ç¼–è¾‘åæ•°æ®
            import json
            from sqlalchemy import func
            from datetime import datetime
            
            # ğŸ”¥ æ·»åŠ æ—¶é—´æˆ³ï¼Œç¡®ä¿APIèƒ½å¤Ÿæ­£ç¡®è¯†åˆ«æ‰‹åŠ¨ç¼–è¾‘çš„æ•°æ®
            update_data['last_updated'] = datetime.utcnow().isoformat()
            
            latest_result.final_config = json.dumps(update_data, ensure_ascii=False)
            latest_result.updated_at = func.now()
            
            # å¦‚æœæœ‰è§’è‰²æ•°æ®ï¼Œæ›´æ–°detected_characters
            updated_characters = []
            if 'synthesis_json' in update_data and 'characters' in update_data['synthesis_json']:
                characters = update_data['synthesis_json']['characters']
                character_names = [char.get('name', '') for char in characters if char.get('name')]
                latest_result.detected_characters = character_names
                updated_characters = characters
            
            db.commit()
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ›´æ–°ä¹¦ç±è§’è‰²æ±‡æ€»
            # å½“ç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘ç« èŠ‚åˆ†ææ•°æ®æ—¶ï¼Œéœ€è¦åŒæ­¥æ›´æ–°ä¹¦ç±çš„è§’è‰²æ±‡æ€»
            try:
                if updated_characters:
                    logger.info(f"ğŸ”„ [æ›´æ–°ä¹¦ç±è§’è‰²æ±‡æ€»] ç« èŠ‚ {chapter_id} çš„è§’è‰²æ•°æ®å·²æ›´æ–°ï¼ŒåŒæ­¥åˆ°ä¹¦ç±æ±‡æ€»")
                    
                    # æ›´æ–°ä¹¦ç±è§’è‰²æ±‡æ€»
                    book = db.query(Book).filter(Book.id == book_id).first()
                    if book:
                        book.update_character_summary(updated_characters, chapter_id)
                        db.commit()
                        logger.info(f"âœ… [æ›´æ–°ä¹¦ç±è§’è‰²æ±‡æ€»] æˆåŠŸæ›´æ–°ä¹¦ç± {book_id} çš„è§’è‰²æ±‡æ€»")
                    else:
                        logger.warning(f"âš ï¸ [æ›´æ–°ä¹¦ç±è§’è‰²æ±‡æ€»] æœªæ‰¾åˆ°ä¹¦ç± {book_id}")
                        
            except Exception as summary_error:
                logger.warning(f"âš ï¸ [æ›´æ–°ä¹¦ç±è§’è‰²æ±‡æ€»] æ›´æ–°å¤±è´¥: {str(summary_error)}")
                # æ±‡æ€»æ›´æ–°å¤±è´¥ä¸å½±å“ä¸»è¦çš„ä¿å­˜åŠŸèƒ½
            
            # ğŸ”¥ æ–°å¢ï¼šè‡ªåŠ¨è§¦å‘è§’è‰²è¯­éŸ³é…ç½®åŒæ­¥
            # æå–è§’è‰²è¯­éŸ³æ˜ å°„å¹¶åŒæ­¥åˆ°æ‰€æœ‰ç›¸å…³ç« èŠ‚çš„synthesis_plan
            updated_chapters_count = 0
            try:
                if updated_characters:
                    # æ„å»ºè§’è‰²è¯­éŸ³æ˜ å°„
                    character_voice_mappings = {}
                    for char in updated_characters:
                        if char.get('voice_id') and char.get('name'):
                            character_voice_mappings[char['name']] = str(char['voice_id'])
                    
                    logger.info(f"ğŸ”„ [è‡ªåŠ¨åŒæ­¥] ä»ç¼–è¾‘ç»“æœä¸­æå–åˆ°è§’è‰²æ˜ å°„: {character_voice_mappings}")
                    
                    if character_voice_mappings:
                        # å¯¼å…¥åŒæ­¥å‡½æ•°
                        from ..books import _sync_character_voice_to_synthesis_plans
                        
                        # åŒæ­¥è§’è‰²è¯­éŸ³é…ç½®åˆ°ç›¸å…³ç« èŠ‚
                        updated_chapters_count = await _sync_character_voice_to_synthesis_plans(
                            book_id, character_voice_mappings, db
                        )
                        
                        logger.info(f"âœ… [è‡ªåŠ¨åŒæ­¥] æˆåŠŸåŒæ­¥è§’è‰²é…ç½®åˆ° {updated_chapters_count} ä¸ªç« èŠ‚")
                        
            except Exception as sync_error:
                logger.warning(f"âš ï¸ [è‡ªåŠ¨åŒæ­¥] è§’è‰²è¯­éŸ³é…ç½®åŒæ­¥å¤±è´¥: {str(sync_error)}")
                # åŒæ­¥å¤±è´¥ä¸å½±å“ä¸»è¦çš„ä¿å­˜åŠŸèƒ½
                updated_chapters_count = 0
            
            logger.info(f"å·²æ›´æ–°ç« èŠ‚ {chapter_id} çš„æ™ºèƒ½å‡†å¤‡ç»“æœï¼ŒåŒæ­¥äº† {updated_chapters_count} ä¸ªç« èŠ‚")
            
            return {
                "success": True,
                "data": {
                    "result_id": latest_result.id,
                    "updated_at": latest_result.updated_at.isoformat(),
                    "characters_count": len(latest_result.detected_characters) if latest_result.detected_characters else 0,
                    "segments_count": len(update_data.get('synthesis_json', {}).get('synthesis_plan', [])),
                    "synced_chapters": updated_chapters_count  # ğŸ”¥ æ–°å¢ï¼šè¿”å›åŒæ­¥çš„ç« èŠ‚æ•°é‡
                },
                "message": f"æ™ºèƒ½å‡†å¤‡ç»“æœæ›´æ–°æˆåŠŸï¼Œå·²è‡ªåŠ¨åŒæ­¥ {updated_chapters_count} ä¸ªç« èŠ‚çš„è§’è‰²é…ç½®"
            }
            
        except ImportError:
            # å¦‚æœæ²¡æœ‰AnalysisResultæ¨¡å‹ï¼Œå°è¯•æ›´æ–°ç« èŠ‚å­—æ®µ
            try:
                import json
                chapter.character_analysis_result = json.dumps(update_data, ensure_ascii=False)
                db.commit()
                
                from datetime import datetime
                return {
                    "success": True,
                    "data": {
                        "chapter_id": chapter_id,
                        "updated_at": datetime.now().isoformat()
                    },
                    "message": "æ™ºèƒ½å‡†å¤‡ç»“æœæ›´æ–°æˆåŠŸ"
                }
            except Exception as e:
                logger.error(f"æ›´æ–°ç« èŠ‚åˆ†æç»“æœå¤±è´¥: {str(e)}")
                raise HTTPException(status_code=500, detail="æ›´æ–°æ™ºèƒ½å‡†å¤‡ç»“æœå¤±è´¥")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°æ™ºèƒ½å‡†å¤‡ç»“æœå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°æ™ºèƒ½å‡†å¤‡ç»“æœå¤±è´¥: {str(e)}")


@router.post("/ai-resegment")
async def ai_resegment_text(
    request_data: Dict[str, Any],
    db: Session = Depends(get_db)
):
    """
    ä½¿ç”¨AIå¤§æ¨¡å‹é‡æ–°åˆ†æ®µæ–‡æœ¬
    æ­£ç¡®åˆ†ç¦»å¯¹è¯å’Œæ—ç™½ï¼Œè§£å†³"æŸæŸè¯´"çš„åˆ†æ®µé—®é¢˜
    """
    try:
        text = request_data.get("text", "")
        characters = request_data.get("characters", [])
        chapter_id = request_data.get("chapter_id")
        
        if not text.strip():
            raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºAIæç¤ºè¯
        prompt = f"""è¯·å°†ä»¥ä¸‹å°è¯´æ–‡æœ¬é‡æ–°åˆ†æ®µï¼Œæ­£ç¡®åˆ†ç¦»å¯¹è¯å’Œæ—ç™½ã€‚

è§„åˆ™ï¼š
1. "æŸæŸè¯´ï¼š"è¿™ç§æè¿°æ€§æ–‡å­—åº”è¯¥å½’ä¸ºã€æ—ç™½ã€‘
2. å¼•å·""å†…çš„å†…å®¹æ‰æ˜¯è¯¥è§’è‰²çš„ã€å¯¹è¯ã€‘
3. å…¶ä»–æè¿°æ€§æ–‡å­—éƒ½å½’ä¸ºã€æ—ç™½ã€‘

å·²çŸ¥è§’è‰²ï¼š{', '.join(characters)}

è¯·å°†æ–‡æœ¬åˆ†æ®µï¼Œæ¯æ®µæ ‡æ˜è¯´è¯äººï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[è¯´è¯äºº]ï¼šæ–‡æœ¬å†…å®¹

åŸæ–‡ï¼š
{text}

é‡æ–°åˆ†æ®µç»“æœï¼š"""

        logger.info(f"AIé‡æ–°åˆ†æ®µè¯·æ±‚ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}")
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨AIæœåŠ¡ï¼Œæš‚æ—¶ç”¨æ¨¡æ‹Ÿç»“æœ
        # TODO: é›†æˆå®é™…çš„AIæ¨¡å‹è°ƒç”¨
        
        # æ¨¡æ‹ŸAIåˆ†æ®µç»“æœ - æ­£ç¡®å¤„ç†å¯¹è¯åˆ†ç¦»
        segments = []
        
        # ç®€å•çš„è§„åˆ™å¤„ç†ï¼Œå…ˆä½œä¸ºå ä½ç¬¦
        import re
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        segment_id = 1
        
        for sentence in sentences:
            if not sentence.strip():
                continue
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯¹è¯
            if 'ï¼š' in sentence and '"' in sentence:
                # åˆ†ç¦»æè¿°å’Œå¯¹è¯
                parts = sentence.split('ï¼š', 1)
                if len(parts) == 2:
                    desc_part = parts[0].strip() + 'ï¼š'
                    dialog_part = parts[1].strip()
                    
                    # æ·»åŠ æè¿°éƒ¨åˆ†ï¼ˆæ—ç™½ï¼‰
                    segments.append({
                        "segment_id": segment_id,
                        "speaker": "æ—ç™½",
                        "text": desc_part,
                        "voice_name": "ç³»ç»Ÿæ—ç™½",
                        "parameters": {"timeStep": 0.5, "pWeight": 0.5, "tWeight": 0.5}
                    })
                    segment_id += 1
                    
                    # æå–å¼•å·å†…çš„å†…å®¹
                    dialog_match = re.search(r'"([^"]*)"', dialog_part)
                    if dialog_match:
                        dialog_text = dialog_match.group(1)
                        
                        # å°è¯•ä»æè¿°ä¸­æå–è§’è‰²å
                        speaker_name = "æ—ç™½"
                        for char in characters:
                            if char in desc_part:
                                speaker_name = char
                                break
                        
                        segments.append({
                            "segment_id": segment_id,
                            "speaker": speaker_name,
                            "text": f'"{dialog_text}"',
                            "voice_name": speaker_name,
                            "parameters": {"timeStep": 0.5, "pWeight": 0.5, "tWeight": 0.5}
                        })
                        segment_id += 1
                    
                    # å¤„ç†å¼•å·åçš„å…¶ä»–å†…å®¹
                    remaining = re.sub(r'"[^"]*"', '', dialog_part).strip()
                    if remaining:
                        segments.append({
                            "segment_id": segment_id,
                            "speaker": "æ—ç™½",
                            "text": remaining,
                            "voice_name": "ç³»ç»Ÿæ—ç™½",
                            "parameters": {"timeStep": 0.5, "pWeight": 0.5, "tWeight": 0.5}
                        })
                        segment_id += 1
            else:
                # æ™®é€šæè¿°æ€§æ–‡å­—ï¼Œå½’ä¸ºæ—ç™½
                segments.append({
                    "segment_id": segment_id,
                    "speaker": "æ—ç™½",
                    "text": sentence.strip() + "ã€‚",
                    "voice_name": "ç³»ç»Ÿæ—ç™½",
                    "parameters": {"timeStep": 0.5, "pWeight": 0.5, "tWeight": 0.5}
                })
                segment_id += 1
        
        logger.info(f"AIé‡æ–°åˆ†æ®µå®Œæˆï¼Œç”Ÿæˆ {len(segments)} ä¸ªç‰‡æ®µ")
        
        return {
            "success": True,
            "data": {
                "segments": segments,
                "total_segments": len(segments),
                "processing_info": {
                    "method": "ai_resegment",
                    "original_length": len(text),
                    "characters_found": len(characters)
                }
            },
            "message": f"AIé‡æ–°åˆ†æ®µå®Œæˆï¼Œç”Ÿæˆ {len(segments)} ä¸ªç‰‡æ®µ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"AIé‡æ–°åˆ†æ®µå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AIé‡æ–°åˆ†æ®µå¤±è´¥: {str(e)}")