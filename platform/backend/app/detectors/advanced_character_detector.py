"""
é«˜çº§è§’è‰²æ£€æµ‹å™¨
åŸºäºå¤šé‡è§„åˆ™å’Œå¯å‘å¼æ–¹æ³•çš„è§’è‰²è¯†åˆ«
"""

import logging
import re
import requests
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)


class AdvancedCharacterDetector:
    """
    é«˜çº§è§’è‰²æ£€æµ‹å™¨ - åŸºäºå¤šé‡è§„åˆ™å’Œå¯å‘å¼æ–¹æ³•
    """
    
    def __init__(self):
        # å¯¹è¯æ ‡è¯†ç¬¦æ¨¡å¼
        self.dialogue_patterns = [
            # ç›´æ¥å¼•è¯­æ¨¡å¼
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[è¯´é“è®²é—®ç­”å›åº”å–Šå«å˜Ÿå›”å˜€å’•][:ï¼š]?"([^"]+)"',
            r'"([^"]+)"[ï¼Œã€‚]?([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[è¯´é“è®²é—®ç­”]',
            
            # å†’å·å¯¹è¯æ¨¡å¼
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[ï¼š:]"([^"]+)"',
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[ï¼š:]\s*([^ï¼Œã€‚ï¼ï¼Ÿ\n]+)',
            
            # æ ‡è®°å¯¹è¯æ¨¡å¼
            r'ã€([^ã€‘]+)ã€‘[ï¼š:]?([^ï¼Œã€‚ï¼ï¼Ÿ\n]*)',
            r'ã€–([^ã€—]+)ã€—[ï¼š:]?([^ï¼Œã€‚ï¼ï¼Ÿ\n]*)',
            
            # åŠ¨ä½œæè¿°ä¸­çš„è§’è‰²
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[èµ°æ¥å»åˆ°ç«™åèººè·‘è·³]',
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[çœ‹è§å¬åˆ°æƒ³èµ·è®°å¾—]',
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[ç¬‘å“­æ€’å–œæƒŠ]',
            
            # ç§°å‘¼æ¨¡å¼
            r'([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})[å¸ˆçˆ¶å¸ˆå‚…å¤§äººå…ˆç”Ÿå°å§]',
            r'[å¸ˆçˆ¶å¸ˆå‚…å¤§äººå…ˆç”Ÿå°å§]([^ï¼Œã€‚ï¼ï¼Ÿ\s]{2,4})',
        ]
        
        # æ’é™¤è¯æ±‡ - å¸¸è§çš„éè§’è‰²è¯æ±‡
        self.excluded_words = {
            'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'å“ªé‡Œ', 'ä¸ºä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¯æ˜¯', 'ä½†æ˜¯', 'æ‰€ä»¥', 'å› ä¸º',
            'å¦‚æœ', 'è™½ç„¶', 'é‡åˆ°', 'æ…¢æ…¢', 'è€Œè¿™', 'è¿™ä¸€', 'é‚£ä¸€', 'å½“ä»–', 'å½“å¥¹', 'æ­¤æ—¶',
            'æ­¤å', 'ç„¶å', 'æ¥ç€', 'æœ€å', 'ä»é‚£', 'ç»è¿‡', 'ç¥å¥‡', 'åœ¨ä¸€', 'æ­£å‘', 'æ— å¥ˆ',
            'å°½ç®¡', 'è‡ªè¨€', 'å¿ƒæƒ³', 'æš—æƒ³', 'æš—é“', 'å¿ƒé“', 'æƒ³é“', 'æ€è€ƒ', 'çªç„¶', 'å¿½ç„¶',
            'åŸæ¥', 'æœç„¶', 'ç«Ÿç„¶', 'å±…ç„¶', 'å½“ç„¶', 'è‡ªç„¶', 'æ˜¾ç„¶', 'æ˜æ˜¾', 'æ¸…æ¥š', 'çŸ¥é“',
            'çœ‹åˆ°', 'å¬åˆ°', 'æ„Ÿåˆ°', 'è§‰å¾—', 'è®¤ä¸º', 'ä»¥ä¸º', 'ä¼¼ä¹', 'å¥½åƒ', 'ä»¿ä½›', 'çŠ¹å¦‚'
        }
        
        # è§’è‰²æ€§æ ¼å…³é”®è¯
        self.personality_keywords = {
            'gentle': ['æ¸©æŸ”', 'è½»å£°', 'æŸ”å£°', 'ç»†å£°', 'æ¸©å’Œ', 'å’Œè”¼', 'æ…ˆç¥¥', 'æ¸©æŸ”åœ°', 'è½»å£°é“'],
            'fierce': ['å‡¶çŒ›', 'æš´èº', 'ç²—æš´', 'å‡¶ç‹ ', 'ç‹‚æš´', 'éœ¸é“', 'æ€’å¼', 'å’†å“®', 'å¤§å–', 'å‰å£°'],
            'calm': ['æ²‰ç¨³', 'å†·é™', 'æ·¡å®š', 'ä»å®¹', 'é•‡å®š', 'å¹³é™', 'æ·¡æ·¡åœ°', 'å¹³é™åœ°', 'ä»å®¹è¯´'],
            'lively': ['æ´»æ³¼', 'å¼€æœ—', 'çˆ½æœ—', 'æ¬¢å¿«', 'å…´å¥‹', 'çƒ­æƒ…', 'å…´å¥‹åœ°', 'æ¬¢å¿«åœ°', 'çˆ½æœ—ç¬‘'],
            'wise': ['æ™ºæ…§', 'ç¿æ™º', 'èªæ˜', 'æœºæ™º', 'æ·±æ€', 'æ²‰æ€', 'æ€ç´¢', 'æ·±æ€ç†Ÿè™‘'],
            'brave': ['å‹‡æ•¢', 'è‹±å‹‡', 'æ— ç•', 'æœæ•¢', 'åšæ¯…', 'åˆšå¼º', 'å‹‡æ°”', 'èƒ†é‡']
        }
        
        # æ€§åˆ«æ¨æ–­å…³é”®è¯
        self.gender_keywords = {
            'male': ['å¸ˆçˆ¶', 'å¸ˆå‚…', 'å¤§äºº', 'å…ˆç”Ÿ', 'å…¬å­', 'å°‘çˆ·', 'è€çˆ·', 'çˆ·çˆ·', 'çˆ¶äº²', 'çˆ¸çˆ¸'],
            'female': ['å°å§', 'å§‘å¨˜', 'å¤«äºº', 'å¨˜å­', 'å¥³å£«', 'å¥¶å¥¶', 'æ¯äº²', 'å¦ˆå¦ˆ', 'é˜¿å§¨']
        }
    
    def analyze_text(self, text: str, chapter_info: dict):
        """åˆ†ææ–‡æœ¬ä¸­çš„è§’è‰²"""
        
        # 1. åˆ†æ®µå¤„ç†
        segments = self._split_into_segments(text)
        
        # 2. è§’è‰²æå–
        character_candidates = self._extract_characters(segments)
        
        # 3. è§’è‰²éªŒè¯å’Œè¿‡æ»¤
        valid_characters = self._validate_characters(character_candidates, text)
        
        # 4. è§’è‰²å±æ€§åˆ†æ
        analyzed_characters = self._analyze_character_attributes(valid_characters, text)
        
        # 5. æ„å»ºè¿”å›ç»“æœ
        return {
            "chapter_id": chapter_info['chapter_id'],
            "chapter_title": chapter_info['chapter_title'],
            "chapter_number": chapter_info['chapter_number'],
            "detected_characters": analyzed_characters,
            "segments": [],  # å¯ä»¥åç»­æ·»åŠ æ®µè½åˆ†æ
            "processing_stats": {
                "total_segments": len(segments),
                "dialogue_segments": len([s for s in segments if self._is_dialogue(s)]),
                "characters_found": len(analyzed_characters)
            }
        }
    
    def _split_into_segments(self, text: str):
        """å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ®µè½"""
        # æŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å‰²ï¼Œä¿ç•™æ ‡ç‚¹
        segments = re.split(r'([ã€‚ï¼ï¼Ÿ])', text)
        
        # é‡æ–°ç»„åˆå¥å­
        sentences = []
        for i in range(0, len(segments)-1, 2):
            if i+1 < len(segments):
                sentence = segments[i] + segments[i+1]
                if sentence.strip():
                    sentences.append(sentence.strip())
        
        return sentences
    
    def _extract_characters(self, segments):
        """ä»æ®µè½ä¸­æå–è§’è‰²å€™é€‰"""
        character_mentions = {}
        
        for segment_idx, segment in enumerate(segments):
            for pattern in self.dialogue_patterns:
                matches = re.findall(pattern, segment)
                for match in matches:
                    # å¤„ç†ä¸åŒçš„åŒ¹é…ç»„
                    if isinstance(match, tuple):
                        for name in match:
                            if name and len(name) >= 2 and len(name) <= 6:
                                if self._is_valid_character_name(name):
                                    if name not in character_mentions:
                                        character_mentions[name] = {
                                            'frequency': 0,
                                            'segments': [],
                                            'contexts': []
                                        }
                                    character_mentions[name]['frequency'] += 1
                                    character_mentions[name]['segments'].append(segment_idx)
                                    character_mentions[name]['contexts'].append(segment)
                    else:
                        name = match
                        if name and len(name) >= 2 and len(name) <= 6:
                            if self._is_valid_character_name(name):
                                if name not in character_mentions:
                                    character_mentions[name] = {
                                        'frequency': 0,
                                        'segments': [],
                                        'contexts': []
                                    }
                                character_mentions[name]['frequency'] += 1
                                character_mentions[name]['segments'].append(segment_idx)
                                character_mentions[name]['contexts'].append(segment)
        
        return character_mentions
    
    def _is_valid_character_name(self, name: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è§’è‰²å - ä½¿ç”¨AIæ™ºèƒ½åˆ¤æ–­"""
        # åŸºç¡€è¿‡æ»¤ï¼šæ˜æ˜¾ä¸åˆç†çš„æƒ…å†µ
        if not name or len(name) < 1:
            return False
        
        # åŸºç¡€æ’é™¤ï¼šæ˜æ˜¾çš„æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦
        if any(punct in name for punct in ['ã€‚', 'ï¼Œ', 'ï¼', 'ï¼Ÿ', 'ï¼›', '\n', '\t']):
            return False
        
        # å¯¹äºå¤æ‚æƒ…å†µï¼Œä½¿ç”¨AIåˆ¤æ–­
        try:
            return self._ai_validate_character_name(name)
        except Exception as e:
            logger.warning(f"AIè§’è‰²åéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨ä¿å®ˆåˆ¤æ–­: {str(e)}")
            # AIå¤±è´¥æ—¶çš„ä¿å®ˆåˆ¤æ–­
            return len(name) >= 2 and len(name) <= 8 and name not in getattr(self, 'excluded_words', [])
    
    def _ai_validate_character_name(self, name: str) -> bool:
        """ä½¿ç”¨AIéªŒè¯è§’è‰²åæ˜¯å¦åˆç†"""
        try:
            prompt = f"""åˆ¤æ–­ "{name}" æ˜¯å¦æ˜¯ä¸€ä¸ªåˆç†çš„å°è¯´è§’è‰²åã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
1. æ˜¯å¦å¯èƒ½æ˜¯äººåã€ç¥è¯è§’è‰²åã€åŠ¨ç‰©åç­‰
2. æ˜¯å¦ä¸æ˜¯åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯ç­‰è¯­æ³•è¯æ±‡
3. æ˜¯å¦ä¸æ˜¯"ä»€ä¹ˆ"ã€"å“ªé‡Œ"ç­‰ç–‘é—®è¯
4. æ˜¯å¦ä¸æ˜¯"ä½†æ˜¯"ã€"æ‰€ä»¥"ç­‰è¿æ¥è¯
5. æ˜¯å¦èƒ½ä½œä¸ºå°è¯´ä¸­çš„è¯´è¯è§’è‰²

ç‰¹åˆ«æ³¨æ„ï¼š
- "æ—ç™½"ã€"å™è¿°è€…"ã€"ä½œè€…"ç­‰æ˜¯æœ‰æ•ˆçš„ç‰¹æ®Šè§’è‰²
- ç¥è¯å°è¯´ä¸­çš„è§’è‰²åå¯èƒ½è¾ƒé•¿æˆ–åŒ…å«ç‰¹æ®Šå­—ç¬¦
- ç°ä»£å°è¯´å¯èƒ½æœ‰å¤–å›½äººåçš„éŸ³è¯‘

è¯·è¿”å›ï¼š
- validï¼ˆæœ‰æ•ˆçš„è§’è‰²åï¼‰
- invalidï¼ˆæ— æ•ˆçš„åç§°ï¼‰

åç§°ï¼š{name}
åˆ¤æ–­ï¼š"""

            response = self._call_ollama_simple(prompt)
            if response:
                # æå–åˆ¤æ–­ç»“æœ
                result = response.strip().lower()
                if 'valid' in result and 'invalid' not in result:
                    return True
                elif 'invalid' in result:
                    return False
            
            # AIæ— æ³•åˆ¤æ–­æ—¶ï¼Œä½¿ç”¨ä¿å®ˆè§„åˆ™
            return len(name) >= 2 and len(name) <= 8
            
        except Exception as e:
            logger.error(f"AIè§’è‰²åéªŒè¯å¼‚å¸¸: {str(e)}")
            return len(name) >= 2 and len(name) <= 8
    
    def _call_ollama_simple(self, prompt: str) -> Optional[str]:
        """ç®€åŒ–çš„Ollamaè°ƒç”¨ï¼Œç”¨äºå¿«é€Ÿåˆ¤æ–­"""
        try:
            payload = {
                "model": "qwen2.5:14b",  # ğŸ”¥ ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,  # ä½æ¸©åº¦ç¡®ä¿ç¨³å®šåˆ¤æ–­
                    "max_tokens": 50,   # åªéœ€è¦å¾ˆçŸ­çš„å›ç­”
                }
            }
            
            response = requests.post(
                "http://localhost:11434/api/generate",
                json=payload,
                timeout=30  # çŸ­è¶…æ—¶
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            
            return None
            
        except Exception as e:
            logger.warning(f"ç®€åŒ–Ollamaè°ƒç”¨å¤±è´¥: {str(e)}")
            return None
    
    def _validate_characters(self, candidates: dict, full_text: str):
        """éªŒè¯å’Œè¿‡æ»¤è§’è‰²å€™é€‰"""
        valid_characters = {}
        
        for name, data in candidates.items():
            # é¢‘ç‡è¿‡æ»¤ï¼šè‡³å°‘å‡ºç°2æ¬¡
            if data['frequency'] >= 2:
                valid_characters[name] = data
            # æˆ–è€…åœ¨å…¨æ–‡ä¸­æœ‰å¤šæ¬¡æåŠ
            elif full_text.count(name) >= 3:
                data['frequency'] = full_text.count(name)
                valid_characters[name] = data
        
        return valid_characters
    
    def _analyze_character_attributes(self, characters: dict, full_text: str):
        """åˆ†æè§’è‰²å±æ€§"""
        analyzed_characters = []
        
        for name, data in characters.items():
            # åˆ†ææ€§æ ¼ç‰¹å¾
            personality = self._analyze_personality(data['contexts'])
            
            # æ¨æ–­æ€§åˆ«
            gender = self._infer_gender(name, data['contexts'])
            
            # ç”Ÿæˆè§’è‰²é…ç½®
            character_config = {
                'name': name,
                'frequency': data['frequency'],
                'character_trait': {
                    'trait': personality['trait'],
                    'confidence': personality['confidence'],
                    'description': personality['description']
                },
                'first_appearance': min(data['segments']) + 1 if data['segments'] else 1,
                'is_main_character': data['frequency'] >= 5,  # å‡ºç°5æ¬¡ä»¥ä¸Šä¸ºä¸»è¦è§’è‰²
                'recommended_config': {
                    'gender': gender,
                    'personality': personality['trait'],
                    'personality_description': personality['description'],
                    'personality_confidence': personality['confidence'],
                    'description': f'{name}ï¼Œ{gender}è§’è‰²ï¼Œ{personality["description"]}ï¼Œåœ¨æ–‡æœ¬ä¸­å‡ºç°{data["frequency"]}æ¬¡ã€‚',
                    'recommended_tts_params': self._get_tts_params(personality['trait']),
                    'voice_type': f'{gender}_{personality["trait"]}',
                    'color': self._get_character_color(personality['trait'])
                }
            }
            
            analyzed_characters.append(character_config)
        
        # æŒ‰é¢‘ç‡æ’åº
        analyzed_characters.sort(key=lambda x: x['frequency'], reverse=True)
        
        return analyzed_characters
    
    def _analyze_personality(self, contexts: list):
        """åˆ†æè§’è‰²æ€§æ ¼"""
        personality_scores = {trait: 0 for trait in self.personality_keywords.keys()}
        
        # ç»Ÿè®¡æ€§æ ¼å…³é”®è¯
        for context in contexts:
            for trait, keywords in self.personality_keywords.items():
                for keyword in keywords:
                    if keyword in context:
                        personality_scores[trait] += 1
        
        # æ‰¾å‡ºæœ€é«˜åˆ†çš„æ€§æ ¼ç‰¹å¾
        if max(personality_scores.values()) > 0:
            dominant_trait = max(personality_scores, key=personality_scores.get)
            confidence = min(personality_scores[dominant_trait] / len(contexts), 1.0)
        else:
            dominant_trait = 'calm'  # é»˜è®¤æ€§æ ¼
            confidence = 0.3
        
        trait_descriptions = {
            'gentle': 'æ€§æ ¼æ¸©æŸ”ï¼Œè¯´è¯è½»å£°ç»†è¯­',
            'fierce': 'æ€§æ ¼åˆšçƒˆï¼Œè¯´è¯ç›´æ¥æœ‰åŠ›',
            'calm': 'æ€§æ ¼æ²‰ç¨³ï¼Œå¤„äº‹å†·é™',
            'lively': 'æ€§æ ¼æ´»æ³¼ï¼Œå……æ»¡æ´»åŠ›',
            'wise': 'æ™ºæ…§ç¿æ™ºï¼Œæ·±æ€ç†Ÿè™‘',
            'brave': 'å‹‡æ•¢æœæ•¢ï¼Œæ— æ‰€ç•æƒ§'
        }
        
        return {
            'trait': dominant_trait,
            'confidence': confidence,
            'description': trait_descriptions.get(dominant_trait, 'æ€§æ ¼æ¸©å’Œ')
        }
    
    def _infer_gender(self, name: str, contexts: list):
        """æ¨æ–­è§’è‰²æ€§åˆ«"""
        male_score = 0
        female_score = 0
        
        # åŸºäºç§°å‘¼æ¨æ–­
        for context in contexts:
            for keyword in self.gender_keywords['male']:
                if keyword in context:
                    male_score += 1
            for keyword in self.gender_keywords['female']:
                if keyword in context:
                    female_score += 1
        
        # åŸºäºåå­—æ¨æ–­ï¼ˆç®€å•è§„åˆ™ï¼‰
        common_male_chars = ['é¾™', 'è™', 'è±¹', 'é¹°', 'ç‹¼', 'é›„', 'å¼º', 'åˆš', 'å‹‡', 'å¨']
        common_female_chars = ['å‡¤', 'ç‡•', 'èº', 'èŠ±', 'æœˆ', 'é›ª', 'ç‰', 'ç ', 'ç¾', 'ä¸½']
        
        for char in common_male_chars:
            if char in name:
                male_score += 0.5
        
        for char in common_female_chars:
            if char in name:
                female_score += 0.5
        
        return 'male' if male_score > female_score else 'female'
    
    def _get_tts_params(self, personality: str):
        """æ ¹æ®æ€§æ ¼è·å–TTSå‚æ•°"""
        params_map = {
            'gentle': {'time_step': 35, 'p_w': 1.2, 't_w': 2.8},
            'fierce': {'time_step': 28, 'p_w': 1.6, 't_w': 3.2},
            'calm': {'time_step': 32, 'p_w': 1.4, 't_w': 3.0},
            'lively': {'time_step': 30, 'p_w': 1.3, 't_w': 2.9},
            'wise': {'time_step': 34, 'p_w': 1.3, 't_w': 3.1},
            'brave': {'time_step': 29, 'p_w': 1.5, 't_w': 3.1}
        }
        return params_map.get(personality, {'time_step': 32, 'p_w': 1.4, 't_w': 3.0})
    
    def _get_character_color(self, personality: str):
        """æ ¹æ®æ€§æ ¼è·å–è§’è‰²é¢œè‰²"""
        color_map = {
            'gentle': '#FFB6C1',  # æµ…ç²‰è‰²
            'fierce': '#FF6347',  # ç•ªèŒ„çº¢
            'calm': '#06b6d4',   # é’è‰²
            'lively': '#32CD32', # ç»¿è‰²
            'wise': '#9370DB',   # ç´«è‰²
            'brave': '#FF8C00'   # æ©™è‰²
        }
        return color_map.get(personality, '#06b6d4')
    
    def _is_dialogue(self, segment: str):
        """åˆ¤æ–­æ®µè½æ˜¯å¦åŒ…å«å¯¹è¯"""
        dialogue_indicators = ['"', '"', '"', 'ï¼š', ':', 'è¯´', 'é“', 'é—®', 'ç­”', 'å«', 'å–Š']
        return any(indicator in segment for indicator in dialogue_indicators) 