"""
Ollama AIè§’è‰²æ£€æµ‹å™¨
ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ™ºèƒ½è§’è‰²è¯†åˆ«å’Œåˆ†æ
"""

import json
import logging
import os
import requests
import time
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)


class OllamaCharacterDetector:
    """ä½¿ç”¨Ollamaè¿›è¡Œè§’è‰²åˆ†æçš„æ£€æµ‹å™¨ - ä¸»åŠ›æ–¹æ¡ˆ"""
    
    def __init__(self, model_name: str = "qwen2.5:14b", ollama_url: str = None):
        self.model_name = model_name
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæ”¯æŒDockeréƒ¨ç½²
        self.ollama_url = ollama_url or os.getenv("OLLAMA_URL", "http://localhost:11434")
        self.api_url = f"{self.ollama_url}/api/generate"
        
    async def analyze_text(self, text: str, chapter_info: dict) -> dict:
        """ä½¿ç”¨Ollamaåˆ†ææ–‡æœ¬ä¸­çš„è§’è‰² - ç›´æ¥AIåˆ†æï¼Œç®€å•é«˜æ•ˆ"""
        # ğŸ”§ ä½¿ç”¨ç»Ÿä¸€çš„WebSocketç®¡ç†å™¨
        try:
            from app.websocket.manager import websocket_manager
            
            async def send_analysis_progress(session_id, progress, message):
                await websocket_manager.publish_to_topic(
                    f"analysis_session_{session_id}",
                    {
                        "type": "progress_update",
                        "data": {
                            "progress": progress,
                            "message": message,
                            "session_id": session_id
                        }
                    }
                )
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå®šä¹‰ä¸€ä¸ªmockå‡½æ•°
            async def send_analysis_progress(session_id, progress, message):
                logger.info(f"[è¿›åº¦ {progress}%] {message}")
            logger.warning("æ— æ³•å¯¼å…¥websocket_managerï¼Œä½¿ç”¨æ—¥å¿—è®°å½•è¿›åº¦")
        
        start_time = time.time()
        session_id = chapter_info.get('session_id', chapter_info['chapter_id'])
        
        try:
            # å‘é€å¼€å§‹åˆ†æè¿›åº¦
            await send_analysis_progress(session_id, 10, f"å¼€å§‹åˆ†æç« èŠ‚: {chapter_info['chapter_title']}")
            
            # 1. ç›´æ¥è°ƒç”¨Ollamaè¿›è¡Œå…¨æ–‡åˆ†æï¼ˆåŒ…æ‹¬è§’è‰²è¯†åˆ«å’Œæ–‡æœ¬åˆ†æ®µï¼‰
            await send_analysis_progress(session_id, 30, "æ­£åœ¨è°ƒç”¨AIæ¨¡å‹è¿›è¡Œè§’è‰²è¯†åˆ«...")
            
            prompt = self._build_comprehensive_analysis_prompt(text)
            response = self._call_ollama(prompt)
            
            processing_time = time.time() - start_time
            
            if response:
                await send_analysis_progress(session_id, 80, "æ­£åœ¨è§£æAIåˆ†æç»“æœ...")
                
                # è§£æOllamaè¿”å›çš„å®Œæ•´ç»“æœ
                result = self._parse_comprehensive_response(response)
                
                await send_analysis_progress(session_id, 100, f"åˆ†æå®Œæˆï¼Œè¯†åˆ«åˆ°{len(result['characters'])}ä¸ªè§’è‰²")
                
                # æ™ºèƒ½åˆ†æé˜¶æ®µï¼šè¿”å›æ‰€æœ‰è¯†åˆ«åˆ°çš„è§’è‰²ï¼ˆä¸è¿‡æ»¤å·²å­˜åœ¨çš„ï¼‰
                all_characters = result['characters']
                
                return {
                    "chapter_id": chapter_info['chapter_id'],
                    "chapter_title": chapter_info['chapter_title'],
                    "chapter_number": chapter_info['chapter_number'],
                    "detected_characters": all_characters,  # è¿”å›æ‰€æœ‰è§’è‰²
                    "segments": result['segments'],
                    "processing_stats": {
                        "total_segments": len(result['segments']),
                        "dialogue_segments": len([s for s in result['segments'] if s['text_type'] == 'dialogue']),
                        "narration_segments": len([s for s in result['segments'] if s['text_type'] == 'narration']),
                        "characters_found": len(result['characters']),
                        "new_characters_found": len(result['characters']),
                        "analysis_method": "ollama_ai_primary",
                        "processing_time": round(processing_time, 2),
                        "text_length": len(text),
                        "ai_model": self.model_name
                    }
                }
            else:
                # Ollamaè°ƒç”¨å¤±è´¥ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯
                logger.error("âŒ Ollama APIè°ƒç”¨å¤±è´¥ï¼Œæ²¡æœ‰è¿”å›æœ‰æ•ˆå“åº”")
                await send_analysis_progress(session_id, 0, "AIåˆ†æå¤±è´¥")
                raise Exception("Ollama APIè°ƒç”¨å¤±è´¥ï¼Œæ²¡æœ‰è¿”å›æœ‰æ•ˆå“åº”")
                
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ Ollamaè§’è‰²åˆ†æå¼‚å¸¸å¤±è´¥: {str(e)}")
            await send_analysis_progress(session_id, 0, f"AIåˆ†æå¤±è´¥: {str(e)}")
            raise Exception(f"Ollamaè§’è‰²åˆ†æå¤±è´¥: {str(e)}")
    
# å›é€€é€»è¾‘å·²ç§»é™¤ - å¤§æ¨¡å‹å¤±è´¥å°±æ˜¯å¤±è´¥ï¼

    def _build_comprehensive_analysis_prompt(self, text: str) -> str:
        """æ„å»ºç»¼åˆåˆ†ææç¤ºè¯"""
        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œé¿å…è¶…æ—¶
        limited_text = text[:1500] if len(text) > 1500 else text
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡å°è¯´æ–‡æœ¬åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å°è¯´æ–‡æœ¬ï¼Œè¯†åˆ«è§’è‰²å¹¶æ­£ç¡®åˆ†æ®µã€‚

æ–‡æœ¬ï¼š
{limited_text}

åˆ†æè¦æ±‚ï¼š
1. è¯†åˆ«æ‰€æœ‰è¯´è¯çš„è§’è‰²ï¼ˆåŒ…æ‹¬æ—ç™½ï¼‰
2. å°†æ–‡æœ¬æŒ‰å¥å­åˆ†æ®µï¼Œæ¯æ®µæ ‡è®°æ­£ç¡®çš„è¯´è¯è€…
3. **æ ¸å¿ƒè¦æ±‚**ï¼šæ­£ç¡®åˆ†ç¦»æ··åˆå¯¹è¯æ–‡æœ¬

å…³é”®åˆ†æ®µè§„åˆ™ï¼š
- æ··åˆæ–‡æœ¬å¦‚"é¡¹ç¾½å†·ç¬‘ä¸€å£°ï¼š"ä½ åˆæ˜¯ä½•äººï¼Ÿ""å¿…é¡»åˆ†ä¸ºä¸¤æ®µï¼š
  ç¬¬ä¸€æ®µï¼š"é¡¹ç¾½å†·ç¬‘ä¸€å£°ï¼š" â†’ è¯´è¯è€…ï¼šæ—ç™½
  ç¬¬äºŒæ®µï¼š"ä½ åˆæ˜¯ä½•äººï¼Ÿ" â†’ è¯´è¯è€…ï¼šé¡¹ç¾½
- æ‰€æœ‰"æŸæŸè¯´ï¼š"ã€"æŸæŸé“ï¼š"ã€"æŸæŸä½å£°é“ï¼š"ç­‰æè¿°æ€§åŠ¨ä½œæ–‡å­—éƒ½æ˜¯æ—ç™½
- åªæœ‰å¼•å·""å†…çš„å®é™…å¯¹è¯å†…å®¹æ‰æ˜¯è§’è‰²å‘è¨€
- çº¯å™è¿°æ–‡å­—ï¼ˆå¦‚"åªè§å±±åŠ¿é™©å³»"ã€"æ­¤æ—¶å¤©è‰²å·²æ™š"ï¼‰éƒ½æ˜¯æ—ç™½

**ğŸ§  å¿ƒç†æå†™ç‰¹æ®Šè§„åˆ™ï¼ˆé‡è¦ï¼‰**ï¼š
- "ä»–å¿ƒé‡Œæƒ³"ã€"å¥¹æš—è‡ªç¢ç£¨"ã€"æ—æ¸Šæƒ³åˆ°"åçš„å¼•å·å†…å®¹æ˜¯è¯¥è§’è‰²çš„å¿ƒç†æ´»åŠ¨
- ç¤ºä¾‹ï¼š"ä»–å¿ƒé‡Œæš—è‡ªç¢ç£¨ï¼Œ\"è¯´ä¸å®šæ˜¯ä»€ä¹ˆå¤±ä¼ çš„å¤ä»£å¯†ç ï¼Ÿ\"" 
  â†’ åˆ†ä¸ºä¸¤æ®µï¼šç¬¬ä¸€æ®µ"ä»–å¿ƒé‡Œæš—è‡ªç¢ç£¨ï¼Œ"ï¼ˆæ—ç™½ï¼‰ï¼Œç¬¬äºŒæ®µ"\"è¯´ä¸å®šæ˜¯ä»€ä¹ˆå¤±ä¼ çš„å¤ä»£å¯†ç ï¼Ÿ\""ï¼ˆè¯¥è§’è‰²å†…å¿ƒç‹¬ç™½ï¼‰
- å¿ƒç†æå†™å…³é”®è¯ï¼šå¿ƒé‡Œæƒ³ã€å¿ƒæƒ³ã€æš—æƒ³ã€æš—é“ã€å¿ƒé“ã€ç¢ç£¨ã€æ€è€ƒã€æƒ³åˆ°ã€å¿ƒä¸­æš—æƒ³ç­‰
- å¿ƒç†æå†™åŒæ ·ç®—ä½œè§’è‰²å‘è¨€ï¼Œtext_typeæ ‡è®°ä¸º"inner_monologue"

**ğŸ¯ è§’è‰²åç§°ä¸€è‡´æ€§è¦æ±‚ï¼ˆæ ¸å¿ƒï¼‰**ï¼š
- åŒä¸€è§’è‰²å¿…é¡»ä½¿ç”¨ç»Ÿä¸€çš„åç§°ï¼Œé¿å…å¤šç§ç§°å‘¼
- ä¼˜å…ˆä½¿ç”¨å…·ä½“äººåï¼ˆå¦‚"é²å…ƒå…¬ä¸»"ï¼‰ï¼Œé¿å…æ³›æŒ‡ç§°å‘¼ï¼ˆå¦‚"å¥³å­"ã€"å°‘å¥³"ã€"å°å§"ï¼‰
- å¦‚æœæ–‡ä¸­åŒæ—¶å‡ºç°"é²å…ƒå…¬ä¸»"å’Œ"å¥³å­"ï¼Œç»Ÿä¸€ä½¿ç”¨"é²å…ƒå…¬ä¸»"
- å¦‚æœæ–‡ä¸­åŒæ—¶å‡ºç°"æ—æ¸Š"å’Œ"é‚£äºº"ï¼Œç»Ÿä¸€ä½¿ç”¨"æ—æ¸Š"
- ç¡®ä¿charactersåˆ—è¡¨å’Œsegmentsä¸­çš„speakerå®Œå…¨ä¸€è‡´

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰ï¼š
{{
  "segments": [
    {{"order": 1, "text": "æ–‡æœ¬å†…å®¹", "speaker": "è¯´è¯è€…", "text_type": "dialogue/narration/inner_monologue", "confidence": 0.9}}
  ],
  "characters": [
    {{"name": "è§’è‰²å", "frequency": å‡ºç°æ¬¡æ•°, "gender": "male/female/neutral", "personality": "calm/brave/gentle", "personality_description": "æ€§æ ¼æè¿°", "is_main_character": true/false, "confidence": 0.8}}
  ]
}}

text_typeè¯´æ˜ï¼š
- dialogueï¼šè§’è‰²å¯¹è¯ï¼ˆè¯´å‡ºçš„è¯ï¼‰
- narrationï¼šæ—ç™½å™è¿°
- inner_monologueï¼šè§’è‰²å†…å¿ƒç‹¬ç™½/å¿ƒç†æ´»åŠ¨

é‡è¦æé†’ï¼š
- è§’è‰²åå¿…é¡»å®Œæ•´ï¼ˆå¦‚"å­™æ‚Ÿç©º"è€Œä¸æ˜¯"æ‚Ÿç©º"ï¼‰
- ä¸¥æ ¼åŒºåˆ†å™è¿°ï¼ˆæ—ç™½ï¼‰å’Œå¯¹è¯ï¼ˆè§’è‰²ï¼‰
- å¿…é¡»æ­£ç¡®åˆ†ç¦»åŠ¨ä½œæè¿°å’Œå®é™…å¯¹è¯
- åªè¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—"""
        
        return prompt

    def _call_ollama(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨Ollama API"""
        try:
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.2,
                    "top_p": 0.8,
                    "max_tokens": 2000,
                    "num_ctx": 4096
                }
            }
            
            response = requests.post(
                self.api_url,
                json=payload,
                timeout=180
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            else:
                logger.error(f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("Ollama APIè°ƒç”¨è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"Ollama APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None
    
    def _parse_comprehensive_response(self, response: str) -> Dict:
        """è§£æOllamaè¿”å›çš„ç»¼åˆåˆ†æç»“æœ"""
        try:
            # è®°å½•åŸå§‹å“åº”ç”¨äºè°ƒè¯•
            logger.info(f"OllamaåŸå§‹å“åº”: {response[:500]}...")
            
            # æå–JSONéƒ¨åˆ†
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                data = json.loads(json_str)
                
                logger.info(f"è§£æçš„JSONæ•°æ®: {json.dumps(data, ensure_ascii=False, indent=2)}")
                
                # å¤„ç†segments
                segments = []
                for i, seg_data in enumerate(data.get('segments', [])):
                    # æ”¯æŒæ–°çš„text_type: inner_monologue
                    text_type = seg_data.get('text_type', 'narration')
                    if text_type not in ['dialogue', 'narration', 'inner_monologue']:
                        text_type = 'narration'  # é»˜è®¤ä¸ºæ—ç™½
                        
                    segments.append({
                        'order': seg_data.get('order', i + 1),
                        'text': seg_data.get('text', ''),
                        'speaker': seg_data.get('speaker', 'æ—ç™½'),
                        'confidence': seg_data.get('confidence', 0.8),
                        'detection_rule': 'ollama_ai',
                        'text_type': text_type
                    })
                
                # å¤„ç†characters
                characters = []
                for char_data in data.get('characters', []):
                    if isinstance(char_data, dict) and 'name' in char_data:
                        name = char_data.get('name', '')
                        if name and len(name) >= 2:
                            characters.append({
                                'name': name,
                                'frequency': char_data.get('frequency', 1),
                                'character_trait': {
                                    'trait': char_data.get('personality', 'calm'),
                                    'confidence': char_data.get('confidence', 0.8),
                                    'description': char_data.get('personality_description', 'æ€§æ ¼ç‰¹å¾å¾…åˆ†æ')
                                },
                                'first_appearance': 1,
                                'is_main_character': char_data.get('is_main_character', False),
                                'recommended_config': {
                                    'gender': self._infer_gender_smart(name, char_data.get('gender', 'unknown')),
                                    'personality': char_data.get('personality', 'calm'),
                                    'personality_description': char_data.get('personality_description', 'æ€§æ ¼ç‰¹å¾å¾…åˆ†æ'),
                                    'personality_confidence': char_data.get('confidence', 0.8),
                                    'description': f"{name}ï¼Œ{self._infer_gender_smart(name, char_data.get('gender', 'unknown'))}è§’è‰²ï¼Œ{char_data.get('personality_description', 'æ€§æ ¼ç‰¹å¾å¾…åˆ†æ')}ï¼Œåœ¨æ–‡æœ¬ä¸­å‡ºç°{char_data.get('frequency', 1)}æ¬¡ã€‚",
                                    'recommended_tts_params': self._get_tts_params(char_data.get('personality', 'calm')),
                                    'voice_type': f"{self._infer_gender_smart(name, char_data.get('gender', 'unknown'))}_{char_data.get('personality', 'calm')}",
                                    'color': self._get_character_color(char_data.get('personality', 'calm'))
                                }
                            })
                
                return {
                    'segments': segments,
                    'characters': characters
                }
            
            else:
                logger.error("æ— æ³•ä»Ollamaå“åº”ä¸­æå–JSONæ•°æ®")
                return {'segments': [], 'characters': []}
                
        except json.JSONDecodeError as e:
            logger.error(f"è§£æOllama JSONå“åº”å¤±è´¥: {str(e)}")
            logger.error(f"åŸå§‹å“åº”: {response}")
            return {'segments': [], 'characters': []}
        except Exception as e:
            logger.error(f"å¤„ç†Ollamaå“åº”å¼‚å¸¸: {str(e)}")
            return {'segments': [], 'characters': []}

    def _get_tts_params(self, personality: str) -> Dict:
        """æ ¹æ®æ€§æ ¼è·å–TTSå‚æ•°"""
        params_map = {
            'gentle': {'time_step': 35, 'p_w': 1.2, 't_w': 2.8},
            'fierce': {'time_step': 28, 'p_w': 1.6, 't_w': 3.2},
            'calm': {'time_step': 32, 'p_w': 1.4, 't_w': 3.0},
            'lively': {'time_step': 30, 'p_w': 1.3, 't_w': 2.9},
            'wise': {'time_step': 34, 'p_w': 1.3, 't_w': 3.1},
            'brave': {'time_step': 29, 'p_w': 1.5, 't_w': 3.1}
        }
        return params_map.get(personality, {'time_step': 32, 'p_w': 1.4, 't_w': 3.0})
    
    def _get_character_color(self, personality: str) -> str:
        """æ ¹æ®æ€§æ ¼è·å–è§’è‰²é¢œè‰²"""
        color_map = {
            'gentle': '#FFB6C1',  # æµ…ç²‰è‰²
            'fierce': '#FF6347',  # ç•ªèŒ„çº¢
            'calm': '#06b6d4',   # é’è‰²
            'lively': '#32CD32', # ç»¿è‰²
            'wise': '#9370DB',   # ç´«è‰²
            'brave': '#FF8C00'   # æ©™è‰²
        }
        return color_map.get(personality, '#06b6d4')
    
    def _infer_gender_smart(self, name: str, ai_gender: str) -> str:
        """æ™ºèƒ½æ¨æ–­è§’è‰²æ€§åˆ« - å®Œå…¨ä¾èµ–AIåˆ¤æ–­ï¼Œç§»é™¤ç¡¬ç¼–ç """
        # å¦‚æœAIå·²ç»æ­£ç¡®è¯†åˆ«äº†æ€§åˆ«ï¼Œç›´æ¥ä½¿ç”¨
        if ai_gender and ai_gender in ['male', 'female', 'neutral']:
            return ai_gender
        
        # å¦‚æœAIæ²¡æœ‰è¿”å›æ€§åˆ«ä¿¡æ¯ï¼Œè°ƒç”¨ä¸“é—¨çš„æ€§åˆ«è¯†åˆ«AI
        try:
            gender = self._ai_infer_gender(name)
            if gender in ['male', 'female', 'neutral']:
                logger.info(f"AIæ¨æ–­è§’è‰² '{name}' æ€§åˆ«: {gender}")
                return gender
        except Exception as e:
            logger.warning(f"AIæ€§åˆ«æ¨æ–­å¤±è´¥: {str(e)}")
        
        # é»˜è®¤è¿”å›unknownï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©
        logger.warning(f"æ— æ³•æ¨æ–­è§’è‰² '{name}' çš„æ€§åˆ«")
        return 'unknown'
    
    def _ai_infer_gender(self, character_name: str) -> str:
        """ä½¿ç”¨AIæ¨æ–­è§’è‰²æ€§åˆ«"""
        try:
            prompt = f"""è¯·åˆ¤æ–­è§’è‰² "{character_name}" çš„æ€§åˆ«ã€‚

åˆ¤æ–­è§„åˆ™ï¼š
1. åŸºäºä¸­æ–‡å§“åçš„å¸¸è§ç‰¹å¾
2. åŸºäºæ–‡å­¦ä½œå“ä¸­çš„è§’è‰²è®¾å®š
3. åŸºäºç§°è°“ã€å¤´è¡”çš„è¯­ä¹‰å«ä¹‰

è¿”å›æ ¼å¼ï¼ˆåªè¿”å›ä¸€ä¸ªè¯ï¼‰ï¼š
- maleï¼ˆç”·æ€§ï¼‰
- femaleï¼ˆå¥³æ€§ï¼‰  
- neutralï¼ˆä¸­æ€§ï¼Œå¦‚æ—ç™½ã€å™è¿°è€…ï¼‰

è§’è‰²åï¼š{character_name}
æ€§åˆ«ï¼š"""

            response = self._call_ollama(prompt)
            if response:
                # æå–æ€§åˆ«åˆ¤æ–­
                gender = response.strip().lower()
                if 'male' in gender and 'female' not in gender:
                    return 'male'
                elif 'female' in gender:
                    return 'female'
                elif 'neutral' in gender:
                    return 'neutral'
            
            return 'unknown'
            
        except Exception as e:
            logger.error(f"AIæ€§åˆ«æ¨æ–­å¼‚å¸¸: {str(e)}")
            return 'unknown' 