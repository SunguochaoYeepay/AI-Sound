#!/usr/bin/env python3
"""
è¯Šæ–­TTSæœåŠ¡é—®é¢˜
"""
import requests
import json

def diagnose_tts():
    print("ğŸ” === è¯Šæ–­TTSæœåŠ¡çŠ¶æ€ ===")
    
    # 1. æ£€æŸ¥TTSæœåŠ¡å¥åº·çŠ¶æ€
    print("\n1. æ£€æŸ¥TTSæœåŠ¡å¥åº·çŠ¶æ€...")
    try:
        health_response = requests.get("http://localhost:7929/health", timeout=5)
        if health_response.status_code == 200:
            print("âœ… TTSæœåŠ¡è¿è¡Œæ­£å¸¸")
            health_data = health_response.json()
            print(f"   çŠ¶æ€: {health_data}")
        else:
            print(f"âŒ TTSæœåŠ¡çŠ¶æ€å¼‚å¸¸: {health_response.status_code}")
    except requests.exceptions.ConnectionError:
        print("âŒ TTSæœåŠ¡æœªå¯åŠ¨æˆ–æ— æ³•è¿æ¥")
        print("   è¯·æ£€æŸ¥MegaTTS3æœåŠ¡æ˜¯å¦åœ¨ç«¯å£7929è¿è¡Œ")
        return
    except Exception as e:
        print(f"âŒ TTSå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return
    
    # 2. æ£€æŸ¥GPUçŠ¶æ€
    print("\n2. æ£€æŸ¥GPUçŠ¶æ€...")
    try:
        gpu_response = requests.get("http://localhost:7929/gpu-info", timeout=5)
        if gpu_response.status_code == 200:
            gpu_data = gpu_response.json()
            print("âœ… GPUä¿¡æ¯è·å–æˆåŠŸ")
            print(f"   GPUæ•°é‡: {gpu_data.get('gpu_count', 'æœªçŸ¥')}")
            print(f"   å½“å‰GPU: {gpu_data.get('current_device', 'æœªçŸ¥')}")
            print(f"   GPUå†…å­˜: {gpu_data.get('memory_info', 'æœªçŸ¥')}")
        else:
            print(f"âš ï¸  æ— æ³•è·å–GPUä¿¡æ¯: {gpu_response.status_code}")
    except Exception as e:
        print(f"âš ï¸  GPUä¿¡æ¯æ£€æŸ¥å¤±è´¥: {e}")
    
    # 3. å°è¯•ç®€å•çš„TTSæµ‹è¯•
    print("\n3. è¿›è¡Œç®€å•TTSåˆæˆæµ‹è¯•...")
    test_data = {
        "text": "ä½ å¥½ï¼Œè¿™æ˜¯æµ‹è¯•ã€‚",
        "reference_audio": "",  # ä½¿ç”¨é»˜è®¤å£°éŸ³
        "time_step": 20,
        "p_weight": 1.0,
        "t_weight": 1.0
    }
    
    try:
        tts_response = requests.post("http://localhost:7929/synthesize", 
                                   json=test_data, timeout=30)
        if tts_response.status_code == 200:
            print("âœ… TTSåˆæˆæµ‹è¯•æˆåŠŸ")
            result = tts_response.json()
            print(f"   åˆæˆç»“æœ: {result.get('message', 'æˆåŠŸ')}")
        else:
            print(f"âŒ TTSåˆæˆæµ‹è¯•å¤±è´¥: {tts_response.status_code}")
            try:
                error_data = tts_response.json()
                print(f"   é”™è¯¯ä¿¡æ¯: {error_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                # åˆ†æé”™è¯¯ç±»å‹
                error_msg = error_data.get('error', '')
                if 'CUDA' in error_msg:
                    print("\nğŸ’¡ è¿™æ˜¯CUDA GPUé”™è¯¯ï¼Œå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
                    print("   1. æ£€æŸ¥GPUé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
                    print("   2. æ£€æŸ¥CUDAç‰ˆæœ¬æ˜¯å¦ä¸PyTorchå…¼å®¹")
                    print("   3. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³")
                    print("   4. å°è¯•é‡å¯MegaTTS3æœåŠ¡")
                    print("   5. å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨CPUæ¨¡å¼")
                elif 'memory' in error_msg.lower():
                    print("\nğŸ’¡ è¿™æ˜¯å†…å­˜é”™è¯¯ï¼Œå»ºè®®:")
                    print("   1. é‡Šæ”¾å…¶ä»–GPUè¿›ç¨‹çš„æ˜¾å­˜")
                    print("   2. é‡å¯MegaTTS3æœåŠ¡")
                    print("   3. å‡å°‘batch_sizeå‚æ•°")
            except:
                print(f"   åŸå§‹å“åº”: {tts_response.text}")
    except requests.exceptions.Timeout:
        print("âŒ TTSåˆæˆè¶…æ—¶")
        print("   è¿™å¯èƒ½è¡¨ç¤ºæœåŠ¡å“åº”å¾ˆæ…¢æˆ–å¡ä½äº†")
    except Exception as e:
        print(f"âŒ TTSåˆæˆæµ‹è¯•å¼‚å¸¸: {e}")
    
    # 4. å»ºè®®
    print("\nğŸ’¡ å»ºè®®æ“ä½œ:")
    print("1. å¦‚æœæ˜¯CUDAé”™è¯¯ï¼Œå°è¯•é‡å¯MegaTTS3æœåŠ¡")
    print("2. æ£€æŸ¥ç³»ç»ŸGPUå†…å­˜ä½¿ç”¨æƒ…å†µ")
    print("3. ç¡®è®¤MegaTTS3æœåŠ¡é…ç½®æ­£ç¡®")
    print("4. å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯ä»¥æš‚æ—¶ç¦ç”¨GPUåŠ é€Ÿ")

if __name__ == "__main__":
    diagnose_tts() 