# 基于文件的音频混合引擎

## 🎯 核心价值

基于顺序生成的音频文件，使用CPU进行智能混合，避免GPU资源冲突，确保混合质量。

## 🔄 基于文件的混合策略

### 文件混合架构
```python
class FileBasedAudioMixer:
    def __init__(self):
        self.audio_loader = AudioFileLoader()
        self.ducking_processor = DuckingProcessor()
        self.quality_enhancer = AudioQualityEnhancer()
    
    def mix_audio_files(
        self,
        dialogue_files: List[str],
        environment_files: List[str], 
        timeline: Timeline
    ) -> MixedAudio:
        # 1. 加载所有音频文件
        dialogue_tracks = self._load_dialogue_files(dialogue_files)
        environment_tracks = self._load_environment_files(environment_files)
        
        # 2. 创建主音轨
        master_track = self._create_master_track(timeline.total_duration)
        
        # 3. 分层混合
        master_track = self._mix_environment_layer(master_track, environment_tracks, timeline)
        master_track = self._mix_dialogue_layer(master_track, dialogue_tracks, timeline)
        
        # 4. 智能闪避和质量优化
        final_audio = self._apply_ducking_and_enhancement(master_track)
        
        return final_audio
```

## 🎵 智能闪避算法

### 对话时环境音自动降低
```python
def _apply_intelligent_ducking(self, master_track: AudioTrack, timeline: Timeline) -> AudioTrack:
    """智能闪避：对话时环境音自动降低"""
    
    ducked_track = master_track.copy()
    
    for dialogue_segment in timeline.dialogue_segments:
        start_time = dialogue_segment.start
        end_time = dialogue_segment.end
        
        # 闪避参数
        duck_amount = -6.0  # 降低6dB
        duck_attack = 0.1   # 100ms渐入
        duck_release = 0.3  # 300ms渐出
        
        # 应用闪避效果
        ducked_track = ducked_track.apply_ducking(
            start_time=start_time - duck_attack,
            end_time=end_time + duck_release,
            reduction_db=duck_amount,
            attack_time=duck_attack,
            release_time=duck_release
        )
    
    return ducked_track
```

### 基于pydub的实现
```python
from pydub import AudioSegment

def _mix_with_pydub(self, dialogue_files: List[str], environment_files: List[str], timeline: Timeline) -> AudioSegment:
    """使用pydub进行音频混合"""
    
    # 1. 创建静音主轨
    total_duration_ms = int(timeline.total_duration * 1000)
    master_track = AudioSegment.silent(duration=total_duration_ms)
    
    # 2. 添加环境音
    for env_track in timeline.environment_tracks:
        env_audio = AudioSegment.from_wav(env_track.file_path)
        start_ms = int(env_track.start * 1000)
        
        # 调节音量
        volume_adjusted = env_audio + env_track.volume_db
        
        # 叠加到主轨
        master_track = master_track.overlay(volume_adjusted, position=start_ms)
    
    # 3. 添加对话音频
    for dialogue_segment in timeline.dialogue_segments:
        dialogue_audio = AudioSegment.from_wav(dialogue_segment.file_path)
        start_ms = int(dialogue_segment.start * 1000)
        
        # 对话音频优先级更高
        master_track = master_track.overlay(dialogue_audio, position=start_ms)
    
    return master_track
```

## 📤 多格式导出

### 支持格式
```python
EXPORT_FORMATS = {
    "high_quality": {
        "format": "wav",
        "sample_rate": 48000,
        "bit_depth": 24,
        "channels": 2
    },
    "streaming": {
        "format": "mp3", 
        "bitrate": 320,
        "channels": 2
    },
    "mobile": {
        "format": "aac",
        "bitrate": 128,
        "channels": 2
    }
}

def export_mixed_audio(self, mixed_audio: AudioSegment, format_type: str = "high_quality") -> str:
    """导出混合音频"""
    
    config = EXPORT_FORMATS[format_type]
    output_path = f"mixed_audio_{int(time.time())}.{config['format']}"
    
    # 应用导出设置
    if config["format"] == "wav":
        mixed_audio.export(output_path, format="wav")
    elif config["format"] == "mp3":
        mixed_audio.export(output_path, format="mp3", bitrate=f"{config['bitrate']}k")
    elif config["format"] == "aac":
        mixed_audio.export(output_path, format="mp4", codec="aac", bitrate=f"{config['bitrate']}k")
    
    return output_path
```

---

**核心价值**: 基于pydub的简洁混合方案，CPU处理避免GPU冲突，确保稳定性！