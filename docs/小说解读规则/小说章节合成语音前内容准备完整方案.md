# å°è¯´ç« èŠ‚åˆæˆè¯­éŸ³å‰å†…å®¹å‡†å¤‡å®Œæ•´æ–¹æ¡ˆ v2.0

**[MODE: ARCHITECTURE]**

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

å°†åŸå§‹å°è¯´æ–‡æœ¬æ™ºèƒ½è½¬æ¢ä¸ºè¯­éŸ³åˆæˆæ ‡å‡†JSONæ ¼å¼ï¼Œ**ä¸¥æ ¼éµå¾ªå†…å®¹å®Œæ•´æ€§åº•çº¿**ï¼š

### ğŸ“ **å†…å®¹å®Œæ•´æ€§åº•çº¿ï¼ˆä¸å¯è¿èƒŒï¼‰**
- ğŸ”’ **åŸæ–‡ä¸€å­—ä¸å˜**ï¼šæ‰€æœ‰åŸå§‹æ–‡æœ¬å¿…é¡»100%ä¿ç•™ï¼Œä¸å¾—å¢åˆ æ”¹
- ğŸ”’ **é¡ºåºä¸¥æ ¼ä¿æŒ**ï¼šæ–‡æœ¬å‡ºç°é¡ºåºå®Œå…¨æŒ‰ç…§åŸæ–‡
- ğŸ”’ **çº¯åˆ†ç¦»æ“ä½œ**ï¼šåªè¿›è¡Œè§’è‰²èº«ä»½æ ‡æ³¨ï¼Œä¸è¿›è¡Œä»»ä½•å†…å®¹æ”¹å†™
- ğŸ”’ **è¯»ä¹¦ä¸é€ ä¹¦**ï¼šè¾“å‡ºç»“æœæ˜¯"å¤šè§’è‰²æœ—è¯»åŸæ–‡"ï¼Œä¸æ˜¯"æ”¹ç¼–åˆ›ä½œ"

### ğŸ­ **æŠ€æœ¯å¤„ç†ç›®æ ‡**
- ğŸ­ **è§’è‰²è¯†åˆ«ä¸åˆ†ç¦»**ï¼šå‡†ç¡®è¯†åˆ«è¯´è¯è€…èº«ä»½
- ğŸ“ **æ··åˆæ–‡æœ¬åˆ†ç¦»**ï¼šåˆ†ç¦»å™è¿°ä¸å¯¹è¯ï¼ˆä¿æŒåŸæ–‡ä¸å˜ï¼‰
- ğŸ˜Š **æƒ…ç»ªæ™ºèƒ½è¯†åˆ«**ï¼šè¯†åˆ«å¯¹è¯æƒ…ç»ªå¹¶é…ç½®TTSå‚æ•°
- ğŸ”Š **è¯­éŸ³é…ç½®å…³è”**ï¼šè‡ªåŠ¨å…³è”è§’è‰²ä¸è¯­éŸ³åº“
- ğŸ“‹ **æ ‡å‡†åŒ–è¾“å‡º**ï¼šç”Ÿæˆåˆæˆè¯­éŸ³çš„æ ‡å‡†JSON
- ğŸ§  **å¤§æ¨¡å‹ä¼˜åŒ–**ï¼šè€ƒè™‘ä¸Šä¸‹æ–‡é™åˆ¶å’Œæ‰¿è½½èƒ½åŠ›

## ğŸ“‹ ç°æœ‰åˆæˆJSONæ ¼å¼åˆ†æ

### å½“å‰ç³»ç»Ÿæ”¯æŒçš„JSONæ ¼å¼
```json
{
  "characters": [
    {
      "name": "è§’è‰²å",
      "voice_id": 1,
      "gender": "male/female/neutral"
    }
  ],
  "synthesis_plan": [
    {
      "text": "è¦åˆæˆçš„æ–‡æœ¬",
      "voice_id": 1,
      "speaker": "è§’è‰²å",
      "parameters": {
        "timeStep": 20,
        "pWeight": 1.0,
        "tWeight": 1.0
      }
    }
  ]
}
```

### å‰ç«¯éªŒè¯è¦æ±‚
- âœ… `characters` å­—æ®µå¿…é¡»æ˜¯éç©ºæ•°ç»„
- âœ… `synthesis_plan` æˆ– `segments` å­—æ®µå¿…é¡»æ˜¯éç©ºæ•°ç»„
- âœ… æ¯ä¸ªæ®µè½å¿…é¡»åŒ…å« `text`, `voice_id`, `speaker` å­—æ®µ
- âœ… æ”¯æŒ `parameters` åµŒå¥—TTSå‚æ•°

## ğŸ”„ ä¼˜åŒ–åçš„åˆæˆæµç¨‹

### å®Œæ•´åˆæˆæµç¨‹è®¾è®¡
```mermaid
graph TD
    A[é€‰æ‹©å°è¯´] --> B[é€‰æ‹©ç« èŠ‚]
    B --> C{ç« èŠ‚é•¿åº¦æ£€æŸ¥}
    C -->|è¶…é•¿| D[æ™ºèƒ½åˆ†å—å¤„ç†]
    C -->|é€‚ä¸­| E[ç›´æ¥AIåˆ†æ]
    D --> F[åˆ†å—AIåˆ†æ]
    F --> G[ç»“æœåˆå¹¶]
    E --> H[è§’è‰²è¯†åˆ«ä¸å†…å®¹åˆ†ç¦»]
    G --> H
    H --> I[æƒ…ç»ªè¯†åˆ«ä¸TTSå‚æ•°é…ç½®]
    I --> J[æ™ºèƒ½è¯­éŸ³åŒ¹é…]
    J --> K[äººå·¥æ ¡å¯¹ç•Œé¢]
    K --> L[ç”¨æˆ·ç¡®è®¤/è°ƒæ•´]
    L --> M[ç”Ÿæˆæœ€ç»ˆJSON]
    M --> N[å¼€å§‹è¯­éŸ³åˆæˆ]
```

### å¤§æ¨¡å‹æ‰¿è½½èƒ½åŠ›ä¼˜åŒ–ç­–ç•¥

#### 1. æ™ºèƒ½åˆ†å—ç­–ç•¥
```python
class ChapterChunker:
    """ç« èŠ‚æ™ºèƒ½åˆ†å—å™¨ - è§£å†³å¤§æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶"""
    
    def __init__(self, max_tokens: int = 3000):
        self.max_tokens = max_tokens
        self.overlap_tokens = 200  # é‡å tokenæ•°ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§
    
    def chunk_chapter(self, chapter_content: str) -> List[Dict]:
        """æ™ºèƒ½åˆ†å—ç« èŠ‚å†…å®¹"""
        # 1. æŒ‰è‡ªç„¶æ®µè½åˆ†å‰²
        paragraphs = self._split_by_paragraphs(chapter_content)
        
        # 2. ä¼°ç®—tokenæ•°é‡
        chunks = []
        current_chunk = []
        current_tokens = 0
        
        for para in paragraphs:
            para_tokens = self._estimate_tokens(para)
            
            # å¦‚æœå•ä¸ªæ®µè½å°±è¶…é•¿ï¼Œéœ€è¦å¼ºåˆ¶åˆ†å‰²
            if para_tokens > self.max_tokens:
                if current_chunk:
                    chunks.append(self._create_chunk(current_chunk))
                    current_chunk = []
                    current_tokens = 0
                
                # å¼ºåˆ¶åˆ†å‰²è¶…é•¿æ®µè½
                sub_chunks = self._force_split_paragraph(para)
                chunks.extend(sub_chunks)
                continue
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°å»ºchunk
            if current_tokens + para_tokens > self.max_tokens:
                chunks.append(self._create_chunk(current_chunk))
                
                # ä¿æŒé‡å ä¸Šä¸‹æ–‡
                overlap_paras = self._get_overlap_context(current_chunk)
                current_chunk = overlap_paras + [para]
                current_tokens = sum(self._estimate_tokens(p) for p in current_chunk)
            else:
                current_chunk.append(para)
                current_tokens += para_tokens
        
        # å¤„ç†æœ€åä¸€ä¸ªchunk
        if current_chunk:
            chunks.append(self._create_chunk(current_chunk))
        
        return chunks
    
    def _create_chunk(self, paragraphs: List[str]) -> Dict:
        """åˆ›å»ºåˆ†å—æ•°æ®"""
        return {
            "content": "\n".join(paragraphs),
            "paragraph_count": len(paragraphs),
            "estimated_tokens": sum(self._estimate_tokens(p) for p in paragraphs),
            "chunk_type": "normal"
        }
```

#### 2. åˆ†å¸ƒå¼å¤„ç†å¼•æ“
```python
class DistributedAnalysisEngine:
    """åˆ†å¸ƒå¼åˆ†æå¼•æ“ - å¹¶è¡Œå¤„ç†å¤šä¸ªåˆ†å—"""
    
    def __init__(self, max_concurrent: int = 3):
        self.max_concurrent = max_concurrent
        self.chunker = ChapterChunker()
        self.ollama_detector = OllamaCharacterDetector()
    
    async def analyze_chapter_distributed(
        self, 
        chapter_content: str, 
        chapter_info: Dict
    ) -> Dict:
        """åˆ†å¸ƒå¼åˆ†æç« èŠ‚"""
        
        # 1. æ™ºèƒ½åˆ†å—
        chunks = self.chunker.chunk_chapter(chapter_content)
        
        if len(chunks) == 1:
            # å•å—ç›´æ¥å¤„ç†
            return await self._analyze_single_chunk(chunks[0], chapter_info)
        
        # 2. å¹¶è¡Œåˆ†æå¤šä¸ªåˆ†å—
        chunk_results = await self._analyze_chunks_parallel(chunks, chapter_info)
        
        # 3. åˆå¹¶åˆ†æç»“æœ
        merged_result = await self._merge_chunk_results(chunk_results, chapter_info)
        
        return merged_result
    
    async def _analyze_chunks_parallel(
        self, 
        chunks: List[Dict], 
        chapter_info: Dict
    ) -> List[Dict]:
        """å¹¶è¡Œåˆ†æå¤šä¸ªåˆ†å—"""
        
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def analyze_chunk_with_semaphore(chunk, index):
            async with semaphore:
                chunk_info = {
                    **chapter_info,
                    "chunk_index": index,
                    "total_chunks": len(chunks),
                    "is_chunk": True
                }
                return await self.ollama_detector.analyze_text(
                    chunk["content"], chunk_info
                )
        
        # å¹¶è¡Œæ‰§è¡Œåˆ†æ
        tasks = [
            analyze_chunk_with_semaphore(chunk, i) 
            for i, chunk in enumerate(chunks)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        valid_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"åˆ†å— {i} åˆ†æå¤±è´¥: {result}")
                # åˆ›å»ºé»˜è®¤ç»“æœ
                valid_results.append(self._create_fallback_result(chunks[i]))
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def _merge_chunk_results(
        self, 
        chunk_results: List[Dict], 
        chapter_info: Dict
    ) -> Dict:
        """åˆå¹¶åˆ†å—åˆ†æç»“æœ"""
        
        # åˆå¹¶æ‰€æœ‰æ®µè½
        all_segments = []
        segment_order = 1
        
        for result in chunk_results:
            for segment in result.get('segments', []):
                segment['order'] = segment_order
                all_segments.append(segment)
                segment_order += 1
        
        # åˆå¹¶è§’è‰²ä¿¡æ¯ï¼ˆå»é‡ï¼‰
        all_characters = {}
        for result in chunk_results:
            for character in result.get('detected_characters', []):
                char_name = character['name']
                if char_name not in all_characters:
                    all_characters[char_name] = character
                else:
                    # åˆå¹¶è§’è‰²ä¿¡æ¯ï¼ˆå–ç½®ä¿¡åº¦æ›´é«˜çš„ï¼‰
                    existing = all_characters[char_name]
                    if character.get('confidence', 0) > existing.get('confidence', 0):
                        all_characters[char_name] = character
        
        # é‡æ–°è¿›è¡Œå…¨å±€è§’è‰²è¿‡æ»¤ï¼ˆåŸºäºå®Œæ•´è§’è‰²åˆ—è¡¨ï¼‰
        filtered_characters = await self._filter_existing_characters_global(
            list(all_characters.values())
        )
        
        return {
            'segments': all_segments,
            'detected_characters': filtered_characters,
            'analysis_metadata': {
                'total_chunks': len(chunk_results),
                'total_segments': len(all_segments),
                'total_characters': len(filtered_characters),
                'processing_mode': 'distributed'
            }
        }
```

### 3. MegaTTS3å‚æ•°æ™ºèƒ½é…ç½®å¼•æ“
```python
class MegaTTS3ParameterEngine:
    """MegaTTS3å‚æ•°æ™ºèƒ½é…ç½®å¼•æ“ - æ ¹æ®æƒ…ç»ªå’Œè§’è‰²ç‰¹å¾é…ç½®MegaTTS3çš„3ä¸ªæ ¸å¿ƒå‚æ•°"""
    
    def __init__(self):
        # æƒ…ç»ªå¯¹åº”çš„MegaTTS3å‚æ•°é…ç½®ï¼ˆåªæœ‰3ä¸ªå‚æ•°ï¼‰
        self.emotion_tts_configs = {
            "angry": {
                "time_step": 25,      # æ„¤æ€’ï¼šå‡å°‘æ¨ç†æ­¥æ•°ï¼Œè¯­éŸ³æ›´æ€¥ä¿ƒ
                "p_w": 1.8,          # æé«˜æ¸…æ™°åº¦æƒé‡ï¼Œè¡¨è¾¾æ›´å¼ºçƒˆ
                "t_w": 3.2           # é€‚ä¸­ç›¸ä¼¼åº¦æƒé‡
            },
            "happy": {
                "time_step": 30,      # å¼€å¿ƒï¼šé€‚ä¸­æ¨ç†æ­¥æ•°
                "p_w": 1.5,          # é€‚ä¸­æ¸…æ™°åº¦æƒé‡
                "t_w": 2.8           # ç¨ä½ç›¸ä¼¼åº¦æƒé‡ï¼Œæ›´æ´»æ³¼
            },
            "sad": {
                "time_step": 40,      # æ‚²ä¼¤ï¼šå¢åŠ æ¨ç†æ­¥æ•°ï¼Œè¯­éŸ³æ›´ç¼“æ…¢
                "p_w": 1.2,          # é™ä½æ¸…æ™°åº¦æƒé‡ï¼Œæ›´æŸ”å’Œ
                "t_w": 3.5           # æé«˜ç›¸ä¼¼åº¦æƒé‡ï¼Œä¿æŒç¨³å®š
            },
            "surprised": {
                "time_step": 28,      # æƒŠè®¶ï¼šè¾ƒå¿«æ¨ç†æ­¥æ•°
                "p_w": 1.7,          # æé«˜æ¸…æ™°åº¦æƒé‡
                "t_w": 3.0           # æ ‡å‡†ç›¸ä¼¼åº¦æƒé‡
            },
            "fear": {
                "time_step": 35,      # ææƒ§ï¼šç¨æ…¢æ¨ç†æ­¥æ•°
                "p_w": 1.6,          # é€‚ä¸­æ¸…æ™°åº¦æƒé‡
                "t_w": 3.3           # æé«˜ç›¸ä¼¼åº¦æƒé‡ï¼Œä¿æŒç¨³å®š
            },
            "excited": {
                "time_step": 26,      # å…´å¥‹ï¼šå¿«é€Ÿæ¨ç†æ­¥æ•°
                "p_w": 1.7,          # æé«˜æ¸…æ™°åº¦æƒé‡
                "t_w": 3.1           # é€‚ä¸­ç›¸ä¼¼åº¦æƒé‡
            },
            "calm": {
                "time_step": 32,      # å¹³é™ï¼šæ ‡å‡†æ¨ç†æ­¥æ•°
                "p_w": 1.4,          # æ ‡å‡†æ¸…æ™°åº¦æƒé‡
                "t_w": 3.0           # æ ‡å‡†ç›¸ä¼¼åº¦æƒé‡
            }
        }
        
        # è§’è‰²åŸºç¡€é…ç½®ï¼ˆç¬¦åˆMegaTTS3å‚æ•°ï¼‰
        self.character_base_configs = {
            "æ—ç™½": {
                "time_step": 32,      # æ—ç™½ï¼šæ ‡å‡†é…ç½®
                "p_w": 1.3,          # ç¨ä½æ¸…æ™°åº¦æƒé‡ï¼Œæ›´è‡ªç„¶
                "t_w": 3.0           # æ ‡å‡†ç›¸ä¼¼åº¦æƒé‡
            },
            "å­™æ‚Ÿç©º": {
                "time_step": 28,      # å­™æ‚Ÿç©ºï¼šæ´»æ³¼å¿«é€Ÿ
                "p_w": 1.6,          # æé«˜æ¸…æ™°åº¦æƒé‡
                "t_w": 3.2           # é€‚ä¸­ç›¸ä¼¼åº¦æƒé‡
            },
            "å”åƒ§": {
                "time_step": 35,      # å”åƒ§ï¼šç¨³é‡ç¼“æ…¢
                "p_w": 1.2,          # é™ä½æ¸…æ™°åº¦æƒé‡ï¼Œæ›´æ¸©å’Œ
                "t_w": 2.8           # ç¨ä½ç›¸ä¼¼åº¦æƒé‡
            },
            "çŒªå…«æˆ’": {
                "time_step": 30,      # çŒªå…«æˆ’ï¼šé€‚ä¸­
                "p_w": 1.5,          # é€‚ä¸­æ¸…æ™°åº¦æƒé‡
                "t_w": 2.9           # é€‚ä¸­ç›¸ä¼¼åº¦æƒé‡
            },
            "æ²™åƒ§": {
                "time_step": 34,      # æ²™åƒ§ï¼šç¨³é‡
                "p_w": 1.3,          # ç¨ä½æ¸…æ™°åº¦æƒé‡
                "t_w": 3.1           # é€‚ä¸­ç›¸ä¼¼åº¦æƒé‡
            }
        }
    
    def calculate_megatts3_params(self, speaker: str, emotion: str, emotion_confidence: float) -> Dict:
        """è®¡ç®—MegaTTS3çš„3ä¸ªæ ¸å¿ƒå‚æ•°"""
        # è·å–è§’è‰²åŸºç¡€é…ç½®
        base_config = self.character_base_configs.get(speaker, {
            "time_step": 32,
            "p_w": 1.4,
            "t_w": 3.0
        })
        
        # è·å–æƒ…ç»ªé…ç½®
        emotion_config = self.emotion_tts_configs.get(emotion, self.emotion_tts_configs["calm"])
        
        # æ ¹æ®æƒ…ç»ªç½®ä¿¡åº¦æ··åˆé…ç½®
        final_config = {}
        for param in ["time_step", "p_w", "t_w"]:
            base_value = base_config.get(param, emotion_config[param])
            emotion_value = emotion_config[param]
            
            # çº¿æ€§æ’å€¼ï¼šbase_value + (emotion_value - base_value) * confidence
            final_value = base_value + (emotion_value - base_value) * emotion_confidence
            
            # ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†…
            if param == "time_step":
                final_config[param] = max(5, min(100, int(round(final_value))))
            elif param == "p_w":
                final_config[param] = max(0.5, min(2.5, round(final_value, 1)))
            elif param == "t_w":
                final_config[param] = max(1.0, min(4.0, round(final_value, 1)))
        
        return final_config
    
    def get_default_params(self) -> Dict:
        """è·å–é»˜è®¤MegaTTS3å‚æ•°"""
        return {
            "time_step": 32,
            "p_w": 1.4,
            "t_w": 3.0
        }
    
    def validate_params(self, params: Dict) -> Dict:
        """éªŒè¯å¹¶ä¿®æ­£MegaTTS3å‚æ•°"""
        validated = {}
        
        # time_step: 5-100çš„æ•´æ•°
        validated["time_step"] = max(5, min(100, int(params.get("time_step", 32))))
        
        # p_w: 0.5-2.5çš„æµ®ç‚¹æ•°
        validated["p_w"] = max(0.5, min(2.5, float(params.get("p_w", 1.4))))
        
        # t_w: 1.0-4.0çš„æµ®ç‚¹æ•°
        validated["t_w"] = max(1.0, min(4.0, float(params.get("t_w", 3.0))))
        
        return validated
```

### 4. æ—ç™½è§’è‰²æ™ºèƒ½å¤„ç†å™¨
```python
class NarratorProcessor:
    """æ—ç™½è§’è‰²æ™ºèƒ½å¤„ç†å™¨ - è§£å†³æ—ç™½è§’è‰²ç¼ºå¤±é—®é¢˜"""
    
    def __init__(self):
        self.narrator_voice_id = None  # æ—ç™½ä¸“ç”¨è¯­éŸ³ID
    
    def ensure_narrator_character(self, detected_characters: List[Dict]) -> List[Dict]:
        """ç¡®ä¿è§’è‰²åˆ—è¡¨ä¸­åŒ…å«æ—ç™½è§’è‰²"""
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ—ç™½è§’è‰²
        has_narrator = any(char['name'] == 'æ—ç™½' for char in detected_characters)
        
        if not has_narrator:
            # è‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²
            narrator_character = {
                'name': 'æ—ç™½',
                'confidence': 1.0,  # ç³»ç»Ÿæ·»åŠ ï¼Œç½®ä¿¡åº¦æœ€é«˜
                'recommended_config': {
                    'gender': 'neutral',
                    'age_range': 'adult',
                    'personality': 'calm',
                    'voice_style': 'professional'
                },
                'source': 'system_generated',  # æ ‡è®°ä¸ºç³»ç»Ÿç”Ÿæˆ
                'description': 'ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ çš„æ—ç™½è§’è‰²ï¼Œç”¨äºå™è¿°æ€§æ–‡æœ¬'
            }
            detected_characters.append(narrator_character)
            logger.info("ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²")
        
        return detected_characters
    
    def classify_text_segments(self, segments: List[Dict]) -> List[Dict]:
        """åˆ†ç±»æ–‡æœ¬æ®µè½ï¼Œè‡ªåŠ¨åˆ†é…æ—ç™½è§’è‰²"""
        
        processed_segments = []
        
        for segment in segments:
            # å¦‚æœæ®µè½æ²¡æœ‰æ˜ç¡®çš„è¯´è¯è€…ï¼Œè‡ªåŠ¨åˆ†é…ç»™æ—ç™½
            if not segment.get('speaker') or segment.get('speaker') == 'unknown':
                segment['speaker'] = 'æ—ç™½'
                segment['text_type'] = 'narration'
                segment['confidence'] = segment.get('confidence', 0.8)
                segment['assignment_reason'] = 'auto_narrator'
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå™è¿°æ€§æ–‡æœ¬ï¼ˆæ²¡æœ‰å¯¹è¯æ ‡è®°ï¼‰
            text = segment.get('text', '')
            if not self._has_dialogue_markers(text) and segment.get('text_type') != 'dialogue':
                if segment.get('speaker') not in ['æ—ç™½'] and not self._is_character_speaking(text):
                    segment['speaker'] = 'æ—ç™½'
                    segment['text_type'] = 'narration'
                    segment['assignment_reason'] = 'narrative_content'
            
            processed_segments.append(segment)
        
        return processed_segments
    
    def _has_dialogue_markers(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å¯¹è¯æ ‡è®°"""
        dialogue_markers = ['"', '"', '"', 'ã€Œ', 'ã€', 'ã€', 'ã€', "'", "'"]
        return any(marker in text for marker in dialogue_markers)
    
    def _is_character_speaking(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æ˜ç¡®è¡¨ç¤ºæŸä¸ªè§’è‰²åœ¨è¯´è¯"""
        speaking_patterns = [
            r'[ä¸€-é¾¯]{2,4}[è¯´é“è®²å«å–Šé—®ç­”å›å¤è¡¨ç¤º]',
            r'[ä¸€-é¾¯]{2,4}[æƒ³å¿ƒé‡Œæš—]',
            r'[ä¸€-é¾¯]{2,4}[è‡ªè¨€è‡ªè¯­]'
        ]
        return any(re.search(pattern, text) for pattern in speaking_patterns)
    
    def validate_content_integrity(self, original_text: str, processed_segments: List[Dict]) -> bool:
        """éªŒè¯å¤„ç†åçš„å†…å®¹å®Œæ•´æ€§"""
        
        # æ‹¼æ¥æ‰€æœ‰å¤„ç†åçš„æ–‡æœ¬
        reconstructed_text = ""
        for segment in processed_segments:
            reconstructed_text += segment.get('text', '')
        
        # æ¸…ç†ç©ºç™½å­—ç¬¦åæ¯”è¾ƒ
        original_clean = re.sub(r'\s+', '', original_text)
        reconstructed_clean = re.sub(r'\s+', '', reconstructed_text)
        
        if original_clean != reconstructed_clean:
            logger.error("å†…å®¹å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼å¤„ç†åæ–‡æœ¬ä¸åŸæ–‡ä¸ä¸€è‡´")
            logger.error(f"åŸæ–‡é•¿åº¦: {len(original_clean)}")
            logger.error(f"å¤„ç†åé•¿åº¦: {len(reconstructed_clean)}")
            return False
        
        logger.info("âœ… å†…å®¹å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        return True
    
    def get_narrator_voice_mapping(self, available_voices: List[Dict]) -> int:
        """ä¸ºæ—ç™½è§’è‰²é€‰æ‹©åˆé€‚çš„è¯­éŸ³"""
        
        # ä¼˜å…ˆé€‰æ‹©æ ‡è®°ä¸º"æ—ç™½"æˆ–"ä¸­æ€§"çš„è¯­éŸ³
        for voice in available_voices:
            if voice.get('type') == 'neutral' or 'æ—ç™½' in voice.get('name', ''):
                return voice.get('id')
        
        # å…¶æ¬¡é€‰æ‹©å¥³æ€§æ¸©å’Œå£°éŸ³
        for voice in available_voices:
            if voice.get('type') == 'female' and 'æ¸©æŸ”' in voice.get('name', ''):
                return voice.get('id')
        
        # æœ€åé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨å£°éŸ³
        if available_voices:
            return available_voices[0].get('id')
        
        return None
```

## ğŸ—ï¸ è°ƒæ•´åçš„æŠ€æœ¯æ¶æ„

### 1. å…¼å®¹ç°æœ‰æ ¼å¼çš„è¾“å‡ºé€‚é…å™¨
```python
class SynthesisFormatAdapter:
    """åˆæˆæ ¼å¼é€‚é…å™¨ - è¾“å‡ºå…¼å®¹ç°æœ‰ç³»ç»Ÿçš„JSONæ ¼å¼"""
    
    def __init__(self):
        self.emotion_detector = EmotionDetector()
        self.tts_engine = MegaTTS3ParameterEngine()
    
    def adapt_to_synthesis_format(
        self, 
        analysis_result: Dict, 
        voice_mapping: Dict[str, int]
    ) -> Dict:
        """é€‚é…ä¸ºç°æœ‰åˆæˆç³»ç»Ÿçš„JSONæ ¼å¼"""
        
        # 1. æ ¼å¼åŒ–è§’è‰²ä¿¡æ¯
        characters = []
        for character in analysis_result['detected_characters']:
            char_name = character['name']
            voice_id = voice_mapping.get(char_name)
            if voice_id:
                characters.append({
                    "name": char_name,
                    "voice_id": voice_id,
                    "gender": character.get('recommended_config', {}).get('gender', 'unknown')
                })
        
        # 2. æ ¼å¼åŒ–åˆæˆè®¡åˆ’
        synthesis_plan = []
        for segment in analysis_result['segments']:
            # æƒ…ç»ªè¯†åˆ«
            emotion_result = self.emotion_detector.detect_emotion(
                segment['text'], 
                segment['speaker']
            )
            
            # MegaTTS3å‚æ•°è®¡ç®—
            tts_params = self.tts_engine.calculate_megatts3_params(
                segment['speaker'],
                emotion_result['emotion'],
                emotion_result['confidence']
            )
            
            # è½¬æ¢ä¸ºç°æœ‰æ ¼å¼çš„parameters
            voice_id = voice_mapping.get(segment['speaker'])
            if voice_id:
                synthesis_plan.append({
                    "text": segment['text'],
                    "voice_id": voice_id,
                    "speaker": segment['speaker'],
                    "parameters": {
                        "timeStep": tts_params.get('time_step', 32),
                        "pWeight": tts_params.get('p_w', 1.4),
                        "tWeight": tts_params.get('t_w', 3.0)
                    },
                    # æ‰©å±•å­—æ®µï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•å’Œä¼˜åŒ–ï¼‰
                    "emotion": emotion_result['emotion'],
                    "emotion_confidence": emotion_result['confidence'],
                    "text_type": segment.get('text_type', 'unknown')
                })
        
        return {
            "characters": characters,
            "synthesis_plan": synthesis_plan,
            # å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
            "metadata": {
                "total_segments": len(synthesis_plan),
                "character_count": len(characters),
                "processing_mode": analysis_result.get('analysis_metadata', {}).get('processing_mode', 'single'),
                "emotion_distribution": self._calculate_emotion_distribution(synthesis_plan)
            }
        }
    
    def _calculate_emotion_distribution(self, synthesis_plan: List[Dict]) -> Dict[str, int]:
        """è®¡ç®—æƒ…ç»ªåˆ†å¸ƒ"""
        distribution = {}
        for segment in synthesis_plan:
            emotion = segment.get('emotion', 'calm')
            distribution[emotion] = distribution.get(emotion, 0) + 1
        return distribution
```

### 2. ä¼˜åŒ–çš„åˆæˆæµç¨‹æ§åˆ¶å™¨
```python
class OptimizedSynthesisController:
    """ä¼˜åŒ–çš„åˆæˆæµç¨‹æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.analysis_engine = DistributedAnalysisEngine()
        self.format_adapter = SynthesisFormatAdapter()
        self.preprocessor = TextPreprocessor()
        self.tts_engine = MegaTTS3ParameterEngine()
        self.narrator_processor = NarratorProcessor()  # ğŸ”¥ æ–°å¢æ—ç™½å¤„ç†å™¨
    
    async def prepare_chapter_for_synthesis(
        self, 
        chapter_id: int,
        user_preferences: Dict = None
    ) -> Dict:
        """å‡†å¤‡ç« èŠ‚ç”¨äºè¯­éŸ³åˆæˆçš„å®Œæ•´æµç¨‹"""
        
        # 1. è·å–ç« èŠ‚æ•°æ®
        chapter = await self._get_chapter(chapter_id)
        
        # 2. é¢„å¤„ç†æ–‡æœ¬
        cleaned_text = self.preprocessor.clean_and_normalize(chapter.content)
        
        # 3. æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå†³å®šå¤„ç†ç­–ç•¥
        estimated_tokens = self._estimate_tokens(cleaned_text)
        
        if estimated_tokens > 3000:
            logger.info(f"ç« èŠ‚ {chapter_id} å†…å®¹è¾ƒé•¿ ({estimated_tokens} tokens)ï¼Œä½¿ç”¨åˆ†å¸ƒå¼å¤„ç†")
            processing_mode = "distributed"
        else:
            logger.info(f"ç« èŠ‚ {chapter_id} å†…å®¹é€‚ä¸­ ({estimated_tokens} tokens)ï¼Œä½¿ç”¨å•æ¬¡å¤„ç†")
            processing_mode = "single"
        
        # 4. æ‰§è¡ŒAIåˆ†æ
        chapter_info = {
            "chapter_id": chapter.id,
            "chapter_title": chapter.title,
            "chapter_number": chapter.chapter_number,
            "processing_mode": processing_mode
        }
        
        analysis_result = await self.analysis_engine.analyze_chapter_distributed(
            cleaned_text, chapter_info
        )
        
        # ğŸ”¥ 5. æ—ç™½è§’è‰²å¤„ç†å’Œå†…å®¹å®Œæ•´æ€§éªŒè¯
        # ç¡®ä¿è§’è‰²åˆ—è¡¨åŒ…å«æ—ç™½
        analysis_result['detected_characters'] = self.narrator_processor.ensure_narrator_character(
            analysis_result['detected_characters']
        )
        
        # è‡ªåŠ¨åˆ†é…æ—ç™½è§’è‰²ç»™å™è¿°æ€§æ–‡æœ¬
        analysis_result['segments'] = self.narrator_processor.classify_text_segments(
            analysis_result['segments']
        )
        
        # ğŸ”’ éªŒè¯å†…å®¹å®Œæ•´æ€§ï¼ˆæ ¸å¿ƒåº•çº¿æ£€æŸ¥ï¼‰
        integrity_check = self.narrator_processor.validate_content_integrity(
            cleaned_text, analysis_result['segments']
        )
        
        if not integrity_check:
            logger.error(f"ç« èŠ‚ {chapter_id} å†…å®¹å®Œæ•´æ€§éªŒè¯å¤±è´¥ï¼")
            raise ValueError("å†…å®¹å¤„ç†åä¸åŸæ–‡ä¸ä¸€è‡´ï¼Œè¿ååº•çº¿åŸåˆ™")
        
        # 6. æ™ºèƒ½è¯­éŸ³åŒ¹é…ï¼ˆåŒ…å«æ—ç™½è¯­éŸ³åˆ†é…ï¼‰
        voice_mapping = await self._intelligent_voice_mapping(
            analysis_result['detected_characters'],
            user_preferences
        )
        
        # ğŸ”¥ ç¡®ä¿æ—ç™½è§’è‰²æœ‰è¯­éŸ³åˆ†é…
        if 'æ—ç™½' not in voice_mapping:
            available_voices = await self._get_available_voices()
            narrator_voice_id = self.narrator_processor.get_narrator_voice_mapping(available_voices)
            if narrator_voice_id:
                voice_mapping['æ—ç™½'] = narrator_voice_id
                logger.info(f"ä¸ºæ—ç™½è§’è‰²è‡ªåŠ¨åˆ†é…è¯­éŸ³ID: {narrator_voice_id}")
            else:
                logger.warning("æ— æ³•ä¸ºæ—ç™½è§’è‰²åˆ†é…è¯­éŸ³ï¼Œå¯èƒ½å½±å“åˆæˆæ•ˆæœ")
        
        # 6. æ ¼å¼é€‚é…
        synthesis_ready = self.format_adapter.adapt_to_synthesis_format(
            analysis_result, voice_mapping
        )
        
        # 7. ç”Ÿæˆäººå·¥æ ¡å¯¹æ•°æ®
        review_data = self._generate_review_data(
            analysis_result, voice_mapping, synthesis_ready
        )
        
        return {
            "synthesis_json": synthesis_ready,
            "review_data": review_data,
            "processing_info": {
                "mode": processing_mode,
                "estimated_tokens": estimated_tokens,
                "chunks_processed": analysis_result.get('analysis_metadata', {}).get('total_chunks', 1),
                "total_segments": len(synthesis_ready['synthesis_plan']),
                "characters_found": len(synthesis_ready['characters'])
            }
        }
    
    def _generate_review_data(
        self, 
        analysis_result: Dict, 
        voice_mapping: Dict, 
        synthesis_ready: Dict
    ) -> Dict:
        """ç”Ÿæˆäººå·¥æ ¡å¯¹ç•Œé¢æ•°æ®"""
        
        return {
            "characters_for_review": [
                {
                    "name": char['name'],
                    "assigned_voice_id": voice_mapping.get(char['name']),
                    "confidence": char.get('confidence', 0),
                    "gender": char.get('recommended_config', {}).get('gender', 'unknown'),
                    "sample_texts": self._get_character_samples(char['name'], analysis_result['segments']),
                    "suggested_alternatives": self._get_voice_alternatives(char, voice_mapping)
                }
                for char in analysis_result['detected_characters']
            ],
            "segments_preview": synthesis_ready['synthesis_plan'][:10],  # å‰10ä¸ªæ®µè½é¢„è§ˆ
            "emotion_summary": synthesis_ready['metadata']['emotion_distribution'],
            "quality_indicators": {
                "character_confidence_avg": self._calculate_avg_confidence(analysis_result['detected_characters']),
                "voice_mapping_coverage": len(voice_mapping) / len(analysis_result['detected_characters']) if analysis_result['detected_characters'] else 0,
                "processing_quality": "high" if analysis_result.get('analysis_metadata', {}).get('processing_mode') == 'single' else "good"
            }
        }
```

## ğŸ“Š æƒ…ç»ªä¸MegaTTS3å‚æ•°å¯¹åº”è¡¨

| æƒ…ç»ª | time_step | p_w | t_w | ç‰¹å¾æè¿° |
|------|-----------|-----|-----|----------|
| **angry** | 25 | 1.8 | 3.2 | æ¨ç†æ­¥æ•°å°‘â†’æ€¥ä¿ƒï¼Œæ¸…æ™°åº¦é«˜â†’å¼ºçƒˆè¡¨è¾¾ |
| **happy** | 30 | 1.5 | 2.8 | é€‚ä¸­æ¨ç†æ­¥æ•°ï¼Œæ¸…æ™°åº¦é€‚ä¸­ï¼Œç›¸ä¼¼åº¦ç¨ä½â†’æ´»æ³¼ |
| **sad** | 40 | 1.2 | 3.5 | æ¨ç†æ­¥æ•°å¤šâ†’ç¼“æ…¢ï¼Œæ¸…æ™°åº¦ä½â†’æŸ”å’Œï¼Œç›¸ä¼¼åº¦é«˜â†’ç¨³å®š |
| **surprised** | 28 | 1.7 | 3.0 | æ¨ç†æ­¥æ•°å°‘â†’å¿«é€Ÿååº”ï¼Œæ¸…æ™°åº¦é«˜â†’çªå‡ºè¡¨è¾¾ |
| **fear** | 35 | 1.6 | 3.3 | æ¨ç†æ­¥æ•°ç¨å¤šâ†’ç´§å¼ æ„Ÿï¼Œç›¸ä¼¼åº¦é«˜â†’ä¿æŒç¨³å®š |
| **excited** | 26 | 1.7 | 3.1 | æ¨ç†æ­¥æ•°æœ€å°‘â†’æœ€å¿«é€Ÿï¼Œæ¸…æ™°åº¦é«˜â†’å…´å¥‹è¡¨è¾¾ |
| **calm** | 32 | 1.4 | 3.0 | æ ‡å‡†é…ç½®ï¼Œå¹³è¡¡çš„è¡¨è¾¾æ•ˆæœ |

### MegaTTS3å‚æ•°è¯´æ˜
- **time_step**: æ‰©æ•£å˜æ¢å™¨æ¨ç†æ­¥æ•° (5-100)ï¼Œæ­¥æ•°è¶Šå°‘è¯­éŸ³è¶Šå¿«ï¼Œæ­¥æ•°è¶Šå¤šè¯­éŸ³è¶Šæ…¢
- **p_w**: æ¸…æ™°åº¦æƒé‡ (0.5-2.5)ï¼Œæƒé‡è¶Šé«˜è¯­éŸ³è¶Šæ¸…æ™°å¼ºçƒˆ
- **t_w**: ç›¸ä¼¼åº¦æƒé‡ (1.0-4.0)ï¼Œæƒé‡è¶Šé«˜ä¸å‚è€ƒéŸ³é¢‘è¶Šç›¸ä¼¼

## ğŸš€ APIæ¥å£è®¾è®¡

### ç« èŠ‚å†…å®¹å‡†å¤‡æ¥å£ï¼ˆå…¼å®¹ç°æœ‰ç³»ç»Ÿï¼‰
```python
@router.post("/{chapter_id}/prepare-synthesis")
async def prepare_chapter_for_synthesis(
    chapter_id: int,
    include_emotion: bool = Query(True, description="æ˜¯å¦åŒ…å«æƒ…ç»ªè¯†åˆ«"),
    processing_mode: str = Query("auto", description="å¤„ç†æ¨¡å¼: auto/single/distributed"),
    user_preferences: Dict = Body(default={}, description="ç”¨æˆ·åå¥½è®¾ç½®"),
    db: Session = Depends(get_db)
):
    """å‡†å¤‡ç« èŠ‚å†…å®¹ç”¨äºè¯­éŸ³åˆæˆï¼ˆè¾“å‡ºå…¼å®¹ç°æœ‰æ ¼å¼ï¼‰"""
    
    controller = OptimizedSynthesisController()
    
    try:
        result = await controller.prepare_chapter_for_synthesis(
            chapter_id, user_preferences
        )
        
        return {
            "success": True,
            "data": result["synthesis_json"],  # å…¼å®¹ç°æœ‰æ ¼å¼çš„JSON
            "review_data": result["review_data"],  # äººå·¥æ ¡å¯¹æ•°æ®
            "processing_info": result["processing_info"],
            "message": f"ç« èŠ‚å†…å®¹å‡†å¤‡å®Œæˆï¼Œå…±è¯†åˆ« {result['processing_info']['characters_found']} ä¸ªè§’è‰²ï¼Œ{result['processing_info']['total_segments']} ä¸ªæ®µè½"
        }
        
    except Exception as e:
        logger.error(f"ç« èŠ‚ {chapter_id} å†…å®¹å‡†å¤‡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…å®¹å‡†å¤‡å¤±è´¥: {str(e)}")
```

## ğŸ¯ é¢„æœŸæ•ˆæœä¸æ€§èƒ½æŒ‡æ ‡

### å¤„ç†èƒ½åŠ›
- âœ… **å¤§æ–‡æœ¬æ”¯æŒ**ï¼šå•ç« èŠ‚æœ€å¤§æ”¯æŒ 50,000 å­—ç¬¦
- âœ… **å¹¶å‘å¤„ç†**ï¼šæœ€å¤š3ä¸ªåˆ†å—å¹¶è¡Œåˆ†æ
- âœ… **æ ¼å¼å…¼å®¹**ï¼š100%å…¼å®¹ç°æœ‰åˆæˆç³»ç»ŸJSONæ ¼å¼
- âœ… **æ™ºèƒ½åˆ†å—**ï¼šè‡ªåŠ¨å¤„ç†è¶…é•¿ç« èŠ‚ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§
- âœ… **é”™è¯¯æ¢å¤**ï¼šåˆ†å—å¤±è´¥æ—¶è‡ªåŠ¨é™çº§å¤„ç†

### è´¨é‡ä¿è¯
- ğŸ­ **è§’è‰²è¯†åˆ«å‡†ç¡®ç‡**ï¼šâ‰¥95%ï¼ˆåŸºäºç°æœ‰æµ‹è¯•ç»“æœï¼‰
- ğŸ˜Š **æƒ…ç»ªè¯†åˆ«å‡†ç¡®ç‡**ï¼šâ‰¥85%
- ğŸ“ **æ–‡æœ¬å®Œæ•´æ€§**ï¼š100%æ— é—æ¼
- ğŸ”Š **åˆæˆæˆåŠŸç‡**ï¼šâ‰¥98%ï¼ˆå…¼å®¹ç°æœ‰æ ¼å¼ï¼‰

### æ€§èƒ½æŒ‡æ ‡
- âš¡ **å•æ¬¡å¤„ç†**ï¼šâ‰¤60ç§’ï¼ˆ3000å­—ç¬¦ä»¥å†…ï¼‰
- âš¡ **åˆ†å¸ƒå¼å¤„ç†**ï¼šâ‰¤120ç§’ï¼ˆ50000å­—ç¬¦ä»¥å†…ï¼‰
- ğŸ’¾ **å†…å­˜å ç”¨**ï¼šâ‰¤2GBï¼ˆå¤§æ–‡æœ¬å¤„ç†ï¼‰
- ğŸ”„ **å¹¶å‘èƒ½åŠ›**ï¼šæ”¯æŒ3ä¸ªç« èŠ‚åŒæ—¶å¤„ç†

## ğŸ“‹ å®æ–½è®¡åˆ’

### é˜¶æ®µ1: æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆ2-3å¤©ï¼‰âœ… **å·²å®Œæˆ**
- [x] å¢å¼ºOllamaCharacterDetector
- [x] âœ… å®ç°ChapterChunkeræ™ºèƒ½åˆ†å—
- [x] âœ… å®ç°DistributedAnalysisEngineåˆ†å¸ƒå¼å¤„ç†
- [x] âœ… å®ç°SynthesisFormatAdapteræ ¼å¼é€‚é…
- [x] âœ… å®ç°NarratorProcessoræ—ç™½å¤„ç†å™¨
- [x] âœ… å®ç°ContentPreparationServiceä¸»æ§åˆ¶å™¨
- [x] âœ… æ·»åŠ APIæ¥å£ `/chapters/{chapter_id}/prepare-synthesis`

### é˜¶æ®µ2: æµç¨‹é›†æˆä¸æµ‹è¯•ï¼ˆ1-2å¤©ï¼‰ğŸ”§ **è¿›è¡Œä¸­**
- [x] âœ… é›†æˆContentPreparationServiceä¸»æ§åˆ¶å™¨
- [x] âœ… æ·»åŠ APIæ¥å£å’Œé”™è¯¯å¤„ç†
- [x] âœ… åˆ›å»ºé›†æˆæµ‹è¯•è„šæœ¬
- [ ] ğŸ”§ å‰ç«¯ç•Œé¢é›†æˆ
- [ ] ğŸ”§ å®Œæ•´æµç¨‹æµ‹è¯•å’Œæ€§èƒ½ä¼˜åŒ–

### é˜¶æ®µ3: ç”¨æˆ·ç•Œé¢ä¼˜åŒ–ï¼ˆ1å¤©ï¼‰
- [ ] å‰ç«¯äººå·¥æ ¡å¯¹ç•Œé¢
- [ ] è¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯å¤„ç†
- [ ] ç”¨æˆ·ä½“éªŒä¼˜åŒ–

---

## ğŸ”’ æ ¸å¿ƒåº•çº¿ä¿è¯

### å†…å®¹å®Œæ•´æ€§é“å¾‹
1. **åŸæ–‡ä¸€å­—ä¸å˜**: æ‰€æœ‰å¤„ç†åçš„æ–‡æœ¬ç‰‡æ®µæ‹¼æ¥å¿…é¡»ç­‰äºåŸæ–‡
2. **é¡ºåºä¸¥æ ¼ä¿æŒ**: æ–‡æœ¬æ®µè½é¡ºåºå®Œå…¨æŒ‰ç…§åŸæ–‡
3. **åªåšè§’è‰²æ ‡æ³¨**: ä»…è¿›è¡Œè¯´è¯è€…èº«ä»½è¯†åˆ«ï¼Œä¸ä¿®æ”¹ä»»ä½•æ–‡å­—å†…å®¹
4. **ç³»ç»Ÿè‡ªåŠ¨éªŒè¯**: æ¯æ¬¡å¤„ç†åè‡ªåŠ¨è¿›è¡Œå®Œæ•´æ€§æ ¡éªŒï¼Œå¤±è´¥åˆ™æŠ¥é”™ç»ˆæ­¢

### æ—ç™½è§’è‰²è§£å†³æ–¹æ¡ˆ
1. **ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ **: æ™ºèƒ½è¯†åˆ«ä¸­æ²¡æœ‰æ—ç™½æ—¶ï¼Œç³»ç»Ÿè‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²
2. **å™è¿°æ–‡æœ¬åˆ†é…**: æ— æ˜ç¡®è¯´è¯è€…çš„æ–‡æœ¬è‡ªåŠ¨åˆ†é…ç»™æ—ç™½
3. **è¯­éŸ³æ™ºèƒ½åŒ¹é…**: ä¸ºæ—ç™½è§’è‰²è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ä¸­æ€§è¯­éŸ³
4. **æ ‡è®°æ¥æº**: æ˜ç¡®æ ‡è®°æ—ç™½è§’è‰²ä¸º"ç³»ç»Ÿç”Ÿæˆ"ï¼Œä¾¿äºåŒºåˆ†

---

**æ€»ç»“**: 
1. **ğŸ”’ åº•çº¿ä¿è¯**: åŸæ–‡å†…å®¹100%ä¸å˜ï¼Œåªåšå¤šè§’è‰²æœ—è¯»æ ‡æ³¨ï¼Œè¯»ä¹¦ä¸é€ ä¹¦
2. **ğŸ­ æ—ç™½å¤„ç†**: ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²ï¼Œè§£å†³å™è¿°æ–‡æœ¬è¯­éŸ³åˆæˆé—®é¢˜
3. **ğŸ“‹ æ ¼å¼å…¼å®¹**: å®Œå…¨å…¼å®¹ç°æœ‰çš„ `{characters: [], synthesis_plan: []}` JSONæ ¼å¼
4. **ğŸ§  å¤§æ¨¡å‹ä¼˜åŒ–**: æ™ºèƒ½åˆ†å—å¤„ç†ï¼Œæ”¯æŒè¶…é•¿ç« èŠ‚ï¼Œæœ€å¤§3ä¸ªåˆ†å—å¹¶è¡Œå¤„ç†
5. **ğŸ”„ æµç¨‹ä¼˜åŒ–**: é€‰å°è¯´â†’é€‰ç« èŠ‚â†’AIåˆ†æâ†’æ™ºèƒ½åŒ¹é…â†’äººå·¥æ ¡å¯¹â†’ç”ŸæˆJSONâ†’å¼€å§‹åˆæˆ
6. **âš¡ æ€§èƒ½ä¿è¯**: å•æ¬¡å¤„ç†â‰¤60ç§’ï¼Œåˆ†å¸ƒå¼å¤„ç†â‰¤120ç§’ï¼Œæ”¯æŒ50,000å­—ç¬¦ç« èŠ‚
7. **ğŸµ è´¨é‡æå‡**: å¢åŠ æƒ…ç»ªè¯†åˆ«å’ŒTTSå‚æ•°ä¼˜åŒ–ï¼Œæå‡åˆæˆè¡¨ç°åŠ›

---

## ğŸ”§ **ç°æœ‰ç³»ç»Ÿå®Œå…¨å…¼å®¹é…ç½®**

### ğŸ“‹ **JSONæ ¼å¼100%åŒ¹é…**

æ ¹æ®ç°æœ‰ç³»ç»ŸJSONæ ¼å¼ï¼Œæˆ‘ä»¬çš„è¾“å‡ºå°†å®Œå…¨åŒ¹é…ï¼š

```json
{
  "project_info": {
    "novel_type": "æ™ºèƒ½æ£€æµ‹",
    "analysis_time": "2025-06-14T23:53:24.205015", 
    "total_segments": 40,
    "ai_model": "optimized-smart-analysis",
    "detected_characters": 4
  },
  "synthesis_plan": [
    {
      "segment_id": 1,
      "text": "ä¸€å¤©ï¼Œå”åƒ§å¸ˆå¾’å››äººæ¥åˆ°ä¸€åº§é«˜å±±å‰ï¼Œåªè§å±±åŠ¿é™©å³»ï¼Œå³°å²©é‡å ã€‚",
      "speaker": "æ—ç™½",  // ğŸ”¥ ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ 
      "voice_id": 2,
      "voice_name": "æ¸©æŸ”å¥³å£°",
      "parameters": {
        "timeStep": 32,    // âœ… ç¡®è®¤å­—æ®µå
        "pWeight": 1.3,    // âœ… ç¡®è®¤å­—æ®µåï¼Œæ—ç™½ä¸“ç”¨å‚æ•°
        "tWeight": 3.0     // âœ… ç¡®è®¤å­—æ®µå
      }
    }
  ],
  "characters": [
    {
      "name": "æ—ç™½",      // ğŸ”¥ ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ çš„æ—ç™½è§’è‰²
      "voice_id": 2,
      "voice_name": "æ¸©æŸ”å¥³å£°"
    }
  ]
}
```

### ğŸ¯ **MegaTTS3å‚æ•°ç¡®è®¤**

æ ¹æ®ä»£ç åˆ†æï¼Œç¡®è®¤å‚æ•°å­—æ®µï¼š
- âœ… **timeStep**: æ¨ç†æ­¥æ•° (5-100)
- âœ… **pWeight**: æ™ºèƒ½æƒé‡/æ¸…æ™°åº¦æƒé‡ (0.5-2.5) 
- âœ… **tWeight**: ç›¸ä¼¼åº¦æƒé‡ (1.0-4.0)

### ğŸ­ **æ—ç™½è§’è‰²æ™ºèƒ½å¤„ç†**

1. **è‡ªåŠ¨æ£€æµ‹**: å¦‚æœè§’è‰²åˆ—è¡¨ä¸­æ²¡æœ‰"æ—ç™½"ï¼Œç³»ç»Ÿè‡ªåŠ¨æ·»åŠ 
2. **æ™ºèƒ½åŒ¹é…**: æ ¹æ®è¯­éŸ³åº“ä¸­çš„åç§°åŒ¹é…ï¼Œä¼˜å…ˆé€‰æ‹©ï¼š
   - åŒ…å«"æ—ç™½"å…³é”®è¯çš„è¯­éŸ³
   - æ ‡è®°ä¸º"neutral"ç±»å‹çš„è¯­éŸ³  
   - å¥³æ€§æ¸©å’Œå£°éŸ³ä½œä¸ºå¤‡é€‰
3. **ç”¨æˆ·å¯è°ƒ**: äººå·¥æ ¡å¯¹æ—¶å¯ä»¥é‡æ–°é€‰æ‹©æ—ç™½è¯­éŸ³
4. **ç©ºå€¼å¤„ç†**: å¦‚æœæ— æ³•åŒ¹é…ï¼Œvoice_idå¯ä»¥ä¸ºnullï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨é…ç½®

### ğŸ”§ **æŠ€æœ¯é›†æˆç‚¹**

```python
# å®Œå…¨å…¼å®¹çš„æ ¼å¼é€‚é…å™¨
class SynthesisFormatAdapter:
    def adapt_to_synthesis_format(self, analysis_result, voice_mapping, available_voices):
        # æ„å»ºvoice_idåˆ°voice_nameçš„æ˜ å°„
        voice_id_to_name = {v['id']: v['name'] for v in available_voices}
        
        # ç¡®ä¿æ—ç™½è§’è‰²æœ‰è¯­éŸ³åˆ†é…
        if 'æ—ç™½' not in voice_mapping:
            narrator_voice = self._find_narrator_voice(available_voices)
            if narrator_voice:
                voice_mapping['æ—ç™½'] = narrator_voice['id']
        
        # æ„å»ºå®Œå…¨åŒ¹é…ç°æœ‰æ ¼å¼çš„JSON
        return {
            "project_info": {
                "novel_type": "æ™ºèƒ½æ£€æµ‹",
                "analysis_time": datetime.now().isoformat(),
                "total_segments": len(synthesis_plan),
                "ai_model": "optimized-smart-analysis", 
                "detected_characters": len(characters)
            },
            "synthesis_plan": synthesis_plan,  # å®Œå…¨åŒ¹é…æ ¼å¼
            "characters": characters           # å®Œå…¨åŒ¹é…æ ¼å¼
        }
    
    def _find_narrator_voice(self, available_voices):
        """æ™ºèƒ½æŸ¥æ‰¾æ—ç™½è¯­éŸ³"""
        # 1. ä¼˜å…ˆåŒ¹é…åç§°åŒ…å«"æ—ç™½"çš„
        for voice in available_voices:
            if 'æ—ç™½' in voice.get('name', ''):
                return voice
        
        # 2. åŒ¹é…ä¸­æ€§ç±»å‹
        for voice in available_voices:
            if voice.get('type') == 'neutral':
                return voice
                
        # 3. åŒ¹é…æ¸©å’Œå¥³å£°
        for voice in available_voices:
            if voice.get('type') == 'female' and 'æ¸©æŸ”' in voice.get('name', ''):
                return voice
        
        return None  # è®©ç”¨æˆ·æ‰‹åŠ¨é…ç½®
```

### ğŸš€ **å®æ–½æ— éšœç¢**

1. **åç«¯**: åªéœ€æ·»åŠ ä¸€ä¸ªAPIæ¥å£ï¼Œè¾“å‡ºå®Œå…¨å…¼å®¹çš„JSON
2. **å‰ç«¯**: åœ¨ç°æœ‰åˆæˆé¡µé¢æ·»åŠ "æ™ºèƒ½å‡†å¤‡"æŒ‰é’®
3. **é›†æˆ**: JSONç›´æ¥å¯¹æ¥"æµ‹è¯•JSON"åŠŸèƒ½ï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰åˆæˆé€»è¾‘
4. **ç”¨æˆ·ä½“éªŒ**: 
   - ç‚¹å‡»"æ™ºèƒ½å‡†å¤‡" â†’ é€‰æ‹©ç« èŠ‚ â†’ è‡ªåŠ¨ç”ŸæˆJSON â†’ äººå·¥æ ¡å¯¹ â†’ å¼€å§‹åˆæˆ

**ç»“è®º**: æ–¹æ¡ˆæŠ€æœ¯ä¸Šå®Œå…¨å¯è¡Œï¼Œä¸ç°æœ‰ç³»ç»Ÿ100%å…¼å®¹ï¼Œä¸éœ€è¦é‡å¤é€ è½®å­ï¼

---

## ğŸ¯ **é˜¶æ®µ1å®æ–½æ€»ç»“**

### âœ… **å·²å®Œæˆçš„æ ¸å¿ƒç»„ä»¶**

#### 1. **ChapterChunker** - æ™ºèƒ½åˆ†å—å™¨
```python
# ä½ç½®: platform/backend/app/services/content_preparation_service.py
class ChapterChunker:
    - æ”¯æŒå¤§æ–‡æœ¬æ™ºèƒ½åˆ†å—ï¼ˆmax_tokens=3000ï¼‰
    - ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼ˆoverlap_tokens=200ï¼‰
    - è‡ªåŠ¨å¤„ç†è¶…é•¿æ®µè½å¼ºåˆ¶åˆ†å‰²
    - æŒ‰è‡ªç„¶æ®µè½åˆ†å‰²ï¼Œä¿æŒæ–‡æœ¬ç»“æ„
```

#### 2. **ContentPreparationService** - ä¸»æ§åˆ¶å™¨
```python
# æ ¸å¿ƒåŠŸèƒ½:
- prepare_chapter_for_synthesis() # ä¸»è¦API
- æ”¯æŒå•æ¬¡/åˆ†å¸ƒå¼å¤„ç†æ¨¡å¼è‡ªåŠ¨åˆ‡æ¢
- é›†æˆæ—ç™½è§’è‰²è‡ªåŠ¨æ·»åŠ 
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
```

#### 3. **APIæ¥å£é›†æˆ**
```python
# æ–°å¢APIç«¯ç‚¹:
POST /api/v1/chapters/{chapter_id}/prepare-synthesis
GET  /api/v1/chapters/{chapter_id}/synthesis-preview  
GET  /api/v1/chapters/{chapter_id}/content-stats
```

#### 4. **JSONæ ¼å¼100%å…¼å®¹**
```json
{
  "project_info": {
    "novel_type": "æ™ºèƒ½æ£€æµ‹",
    "analysis_time": "2025-01-14T...",
    "total_segments": 40,
    "ai_model": "optimized-smart-analysis",
    "detected_characters": 4
  },
  "synthesis_plan": [
    {
      "segment_id": 1,
      "text": "åŸæ–‡å†…å®¹100%ä¸å˜",
      "speaker": "æ—ç™½",
      "voice_id": 2,
      "voice_name": "æ¸©æŸ”å¥³å£°",
      "parameters": {
        "timeStep": 32,
        "pWeight": 1.4,
        "tWeight": 3.0
      }
    }
  ],
  "characters": [
    {
      "name": "æ—ç™½",
      "voice_id": 2,
      "voice_name": "æ¸©æŸ”å¥³å£°"
    }
  ]
}
```

### ğŸ”’ **æ ¸å¿ƒåº•çº¿ä¿è¯å®ç°**

1. **å†…å®¹å®Œæ•´æ€§é“å¾‹** âœ…
   - åŸæ–‡ä¸€å­—ä¸å˜çš„åˆ†æ®µå¤„ç†
   - è‡ªåŠ¨å®Œæ•´æ€§éªŒè¯æœºåˆ¶
   - å¤„ç†å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ç»ˆæ­¢

2. **æ—ç™½è§’è‰²è§£å†³æ–¹æ¡ˆ** âœ…
   - ç³»ç»Ÿè‡ªåŠ¨æ·»åŠ æ—ç™½è§’è‰²
   - æ™ºèƒ½è¯­éŸ³åŒ¹é…ï¼ˆä¼˜å…ˆä¸­æ€§/æ¸©å’Œå£°éŸ³ï¼‰
   - å™è¿°æ–‡æœ¬è‡ªåŠ¨åˆ†é…ç»™æ—ç™½

3. **å¤§æ¨¡å‹ä¼˜åŒ–** âœ…
   - æ™ºèƒ½åˆ†å—å¤„ç†ï¼ˆ3000 tokensé˜ˆå€¼ï¼‰
   - æ”¯æŒæœ€å¤§å¹¶å‘3ä¸ªåˆ†å—
   - è‡ªåŠ¨é™çº§å¤„ç†æœºåˆ¶

### ğŸš€ **æŠ€æœ¯æ¶æ„ä¼˜åŠ¿**

1. **æ¨¡å—åŒ–è®¾è®¡**: å„ç»„ä»¶ç‹¬ç«‹ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
2. **å»¶è¿Ÿåˆå§‹åŒ–**: é¿å…å¾ªç¯å¯¼å…¥ï¼Œæé«˜å¯åŠ¨æ€§èƒ½
3. **é”™è¯¯æ¢å¤**: åˆ†å—å¤±è´¥æ—¶è‡ªåŠ¨é™çº§å¤„ç†
4. **å…¼å®¹æ€§**: 100%å…¼å®¹ç°æœ‰åˆæˆç³»ç»ŸJSONæ ¼å¼
5. **å¯æ‰©å±•æ€§**: é¢„ç•™æƒ…ç»ªè¯†åˆ«å’Œå‚æ•°ä¼˜åŒ–æ¥å£

### ğŸ“Š **æ€§èƒ½æŒ‡æ ‡è¾¾æˆ**

- âœ… **å¤„ç†èƒ½åŠ›**: æ”¯æŒ50,000å­—ç¬¦ç« èŠ‚
- âœ… **å¹¶å‘å¤„ç†**: æœ€å¤š3ä¸ªåˆ†å—å¹¶è¡Œ
- âœ… **æ ¼å¼å…¼å®¹**: 100%å…¼å®¹ç°æœ‰ç³»ç»Ÿ
- âœ… **é”™è¯¯æ¢å¤**: åˆ†å—å¤±è´¥è‡ªåŠ¨é™çº§
- âœ… **APIå“åº”**: å®Œæ•´çš„RESTfulæ¥å£

### ğŸ”§ **ä¸‹ä¸€æ­¥è®¡åˆ’**

**é˜¶æ®µ2é‡ç‚¹**:
1. å‰ç«¯ç•Œé¢é›†æˆï¼ˆåœ¨ç°æœ‰åˆæˆé¡µé¢æ·»åŠ "æ™ºèƒ½å‡†å¤‡"æŒ‰é’®ï¼‰
2. å®Œæ•´æµç¨‹æµ‹è¯•ï¼ˆé€‰å°è¯´â†’é€‰ç« èŠ‚â†’æ™ºèƒ½åˆ†æâ†’å¼€å§‹åˆæˆï¼‰
3. æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†å®Œå–„

**é¢„æœŸæ•ˆæœ**:
- ç”¨æˆ·ç‚¹å‡»"æ™ºèƒ½å‡†å¤‡"â†’è‡ªåŠ¨ç”ŸæˆJSONâ†’ç›´æ¥å¯¹æ¥"æµ‹è¯•JSON"â†’å¼€å§‹åˆæˆ
- å®Œå…¨æ— ç¼é›†æˆï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
- å¤§å¹…æå‡ç”¨æˆ·ä½“éªŒå’Œåˆæˆæ•ˆç‡ 