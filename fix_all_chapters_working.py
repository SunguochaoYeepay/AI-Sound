import sys
import os
sys.path.append('platform/backend')

try:
    from app.database import SessionLocal
    from app.models import Book, BookChapter, AnalysisResult
    from app.services.chapter_analysis_service import ChapterAnalysisService
    import json
    import re
    print("âœ… å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def fix_character_detection():
    """ä¿®å¤è§’è‰²è¯†åˆ«é€»è¾‘"""
    db = SessionLocal()
    try:
        print("ğŸ” æŸ¥æ‰¾ç¬¬2ç« ...")
        # è·å–ç¬¬2ç« ï¼ˆæœ‰åˆ†æç»“æœçš„é‚£ä¸€ç« ï¼‰
        chapter = db.query(BookChapter).filter(
            BookChapter.book_id == 9, 
            BookChapter.chapter_number == 2
        ).first()
        
        if not chapter:
            print("âŒ æœªæ‰¾åˆ°ç¬¬2ç« ")
            return
            
        print(f"âœ… æ‰¾åˆ°ç¬¬{chapter.chapter_number}ç« : {chapter.chapter_title}")
        
        # ä»ç« èŠ‚å†…å®¹é‡æ–°åˆ†æè§’è‰²
        content = chapter.content
        if not content:
            print("âŒ ç« èŠ‚å†…å®¹ä¸ºç©º")
            return
            
        print(f"ğŸ“„ ç« èŠ‚å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        
        # é‡æ–°åˆ†æè§’è‰²å’Œåˆ†æ®µ
        print("ğŸ”§ é‡æ–°åˆ†æè§’è‰²...")
        characters = extract_characters_from_text(content)
        
        print("ğŸ”§ é‡æ–°åˆ†æ®µ...")
        segments = segment_text_with_speakers(content, characters)
        
        print(f"\n=== âœ¨ é‡æ–°è¯†åˆ«çš„è§’è‰² ({len(characters)}ä¸ª) ===")
        for char in characters:
            print(f"- {char['name']} (æ€§åˆ«: {char['gender']}, é¢‘æ¬¡: {char['frequency']}, ä¸»è§’: {char['is_main_character']})")
        
        print(f"\n=== ğŸ“ é‡æ–°åˆ†æ®µç»“æœ (å‰10æ®µï¼Œå…±{len(segments)}æ®µ) ===")
        for i, seg in enumerate(segments[:10]):
            text = seg['text'][:50] + '...' if len(seg['text']) > 50 else seg['text']
            print(f"{i+1}. [{seg['speaker']}]: {text}")
        
        # æ„å»ºæ–°çš„åˆ†æç»“æœ
        new_analysis = {
            'detected_characters': characters,
            'segments': segments,
            'processing_stats': {
                'total_segments': len(segments),
                'characters_found': len(characters),
                'processing_method': 'manual_fix',
                'confidence': 0.9
            }
        }
        
        print("ğŸ’¾ æ›´æ–°æ•°æ®åº“...")
        # æ›´æ–°æ•°æ®åº“ä¸­çš„åˆ†æç»“æœ
        analysis_result = db.query(AnalysisResult).filter(
            AnalysisResult.chapter_id == chapter.id
        ).first()
        
        if analysis_result:
            analysis_result.result_data = json.dumps(new_analysis, ensure_ascii=False)
            analysis_result.confidence_score = 0.9
            db.commit()
            print(f"âœ… å·²æ›´æ–°ç« èŠ‚ {chapter.id} çš„åˆ†æç»“æœ")
        else:
            print("âŒ æœªæ‰¾åˆ°åˆ†æç»“æœè®°å½•")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
    finally:
        db.close()

def extract_characters_from_text(content):
    """ä»æ–‡æœ¬ä¸­æå–è§’è‰²"""
    characters = {}
    
    # è¥¿æ¸¸è®°å¸¸è§è§’è‰²æ¨¡å¼
    character_patterns = [
        r'(å­™æ‚Ÿç©º|æ‚Ÿç©º|å¤§åœ£|çŒ´ç‹|è¡Œè€…)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(å”åƒ§|ä¸‰è—|å¸ˆçˆ¶|é•¿è€)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(çŒªå…«æˆ’|å…«æˆ’|å‘†å­)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(æ²™åƒ§|æ²™å’Œå°š|æ²™å¸ˆå¼Ÿ)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(ç™½éª¨ç²¾|å¦–ç²¾|å¥³å¦–)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(è§‚éŸ³|è©è¨)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(å¦‚æ¥|ä½›ç¥–)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(ç‰å¸|å¤©å¸|çš‡å¸)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)',
        r'(è€å›|å¤ªä¸Šè€å›)(?=[è¯´é“ï¼šï¼Œã€‚ï¼ï¼Ÿ]|$)'
    ]
    
    # ç»Ÿè®¡è§’è‰²å‡ºç°é¢‘æ¬¡
    for pattern in character_patterns:
        matches = re.findall(pattern, content)
        for match in matches:
            name = normalize_character_name(match)
            if name not in characters:
                characters[name] = {
                    'name': name,
                    'frequency': 0,
                    'gender': infer_gender(name),
                    'is_main_character': is_main_character(name)
                }
            characters[name]['frequency'] += 1
    
    # æ·»åŠ æ—ç™½è§’è‰²
    characters['æ—ç™½'] = {
        'name': 'æ—ç™½',
        'frequency': 50,  # æ—ç™½é¢‘æ¬¡è¾ƒé«˜
        'gender': 'neutral',
        'is_main_character': False
    }
    
    return list(characters.values())

def normalize_character_name(name):
    """æ ‡å‡†åŒ–è§’è‰²åç§°"""
    name_mapping = {
        'æ‚Ÿç©º': 'å­™æ‚Ÿç©º',
        'å¤§åœ£': 'å­™æ‚Ÿç©º', 
        'çŒ´ç‹': 'å­™æ‚Ÿç©º',
        'è¡Œè€…': 'å­™æ‚Ÿç©º',
        'ä¸‰è—': 'å”åƒ§',
        'å¸ˆçˆ¶': 'å”åƒ§',
        'é•¿è€': 'å”åƒ§',
        'å‘†å­': 'çŒªå…«æˆ’',
        'æ²™å¸ˆå¼Ÿ': 'æ²™åƒ§',
        'æ²™å’Œå°š': 'æ²™åƒ§',
        'å¦–ç²¾': 'ç™½éª¨ç²¾',
        'å¥³å¦–': 'ç™½éª¨ç²¾',
        'è©è¨': 'è§‚éŸ³',
        'ä½›ç¥–': 'å¦‚æ¥',
        'å¤©å¸': 'ç‰å¸',
        'çš‡å¸': 'ç‰å¸',
        'å¤ªä¸Šè€å›': 'è€å›'
    }
    return name_mapping.get(name, name)

def infer_gender(name):
    """æ¨æ–­è§’è‰²æ€§åˆ«"""
    male_chars = ['å­™æ‚Ÿç©º', 'å”åƒ§', 'çŒªå…«æˆ’', 'æ²™åƒ§', 'å¦‚æ¥', 'ç‰å¸', 'è€å›']
    female_chars = ['ç™½éª¨ç²¾', 'è§‚éŸ³']
    
    if name in male_chars:
        return 'male'
    elif name in female_chars:
        return 'female'
    else:
        return 'unknown'

def is_main_character(name):
    """åˆ¤æ–­æ˜¯å¦ä¸ºä¸»è¦è§’è‰²"""
    main_chars = ['å­™æ‚Ÿç©º', 'å”åƒ§', 'çŒªå…«æˆ’', 'æ²™åƒ§']
    return name in main_chars

def segment_text_with_speakers(content, characters):
    """é‡æ–°åˆ†æ®µå¹¶åˆ†é…è¯´è¯äºº"""
    segments = []
    
    # æŒ‰æ ‡ç‚¹åˆ†å‰²æ–‡æœ¬
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
    char_names = [char['name'] for char in characters if char['name'] != 'æ—ç™½']
    
    for i, sentence in enumerate(sentences):
        if not sentence.strip():
            continue
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯¹è¯
        speaker = 'æ—ç™½'  # é»˜è®¤ä¸ºæ—ç™½
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è§’è‰²è¯´è¯çš„æ¨¡å¼
        for char_name in char_names:
            if char_name in sentence:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹è¯è€Œä¸æ˜¯æè¿°
                if 'ï¼š' in sentence and '"' in sentence:
                    # è¿™æ˜¯å¯¹è¯ï¼Œä½†éœ€è¦åˆ†ç¦»æè¿°å’Œå¯¹è¯å†…å®¹
                    if sentence.find(char_name) < sentence.find('ï¼š'):
                        # è§’è‰²ååœ¨å†’å·å‰ï¼Œè¿™æ˜¯æè¿°æ€§æ–‡å­—ï¼Œåº”è¯¥æ˜¯æ—ç™½
                        speaker = 'æ—ç™½'
                    else:
                        speaker = char_name
                elif '"' in sentence:
                    # åŒ…å«å¼•å·ï¼Œå¯èƒ½æ˜¯å¯¹è¯
                    speaker = char_name
                # å¦‚æœåªæ˜¯æåˆ°è§’è‰²åä½†æ²¡æœ‰å¯¹è¯æ ‡è¯†ï¼Œä¿æŒä¸ºæ—ç™½
        
        segment = {
            'text': sentence.strip() + 'ã€‚',
            'speaker': speaker,
            'text_type': 'dialogue' if speaker != 'æ—ç™½' else 'narration',
            'confidence': 0.8
        }
        segments.append(segment)
    
    return segments

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ä¿®å¤è§’è‰²è¯†åˆ«...")
    fix_character_detection()
    print("ğŸ‰ ä¿®å¤å®Œæˆ!") 